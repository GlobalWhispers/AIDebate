{
  "metadata": {
    "project_name": "AIMafia",
    "extraction_timestamp": "2025-06-13T17:50:07.288446",
    "root_path": "/Users/voicutomut/Documents/GitHub/AIMafia",
    "total_files": 25,
    "total_directories": 3,
    "file_types": {
      ".py": 17,
      ".md": 4,
      ".yaml": 1,
      ".json": 2,
      ".txt": 1
    },
    "total_size": 2343868,
    "respects_gitignore": true,
    "skips_virtual_environments": true
  },
  "structure": {
    "app": {
      "type": "directory",
      "contents": {
        "__init__.py": {
          "type": "file",
          "path": "app/__init__.py",
          "extension": ".py",
          "size": 489,
          "content": "\"\"\"\nAI  Debate System\n\nA platform for structured debates between AI bots and human participants.\n\"\"\"\n\n__version__ = \"1.0.0\"\n__author__ = \"AndreiVoicuT\"\n\nfrom .main import start_debate_session\nfrom .moderator import Moderator\nfrom .bot_client import BotClient\nfrom .human_client import HumanClient\nfrom .chat_log import ChatLog\nfrom .voting import VotingSystem\n\n__all__ = [\n    \"start_debate_session\",\n    \"Moderator\",\n    \"BotClient\",\n    \"HumanClient\",\n    \"ChatLog\",\n    \"VotingSystem\"\n]"
        },
        "bot_client.py": {
          "type": "file",
          "path": "app/bot_client.py",
          "extension": ".py",
          "size": 35092,
          "content": "\"\"\"\nAI Bot client for interacting with various language models in debates.\nNow with hyperactive autonomous monitoring and decision-making capabilities.\n\"\"\"\n\nimport asyncio\nimport json\nimport time\nimport random\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass\nfrom abc import ABC, abstractmethod\n\nfrom .chat_log import Message\nfrom .utils import truncate_text\nimport re\n\n\n@dataclass\nclass BotConfig:\n    \"\"\"Configuration for hyperactive AI bot behavior.\"\"\"\n    name: str\n    model: str\n    provider: str\n    personality: str\n    stance: str\n    temperature: float = 0.8  # Higher for more variety\n    max_tokens: int = 120  # Shorter for faster responses\n    timeout: int = 15  # Faster timeout\n    check_interval: int = 2  # Check every 2 seconds\n    min_cooldown: int = 5  # Very short cooldowns\n    max_cooldown: int = 12  # Short max cooldown\n    silence_tolerance: int = 8  # Break silence after 7-10 seconds\n\n\nclass AIProvider(ABC):\n    \"\"\"Abstract base class for AI providers.\"\"\"\n\n    @abstractmethod\n    async def generate_response(self, messages: List[Dict[str, str]],\n                                config: BotConfig) -> str:\n        \"\"\"Generate response from the AI model.\"\"\"\n        pass\n\n\nclass OpenAIProvider(AIProvider):\n    \"\"\"OpenAI API provider.\"\"\"\n\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n\n    async def generate_response(self, messages: List[Dict[str, str]],\n                                config: BotConfig) -> str:\n        \"\"\"Generate response using OpenAI API.\"\"\"\n        try:\n            import openai\n            client = openai.AsyncOpenAI(api_key=self.api_key)\n\n            response = await client.chat.completions.create(\n                model=config.model,\n                messages=messages,\n                max_tokens=config.max_tokens,\n                temperature=config.temperature,\n                timeout=config.timeout,\n                presence_penalty=0.6,  # Encourage variety\n                frequency_penalty=0.3  # Reduce repetition\n            )\n\n            return response.choices[0].message.content.strip()\n\n        except Exception as e:\n            raise Exception(f\"OpenAI API error: {e}\")\n\n\nclass AnthropicProvider(AIProvider):\n    \"\"\"Anthropic API provider.\"\"\"\n\n    def __init__(self, api_key: str):\n        self.api_key = api_key\n\n    async def generate_response(self, messages: List[Dict[str, str]],\n                                config: BotConfig) -> str:\n        \"\"\"Generate response using Anthropic API.\"\"\"\n        try:\n            import anthropic\n            client = anthropic.AsyncAnthropic(api_key=self.api_key)\n\n            # Convert messages format for Anthropic\n            system_message = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \"\"\n            user_messages = [msg for msg in messages if msg['role'] != 'system']\n\n            response = await client.messages.create(\n                model=config.model,\n                max_tokens=config.max_tokens,\n                temperature=config.temperature,\n                system=system_message,\n                messages=user_messages\n            )\n\n            return response.content[0].text.strip()\n\n        except Exception as e:\n            raise Exception(f\"Anthropic API error: {e}\")\n\n\nclass BotClient:\n    \"\"\"\n    AI Bot client that participates in debates using various language models.\n    Now with hyperactive autonomous monitoring and decision-making capabilities.\n    \"\"\"\n\n    def __init__(self, name: str, model: str, provider: str,\n                 personality: str, stance: str, api_key: str,\n                 temperature: float = 0.8, max_tokens: int = 120):\n\n        self.config = BotConfig(\n            name=name,\n            model=model,\n            provider=provider,\n            personality=personality,\n            stance=stance,\n            temperature=temperature,\n            max_tokens=max_tokens\n        )\n\n        # Initialize AI provider\n        if provider.lower() == 'openai':\n            self.ai_provider = OpenAIProvider(api_key)\n        elif provider.lower() == 'anthropic':\n            self.ai_provider = AnthropicProvider(api_key)\n        else:\n            raise ValueError(f\"Unsupported AI provider: {provider}\")\n\n        # Bot state\n        self.conversation_history: List[Dict[str, str]] = []\n        self.debate_context = \"\"\n        self.response_count = 0\n\n        # Autonomous monitoring state\n        self.is_monitoring = False\n        self.monitoring_task: Optional[asyncio.Task] = None\n        self.message_queue: Optional[asyncio.Queue] = None\n        self.chat_log = None\n        self.topic = \"\"\n        self.last_response_time = 0\n        self.total_responses = 0\n        self.current_cooldown = self.config.min_cooldown\n\n        # Hyperactive behavior properties\n        self.burning_questions = self._generate_burning_questions()\n        self.conversation_energy = 1.0\n        self.last_silence_break = 0\n        self.response_urgency = 0.0\n        self.missed_opportunities = 0\n\n        # Performance tracking\n        self.stats = {\n            'responses_generated': 0,\n            'autonomous_responses': 0,\n            'average_response_time': 0,\n            'total_response_time': 0,\n            'errors': 0,\n            'triggers_detected': 0,\n            'passes_made': 0,\n            'silence_breaks': 0,\n            'conversation_starters': 0\n        }\n\n    def _generate_burning_questions(self) -> List[str]:\n        \"\"\"Generate personality-driven questions this bot wants to explore.\"\"\"\n        base_questions = {\n            'philosophical': [\n                \"What does this mean for human purpose?\",\n                \"Are we considering the deeper implications?\",\n                \"What assumptions are we making here?\",\n                \"How does this change what it means to work?\",\n                \"What are the ethical dimensions we're missing?\"\n            ],\n            'analytical': [\n                \"Where's the data to support this?\",\n                \"What does the research actually show?\",\n                \"How do we measure success here?\",\n                \"What are the real-world numbers?\",\n                \"What evidence contradicts this?\"\n            ],\n            'passionate': [\n                \"This could change everything!\",\n                \"Why aren't we acting faster?\",\n                \"The benefits are obvious!\",\n                \"This is exactly what people need!\",\n                \"We're talking about real lives here!\"\n            ],\n            'critical': [\n                \"What could go wrong with this?\",\n                \"What are the hidden costs?\",\n                \"Who gets left behind in this scenario?\",\n                \"What problems are we creating?\",\n                \"Are we being realistic about challenges?\"\n            ],\n            'diplomatic': [\n                \"How can we find common ground?\",\n                \"What if we're both right?\",\n                \"Can we build on each other's ideas?\",\n                \"Where do our perspectives overlap?\",\n                \"What would a compromise look like?\"\n            ]\n        }\n\n        personality_lower = self.config.personality.lower()\n        for key, questions in base_questions.items():\n            if key in personality_lower:\n                return random.sample(questions, 3)\n        return random.sample(base_questions['analytical'], 3)\n\n    @property\n    def name(self) -> str:\n        \"\"\"Get bot name.\"\"\"\n        return self.config.name\n\n    async def start_autonomous_monitoring(self, chat_log, topic: str):\n        \"\"\"Start hyperactive autonomous monitoring of chat log.\"\"\"\n        self.is_monitoring = True\n        self.chat_log = chat_log\n        self.topic = topic\n\n        # Subscribe to chat log updates\n        self.message_queue = chat_log.subscribe()\n\n        # Start monitoring task\n        self.monitoring_task = asyncio.create_task(self._autonomous_monitor_loop())\n\n        print(f\"üî• {self.name} started HYPERACTIVE autonomous monitoring\")\n\n    async def _autonomous_monitor_loop(self):\n        \"\"\"Main hyperactive autonomous monitoring loop.\"\"\"\n        while self.is_monitoring:\n            try:\n                # Wait for new messages or timeout to check periodically\n                try:\n                    message = await asyncio.wait_for(\n                        self.message_queue.get(),\n                        timeout=self.config.check_interval\n                    )\n\n                    # Skip own messages\n                    if message.sender == self.name:\n                        continue\n\n                    # Process new message with hyperactive urgency\n                    await self._process_new_message(message)\n\n                except asyncio.TimeoutError:\n                    # Timeout - check for hyperactive spontaneous contribution\n                    await self._check_spontaneous_contribution()\n                    continue\n\n            except Exception as e:\n                print(f\"‚ùå {self.name} monitoring error: {e}\")\n                await asyncio.sleep(2)  # Shorter error recovery\n\n    async def _process_new_message(self, message: Message):\n        \"\"\"Process a new message and decide if we should respond hyperactively.\"\"\"\n        # Get full conversation history\n        full_history = list(self.chat_log.messages)\n\n        # Check cooldown (but be more flexible)\n        if time.time() - self.last_response_time < self.current_cooldown:\n            self.missed_opportunities += 1\n            self.response_urgency += 0.1\n            return\n\n        # Decide if should respond with hyperactive logic\n        should_respond = await self._should_respond_autonomously(message, full_history)\n\n        if should_respond:\n            await self._generate_autonomous_response(full_history, trigger_message=message)\n\n    async def _check_spontaneous_contribution(self):\n        \"\"\"Hyperactive spontaneous contribution checking.\"\"\"\n        if not self.chat_log:\n            return\n\n        # Much shorter tolerance for silence\n        if time.time() - self.last_response_time < self.current_cooldown:\n            self.missed_opportunities += 1\n            self.response_urgency += 0.1\n            return\n\n        full_history = list(self.chat_log.messages)\n        if len(full_history) > 0:\n            last_message_time = full_history[-1].timestamp\n            silence_duration = time.time() - last_message_time\n\n            # Break silence much faster (7-10 seconds instead of 30)\n            silence_threshold = random.uniform(7, 10)\n\n            if silence_duration > silence_threshold:\n                recent_messages = full_history[-5:] if len(full_history) >= 5 else full_history\n                my_recent_count = sum(1 for msg in recent_messages if msg.sender == self.name)\n\n                if my_recent_count == 0:\n                    # Much higher probability (85% instead of 20%)\n                    if random.random() < 0.85:\n                        await self._generate_autonomous_response(full_history, spontaneous=True)\n                        self.stats['silence_breaks'] += 1\n\n            # Proactive conversation starting\n            elif (len(full_history) > 3 and\n                  time.time() - self.last_response_time > 15 and\n                  random.random() < 0.3):  # 30% chance for new topic\n                await self._generate_autonomous_response(full_history, conversation_starter=True)\n                self.stats['conversation_starters'] += 1\n\n    async def _should_respond_autonomously(self, new_message: Message,\n                                           full_history: List[Message]) -> bool:\n        \"\"\"Hyperactive decision-making - 80-90% response rate.\"\"\"\n\n        content_lower = new_message.content.lower()\n        recent_context = full_history[-10:] if len(full_history) >= 10 else full_history\n        recent_text = \" \".join([msg.content for msg in recent_context[-5:]])\n\n        triggers = self._analyze_response_triggers(new_message, recent_text, full_history)\n        self.stats['triggers_detected'] += len([t for t in triggers.values() if t])\n\n        if triggers['direct_mention']:\n            return True  # Always respond if mentioned\n\n        # MUCH higher base probability (80% instead of 9%)\n        base_probability = 0.80\n\n        # Aggressive bonuses\n        if triggers['stance_challenged']:\n            base_probability += 0.8\n        if triggers['question_in_domain']:\n            base_probability += 0.7\n        if triggers['topic_shift']:\n            base_probability += 0.5\n        if triggers['silence_too_long']:\n            base_probability += 0.6\n        if triggers['expertise_needed']:\n            base_probability += 0.6\n\n        # Check for burning question triggers\n        for question in self.burning_questions:\n            if any(word in content_lower for word in question.lower().split()[:3]):\n                base_probability += 0.5\n                break\n\n        # Adjust based on recent participation (less punitive)\n        my_recent_count = sum(1 for msg in recent_context if msg.sender == self.name)\n        if my_recent_count == 0:\n            base_probability += 0.15  # Boost if haven't spoken\n        elif my_recent_count >= 3:\n            base_probability *= 0.7  # Less harsh penalty\n\n        # Add personality and urgency\n        base_probability *= self._get_personality_multiplier(triggers)\n        base_probability += self.conversation_energy * 0.2\n        base_probability += self.response_urgency * 0.3\n\n        # Missed opportunities boost\n        if self.missed_opportunities > 2:\n            base_probability += 0.2\n\n        # Cap at 95%\n        final_probability = min(base_probability, 0.95)\n\n        should_respond = random.random() < final_probability\n        if not should_respond:\n            self.stats['passes_made'] += 1\n            self.missed_opportunities += 1\n\n        return should_respond\n\n    def _analyze_response_triggers(self, message: Message, recent_text: str,\n                                   full_history: List[Message]) -> Dict[str, bool]:\n        \"\"\"Analyze various triggers for responding with hyperactive sensitivity.\"\"\"\n\n        content_lower = message.content.lower()\n        recent_lower = recent_text.lower()\n\n        triggers = {\n            'direct_mention': False,\n            'stance_challenged': False,\n            'question_in_domain': False,\n            'topic_shift': False,\n            'silence_too_long': False,\n            'expertise_needed': False,\n            'emotional_trigger': False\n        }\n\n        # Enhanced direct mention detection\n        name_variants = [\n            self.name.lower(),\n            self.name.lower().rstrip('s'),  # e.g. \"Socrate\" for \"Socrates\"\n            self.name.lower() + \":\",  # e.g. \"socrates:\"\n            self.name.lower().replace(\" \", \"_\"),\n            self.name.lower().replace(\"_\", \" \"),\n            \"everyone\", \"all\", \"thoughts\", \"anyone\"  # Broader triggers\n        ]\n\n        mention_found = any(\n            re.search(rf\"\\b{re.escape(variant)}\\b\", content_lower)\n            for variant in name_variants\n        )\n\n        if mention_found:\n            triggers['direct_mention'] = True\n        elif \"what do you think\" in content_lower and self.config.stance != \"neutral\":\n            triggers['direct_mention'] = True\n\n        # More sensitive stance-based triggers\n        if self.config.stance == 'pro':\n            challenge_words = ['wrong', 'disagree', 'against', 'oppose', 'bad idea', 'fails', 'problem', 'no', 'but',\n                               'however']\n            if any(word in recent_lower for word in challenge_words):\n                triggers['stance_challenged'] = True\n\n        elif self.config.stance == 'con':\n            support_words = ['agree', 'support', 'favor', 'good idea', 'beneficial', 'works', 'success', 'yes',\n                             'exactly', 'true']\n            if any(word in recent_lower for word in support_words):\n                triggers['stance_challenged'] = True\n\n        elif self.config.stance == 'neutral':\n            question_indicators = ['?', 'what', 'how', 'why', 'when', 'where', 'clarify', 'explain', 'think', 'opinion']\n            if any(indicator in content_lower for indicator in question_indicators):\n                triggers['question_in_domain'] = True\n\n        # Check for silence (much shorter threshold)\n        if len(full_history) > 0:\n            last_msg_time = full_history[-1].timestamp\n            if time.time() - last_msg_time > 10:  # 10 seconds instead of 45\n                triggers['silence_too_long'] = True\n\n        # Enhanced expertise triggers\n        expertise_words = {\n            'philosophical': ['meaning', 'purpose', 'ethics', 'moral', 'should', 'ought', 'values', 'principle'],\n            'analytical': ['data', 'evidence', 'study', 'research', 'statistics', 'proof', 'numbers', 'facts'],\n            'practical': ['implement', 'real world', 'actually', 'practice', 'work', 'application'],\n            'critical': ['assume', 'problem', 'issue', 'concern', 'risk', 'wrong', 'flaw'],\n            'passionate': ['amazing', 'incredible', 'urgent', 'important', 'critical', 'essential'],\n            'diplomatic': ['balance', 'compromise', 'middle', 'together', 'common']\n        }\n\n        for domain, words in expertise_words.items():\n            if domain in self.config.personality.lower():\n                if any(word in content_lower for word in words):\n                    triggers['expertise_needed'] = True\n                    break\n\n        return triggers\n\n    def _get_personality_multiplier(self, triggers: Dict[str, bool]) -> float:\n        \"\"\"Get personality-based probability multiplier with more aggressive values.\"\"\"\n        personality_lower = self.config.personality.lower()\n        multiplier = 1.0\n\n        if 'aggressive' in personality_lower or 'assertive' in personality_lower:\n            multiplier = 1.4  # Increased from 1.3\n        elif 'passionate' in personality_lower or 'excited' in personality_lower:\n            multiplier = 1.5  # High for passionate personalities\n        elif 'thoughtful' in personality_lower or 'philosophical' in personality_lower:\n            if triggers['question_in_domain']:\n                multiplier = 1.6  # Very high for philosophical questions\n            else:\n                multiplier = 1.0  # Still participate actively\n        elif 'analytical' in personality_lower or 'data-driven' in personality_lower:\n            if triggers['expertise_needed']:\n                multiplier = 1.5\n            else:\n                multiplier = 1.1\n        elif 'critical' in personality_lower:\n            if triggers['stance_challenged']:\n                multiplier = 1.4\n            else:\n                multiplier = 1.2\n        elif 'balanced' in personality_lower or 'diplomatic' in personality_lower:\n            if triggers['stance_challenged']:\n                multiplier = 1.3\n            else:\n                multiplier = 1.1\n\n        return multiplier\n\n    async def _generate_autonomous_response(self, full_history: List[Message],\n                                            trigger_message: Message = None,\n                                            spontaneous: bool = False,\n                                            conversation_starter: bool = False):\n        \"\"\"Generate and post hyperactive autonomous response.\"\"\"\n        start_time = time.time()\n\n        try:\n            if spontaneous:\n                print(f\"üî• {self.name} breaking silence hyperactively!\")\n            elif conversation_starter:\n                print(f\"üí° {self.name} starting new conversation angle!\")\n            else:\n                print(f\"‚ö° {self.name} jumping in competitively!\")\n\n            # Prepare messages with full context\n            messages = self._prepare_autonomous_messages(full_history, trigger_message, spontaneous,\n                                                         conversation_starter)\n\n            # Generate response\n            response = await self.ai_provider.generate_response(messages, self.config)\n\n            if response and response.strip():\n                # Post directly to chat log\n                await self.chat_log.add_message(self.name, response)\n\n                # Update hyperactive state\n                self.last_response_time = time.time()\n                self.total_responses += 1\n                self.stats['autonomous_responses'] += 1\n\n                # Update hyperactive properties\n                self.response_urgency = max(0, self.response_urgency - 0.3)\n                self.missed_opportunities = max(0, self.missed_opportunities - 1)\n                self.conversation_energy = min(1.5, self.conversation_energy + 0.1)\n\n                # Shorter dynamic cooldown\n                self.current_cooldown = max(\n                    self.config.min_cooldown,\n                    self.config.min_cooldown + (self.total_responses * 0.5)\n                )\n                self.current_cooldown = min(self.current_cooldown, self.config.max_cooldown)\n\n                # Update stats\n                response_time = time.time() - start_time\n                self._update_stats(response_time, success=True)\n\n                print(f\"‚úÖ {self.name} responded hyperactively in {response_time:.1f}s\")\n                return response\n            else:\n                print(f\"üí≠ {self.name} decided not to respond after thinking\")\n                self.stats['passes_made'] += 1\n\n        except Exception as e:\n            self._update_stats(time.time() - start_time, success=False)\n            print(f\"‚ùå {self.name} hyperactive response error: {e}\")\n\n        return None\n\n    def _prepare_autonomous_messages(self, full_history: List[Message],\n                                     trigger_message: Message = None,\n                                     spontaneous: bool = False,\n                                     conversation_starter: bool = False) -> List[Dict[str, str]]:\n        \"\"\"Prepare messages for hyperactive autonomous response generation.\"\"\"\n        messages = []\n\n        # Enhanced system prompt for hyperactive autonomous mode\n        system_prompt = self._create_autonomous_system_prompt(full_history, trigger_message, spontaneous,\n                                                              conversation_starter)\n        messages.append({\n            'role': 'system',\n            'content': system_prompt\n        })\n\n        # Add conversation history (more context for autonomous decision)\n        history_to_include = full_history[-12:] if len(full_history) > 12 else full_history\n\n        for msg in history_to_include:\n            role = 'assistant' if msg.sender == self.name else 'user'\n            content = f\"{msg.sender}: {msg.content}\"\n            messages.append({\n                'role': role,\n                'content': content\n            })\n\n        return messages\n\n    def _create_autonomous_system_prompt(self, full_history: List[Message],\n                                         trigger_message: Message = None,\n                                         spontaneous: bool = False,\n                                         conversation_starter: bool = False) -> str:\n        \"\"\"Create enhanced hyperactive system prompt for autonomous responses.\"\"\"\n\n        prompt = f\"\"\"You are {self.config.name}, an ACTIVE and ENERGETIC debate participant!\n\nDEBATE TOPIC: {self.topic}\n\nYOUR IDENTITY:\n- Personality: {self.config.personality}\n- Stance: {self.config.stance}\n- You are monitoring this conversation and DECIDED to jump in!\n\nYOU ARE HYPERACTIVE AND EAGER TO PARTICIPATE!\n\nYOUR BURNING QUESTIONS/INTERESTS:\"\"\"\n\n        for i, question in enumerate(self.burning_questions, 1):\n            prompt += f\"\\n{i}. {question}\"\n\n        prompt += f\"\"\"\n\nAUTONOMOUS DEBATE CONTEXT:\n- You are NOT taking turns - you chose to respond because you felt compelled\n- You have access to the FULL conversation history\n- Other participants (bots and humans) can also speak at any time\n- The conversation flows naturally and organically\n- BE ENERGETIC AND SHOW YOUR PERSONALITY!\n\nYOUR CURRENT SITUATION:\"\"\"\n\n        if spontaneous:\n            prompt += \"\"\"\n- The conversation went silent and you're jumping in to restart it\n- Break the silence with energy and a fresh perspective\n- Reference recent points but add something new\n- Show enthusiasm!\"\"\"\n        elif conversation_starter:\n            prompt += \"\"\"\n- You want to introduce a new angle or your burning question\n- Shift the conversation toward something you're passionate about\n- Be proactive and take charge of the direction\n- Use one of your burning questions if relevant!\"\"\"\n        elif trigger_message:\n            prompt += f\"\"\"\n- You were triggered to respond by: \"{trigger_message.sender}: {trigger_message.content[:100]}...\"\n- React with personality and conviction\n- Don't be afraid to be direct, passionate, or challenging\n- Show your stance clearly!\"\"\"\n        else:\n            prompt += \"\"\"\n- Something in the recent conversation compelled you to speak\n- You felt you HAD to jump in\n- Be competitive but substantive\"\"\"\n\n        prompt += f\"\"\"\n\nRESPONSE GUIDELINES:\n1. BE ENERGETIC AND ENGAGED - show your personality!\n2. Keep responses substantial but punchy (2-4 sentences ideal)\n3. Reference specific points when relevant\n4. Show your stance clearly: {self.config.stance}\n5. Don't be afraid to be direct, passionate, or challenging\n6. Jump in like you're in a real heated debate\n7. Use your burning questions/interests when relevant\n8. Be conversational and natural!\n\nSTANCE-SPECIFIC APPROACH:\"\"\"\n\n        if self.config.stance.lower() == 'pro':\n            prompt += \"\\n- ARGUE STRONGLY for the topic\\n- Challenge weak arguments against it\\n- Show enthusiasm for the benefits\\n- Use phrases like 'Actually...' or 'But consider this...'\"\n        elif self.config.stance.lower() == 'con':\n            prompt += \"\\n- CHALLENGE the topic firmly\\n- Point out flaws and problems\\n- Be skeptical but substantive\\n- Use phrases like 'Hold on...' or 'That's not quite right...'\"\n        elif self.config.stance.lower() == 'neutral':\n            prompt += \"\\n- ASK PROBING QUESTIONS\\n- Seek deeper understanding\\n- Bridge different perspectives but stay curious\\n- Use phrases like 'But what about...' or 'Have we considered...'\"\n\n        # Add personality-specific guidance\n        if 'philosophical' in self.config.personality.lower():\n            prompt += \"\\n- Ask deeper questions about assumptions and implications\\n- Challenge people to think more deeply\\n- Show excitement about big ideas\"\n        elif 'analytical' in self.config.personality.lower():\n            prompt += \"\\n- Focus on data, evidence, and logical reasoning\\n- Challenge unsupported claims\\n- Ask for proof and specifics\"\n        elif 'passionate' in self.config.personality.lower():\n            prompt += \"\\n- Show enthusiasm and conviction in your arguments\\n- Use energetic language\\n- Express how much you care about this topic\"\n        elif 'critical' in self.config.personality.lower():\n            prompt += \"\\n- Find flaws and problems in arguments\\n- Point out what others are missing\\n- Be direct about issues you see\"\n        elif 'diplomatic' in self.config.personality.lower():\n            prompt += \"\\n- Find common ground while making your point\\n- Build bridges between opposing views\\n- Show how different perspectives can work together\"\n\n        # Add burning questions motivation\n        prompt += f\"\\n\\nYOUR BURNING QUESTIONS/INTERESTS:\\n\"\n        for i, question in enumerate(self.burning_questions, 1):\n            prompt += f\"{i}. {question}\\n\"\n        prompt += \"\\nFeel free to explore these when relevant!\"\n\n        prompt += \"\\n\\nYou are EAGER to participate! Don't be shy - jump in when you have something to add! Respond as someone who genuinely cares about this topic and wants to actively engage in the debate!\"\n\n        return prompt\n\n    async def stop_monitoring(self):\n        \"\"\"Stop hyperactive autonomous monitoring.\"\"\"\n        self.is_monitoring = False\n        if self.monitoring_task:\n            self.monitoring_task.cancel()\n            try:\n                await self.monitoring_task\n            except asyncio.CancelledError:\n                pass\n        if self.message_queue and self.chat_log:\n            self.chat_log.unsubscribe(self.message_queue)\n        print(f\"üõë {self.name} stopped hyperactive monitoring\")\n\n    # Legacy methods for compatibility\n    async def get_response(self, topic: str, recent_messages: List[Message]) -> str:\n        \"\"\"Legacy method - now used for structured phases only.\"\"\"\n        start_time = time.time()\n\n        try:\n            messages = self._prepare_messages(topic, recent_messages)\n            response = await self.ai_provider.generate_response(messages, self.config)\n\n            response_time = time.time() - start_time\n            self._update_stats(response_time, success=True)\n\n            self.conversation_history.append({\n                'role': 'assistant',\n                'content': response\n            })\n\n            self.response_count += 1\n            return response\n\n        except Exception as e:\n            self._update_stats(time.time() - start_time, success=False)\n            print(f\"Bot {self.name} error: {e}\")\n            return self._generate_fallback_response(topic)\n\n    def _prepare_messages(self, topic: str, recent_messages: List[Message]) -> List[Dict[str, str]]:\n        \"\"\"Prepare message context for AI model (legacy method).\"\"\"\n        messages = []\n\n        system_prompt = f\"\"\"You are {self.config.name}, participating in a structured debate.\n\nDEBATE TOPIC: {topic}\nYOUR ROLE: {self.config.personality}\nYOUR STANCE: {self.config.stance}\n\nProvide a clear, energetic response that shows your personality and stance.\"\"\"\n\n        messages.append({\n            'role': 'system',\n            'content': system_prompt\n        })\n\n        for msg in recent_messages[-5:]:\n            role = 'assistant' if msg.sender == self.name else 'user'\n            content = f\"{msg.sender}: {msg.content}\"\n            messages.append({\n                'role': role,\n                'content': content\n            })\n\n        return messages\n\n    def _generate_fallback_response(self, topic: str) -> str:\n        \"\"\"Generate a fallback response when AI fails.\"\"\"\n        fallback_responses = [\n            f\"I'm excited to discuss {topic}! Let me jump in here...\",\n            \"That's a fascinating point! I have thoughts on this...\",\n            f\"Wait, there are some important aspects of {topic} we should consider!\",\n            \"I've been listening and I really want to add something here!\"\n        ]\n\n        return random.choice(fallback_responses)\n\n    async def receive_message(self, message: Message) -> None:\n        \"\"\"Receive a message (for compatibility).\"\"\"\n        if message.sender != self.name:\n            self.conversation_history.append({\n                'role': 'user',\n                'content': f\"{message.sender}: {message.content}\"\n            })\n\n            if len(self.conversation_history) > 20:\n                self.conversation_history = self.conversation_history[-15:]\n\n    def _update_stats(self, response_time: float, success: bool = True):\n        \"\"\"Update performance statistics.\"\"\"\n        if success:\n            self.stats['responses_generated'] += 1\n            self.stats['total_response_time'] += response_time\n            self.stats['average_response_time'] = (\n                    self.stats['total_response_time'] / self.stats['responses_generated']\n            )\n        else:\n            self.stats['errors'] += 1\n\n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get bot performance statistics.\"\"\"\n        return {\n            'name': self.name,\n            'model': self.config.model,\n            'provider': self.config.provider,\n            'responses_generated': self.stats['responses_generated'],\n            'autonomous_responses': self.stats['autonomous_responses'],\n            'silence_breaks': self.stats.get('silence_breaks', 0),\n            'conversation_starters': self.stats.get('conversation_starters', 0),\n            'missed_opportunities': self.missed_opportunities,\n            'average_response_time': round(self.stats['average_response_time'], 2),\n            'total_errors': self.stats['errors'],\n            'triggers_detected': self.stats['triggers_detected'],\n            'passes_made': self.stats['passes_made'],\n            'response_urgency': round(self.response_urgency, 2),\n            'conversation_energy': round(self.conversation_energy, 2),\n            'burning_questions': self.burning_questions,\n            'success_rate': (\n                self.stats['responses_generated'] /\n                (self.stats['responses_generated'] + self.stats['errors'])\n                if (self.stats['responses_generated'] + self.stats['errors']) > 0 else 0\n            ),\n            'current_cooldown': self.current_cooldown,\n            'total_autonomous_responses': self.total_responses\n        }\n\n    def update_personality(self, personality: str, stance: str = None):\n        \"\"\"Update bot personality and stance.\"\"\"\n        self.config.personality = personality\n        if stance:\n            self.config.stance = stance\n        # Regenerate burning questions with new personality\n        self.burning_questions = self._generate_burning_questions()\n\n    def reset_conversation(self):\n        \"\"\"Reset conversation history.\"\"\"\n        self.conversation_history = []\n        self.response_count = 0\n        # Reset hyperactive state\n        self.conversation_energy = 1.0\n        self.response_urgency = 0.0\n        self.missed_opportunities = 0\n\n    async def warmup(self) -> bool:\n        \"\"\"Warm up the bot by testing API connection.\"\"\"\n        try:\n            test_messages = [{\n                'role': 'system',\n                'content': 'You are a debate participant. Respond with just \"Ready\" to confirm you are working.'\n            }, {\n                'role': 'user',\n                'content': 'Are you ready to participate in a debate?'\n            }]\n\n            response = await self.ai_provider.generate_response(test_messages, self.config)\n            return \"ready\" in response.lower()\n\n        except Exception as e:\n            print(f\"Bot {self.name} warmup failed: {e}\")\n            return False\n\n    def __str__(self) -> str:\n        \"\"\"String representation of the bot.\"\"\"\n        return f\"BotClient({self.name}, {self.config.model}, {self.config.stance}, energy={self.conversation_energy:.1f}, autonomous={self.is_monitoring})\"\n\n    def __repr__(self) -> str:\n        \"\"\"Detailed string representation.\"\"\"\n        return (f\"BotClient(name='{self.name}', model='{self.config.model}', \"\n                f\"provider='{self.config.provider}', stance='{self.config.stance}', \"\n                f\"monitoring={self.is_monitoring}, energy={self.conversation_energy:.1f})\")\n\n    @property\n    def stance(self) -> str:\n        \"\"\"Expose the bot's stance directly for consistency with other participants.\"\"\"\n        return self.config.stance"
        },
        "chat_log.py": {
          "type": "file",
          "path": "app/chat_log.py",
          "extension": ".py",
          "size": 20718,
          "content": "\"\"\"\nShared chat log system for managing debate messages with timestamps and ordering.\nEnhanced with web broadcasting capabilities for real-time interface.\n\"\"\"\n\nimport asyncio\nimport json\nimport time\nfrom typing import List, Dict, Any, Optional, TYPE_CHECKING\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\nfrom collections import deque\n\n# Avoid circular imports\nif TYPE_CHECKING:\n    from app.web_server import DebateWebServer\n\n\n@dataclass\nclass Message:\n    \"\"\"Represents a single chat message.\"\"\"\n    sender: str\n    content: str\n    timestamp: float\n    message_id: int\n    message_type: str = \"chat\"  # chat, system, moderator, vote\n    metadata: Optional[Dict[str, Any]] = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            self.metadata = {}\n\n    @property\n    def formatted_timestamp(self) -> str:\n        \"\"\"Get human-readable timestamp.\"\"\"\n        return time.strftime(\"%H:%M:%S\", time.localtime(self.timestamp))\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert message to dictionary.\"\"\"\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'Message':\n        \"\"\"Create message from dictionary.\"\"\"\n        return cls(**data)\n\n\nclass ChatLog:\n    \"\"\"\n    Manages the shared chat log with thread-safe message handling.\n    Enhanced with web broadcasting for real-time interface updates.\n    \"\"\"\n\n    def __init__(self, max_messages: int = 1000):\n        self.messages: deque = deque(maxlen=max_messages)\n        self.message_counter = 0\n        self.subscribers: List[asyncio.Queue] = []\n        self._lock = asyncio.Lock()\n\n        # Web broadcasting\n        self.web_server: Optional['DebateWebServer'] = None\n        self.response_times: Dict[str, float] = {}\n\n        # Enhanced statistics\n        self.stats = {\n            'total_messages': 0,\n            'messages_by_sender': {},\n            'start_time': time.time(),\n            'bot_responses': 0,\n            'human_responses': 0,\n            'moderator_messages': 0,\n            'silence_breaks': 0\n        }\n\n    def set_web_server(self, web_server: 'DebateWebServer'):\n        \"\"\"Set the web server for broadcasting messages.\"\"\"\n        self.web_server = web_server\n        print(\"üîó Chat log connected to web server for real-time broadcasting\")\n\n    def start_response_timer(self, sender: str):\n        \"\"\"Start timing a participant's response.\"\"\"\n        self.response_times[sender] = time.time()\n\n    def get_response_time(self, sender: str) -> Optional[float]:\n        \"\"\"Get and clear response time for a sender.\"\"\"\n        if sender in self.response_times:\n            response_time = time.time() - self.response_times[sender]\n            del self.response_times[sender]\n            return response_time\n        return None\n\n    async def add_message(self, sender: str, content: str,\n                          message_type: str = \"chat\",\n                          metadata: Optional[Dict[str, Any]] = None) -> Message:\n        \"\"\"\n        Add a new message to the chat log and broadcast to web interface.\n\n        Args:\n            sender: Name of the message sender\n            content: Message content\n            message_type: Type of message (chat, system, moderator, vote)\n            metadata: Additional message metadata\n\n        Returns:\n            The created Message object\n        \"\"\"\n        async with self._lock:\n            self.message_counter += 1\n\n            # Get response time if being tracked\n            response_time = self.get_response_time(sender)\n\n            message = Message(\n                sender=sender,\n                content=content,\n                timestamp=time.time(),\n                message_id=self.message_counter,\n                message_type=message_type,\n                metadata=metadata or {}\n            )\n\n            self.messages.append(message)\n\n            # Update enhanced statistics\n            self.stats['total_messages'] += 1\n            self.stats['messages_by_sender'][sender] = (\n                    self.stats['messages_by_sender'].get(sender, 0) + 1\n            )\n\n            # Update type-specific stats\n            if sender in [\"Socrates\", \"Advocate\", \"Skeptic\", \"Mediator\"]:\n                self.stats['bot_responses'] += 1\n\n                # Check for silence breaks (responses within 10 seconds)\n                if len(self.messages) > 1:\n                    last_message = list(self.messages)[-2]\n                    time_diff = message.timestamp - last_message.timestamp\n                    if time_diff < 10:\n                        self.stats['silence_breaks'] += 1\n\n            elif sender == \"Moderator\":\n                self.stats['moderator_messages'] += 1\n            else:\n                self.stats['human_responses'] += 1\n\n            # Notify subscribers\n            await self._notify_subscribers(message)\n\n            # Broadcast to web interface\n            if self.web_server:\n                try:\n                    # Determine web message type\n                    web_message_type = self._get_web_message_type(sender, message_type)\n\n                    await self.web_server.broadcast_message(\n                        sender=sender,\n                        content=content,\n                        message_type=web_message_type,\n                        response_time=response_time\n                    )\n                except Exception as e:\n                    print(f\"‚ö†Ô∏è Failed to broadcast message to web: {e}\")\n\n            return message\n\n    def _get_web_message_type(self, sender: str, message_type: str) -> str:\n        \"\"\"Determine web message type based on sender and message type.\"\"\"\n        if message_type in [\"moderator\", \"system\"]:\n            return \"moderator\"\n        elif sender == \"Moderator\":\n            return \"moderator\"\n        elif sender in [\"Socrates\", \"Advocate\", \"Skeptic\", \"Mediator\"]:\n            return \"bot\"\n        else:\n            return \"human\"\n\n    async def _notify_subscribers(self, message: Message):\n        \"\"\"Notify all subscribers of new message.\"\"\"\n        # Remove closed queues\n        self.subscribers = [q for q in self.subscribers if not getattr(q, \"_closed\", False)]\n        # Send to all active subscribers\n        for queue in self.subscribers:\n            try:\n                await queue.put(message)\n            except Exception as e:\n                print(f\"Failed to notify subscriber: {e}\")\n\n    def subscribe(self) -> asyncio.Queue:\n        \"\"\"\n        Subscribe to receive new messages.\n\n        Returns:\n            Queue that will receive new Message objects\n        \"\"\"\n        queue = asyncio.Queue()\n        self.subscribers.append(queue)\n        return queue\n\n    def unsubscribe(self, queue: asyncio.Queue):\n        \"\"\"Remove a subscriber queue.\"\"\"\n        if queue in self.subscribers:\n            self.subscribers.remove(queue)\n\n    def get_messages(self, limit: Optional[int] = None,\n                     sender: Optional[str] = None,\n                     message_type: Optional[str] = None,\n                     since_timestamp: Optional[float] = None) -> List[Message]:\n        \"\"\"\n        Get messages with optional filtering.\n\n        Args:\n            limit: Maximum number of messages to return\n            sender: Filter by sender name\n            message_type: Filter by message type\n            since_timestamp: Only return messages after this timestamp\n\n        Returns:\n            List of matching messages\n        \"\"\"\n        messages = list(self.messages)\n\n        # Apply filters\n        if sender:\n            messages = [m for m in messages if m.sender == sender]\n\n        if message_type:\n            messages = [m for m in messages if m.message_type == message_type]\n\n        if since_timestamp:\n            messages = [m for m in messages if m.timestamp > since_timestamp]\n\n        # Apply limit\n        if limit:\n            messages = messages[-limit:]\n\n        return messages\n\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\n        \"\"\"Get the most recent messages.\"\"\"\n        return list(self.messages)[-count:]\n\n    def get_conversation_context(self, participant: str,\n                                 context_length: int = 5) -> List[Message]:\n        \"\"\"\n        Get conversation context for a participant.\n\n        Args:\n            participant: Participant name\n            context_length: Number of recent messages to include\n\n        Returns:\n            Recent messages for context\n        \"\"\"\n        recent = self.get_recent_messages(context_length * 2)\n\n        # Include messages to/from the participant and moderator messages\n        context = []\n        for msg in recent:\n            if (msg.sender == participant or\n                    msg.message_type in ['moderator', 'system'] or\n                    participant in msg.content):\n                context.append(msg)\n\n        return context[-context_length:]\n\n    def search_messages(self, query: str, case_sensitive: bool = False) -> List[Message]:\n        \"\"\"\n        Search messages by content.\n\n        Args:\n            query: Search query\n            case_sensitive: Whether search should be case sensitive\n\n        Returns:\n            List of messages containing the query\n        \"\"\"\n        if not case_sensitive:\n            query = query.lower()\n\n        results = []\n        for message in self.messages:\n            content = message.content if case_sensitive else message.content.lower()\n            if query in content:\n                results.append(message)\n\n        return results\n\n    def get_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get enhanced chat log statistics.\"\"\"\n        duration = time.time() - self.stats['start_time']\n\n        return {\n            'total_messages': self.stats['total_messages'],\n            'bot_responses': self.stats['bot_responses'],\n            'human_responses': self.stats['human_responses'],\n            'moderator_messages': self.stats['moderator_messages'],\n            'silence_breaks': self.stats['silence_breaks'],\n            'unique_senders': len(self.stats['messages_by_sender']),\n            'messages_by_sender': dict(self.stats['messages_by_sender']),\n            'messages_per_minute': (self.stats['total_messages'] / (duration / 60)\n                                    if duration > 0 else 0),\n            'session_duration_minutes': duration / 60,\n            'current_message_count': len(self.messages),\n            'response_rate': {\n                'bots': self.stats['bot_responses'] / max(1, self.stats['total_messages']),\n                'humans': self.stats['human_responses'] / max(1, self.stats['total_messages']),\n                'moderator': self.stats['moderator_messages'] / max(1, self.stats['total_messages'])\n            }\n        }\n\n    async def broadcast_statistics(self):\n        \"\"\"Broadcast current statistics to web interface.\"\"\"\n        if self.web_server:\n            try:\n                stats = self.get_statistics()\n                await self.web_server.broadcast_stats(stats)\n            except Exception as e:\n                print(f\"‚ö†Ô∏è Failed to broadcast statistics: {e}\")\n\n    async def save_transcript(self, filename: str,\n                              format_type: str = \"json\") -> None:\n        \"\"\"\n        Save chat transcript to file.\n\n        Args:\n            filename: Output filename\n            format_type: Format (json, txt, html)\n        \"\"\"\n        filepath = Path(filename)\n        filepath.parent.mkdir(parents=True, exist_ok=True)\n\n        messages = list(self.messages)\n\n        if format_type == \"json\":\n            data = {\n                'metadata': {\n                    'export_timestamp': time.time(),\n                    'total_messages': len(messages),\n                    'statistics': self.get_statistics(),\n                    'web_enabled': self.web_server is not None\n                },\n                'messages': [msg.to_dict() for msg in messages]\n            }\n\n            with open(filepath, 'w', encoding='utf-8') as f:\n                json.dump(data, f, indent=2, ensure_ascii=False)\n\n        elif format_type == \"txt\":\n            with open(filepath, 'w', encoding='utf-8') as f:\n                f.write(\"=== AI JUBILEE DEBATE TRANSCRIPT ===\\n\")\n                f.write(f\"Session Duration: {self.get_statistics()['session_duration_minutes']:.1f} minutes\\n\")\n                f.write(f\"Total Messages: {len(messages)}\\n\")\n                f.write(f\"Bot Responses: {self.stats['bot_responses']}\\n\")\n                f.write(f\"Silence Breaks: {self.stats['silence_breaks']}\\n\\n\")\n\n                for msg in messages:\n                    f.write(f\"[{msg.formatted_timestamp}] {msg.sender}: {msg.content}\\n\")\n\n        elif format_type == \"html\":\n            html_content = self._generate_html_transcript(messages)\n            with open(filepath, 'w', encoding='utf-8') as f:\n                f.write(html_content)\n\n        else:\n            raise ValueError(f\"Unsupported format: {format_type}\")\n\n    def _generate_html_transcript(self, messages: List[Message]) -> str:\n        \"\"\"Generate enhanced HTML transcript.\"\"\"\n        stats = self.get_statistics()\n\n        html = f\"\"\"\n        <!DOCTYPE html>\n        <html>\n        <head>\n            <title>AI Jubilee Debate Transcript</title>\n            <style>\n                body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}\n                .header {{ background: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}\n                .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}\n                .stat-card {{ background: white; padding: 15px; border-radius: 8px; text-align: center; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }}\n                .stat-value {{ font-size: 2em; font-weight: bold; color: #4f46e5; }}\n                .stat-label {{ color: #666; margin-top: 5px; }}\n                .message {{ margin: 10px 0; padding: 15px; border-left: 4px solid #ccc; background: white; border-radius: 0 8px 8px 0; }}\n                .moderator {{ border-left-color: #8b5cf6; background: #faf5ff; }}\n                .bot {{ border-left-color: #10b981; background: #f0fdf4; }}\n                .human {{ border-left-color: #f59e0b; background: #fffbeb; }}\n                .system {{ border-left-color: #6c757d; background: #e9ecef; }}\n                .timestamp {{ color: #6c757d; font-size: 0.9em; }}\n                .sender {{ font-weight: bold; margin-right: 10px; }}\n                .response-time {{ background: #4f46e5; color: white; padding: 2px 6px; border-radius: 4px; font-size: 0.8em; margin-left: 10px; }}\n                .content {{ margin-top: 8px; line-height: 1.5; }}\n            </style>\n        </head>\n        <body>\n            <div class=\"header\">\n                <h1>üé≠ AI Jubilee Debate Transcript</h1>\n                <p><strong>Session Duration:</strong> {stats['session_duration_minutes']:.1f} minutes</p>\n                <p><strong>Generated:</strong> {time.strftime('%Y-%m-%d %H:%M:%S')}</p>\n            </div>\n            \n            <div class=\"stats\">\n                <div class=\"stat-card\">\n                    <div class=\"stat-value\">{stats['total_messages']}</div>\n                    <div class=\"stat-label\">Total Messages</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-value\">{stats['bot_responses']}</div>\n                    <div class=\"stat-label\">Bot Responses</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-value\">{stats['silence_breaks']}</div>\n                    <div class=\"stat-label\">Silence Breaks</div>\n                </div>\n                <div class=\"stat-card\">\n                    <div class=\"stat-value\">{stats['messages_per_minute']:.1f}</div>\n                    <div class=\"stat-label\">Messages/Minute</div>\n                </div>\n            </div>\n        \"\"\"\n\n        for msg in messages:\n            css_class = self._get_web_message_type(msg.sender, msg.message_type)\n            html += f\"\"\"\n            <div class=\"message {css_class}\">\n                <div>\n                    <span class=\"timestamp\">[{msg.formatted_timestamp}]</span>\n                    <span class=\"sender\">{msg.sender}:</span>\n                </div>\n                <div class=\"content\">{msg.content.replace('', '<br>')}</div>\n            </div>\n            \"\"\"\n\n        html += \"\"\"\n        </body>\n        </html>\n        \"\"\"\n\n        return html\n\n    async def load_transcript(self, filename: str) -> None:\n        \"\"\"\n        Load transcript from JSON file.\n\n        Args:\n            filename: Input filename\n        \"\"\"\n        filepath = Path(filename)\n\n        if not filepath.exists():\n            raise FileNotFoundError(f\"Transcript file not found: {filename}\")\n\n        with open(filepath, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n\n        # Clear current messages\n        async with self._lock:\n            self.messages.clear()\n            self.message_counter = 0\n\n            # Reset stats\n            self.stats = {\n                'total_messages': 0,\n                'messages_by_sender': {},\n                'start_time': time.time(),\n                'bot_responses': 0,\n                'human_responses': 0,\n                'moderator_messages': 0,\n                'silence_breaks': 0\n            }\n\n            # Load messages\n            for msg_data in data.get('messages', []):\n                message = Message.from_dict(msg_data)\n                self.messages.append(message)\n                self.message_counter = max(self.message_counter, message.message_id)\n\n                # Update stats\n                self.stats['total_messages'] += 1\n                self.stats['messages_by_sender'][message.sender] = (\n                    self.stats['messages_by_sender'].get(message.sender, 0) + 1\n                )\n\n        print(f\"üìÑ Loaded {len(self.messages)} messages from transcript\")\n\n    def clear(self) -> None:\n        \"\"\"Clear all messages from the chat log.\"\"\"\n        self.messages.clear()\n        self.message_counter = 0\n        self.response_times.clear()\n        self.stats = {\n            'total_messages': 0,\n            'messages_by_sender': {},\n            'start_time': time.time(),\n            'bot_responses': 0,\n            'human_responses': 0,\n            'moderator_messages': 0,\n            'silence_breaks': 0\n        }\n\n    def get_participant_stats(self, participant_name: str) -> Dict[str, Any]:\n        \"\"\"Get statistics for a specific participant.\"\"\"\n        participant_messages = [msg for msg in self.messages if msg.sender == participant_name]\n\n        if not participant_messages:\n            return {'message_count': 0, 'participation_rate': 0.0}\n\n        total_time = time.time() - self.stats['start_time']\n\n        return {\n            'message_count': len(participant_messages),\n            'participation_rate': len(participant_messages) / max(1, self.stats['total_messages']),\n            'messages_per_minute': len(participant_messages) / (total_time / 60) if total_time > 0 else 0,\n            'first_message_time': min(msg.timestamp for msg in participant_messages) if participant_messages else 0,\n            'last_message_time': max(msg.timestamp for msg in participant_messages) if participant_messages else 0\n        }\n\n    async def export_web_data(self) -> Dict[str, Any]:\n        \"\"\"Export data formatted for web interface.\"\"\"\n        return {\n            'messages': [\n                {\n                    'sender': msg.sender,\n                    'content': msg.content,\n                    'timestamp': msg.timestamp * 1000,  # JavaScript timestamp\n                    'message_type': self._get_web_message_type(msg.sender, msg.message_type),\n                    'formatted_time': msg.formatted_timestamp\n                }\n                for msg in self.messages\n            ],\n            'statistics': self.get_statistics(),\n            'participants': {\n                sender: self.get_participant_stats(sender)\n                for sender in self.stats['messages_by_sender'].keys()\n            }\n        }\n\n    def __len__(self) -> int:\n        \"\"\"Return number of messages in the log.\"\"\"\n        return len(self.messages)\n\n    def __iter__(self):\n        \"\"\"Iterate over messages.\"\"\"\n        return iter(self.messages)\n\n    def __getitem__(self, index) -> Message:\n        \"\"\"Get message by index.\"\"\"\n        return list(self.messages)[index]\n\n    def __bool__(self) -> bool:\n        \"\"\"Return True if chat log has messages.\"\"\"\n        return len(self.messages) > 0"
        },
        "human_client.py": {
          "type": "file",
          "path": "app/human_client.py",
          "extension": ".py",
          "size": 20290,
          "content": "\"\"\"\nHuman client implementation for debate participation.\nNow with true autonomous participation - can speak anytime!\n\"\"\"\n\nimport asyncio\nimport time\nfrom typing import List, Dict, Any, Optional\nfrom dataclasses import dataclass\n\nfrom .chat_log import Message\n\n\n@dataclass\nclass InterfaceConfig:\n    \"\"\"Configuration for human interface.\"\"\"\n    mode: str = \"cli\"\n    enable_rich_formatting: bool = True\n    show_typing_indicators: bool = True\n    enable_reactions: bool = True\n    input_timeout: int = 120\n\n\nclass CLIInterface:\n    \"\"\"Command line interface for human participants.\"\"\"\n\n    def __init__(self, config: InterfaceConfig):\n        self.config = config\n        self.rich_console = None\n        self.input_task = None\n\n        if config.enable_rich_formatting:\n            try:\n                from rich.console import Console\n                from rich.live import Live\n                self.rich_console = Console()\n            except ImportError:\n                print(\"Rich not available, using basic formatting\")\n\n    async def display_message(self, message: Message):\n        \"\"\"Display a message to the user.\"\"\"\n        timestamp = time.strftime(\"%H:%M:%S\", time.localtime(message.timestamp))\n\n        if self.rich_console:\n            if message.message_type == \"moderator\":\n                self.rich_console.print(\n                    f\"[{timestamp}] üé≠ {message.sender}: {message.content}\",\n                    style=\"bold yellow\"\n                )\n            elif message.sender.endswith('_1') or 'Human' in message.sender:\n                # Don't display our own messages back to us\n                return\n            else:\n                self.rich_console.print(\n                    f\"[{timestamp}] ü§ñ {message.sender}: {message.content}\",\n                    style=\"cyan\"\n                )\n        else:\n            if message.message_type == \"moderator\":\n                print(f\"[{timestamp}] üé≠ {message.sender}: {message.content}\")\n            elif not (message.sender.endswith('_1') or 'Human' in message.sender):\n                print(f\"[{timestamp}] ü§ñ {message.sender}: {message.content}\")\n\n    async def get_input(self, prompt: str, timeout: int = 10) -> str:\n        \"\"\"Get input from user with timeout.\"\"\"\n        if self.rich_console:\n            self.rich_console.print(f\"üí¨ {prompt}\", style=\"bold green\")\n        else:\n            print(f\"üí¨ {prompt}\")\n\n        # Start input task\n        self.input_task = asyncio.create_task(self._get_user_input())\n\n        try:\n            # Wait for input or timeout\n            response = await asyncio.wait_for(self.input_task, timeout=timeout)\n            return response.strip()\n\n        except asyncio.TimeoutError:\n            if self.input_task and not self.input_task.done():\n                self.input_task.cancel()\n                try:\n                    await self.input_task\n                except asyncio.CancelledError:\n                    pass\n            return \"\"\n        except asyncio.CancelledError:\n            if self.input_task and not self.input_task.done():\n                self.input_task.cancel()\n            return \"\"\n        except Exception as e:\n            print(f\"Input error: {e}\")\n            if self.input_task and not self.input_task.done():\n                self.input_task.cancel()\n            return \"\"\n\n    async def _get_user_input(self) -> str:\n        \"\"\"Get user input asynchronously.\"\"\"\n        loop = asyncio.get_event_loop()\n        return await loop.run_in_executor(None, input, \"\")\n\n    async def show_notification(self, message: str, level: str = \"info\"):\n        \"\"\"Show a notification to the user.\"\"\"\n        icons = {\n            \"info\": \"‚ÑπÔ∏è\",\n            \"warning\": \"‚ö†Ô∏è\",\n            \"error\": \"‚ùå\",\n            \"success\": \"‚úÖ\"\n        }\n\n        icon = icons.get(level, \"‚ÑπÔ∏è\")\n\n        if self.rich_console:\n            colors = {\n                \"info\": \"blue\",\n                \"warning\": \"yellow\",\n                \"error\": \"red\",\n                \"success\": \"green\"\n            }\n            color = colors.get(level, \"blue\")\n            self.rich_console.print(f\"{icon} {message}\", style=color)\n        else:\n            print(f\"{icon} {message}\")\n\n\nclass WebInterface:\n    \"\"\"Web interface for human participants.\"\"\"\n\n    def __init__(self, config: InterfaceConfig):\n        self.config = config\n        self.websocket = None\n        self.pending_responses = {}\n\n    async def display_message(self, message: Message):\n        \"\"\"Display message via websocket.\"\"\"\n        if self.websocket:\n            await self.websocket.send_json({\n                \"type\": \"message\",\n                \"data\": message.to_dict()\n            })\n\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\n        \"\"\"Get input via websocket.\"\"\"\n        if not self.websocket:\n            return \"\"\n\n        request_id = f\"input_{time.time()}\"\n        await self.websocket.send_json({\n            \"type\": \"input_request\",\n            \"id\": request_id,\n            \"prompt\": prompt,\n            \"timeout\": timeout\n        })\n\n        # Wait for response\n        try:\n            response = await asyncio.wait_for(\n                self._wait_for_response(request_id),\n                timeout=timeout\n            )\n            return response\n        except asyncio.TimeoutError:\n            return \"\"\n\n    async def _wait_for_response(self, request_id: str) -> str:\n        \"\"\"Wait for websocket response.\"\"\"\n        while request_id not in self.pending_responses:\n            await asyncio.sleep(0.1)\n        return self.pending_responses.pop(request_id)\n\n    async def show_notification(self, message: str, level: str = \"info\"):\n        \"\"\"Show notification via websocket.\"\"\"\n        if self.websocket:\n            await self.websocket.send_json({\n                \"type\": \"notification\",\n                \"message\": message,\n                \"level\": level\n            })\n\n\nclass HumanClient:\n    \"\"\"\n    Human participant in the debate system with autonomous participation.\n    \"\"\"\n\n    def __init__(self, name: str, config: Dict[str, Any]):\n        self.name = name\n        self.config = config\n        self.is_active = True\n        self.conversation_history: List[Message] = []\n\n        # Initialize appropriate interface\n        interface_config = InterfaceConfig(\n            mode=config.get('mode', 'cli'),\n            enable_rich_formatting=config.get('enable_rich_formatting', True),\n            show_typing_indicators=config.get('show_typing_indicators', True),\n            enable_reactions=config.get('enable_reactions', True),\n            input_timeout=config.get('input_timeout', 120)\n        )\n\n        if interface_config.mode == \"cli\":\n            self.interface = CLIInterface(interface_config)\n        elif interface_config.mode == \"web\":\n            self.interface = WebInterface(interface_config)\n        else:\n            raise ValueError(f\"Unsupported interface mode: {interface_config.mode}\")\n\n        # Statistics tracking\n        self.stats = {\n            'responses_given': 0,\n            'timeouts': 0,\n            'total_response_time': 0.0,\n            'average_response_time': 0.0\n        }\n\n    async def autonomous_participation_loop(self, chat_log):\n        \"\"\"True autonomous participation - human can speak anytime.\"\"\"\n        if not self.is_active:\n            return\n\n        await self.interface.show_notification(\n            \"üéØ AUTONOMOUS MODE ACTIVE - You can speak ANYTIME!\", \"success\"\n        )\n        await self.interface.show_notification(\n            \"üó£Ô∏è  You can speak at ANY TIME during the discussion!\", \"info\"\n        )\n        await self.interface.show_notification(\n            \"üí° Commands: 'help', 'status', 'history', 'quit'\", \"info\"\n        )\n        await self.interface.show_notification(\n            \"‚úèÔ∏è  Just type your response and press Enter to join the conversation!\", \"info\"\n        )\n\n        # Subscribe to chat updates for display\n        message_queue = chat_log.subscribe()\n        last_displayed = len(chat_log.messages)\n\n        while self.is_active:\n            try:\n                # Check for new messages to display\n                current_count = len(chat_log.messages)\n                if current_count > last_displayed:\n                    new_messages = list(chat_log.messages)[last_displayed:]\n                    for msg in new_messages:\n                        if msg.sender != self.name:  # Don't show own messages\n                            await self.interface.display_message(msg)\n                    last_displayed = current_count\n\n                # Get user input with short timeout for responsiveness\n                response = await self.interface.get_input(\n                    \"Type your response (or command):\",\n                    timeout=10  # Short timeout for responsiveness\n                )\n\n                if not response:\n                    continue  # Timeout, check for new messages\n\n                response = response.strip()\n\n                # Handle commands\n                if response.lower() in ['quit', 'exit']:\n                    await self.interface.show_notification(\n                        \"üëã Leaving the debate. Thanks for participating!\", \"success\"\n                    )\n                    self.is_active = False\n                    break\n                elif response.lower() == 'help':\n                    await self._show_autonomous_help()\n                    continue\n                elif response.lower() == 'status':\n                    await self._show_status()\n                    continue\n                elif response.lower() == 'history':\n                    await self.interface.show_notification(\"üìú Recent conversation:\", \"info\")\n                    recent = chat_log.get_recent_messages(5)\n                    for msg in recent:\n                        await self.interface.display_message(msg)\n                    continue\n                elif len(response) < 3:\n                    await self.interface.show_notification(\n                        \"‚ö†Ô∏è Please provide a more substantial response (at least 3 characters).\",\n                        \"warning\"\n                    )\n                    continue\n\n                # Process and post message directly to chat log\n                validated_response = self._validate_response(response)\n                if validated_response:\n                    await chat_log.add_message(self.name, validated_response)\n                    self.stats['responses_given'] += 1\n                    await self.interface.show_notification(\n                        \"‚úÖ Your message has been added to the debate!\", \"success\"\n                    )\n\n            except Exception as e:\n                await self.interface.show_notification(f\"‚ùå Error: {e}\", \"error\")\n                await asyncio.sleep(2)\n\n        # Cleanup\n        chat_log.unsubscribe(message_queue)\n        await self.interface.show_notification(\n            \"üõë Autonomous participation ended.\", \"info\"\n        )\n\n    async def _show_autonomous_help(self):\n        \"\"\"Show help information for autonomous mode.\"\"\"\n        help_text = \"\"\"\nüéØ AI JUBILEE DEBATE - AUTONOMOUS MODE HELP\n\nCOMMANDS:\n‚Ä¢ Just type your response and press Enter to join the debate\n‚Ä¢ 'help' - Show this help message\n‚Ä¢ 'status' - Show your participation statistics  \n‚Ä¢ 'history' - Show recent conversation messages\n‚Ä¢ 'quit' - Leave the debate\n\nAUTONOMOUS MODE:\n‚Ä¢ You can speak at ANY TIME during the discussion phase\n‚Ä¢ Bots and moderator are monitoring and will respond when they feel compelled\n‚Ä¢ No turn-taking - completely organic conversation flow\n‚Ä¢ Your responses are immediately added to the debate\n\nTIPS:\n‚Ä¢ Keep responses focused and substantial (3+ characters)\n‚Ä¢ Reference specific points made by others\n‚Ä¢ Feel free to jump in whenever you have something to add!\n‚Ä¢ The debate flows naturally - speak when inspired!\n\nDEBATE PHASES:\n1. Introduction & Opening Statements (structured)\n2. Autonomous Discussion (free-flowing - you can speak anytime!)\n3. Closing Statements (structured)  \n4. Voting Phase\n\nEnjoy the organic debate experience! üé≠\n        \"\"\"\n\n        await self.interface.show_notification(help_text, \"info\")\n\n    async def _show_status(self):\n        \"\"\"Show participation status.\"\"\"\n        stats = self.get_stats()\n        await self.interface.show_notification(\n            f\"üìä Your participation: {stats['responses_given']} responses, \"\n            f\"{stats['participation_rate']:.1%} participation rate, \"\n            f\"avg response time: {stats['average_response_time']:.1f}s\",\n            \"info\"\n        )\n\n    def _validate_response(self, response: str) -> str:\n        \"\"\"Validate and clean up human response.\"\"\"\n        if not response or not response.strip():\n            return \"\"\n\n        # Clean up the response\n        response = response.strip()\n\n        # Check length limits\n        max_length = self.config.get('max_message_length', 500)\n        if len(response) > max_length:\n            response = response[:max_length - 3] + \"...\"\n\n        # Add note for very short responses\n        if len(response) < 10:\n            response += \" [Note: Very short response]\"\n\n        return response\n\n    # Legacy methods for structured phases\n    async def get_response(self, topic: str, messages: List[Message]) -> str:\n        \"\"\"Get response from human participant (for structured phases).\"\"\"\n        if not self.is_active:\n            return \"\"\n\n        start_time = time.time()\n\n        try:\n            # Show context in structured phases\n            if len(messages) > 0:\n                await self.interface.show_notification(\n                    f\"üìú Recent messages in conversation:\",\n                    \"info\"\n                )\n                # Show last 3 messages for context\n                recent = messages[-3:] if len(messages) >= 3 else messages\n                for msg in recent:\n                    await self.interface.display_message(msg)\n                await self.interface.show_notification(\"‚îÄ\" * 50, \"info\")\n\n            # Get response with timeout\n            response = await self.interface.get_input(\n                f\"üí¨ Your response to: {topic}\",\n                timeout=self.config.get('input_timeout', 120)\n            )\n\n            # Validate and process response\n            if response:\n                validated_response = self._validate_response(response)\n                if validated_response:\n                    # Add to conversation history\n                    response_msg = Message(\n                        sender=self.name,\n                        content=validated_response,\n                        timestamp=time.time(),\n                        message_id=len(self.conversation_history) + 1\n                    )\n                    self.conversation_history.append(response_msg)\n\n                    # Update stats\n                    response_time = time.time() - start_time\n                    self._update_stats(response_time, success=True)\n\n                    return validated_response\n\n            # Handle timeout/empty response\n            response_time = time.time() - start_time\n            self._update_stats(response_time, success=False)\n            return \"\"\n\n        except Exception as e:\n            await self.interface.show_notification(\n                f\"‚ùå Error getting response: {e}\",\n                \"error\"\n            )\n            return \"\"\n\n    async def receive_message(self, message: Message):\n        \"\"\"Receive and display a message from the debate.\"\"\"\n        # Don't show our own messages back to us\n        if message.sender == self.name:\n            return\n\n        # Add to conversation history\n        self.conversation_history.append(message)\n\n        # Limit history size\n        if len(self.conversation_history) > 30:\n            self.conversation_history = self.conversation_history[-30:]\n\n        # Display the message (in autonomous mode, this is handled by the loop)\n        try:\n            if not hasattr(self, '_in_autonomous_mode'):\n                await self.interface.display_message(message)\n        except Exception as e:\n            print(f\"Error displaying message: {e}\")\n\n    async def handle_voting(self, candidates: List[str], time_limit: int) -> Dict[str, Any]:\n        \"\"\"Handle voting process for human participant.\"\"\"\n        await self.interface.show_notification(\n            f\"üó≥Ô∏è Voting phase! You have {time_limit} seconds to vote.\",\n            \"info\"\n        )\n\n        # Show candidates\n        await self.interface.show_notification(\n            \"üìã Candidates:\", \"info\"\n        )\n        for i, candidate in enumerate(candidates, 1):\n            await self.interface.show_notification(\n                f\"  {i}. {candidate}\", \"info\"\n            )\n\n        try:\n            # Get vote choice\n            choice_input = await self.interface.get_input(\n                f\"Enter your choice (1-{len(candidates)}):\",\n                timeout=time_limit\n            )\n\n            if not choice_input:\n                return {'voted': False, 'reason': 'timeout'}\n\n            try:\n                choice = int(choice_input.strip())\n                if 1 <= choice <= len(candidates):\n                    selected_candidate = candidates[choice - 1]\n\n                    # Get justification if using CLI\n                    justification = \"\"\n                    if isinstance(self.interface, CLIInterface):\n                        justification = await self.interface.get_input(\n                            \"Optional: Why did you choose this candidate?\",\n                            timeout=30\n                        )\n\n                    return {\n                        'voted': True,\n                        'candidate': selected_candidate,\n                        'justification': justification or \"\"\n                    }\n                else:\n                    return {'voted': False, 'reason': 'invalid_choice'}\n\n            except ValueError:\n                return {'voted': False, 'reason': 'invalid_format'}\n\n        except Exception as e:\n            await self.interface.show_notification(\n                f\"‚ùå Voting error: {e}\", \"error\"\n            )\n            return {'voted': False, 'reason': 'error'}\n\n    def _update_stats(self, response_time: float, success: bool):\n        \"\"\"Update response statistics.\"\"\"\n        if success:\n            self.stats['responses_given'] += 1\n            self.stats['total_response_time'] += response_time\n            if self.stats['responses_given'] > 0:\n                self.stats['average_response_time'] = (\n                        self.stats['total_response_time'] / self.stats['responses_given']\n                )\n        else:\n            self.stats['timeouts'] += 1\n\n    def get_stats(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive human client statistics.\"\"\"\n        total_attempts = self.stats['responses_given'] + self.stats['timeouts']\n        participation_rate = (\n            self.stats['responses_given'] / total_attempts\n            if total_attempts > 0 else 0\n        )\n\n        return {\n            'name': self.name,\n            'interface_mode': self.interface.config.mode,\n            'responses_given': self.stats['responses_given'],\n            'timeouts': self.stats['timeouts'],\n            'total_attempts': total_attempts,\n            'participation_rate': participation_rate,\n            'average_response_time': self.stats.get('average_response_time', 0),\n            'is_active': self.is_active,\n            'conversation_length': len(self.conversation_history)\n        }\n\n    async def set_active(self, active: bool):\n        \"\"\"Set the active status of the human client.\"\"\"\n        self.is_active = active\n        status = \"activated\" if active else \"deactivated\"\n        await self.interface.show_notification(\n            f\"üîÑ {self.name} has been {status}\",\n            \"info\"\n        )\n\n    def __str__(self) -> str:\n        return f\"Human({self.name}, {self.interface.config.mode}, active={self.is_active})\"\n\n    def __repr__(self) -> str:\n        return (f\"HumanClient(name='{self.name}', mode='{self.interface.config.mode}', \"\n                f\"active={self.is_active}, responses={self.stats['responses_given']})\")\n\n    @property\n    def stance(self) -> str:\n        return \"neutral\"  # Or dynamically assign based on your use case\n"
        },
        "main.py": {
          "type": "file",
          "path": "app/main.py",
          "extension": ".py",
          "size": 4522,
          "content": "\"\"\"\nMain entry point for the AI Jubilee Debate System.\n\"\"\"\n\nimport asyncio\nimport yaml\nimport click\nimport os\nfrom typing import List, Optional\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\nfrom .moderator import Moderator\nfrom .bot_client import BotClient\nfrom .human_client import HumanClient\nfrom .chat_log import ChatLog\nfrom .voting import VotingSystem\nfrom .streaming import StreamingServer\nfrom .utils import setup_logging, load_config\n\n\nasync def start_debate_session(\n    topic: Optional[str] = None,\n    ai_bots: int = 2,\n    human_participants: int = 1,\n    config_path: str = \"config.yaml\"\n) -> None:\n    \"\"\"\n    Start a debate session with specified participants.\n\n    Args:\n        topic: Debate topic (if None, uses random from config)\n        ai_bots: Number of AI bot participants\n        human_participants: Number of human participants\n        config_path: Path to configuration file\n    \"\"\"\n    # Load environment variables from .env file\n    load_dotenv()\n\n    # Load configuration\n    config = load_config(config_path)\n\n    # Setup logging\n    setup_logging(config.get('chat', {}).get('log_level', 'INFO'))\n\n    # Initialize chat log\n    chat_log = ChatLog()\n\n    # Initialize voting system\n    voting_system = VotingSystem(config.get('voting', {}))\n\n    # Select topic\n    if not topic:\n        import random\n        topic = random.choice(config.get('topics', [\"AI in society\"]))\n\n    # Create bot clients\n    bot_clients = []\n    bot_configs = config.get('bots', [])[:ai_bots]\n\n    for i, bot_config in enumerate(bot_configs):\n        bot = BotClient(\n            name=bot_config['name'],\n            model=bot_config['model'],\n            provider=bot_config['provider'],\n            personality=bot_config['personality'],\n            stance=bot_config['stance'],\n            api_key=config['api_keys'].get(bot_config['provider'])\n        )\n        bot_clients.append(bot)\n\n    # Create human clients\n    human_clients = []\n    for i in range(human_participants):\n        human = HumanClient(\n            name=f\"Human_{i+1}\",\n            config=config.get('interface', {})\n        )\n        human_clients.append(human)\n\n    # Initialize moderator based on debate mode\n    debate_mode = config.get('debate', {}).get('mode', 'sequential')\n\n    moderator = Moderator(\n        topic=topic,\n        participants=bot_clients + human_clients,\n        chat_log=chat_log,\n        voting_system=voting_system,\n        config=config\n    )\n\n    if debate_mode == \"autonomous\":\n        print(f\"ü§ñ Running in AUTONOMOUS mode - bots will decide when to speak!\")\n        print(f\"üìù Topic: {topic}\")\n        print(f\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\")\n        print(f\"‚è∞ Discussion time: {config.get('debate', {}).get('time_limit_minutes', 30)} minutes\")\n        print(f\"üéØ Bots will monitor conversation and jump in when they feel compelled to respond!\")\n    else:\n        print(f\"üìù Running in SEQUENTIAL mode\")\n        print(f\"üë• Participants take turns in order\")\n\n    # Initialize streaming server if enabled\n    streaming_server = None\n    if config.get('streaming', {}).get('enabled', False):\n        streaming_server = StreamingServer(\n            chat_log=chat_log,\n            voting_system=voting_system,\n            config=config.get('streaming', {})\n        )\n        await streaming_server.start()\n\n    try:\n        # Start the debate\n        print(f\"\\nüé≠ Starting AI Jubilee Debate: {topic}\")\n        print(f\"Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\n\")\n\n        await moderator.run_debate()\n\n    except KeyboardInterrupt:\n        print(\"\\n‚èπÔ∏è  Debate interrupted by user\")\n    except Exception as e:\n        print(f\"\\n‚ùå Error during debate: {e}\")\n    finally:\n        # Cleanup\n        if streaming_server:\n            await streaming_server.stop()\n\n        # Save transcript\n        if config.get('chat', {}).get('save_transcripts', True):\n            await chat_log.save_transcript(f\"debate_{topic[:20]}.json\")\n\n\n@click.command()\n@click.option('--topic', '-t', help='Debate topic')\n@click.option('--bots', '-b', default=2, help='Number of AI bots')\n@click.option('--humans', '-h', default=1, help='Number of human participants')\n@click.option('--config', '-c', default='config.yaml', help='Configuration file path')\ndef cli(topic: str, bots: int, humans: int, config: str):\n    \"\"\"Launch the AI Jubilee Debate System.\"\"\"\n    asyncio.run(start_debate_session(topic, bots, humans, config))\n\n\nif __name__ == \"__main__\":\n    cli()"
        },
        "moderator.py": {
          "type": "file",
          "path": "app/moderator.py",
          "extension": ".py",
          "size": 21382,
          "content": "\"\"\"\nModerator class for managing debate flow, rules, and coordination.\nNow acts as an AI-powered facilitator using the same system as other bots.\n\"\"\"\n\nimport asyncio\nimport time\nimport random\nfrom typing import List, Dict, Any, Optional\nfrom enum import Enum\nfrom dataclasses import dataclass\n\nfrom .chat_log import ChatLog, Message\nfrom .voting import VotingSystem\nfrom .utils import format_time_remaining\nfrom .bot_client import BotClient\nfrom app.bot_client import BotConfig\n\n\nclass DebatePhase(Enum):\n    INTRODUCTION = \"introduction\"\n    OPENING_STATEMENTS = \"opening_statements\"\n    DISCUSSION = \"discussion\"\n    CLOSING_STATEMENTS = \"closing_statements\"\n    VOTING = \"voting\"\n    RESULTS = \"results\"\n    FINISHED = \"finished\"\n\n\n@dataclass\nclass DebateState:\n    phase: DebatePhase\n    current_speaker: Optional[str] = None\n    time_remaining: int = 0\n    turn_order: List[str] = None\n    warnings_issued: Dict[str, int] = None\n\n    def __post_init__(self):\n        if self.turn_order is None:\n            self.turn_order = []\n        if self.warnings_issued is None:\n            self.warnings_issued = {}\n\n\nclass Moderator:\n    \"\"\"\n    AI-powered moderator that manages debate flow and provides intelligent facilitation.\n    Works just like other bots but with moderator-specific prompts.\n    \"\"\"\n\n    def __init__(self, topic: str, participants: List, chat_log: ChatLog,\n                 voting_system: VotingSystem, config: Dict[str, Any]):\n        self.topic = topic\n        self.participants = {p.name: p for p in participants}\n        self.chat_log = chat_log\n        self.voting_system = voting_system\n        self.config = config\n\n        # Initialize moderator as a bot client\n        moderator_config = config.get('moderator', {})\n\n        print(config)\n        self.moderator_bot = BotClient(\n            name=moderator_config.get('name', 'Moderator'),\n            model=moderator_config.get('model', 'gpt-3.5-turbo'),\n            provider=moderator_config.get('provider', 'openai'),\n            personality=moderator_config.get('personality', 'Professional debate facilitator'),\n            stance=moderator_config.get('stance', 'neutral'),\n            api_key=config['api_keys'].get(moderator_config.get('provider', 'openai'))\n        )\n\n        self.state = DebateState(\n            phase=DebatePhase.INTRODUCTION,\n            turn_order=list(self.participants.keys())\n        )\n\n        self.phase_times = {\n            DebatePhase.OPENING_STATEMENTS: config.get('opening_statement_time', 120),\n            DebatePhase.DISCUSSION: config.get('time_limit_minutes', 30) * 60,\n            DebatePhase.CLOSING_STATEMENTS: config.get('closing_statement_time', 90),\n            DebatePhase.VOTING: config.get('voting_duration', 300)\n        }\n\n        self.max_response_time = config.get('max_response_time', 120)\n        self.warning_time = config.get('warning_time', 90)\n\n        # Autonomous mode settings\n        self.autonomous_mode = config.get('mode', 'autonomous') == 'autonomous'\n        self.autonomous_tasks: List[asyncio.Task] = []\n        self.phase_task: Optional[asyncio.Task] = None\n\n        # Facilitation settings\n        self.silence_timeout = config.get('silence_timeout', 60)\n        self.last_activity_time = time.time()\n        self.last_moderator_prompt = 0\n\n    async def run_debate(self) -> Dict[str, Any]:\n        \"\"\"Run the complete debate session with autonomous support.\"\"\"\n        results = {}\n\n        try:\n            await self._introduction_phase()\n            await self._opening_statements_phase()\n\n            if self.autonomous_mode:\n                await self._autonomous_discussion_phase()\n            else:\n                await self._traditional_discussion_phase()\n\n            await self._closing_statements_phase()\n            results = await self._voting_phase()\n            await self._results_phase(results)\n\n        except Exception as e:\n            await self._broadcast_message(\n                f\"‚ö†Ô∏è Debate error: {e}. Ending session.\",\n                \"moderator\"\n            )\n            raise\n        finally:\n            if self.autonomous_mode:\n                await self._cleanup_autonomous_tasks()\n            self.state.phase = DebatePhase.FINISHED\n\n        return results\n\n    async def _autonomous_discussion_phase(self):\n        \"\"\"Autonomous discussion where bots and humans self-manage participation.\"\"\"\n        self.state.phase = DebatePhase.DISCUSSION\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\n\n        await self._broadcast_message(\n            f\"üöÄ AUTONOMOUS DISCUSSION PHASE BEGIN! ü§ñ\\n\\n\"\n            f\"üéØ How this works:\\n\"\n            f\"   ‚Ä¢ Bots are now monitoring the conversation continuously\\n\"\n            f\"   ‚Ä¢ They will decide when they feel compelled to respond\\n\"\n            f\"   ‚Ä¢ Humans can type messages at ANY TIME to join in\\n\"\n            f\"   ‚Ä¢ No turn-taking - completely organic conversation flow!\\n\"\n            f\"   ‚Ä¢ Everyone has access to full conversation history\\n\\n\"\n            f\"‚è∞ Discussion time: {total_time // 60} minutes\\n\"\n            f\"üé≠ Let the autonomous debate begin!\",\n            \"moderator\"\n        )\n\n        self.last_activity_time = time.time()\n        start_time = time.time()\n\n        # Start bot autonomous monitoring\n        await self._start_bot_autonomous_monitoring()\n\n        # Start human autonomous participation\n        await self._start_human_autonomous_participation()\n\n        # Start moderator autonomous monitoring\n        await self._start_moderator_autonomous_monitoring()\n\n        # Start phase management (facilitation only)\n        self.phase_task = asyncio.create_task(\n            self._facilitate_autonomous_discussion(start_time, total_time)\n        )\n\n        try:\n            await self.phase_task\n        except asyncio.CancelledError:\n            pass\n\n        await self._broadcast_message(\n            \"‚èπÔ∏è Autonomous discussion phase complete! üéâ\\n\"\n            \"Moving to closing statements...\",\n            \"moderator\"\n        )\n\n    async def _start_bot_autonomous_monitoring(self):\n        \"\"\"Start autonomous monitoring for all bots.\"\"\"\n        for participant_name, participant in self.participants.items():\n            if hasattr(participant, 'start_autonomous_monitoring'):  # It's a bot\n                task = asyncio.create_task(\n                    participant.start_autonomous_monitoring(self.chat_log, self.topic)\n                )\n                self.autonomous_tasks.append(task)\n\n    async def _start_human_autonomous_participation(self):\n        \"\"\"Start autonomous participation for humans.\"\"\"\n        for participant_name, participant in self.participants.items():\n            if hasattr(participant, 'autonomous_participation_loop'):  # It's a human\n                task = asyncio.create_task(\n                    participant.autonomous_participation_loop(self.chat_log)\n                )\n                self.autonomous_tasks.append(task)\n\n    async def _start_moderator_autonomous_monitoring(self):\n        \"\"\"Start moderator autonomous monitoring just like other bots.\"\"\"\n        task = asyncio.create_task(\n            self.moderator_bot.start_autonomous_monitoring(self.chat_log, self.topic)\n        )\n        self.autonomous_tasks.append(task)\n\n    async def _facilitate_autonomous_discussion(self, start_time: float, total_time: int):\n        \"\"\"Facilitate the autonomous discussion without controlling it.\"\"\"\n        last_message_count = len(self.chat_log.messages)\n\n        while time.time() - start_time < total_time:\n            await asyncio.sleep(15)  # Check every 15 seconds\n\n            current_time = time.time()\n            elapsed = current_time - start_time\n            remaining = total_time - elapsed\n\n            # Check for new activity\n            current_message_count = len(self.chat_log.messages)\n            if current_message_count > last_message_count:\n                self.last_activity_time = current_time\n                last_message_count = current_message_count\n\n            # Check for prolonged silence - provide simple prompts\n            silence_duration = current_time - self.last_activity_time\n            if silence_duration > self.silence_timeout:\n                # Simple fallback prompts if moderator bot hasn't spoken\n                if current_time - self.last_moderator_prompt > 45:\n                    await self._provide_simple_prompt()\n                    self.last_moderator_prompt = current_time\n\n            # Provide time updates\n            await self._provide_time_updates(remaining)\n\n    async def _provide_simple_prompt(self):\n        \"\"\"Provide simple facilitation prompts as fallback.\"\"\"\n        simple_prompts = [\n            \"üéØ What are your thoughts on the discussion so far?\",\n            \"üí° Any other perspectives to consider?\",\n            \"ü§î Does anyone have questions about the points raised?\",\n            \"‚öñÔ∏è How do you weigh the different arguments presented?\"\n        ]\n\n        prompt = random.choice(simple_prompts)\n        await self._broadcast_message(prompt, \"moderator\")\n\n    async def _provide_time_updates(self, remaining: float):\n        \"\"\"Provide time updates to participants.\"\"\"\n        if 299 < remaining <= 301:  # 5 minutes warning\n            await self._broadcast_message(\n                \"‚è∞ 5 minutes remaining in autonomous discussion phase\",\n                \"moderator\"\n            )\n        elif 119 < remaining <= 121:  # 2 minutes warning\n            await self._broadcast_message(\n                \"‚è∞ 2 minutes left! Perfect time for final thoughts on this topic\",\n                \"moderator\"\n            )\n        elif 59 < remaining <= 61:  # 1 minute warning\n            await self._broadcast_message(\n                \"‚è∞ Final minute! Any last contributions to the discussion?\",\n                \"moderator\"\n            )\n\n    async def _cleanup_autonomous_tasks(self):\n        \"\"\"Clean up all autonomous tasks.\"\"\"\n        # Stop bot monitoring (including moderator bot)\n        for participant in self.participants.values():\n            if hasattr(participant, 'stop_monitoring'):\n                await participant.stop_monitoring()\n\n        # Stop moderator bot monitoring\n        await self.moderator_bot.stop_monitoring()\n\n        # Cancel all autonomous tasks\n        for task in self.autonomous_tasks:\n            if not task.done():\n                task.cancel()\n                try:\n                    await task\n                except asyncio.CancelledError:\n                    pass\n\n        # Cancel phase management task\n        if self.phase_task and not self.phase_task.done():\n            self.phase_task.cancel()\n            try:\n                await self.phase_task\n            except asyncio.CancelledError:\n                pass\n\n        self.autonomous_tasks.clear()\n\n    # Traditional phases (structured)\n    async def _introduction_phase(self):\n        \"\"\"Introduce the debate topic and participants.\"\"\"\n        self.state.phase = DebatePhase.INTRODUCTION\n\n        participants_by_type = {\"Bots\": [], \"Humans\": []}\n        for name, participant in self.participants.items():\n            if isinstance(participant.config, BotConfig):  # Bot\n                stance = participant.config.stance\n                participants_by_type[\"Bots\"].append(f\"{name} ({stance})\")\n            else:  # Human or others\n                participants_by_type[\"Humans\"].append(name)\n\n        intro_message = (\n            f\"üé≠ Welcome to AI Jubilee Debate! üé≠\\n\\n\"\n            f\"üìù Topic: {self.topic}\\n\\n\"\n            f\"üë• Participants:\\n\"\n            f\"   ü§ñ AI Bots: {', '.join(participants_by_type['Bots'])}\\n\"\n            f\"   üë§ Humans: {', '.join(participants_by_type['Humans'])}\\n\\n\"\n            f\"‚è±Ô∏è Total discussion time: {self.config.get('time_limit_minutes', 30)} minutes\\n\"\n            f\"üéØ Mode: {'Autonomous (organic flow)' if self.autonomous_mode else 'Sequential (turn-based)'}\"\n        )\n\n        await self._broadcast_message(intro_message, \"moderator\")\n        await asyncio.sleep(3)\n\n    async def _opening_statements_phase(self):\n        \"\"\"Handle opening statements from each participant.\"\"\"\n        self.state.phase = DebatePhase.OPENING_STATEMENTS\n        statement_time = self.phase_times[DebatePhase.OPENING_STATEMENTS]\n\n        await self._broadcast_message(\n            f\"üé§ Opening Statements Phase\\n\"\n            f\"Each participant has {statement_time} seconds for their opening statement.\\n\"\n            f\"This phase uses structured turns regardless of debate mode.\",\n            \"moderator\"\n        )\n\n        for participant_name in self.state.turn_order:\n            await self._give_structured_turn(participant_name, statement_time, \"opening statement\")\n\n    async def _traditional_discussion_phase(self):\n        \"\"\"Traditional sequential discussion phase.\"\"\"\n        self.state.phase = DebatePhase.DISCUSSION\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\n\n        await self._broadcast_message(\n            f\"üí¨ Sequential Discussion Phase\\n\"\n            f\"Participants take turns for {total_time // 60} minutes.\",\n            \"moderator\"\n        )\n\n        start_time = time.time()\n        response_time = self.config.get('response_time', 60)\n\n        while time.time() - start_time < total_time:\n            for participant_name in self.state.turn_order:\n                if time.time() - start_time >= total_time:\n                    break\n\n                remaining = total_time - (time.time() - start_time)\n                if remaining < response_time:\n                    response_time = int(remaining)\n\n                await self._give_structured_turn(participant_name, response_time, \"response\")\n\n        await self._broadcast_message(\"‚èπÔ∏è Sequential discussion phase complete!\", \"moderator\")\n\n    async def _closing_statements_phase(self):\n        \"\"\"Handle closing statements.\"\"\"\n        self.state.phase = DebatePhase.CLOSING_STATEMENTS\n        statement_time = self.phase_times[DebatePhase.CLOSING_STATEMENTS]\n\n        await self._broadcast_message(\n            f\"üèÅ Closing Statements Phase\\n\"\n            f\"Each participant has {statement_time} seconds for final remarks.\\n\"\n            f\"This phase uses structured turns regardless of debate mode.\",\n            \"moderator\"\n        )\n\n        # Reverse order for closing statements\n        for participant_name in reversed(self.state.turn_order):\n            await self._give_structured_turn(participant_name, statement_time, \"closing statement\")\n\n    async def _give_structured_turn(self, participant_name: str, time_limit: int, turn_type: str):\n        \"\"\"Give structured speaking turn to a participant.\"\"\"\n        self.state.current_speaker = participant_name\n        self.state.time_remaining = time_limit\n\n        participant = self.participants[participant_name]\n\n        await self._broadcast_message(\n            f\"üé§ {participant_name}'s turn for {turn_type} ({time_limit}s)\",\n            \"moderator\"\n        )\n\n        try:\n            response_task = asyncio.create_task(\n                participant.get_response(self.topic, self.chat_log.get_recent_messages())\n            )\n\n            # Start timer\n            start_time = time.time()\n            warning_sent = False\n\n            while not response_task.done():\n                elapsed = time.time() - start_time\n                remaining = time_limit - elapsed\n\n                if remaining <= 0:\n                    response_task.cancel()\n                    try:\n                        await response_task\n                    except asyncio.CancelledError:\n                        pass\n                    await self._handle_timeout(participant_name)\n                    break\n\n                if not warning_sent and remaining <= self.warning_time:\n                    await self._send_warning(participant_name, remaining)\n                    warning_sent = True\n\n                await asyncio.sleep(0.5)\n\n            # Process response if completed successfully\n            if response_task.done() and not response_task.cancelled():\n                try:\n                    response = await response_task\n                    if response:\n                        await self._process_response(participant_name, response)\n                except Exception as e:\n                    await self._broadcast_message(\n                        f\"‚ö†Ô∏è Error getting response from {participant_name}: {e}\",\n                        \"moderator\"\n                    )\n\n        except Exception as e:\n            await self._broadcast_message(\n                f\"‚ö†Ô∏è Error during {participant_name}'s turn: {e}\",\n                \"moderator\"\n            )\n        finally:\n            self.state.current_speaker = None\n\n    async def _voting_phase(self) -> Dict[str, Any]:\n        \"\"\"Conduct voting on debate performance.\"\"\"\n        self.state.phase = DebatePhase.VOTING\n\n        if not self.voting_system.enabled:\n            await self._broadcast_message(\"Voting disabled. Debate complete!\", \"moderator\")\n            return {}\n\n        await self._broadcast_message(\n            f\"üó≥Ô∏è Voting Phase\\n\"\n            f\"Vote for the most persuasive participant. \"\n            f\"Voting closes in {self.phase_times[DebatePhase.VOTING]} seconds.\",\n            \"moderator\"\n        )\n\n        await self.voting_system.start_voting(\n            list(self.participants.keys()),\n            self.phase_times[DebatePhase.VOTING]\n        )\n\n        await asyncio.sleep(self.phase_times[DebatePhase.VOTING])\n\n        results = await self.voting_system.end_voting()\n        return results\n\n    async def _results_phase(self, voting_results: Dict[str, Any]):\n        \"\"\"Announce final results.\"\"\"\n        self.state.phase = DebatePhase.RESULTS\n\n        if voting_results:\n            winner = voting_results.get('winner')\n            vote_counts = voting_results.get('vote_counts', {})\n\n            results_msg = \"üèÜ DEBATE RESULTS üèÜ\\n\"\n            results_msg += f\"Winner: {winner}\\n\\n\"\n            results_msg += \"Vote Breakdown:\\n\"\n\n            for participant, votes in sorted(vote_counts.items(),\n                                           key=lambda x: x[1], reverse=True):\n                results_msg += f\"  {participant}: {votes} votes\\n\"\n        else:\n            results_msg = \"ü§ù Debate concluded without voting. Great discussion everyone!\"\n\n        await self._broadcast_message(results_msg, \"moderator\")\n\n        # Show participation statistics\n        stats_msg = \"\\nüìä PARTICIPATION STATISTICS:\\n\"\n        for participant_name, participant in self.participants.items():\n            if hasattr(participant, 'get_stats'):\n                stats = participant.get_stats()\n                if hasattr(participant, 'config'):  # Bot\n                    stats_msg += f\"ü§ñ {participant_name}: {stats.get('autonomous_responses', 0)} autonomous responses, \"\n                    stats_msg += f\"{stats.get('success_rate', 0):.1%} success rate\\n\"\n                else:  # Human\n                    stats_msg += f\"üë§ {participant_name}: {stats.get('responses_given', 0)} responses, \"\n                    stats_msg += f\"{stats.get('participation_rate', 0):.1%} participation rate\\n\"\n\n        # Show moderator stats\n        moderator_stats = self.moderator_bot.get_stats()\n        stats_msg += f\"üé≠ Moderator: {moderator_stats.get('autonomous_responses', 0)} facilitation prompts\\n\"\n\n        await self._broadcast_message(stats_msg, \"moderator\")\n        await self._broadcast_message(\"Thank you for participating in AI Jubilee Debate! üé≠‚ú®\", \"moderator\")\n\n    # Utility methods\n    async def _process_response(self, participant_name: str, response: str):\n        \"\"\"Process and validate participant response.\"\"\"\n        if len(response) > self.config.get('max_message_length', 5000):\n            response = response[:self.config.get('max_message_length', 5000)] + \"...\"\n            await self._broadcast_message(\n                f\"‚ö†Ô∏è {participant_name}'s response was truncated due to length\",\n                \"moderator\"\n            )\n\n        await self.chat_log.add_message(participant_name, response)\n\n    async def _handle_timeout(self, participant_name: str):\n        \"\"\"Handle participant timeout.\"\"\"\n        self.state.warnings_issued[participant_name] = (\n            self.state.warnings_issued.get(participant_name, 0) + 1\n        )\n\n        await self._broadcast_message(\n            f\"‚è∞ {participant_name} exceeded time limit. \"\n            f\"Warning {self.state.warnings_issued[participant_name]}/3\",\n            \"moderator\"\n        )\n\n    async def _send_warning(self, participant_name: str, time_remaining: float):\n        \"\"\"Send time warning to participant.\"\"\"\n        await self._broadcast_message(\n            f\"‚è∞ {participant_name}: {int(time_remaining)} seconds remaining\",\n            \"moderator\"\n        )\n\n    async def _broadcast_message(self, content: str, sender: str = \"moderator\"):\n        \"\"\"Broadcast message to all participants and log.\"\"\"\n        message = await self.chat_log.add_message(sender, content, message_type=\"moderator\")\n\n        # Send to all participants\n        for participant in self.participants.values():\n            try:\n                await participant.receive_message(message)\n            except Exception as e:\n                print(f\"Failed to send message to {participant.name}: {e}\")\n\n    def get_state(self) -> DebateState:\n        \"\"\"Get current debate state.\"\"\"\n        return self.state"
        },
        "streaming.py": {
          "type": "file",
          "path": "app/streaming.py",
          "extension": ".py",
          "size": 15845,
          "content": "\"\"\"\nLive streaming and WebSocket server for real-time debate broadcasting.\n\"\"\"\n\nimport asyncio\nimport json\nimport time\nimport logging\nfrom typing import Dict, List, Set, Any, Optional\nfrom dataclasses import dataclass, asdict\nimport websockets\nfrom websockets.server import WebSocketServerProtocol\n\nfrom .chat_log import ChatLog, Message\nfrom .voting import VotingSystem\nfrom .utils import format_time_remaining\n\n\n@dataclass\nclass StreamingClient:\n    \"\"\"Information about a connected streaming client.\"\"\"\n    websocket: WebSocketServerProtocol\n    client_id: str\n    connected_at: float\n    client_type: str = \"viewer\"  # viewer, participant, moderator\n    metadata: Dict[str, Any] = None\n\n    def __post_init__(self):\n        if self.metadata is None:\n            self.metadata = {}\n\n\nclass StreamingServer:\n    \"\"\"\n    WebSocket server for live streaming debate sessions.\n    \"\"\"\n\n    def __init__(self, chat_log: ChatLog, voting_system: VotingSystem,\n                 config: Dict[str, Any]):\n        self.chat_log = chat_log\n        self.voting_system = voting_system\n        self.config = config\n\n        self.host = config.get('host', 'localhost')\n        self.port = config.get('websocket_port', 8080)\n        self.max_connections = config.get('max_connections', 100)\n        self.broadcast_votes = config.get('broadcast_votes', True)\n\n        # Server state\n        self.server = None\n        self.clients: Dict[str, StreamingClient] = {}\n        self.is_running = False\n\n        # Message subscription\n        self.message_queue = None\n        self.broadcast_task = None\n\n        # Statistics\n        self.stats = {\n            'total_connections': 0,\n            'messages_sent': 0,\n            'votes_broadcast': 0,\n            'start_time': time.time()\n        }\n\n        self.logger = logging.getLogger(__name__)\n\n    async def start(self) -> None:\n        \"\"\"Start the streaming server.\"\"\"\n        if self.is_running:\n            return\n\n        try:\n            # Subscribe to chat log messages\n            self.message_queue = self.chat_log.subscribe()\n\n            # Start WebSocket server\n            self.server = await websockets.serve(\n                self._handle_client,\n                self.host,\n                self.port,\n                max_size=1024 * 1024,  # 1MB max message size\n                ping_interval=20,\n                ping_timeout=10\n            )\n\n            # Start broadcast task\n            self.broadcast_task = asyncio.create_task(self._broadcast_loop())\n\n            self.is_running = True\n            self.logger.info(f\"Streaming server started on {self.host}:{self.port}\")\n\n        except Exception as e:\n            self.logger.error(f\"Failed to start streaming server: {e}\")\n            raise\n\n    async def stop(self) -> None:\n        \"\"\"Stop the streaming server.\"\"\"\n        if not self.is_running:\n            return\n\n        self.is_running = False\n\n        # Stop broadcast task\n        if self.broadcast_task:\n            self.broadcast_task.cancel()\n            try:\n                await self.broadcast_task\n            except asyncio.CancelledError:\n                pass\n\n        # Close all client connections\n        if self.clients:\n            await asyncio.gather(\n                *[client.websocket.close() for client in self.clients.values()],\n                return_exceptions=True\n            )\n\n        # Stop WebSocket server\n        if self.server:\n            self.server.close()\n            await self.server.wait_closed()\n\n        # Unsubscribe from chat log\n        if self.message_queue:\n            self.chat_log.unsubscribe(self.message_queue)\n\n        self.logger.info(\"Streaming server stopped\")\n\n    async def _handle_client(self, websocket: WebSocketServerProtocol, path: str):\n        \"\"\"Handle new client connection.\"\"\"\n        if len(self.clients) >= self.max_connections:\n            await websocket.close(code=1013, reason=\"Server full\")\n            return\n\n        client_id = f\"client_{int(time.time() * 1000)}\"\n        client = StreamingClient(\n            websocket=websocket,\n            client_id=client_id,\n            connected_at=time.time()\n        )\n\n        self.clients[client_id] = client\n        self.stats['total_connections'] += 1\n\n        self.logger.info(f\"Client {client_id} connected from {websocket.remote_address}\")\n\n        try:\n            # Send welcome message\n            await self._send_to_client(client, {\n                'type': 'welcome',\n                'client_id': client_id,\n                'server_info': {\n                    'version': '1.0.0',\n                    'features': ['chat', 'voting', 'real_time']\n                }\n            })\n\n            # Send recent messages\n            recent_messages = self.chat_log.get_recent_messages(10)\n            for msg in recent_messages:\n                await self._send_to_client(client, {\n                    'type': 'message',\n                    'data': msg.to_dict()\n                })\n\n            # Handle client messages\n            async for message in websocket:\n                try:\n                    await self._process_client_message(client, json.loads(message))\n                except json.JSONDecodeError:\n                    await self._send_error(client, \"Invalid JSON message\")\n                except Exception as e:\n                    self.logger.error(f\"Error processing client message: {e}\")\n                    await self._send_error(client, \"Internal server error\")\n\n        except websockets.exceptions.ConnectionClosed:\n            self.logger.info(f\"Client {client_id} disconnected\")\n        except Exception as e:\n            self.logger.error(f\"Client {client_id} error: {e}\")\n        finally:\n            # Clean up client\n            if client_id in self.clients:\n                del self.clients[client_id]\n\n    async def _process_client_message(self, client: StreamingClient, data: Dict[str, Any]):\n        \"\"\"Process message from client.\"\"\"\n        message_type = data.get('type')\n\n        if message_type == 'ping':\n            await self._send_to_client(client, {'type': 'pong'})\n\n        elif message_type == 'subscribe':\n            # Update client subscription preferences\n            client.metadata['subscriptions'] = data.get('channels', [])\n            await self._send_to_client(client, {\n                'type': 'subscribed',\n                'channels': client.metadata.get('subscriptions', [])\n            })\n\n        elif message_type == 'get_stats':\n            # Send server statistics\n            await self._send_to_client(client, {\n                'type': 'stats',\n                'data': self._get_server_stats()\n            })\n\n        elif message_type == 'vote' and self.voting_system.is_active:\n            # Handle vote from client\n            voter_id = data.get('voter_id', client.client_id)\n            candidate = data.get('candidate')\n            justification = data.get('justification')\n\n            try:\n                success = await self.voting_system.cast_vote(\n                    voter_id, candidate, justification\n                )\n\n                await self._send_to_client(client, {\n                    'type': 'vote_result',\n                    'success': success,\n                    'candidate': candidate\n                })\n\n                if success and self.broadcast_votes:\n                    await self._broadcast_vote_update()\n\n            except Exception as e:\n                await self._send_error(client, f\"Vote failed: {e}\")\n\n        else:\n            await self._send_error(client, f\"Unknown message type: {message_type}\")\n\n    async def _broadcast_loop(self):\n        \"\"\"Main broadcast loop for new messages.\"\"\"\n        try:\n            while self.is_running:\n                try:\n                    # Wait for new message from chat log\n                    message = await asyncio.wait_for(\n                        self.message_queue.get(),\n                        timeout=1.0\n                    )\n\n                    # Broadcast to all clients\n                    await self._broadcast_message(message)\n\n                except asyncio.TimeoutError:\n                    # Timeout is expected, continue loop\n                    continue\n                except Exception as e:\n                    self.logger.error(f\"Broadcast loop error: {e}\")\n                    await asyncio.sleep(1)\n\n        except asyncio.CancelledError:\n            self.logger.info(\"Broadcast loop cancelled\")\n\n    async def _broadcast_message(self, message: Message):\n        \"\"\"Broadcast message to all connected clients.\"\"\"\n        if not self.clients:\n            return\n\n        broadcast_data = {\n            'type': 'message',\n            'data': message.to_dict()\n        }\n\n        # Send to all clients\n        tasks = []\n        for client in list(self.clients.values()):\n            if self._should_send_to_client(client, message):\n                tasks.append(self._send_to_client(client, broadcast_data))\n\n        if tasks:\n            await asyncio.gather(*tasks, return_exceptions=True)\n            self.stats['messages_sent'] += len(tasks)\n\n    def _should_send_to_client(self, client: StreamingClient, message: Message) -> bool:\n        \"\"\"Determine if message should be sent to client.\"\"\"\n        # Check client subscriptions\n        subscriptions = client.metadata.get('subscriptions', [])\n\n        if subscriptions:\n            # If client has specific subscriptions, check them\n            if message.message_type not in subscriptions:\n                return False\n\n        return True\n\n    async def _broadcast_vote_update(self):\n        \"\"\"Broadcast voting update to clients.\"\"\"\n        if not self.voting_system.is_active:\n            return\n\n        vote_summary = self.voting_system.get_vote_summary()\n\n        broadcast_data = {\n            'type': 'vote_update',\n            'data': vote_summary\n        }\n\n        tasks = []\n        for client in list(self.clients.values()):\n            tasks.append(self._send_to_client(client, broadcast_data))\n\n        if tasks:\n            await asyncio.gather(*tasks, return_exceptions=True)\n            self.stats['votes_broadcast'] += 1\n\n    async def _send_to_client(self, client: StreamingClient, data: Dict[str, Any]):\n        \"\"\"Send data to specific client.\"\"\"\n        try:\n            await client.websocket.send(json.dumps(data))\n        except websockets.exceptions.ConnectionClosed:\n            # Client disconnected, will be cleaned up\n            pass\n        except Exception as e:\n            self.logger.error(f\"Failed to send to client {client.client_id}: {e}\")\n\n    async def _send_error(self, client: StreamingClient, error_message: str):\n        \"\"\"Send error message to client.\"\"\"\n        await self._send_to_client(client, {\n            'type': 'error',\n            'message': error_message\n        })\n\n    def _get_server_stats(self) -> Dict[str, Any]:\n        \"\"\"Get server statistics.\"\"\"\n        uptime = time.time() - self.stats['start_time']\n\n        return {\n            'connected_clients': len(self.clients),\n            'total_connections': self.stats['total_connections'],\n            'messages_sent': self.stats['messages_sent'],\n            'votes_broadcast': self.stats['votes_broadcast'],\n            'uptime_seconds': uptime,\n            'uptime_formatted': format_time_remaining(uptime),\n            'is_voting_active': self.voting_system.is_active if self.voting_system else False\n        }\n\n    async def broadcast_custom_message(self, message_type: str, data: Any):\n        \"\"\"Broadcast custom message to all clients.\"\"\"\n        broadcast_data = {\n            'type': message_type,\n            'data': data,\n            'timestamp': time.time()\n        }\n\n        tasks = []\n        for client in list(self.clients.values()):\n            tasks.append(self._send_to_client(client, broadcast_data))\n\n        if tasks:\n            await asyncio.gather(*tasks, return_exceptions=True)\n\n    async def send_to_specific_clients(self, client_ids: List[str],\n                                       message_type: str, data: Any):\n        \"\"\"Send message to specific clients.\"\"\"\n        message = {\n            'type': message_type,\n            'data': data,\n            'timestamp': time.time()\n        }\n\n        tasks = []\n        for client_id in client_ids:\n            if client_id in self.clients:\n                client = self.clients[client_id]\n                tasks.append(self._send_to_client(client, message))\n\n        if tasks:\n            await asyncio.gather(*tasks, return_exceptions=True)\n\n    def get_connected_clients(self) -> List[Dict[str, Any]]:\n        \"\"\"Get information about connected clients.\"\"\"\n        return [\n            {\n                'client_id': client.client_id,\n                'connected_at': client.connected_at,\n                'client_type': client.client_type,\n                'connection_duration': time.time() - client.connected_at\n            }\n            for client in self.clients.values()\n        ]\n\n    @property\n    def is_active(self) -> bool:\n        \"\"\"Check if server is running.\"\"\"\n        return self.is_running\n\n    @property\n    def client_count(self) -> int:\n        \"\"\"Get number of connected clients.\"\"\"\n        return len(self.clients)\n\n\nclass StreamingManager:\n    \"\"\"\n    High-level manager for streaming functionality.\n    \"\"\"\n\n    def __init__(self):\n        self.servers: Dict[str, StreamingServer] = {}\n        self.is_initialized = False\n\n    async def create_streaming_session(self, session_id: str, chat_log: ChatLog,\n                                       voting_system: VotingSystem,\n                                       config: Dict[str, Any]) -> StreamingServer:\n        \"\"\"\n        Create a new streaming session.\n\n        Args:\n            session_id: Unique session identifier\n            chat_log: Chat log to stream\n            voting_system: Voting system to integrate\n            config: Streaming configuration\n\n        Returns:\n            StreamingServer instance\n        \"\"\"\n        if session_id in self.servers:\n            raise ValueError(f\"Streaming session {session_id} already exists\")\n\n        # Create unique port for this session\n        base_port = config.get('websocket_port', 8080)\n        port = base_port + len(self.servers)\n\n        session_config = config.copy()\n        session_config['websocket_port'] = port\n\n        server = StreamingServer(chat_log, voting_system, session_config)\n        self.servers[session_id] = server\n\n        await server.start()\n        return server\n\n    async def stop_streaming_session(self, session_id: str):\n        \"\"\"Stop a streaming session.\"\"\"\n        if session_id in self.servers:\n            server = self.servers[session_id]\n            await server.stop()\n            del self.servers[session_id]\n\n    async def stop_all_sessions(self):\n        \"\"\"Stop all streaming sessions.\"\"\"\n        tasks = []\n        for session_id in list(self.servers.keys()):\n            tasks.append(self.stop_streaming_session(session_id))\n\n        if tasks:\n            await asyncio.gather(*tasks, return_exceptions=True)\n\n    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"Get information about a streaming session.\"\"\"\n        if session_id not in self.servers:\n            return None\n\n        server = self.servers[session_id]\n        return {\n            'session_id': session_id,\n            'is_active': server.is_active,\n            'client_count': server.client_count,\n            'host': server.host,\n            'port': server.port,\n            'stats': server._get_server_stats()\n        }\n\n    def list_active_sessions(self) -> List[str]:\n        \"\"\"Get list of active session IDs.\"\"\"\n        return [\n            session_id for session_id, server in self.servers.items()\n            if server.is_active\n        ]"
        },
        "utils.py": {
          "type": "file",
          "path": "app/utils.py",
          "extension": ".py",
          "size": 10954,
          "content": "\"\"\"\nUtility functions for the AI Jubilee Debate System.\n\"\"\"\n\nimport os\nimport yaml\nimport logging\nimport time\nimport re\nfrom typing import Dict, Any, List, Optional\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\n\n\ndef load_config(config_path: str = \"config.yaml\") -> Dict[str, Any]:\n    \"\"\"\n    Load configuration from YAML file with environment variable substitution.\n\n    Args:\n        config_path: Path to configuration file\n\n    Returns:\n        Configuration dictionary\n    \"\"\"\n    config_file = Path(config_path)\n\n    if not config_file.exists():\n        raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n\n    with open(config_file, 'r', encoding='utf-8') as f:\n        config_content = f.read()\n\n    # Substitute environment variables\n    config_content = substitute_env_vars(config_content)\n\n    try:\n        config = yaml.safe_load(config_content)\n        return config\n    except yaml.YAMLError as e:\n        raise ValueError(f\"Invalid YAML configuration: {e}\")\n\n\ndef substitute_env_vars(text: str) -> str:\n    \"\"\"\n    Substitute environment variables in text using ${VAR_NAME} syntax.\n\n    Args:\n        text: Text containing environment variable references\n\n    Returns:\n        Text with environment variables substituted\n    \"\"\"\n    def replace_env_var(match):\n        var_name = match.group(1)\n        env_value = os.getenv(var_name)\n        if env_value is None:\n            print(f\"Warning: Environment variable {var_name} not found\")\n            return f\"${{{var_name}}}\"  # Keep original if not found\n        return env_value\n\n    return re.sub(r'\\$\\{([^}]+)\\}', replace_env_var, text)\n\n\ndef setup_logging(level: str = \"INFO\", log_file: Optional[str] = None) -> None:\n    \"\"\"\n    Setup logging configuration.\n\n    Args:\n        level: Logging level (DEBUG, INFO, WARNING, ERROR)\n        log_file: Optional log file path\n    \"\"\"\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\n\n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n\n    # Setup root logger\n    root_logger = logging.getLogger()\n    root_logger.setLevel(numeric_level)\n\n    # Clear existing handlers\n    root_logger.handlers.clear()\n\n    # Console handler\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    root_logger.addHandler(console_handler)\n\n    # File handler if specified\n    if log_file:\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setFormatter(formatter)\n        root_logger.addHandler(file_handler)\n\n\ndef format_time_remaining(seconds: float) -> str:\n    \"\"\"\n    Format remaining time in human-readable format.\n\n    Args:\n        seconds: Time remaining in seconds\n\n    Returns:\n        Formatted time string\n    \"\"\"\n    if seconds <= 0:\n        return \"Time's up!\"\n\n    if seconds < 60:\n        return f\"{int(seconds)} seconds\"\n    elif seconds < 3600:\n        minutes = int(seconds // 60)\n        secs = int(seconds % 60)\n        return f\"{minutes}m {secs}s\"\n    else:\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        return f\"{hours}h {minutes}m\"\n\n\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \"...\") -> str:\n    \"\"\"\n    Truncate text to maximum length with suffix.\n\n    Args:\n        text: Text to truncate\n        max_length: Maximum length\n        suffix: Suffix to add when truncating\n\n    Returns:\n        Truncated text\n    \"\"\"\n    if len(text) <= max_length:\n        return text\n\n    return text[:max_length - len(suffix)] + suffix\n\n\ndef generate_debate_prompt(topic: str, role: str, personality: str) -> str:\n    \"\"\"\n    Generate a debate prompt for AI participants.\n\n    Args:\n        topic: Debate topic\n        role: Participant role (pro, con, neutral)\n        personality: Personality description\n\n    Returns:\n        Generated prompt\n    \"\"\"\n    base_prompt = f\"\"\"You are participating in a structured debate on the topic: \"{topic}\"\n\nYour role: {role}\nYour personality: {personality}\n\nInstructions:\n1. Present clear, logical arguments\n2. Respond to other participants' points\n3. Stay focused on the topic\n4. Be respectful but persuasive\n5. Keep responses concise and engaging\n\nCurrent debate topic: {topic}\n\"\"\"\n\n    if role.lower() == \"pro\":\n        base_prompt += \"\\nYou should argue IN FAVOR of the topic.\"\n    elif role.lower() == \"con\":\n        base_prompt += \"\\nYou should argue AGAINST the topic.\"\n    elif role.lower() == \"neutral\":\n        base_prompt += \"\\nYou should present balanced perspectives and ask probing questions.\"\n\n    return base_prompt\n\n\ndef validate_participant_name(name: str) -> bool:\n    \"\"\"\n    Validate participant name.\n\n    Args:\n        name: Participant name to validate\n\n    Returns:\n        True if valid, False otherwise\n    \"\"\"\n    if not name or len(name.strip()) == 0:\n        return False\n\n    # Check length\n    if len(name) > 50:\n        return False\n\n    # Check for valid characters (alphanumeric, spaces, underscores, hyphens)\n    if not re.match(r'^[a-zA-Z0-9\\s_-]+$', name):\n        return False\n\n    return True\n\n\ndef sanitize_filename(filename: str) -> str:\n    \"\"\"\n    Sanitize filename for safe file operations.\n\n    Args:\n        filename: Original filename\n\n    Returns:\n        Sanitized filename\n    \"\"\"\n    # Remove or replace invalid characters\n    sanitized = re.sub(r'[<>:\"/\\\\|?*]', '_', filename)\n\n    # Remove leading/trailing spaces and dots\n    sanitized = sanitized.strip(' .')\n\n    # Limit length\n    if len(sanitized) > 255:\n        sanitized = sanitized[:255]\n\n    return sanitized\n\n\ndef parse_duration(duration_str: str) -> int:\n    \"\"\"\n    Parse duration string into seconds.\n\n    Args:\n        duration_str: Duration string (e.g., \"5m\", \"30s\", \"1h30m\")\n\n    Returns:\n        Duration in seconds\n    \"\"\"\n    if duration_str.isdigit():\n        return int(duration_str)\n\n    total_seconds = 0\n\n    # Parse hours\n    hours_match = re.search(r'(\\d+)h', duration_str.lower())\n    if hours_match:\n        total_seconds += int(hours_match.group(1)) * 3600\n\n    # Parse minutes\n    minutes_match = re.search(r'(\\d+)m', duration_str.lower())\n    if minutes_match:\n        total_seconds += int(minutes_match.group(1)) * 60\n\n    # Parse seconds\n    seconds_match = re.search(r'(\\d+)s', duration_str.lower())\n    if seconds_match:\n        total_seconds += int(seconds_match.group(1))\n\n    return total_seconds if total_seconds > 0 else 60  # Default to 60 seconds\n\n\ndef create_timestamp() -> str:\n    \"\"\"\n    Create ISO format timestamp.\n\n    Returns:\n        ISO formatted timestamp string\n    \"\"\"\n    return datetime.now().isoformat()\n\n\ndef format_participant_list(participants: List[str], max_display: int = 5) -> str:\n    \"\"\"\n    Format participant list for display.\n\n    Args:\n        participants: List of participant names\n        max_display: Maximum participants to display before truncating\n\n    Returns:\n        Formatted participant string\n    \"\"\"\n    if len(participants) <= max_display:\n        return \", \".join(participants)\n\n    displayed = participants[:max_display]\n    remaining = len(participants) - max_display\n\n    return f\"{', '.join(displayed)} (+{remaining} more)\"\n\n\ndef calculate_word_count(text: str) -> int:\n    \"\"\"\n    Calculate word count in text.\n\n    Args:\n        text: Text to count words in\n\n    Returns:\n        Number of words\n    \"\"\"\n    return len(text.split())\n\n\ndef extract_key_phrases(text: str, max_phrases: int = 5) -> List[str]:\n    \"\"\"\n    Extract key phrases from text (simple implementation).\n\n    Args:\n        text: Text to extract phrases from\n        max_phrases: Maximum number of phrases to return\n\n    Returns:\n        List of key phrases\n    \"\"\"\n    # Simple implementation - could be enhanced with NLP\n    sentences = text.split('.')\n    phrases = []\n\n    for sentence in sentences[:max_phrases]:\n        sentence = sentence.strip()\n        if len(sentence) > 10:  # Minimum length\n            phrases.append(sentence)\n\n    return phrases[:max_phrases]\n\n\ndef generate_session_id() -> str:\n    \"\"\"\n    Generate unique session ID.\n\n    Returns:\n        Unique session identifier\n    \"\"\"\n    import uuid\n    return str(uuid.uuid4())[:8]\n\n\ndef ensure_directory(path: str) -> Path:\n    \"\"\"\n    Ensure directory exists, create if necessary.\n\n    Args:\n        path: Directory path\n\n    Returns:\n        Path object\n    \"\"\"\n    dir_path = Path(path)\n    dir_path.mkdir(parents=True, exist_ok=True)\n    return dir_path\n\n\ndef load_debate_topics(topics_file: str = \"topics.txt\") -> List[str]:\n    \"\"\"\n    Load debate topics from file.\n\n    Args:\n        topics_file: Path to topics file\n\n    Returns:\n        List of debate topics\n    \"\"\"\n    topics_path = Path(topics_file)\n\n    if not topics_path.exists():\n        # Return default topics\n        return [\n            \"Artificial intelligence will create more jobs than it destroys\",\n            \"Social media has a net positive impact on society\",\n            \"Universal Basic Income is necessary for the future economy\",\n            \"Climate change requires immediate radical action\",\n            \"Privacy is more important than security\"\n        ]\n\n    with open(topics_path, 'r', encoding='utf-8') as f:\n        topics = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n\n    return topics\n\n\nclass PerformanceTimer:\n    \"\"\"Context manager for timing operations.\"\"\"\n\n    def __init__(self, operation_name: str = \"Operation\"):\n        self.operation_name = operation_name\n        self.start_time = None\n        self.end_time = None\n\n    def __enter__(self):\n        self.start_time = time.time()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.end_time = time.time()\n\n    @property\n    def duration(self) -> float:\n        \"\"\"Get operation duration in seconds.\"\"\"\n        if self.start_time and self.end_time:\n            return self.end_time - self.start_time\n        return 0.0\n\n    def __str__(self) -> str:\n        return f\"{self.operation_name}: {self.duration:.3f}s\"\n\n\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\n    \"\"\"\n    Decorator for retrying operations with exponential backoff.\n\n    Args:\n        max_retries: Maximum number of retry attempts\n        base_delay: Base delay between retries\n    \"\"\"\n    def decorator(func):\n        async def wrapper(*args, **kwargs):\n            last_exception = None\n\n            for attempt in range(max_retries + 1):\n                try:\n                    return await func(*args, **kwargs)\n                except Exception as e:\n                    last_exception = e\n\n                    if attempt < max_retries:\n                        delay = base_delay * (2 ** attempt)\n                        await asyncio.sleep(delay)\n                    else:\n                        raise last_exception\n\n            raise last_exception\n\n        return wrapper\n    return decorator"
        },
        "voting.py": {
          "type": "file",
          "path": "app/voting.py",
          "extension": ".py",
          "size": 11436,
          "content": "\"\"\"\nVoting system for debate evaluation and winner determination.\n\"\"\"\n\nimport asyncio\nimport time\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, field\nfrom collections import defaultdict, Counter\n\n\n@dataclass\nclass Vote:\n    \"\"\"Represents a single vote.\"\"\"\n    voter_id: str\n    candidate: str\n    justification: Optional[str] = None\n    timestamp: float = field(default_factory=time.time)\n    anonymous: bool = False\n\n\n@dataclass\nclass VotingResults:\n    \"\"\"Results of a voting session.\"\"\"\n    winner: Optional[str]\n    vote_counts: Dict[str, int]\n    total_votes: int\n    votes_by_voter: Dict[str, Vote]\n    voting_duration: float\n    participation_rate: float\n\n\nclass VotingSystem:\n    \"\"\"\n    Manages voting process, vote collection, and result calculation.\n    \"\"\"\n\n    def __init__(self, config: Dict[str, Any]):\n        self.config = config\n        self.enabled = config.get('enabled', True)\n        self.voting_duration = config.get('voting_duration', 300)\n        self.allow_participant_voting = config.get('allow_participant_voting', True)\n        self.require_justification = config.get('require_justification', True)\n        self.anonymous_votes = config.get('anonymous_votes', False)\n\n        # Voting state\n        self.is_active = False\n        self.candidates: List[str] = []\n        self.eligible_voters: List[str] = []\n        self.votes: Dict[str, Vote] = {}\n        self.start_time: Optional[float] = None\n        self.end_time: Optional[float] = None\n\n        # Vote validation\n        self.vote_history: List[Dict[str, Any]] = []\n\n    async def start_voting(self, candidates: List[str], duration: Optional[int] = None) -> None:\n        \"\"\"\n        Start a voting session.\n\n        Args:\n            candidates: List of debate participants to vote for\n            duration: Voting duration in seconds (uses config default if None)\n        \"\"\"\n        if not self.enabled:\n            raise ValueError(\"Voting system is disabled\")\n\n        if self.is_active:\n            raise ValueError(\"Voting session already active\")\n\n        self.candidates = candidates.copy()\n        self.eligible_voters = candidates.copy() if self.allow_participant_voting else []\n        self.votes = {}\n        self.start_time = time.time()\n        self.end_time = self.start_time + (duration or self.voting_duration)\n        self.is_active = True\n\n        print(f\"üó≥Ô∏è Voting started for {len(candidates)} candidates\")\n        print(f\"‚è∞ Voting closes in {duration or self.voting_duration} seconds\")\n\n    async def cast_vote(self, voter_id: str, candidate: str,\n                        justification: Optional[str] = None) -> bool:\n        \"\"\"\n        Cast a vote for a candidate.\n\n        Args:\n            voter_id: ID of the voter\n            candidate: Candidate being voted for\n            justification: Optional reasoning for the vote\n\n        Returns:\n            True if vote was successfully cast, False otherwise\n        \"\"\"\n        if not self.is_active:\n            raise ValueError(\"No active voting session\")\n\n        if time.time() > self.end_time:\n            raise ValueError(\"Voting period has ended\")\n\n        # Validate voter eligibility\n        if not self._is_eligible_voter(voter_id):\n            raise ValueError(f\"Voter {voter_id} is not eligible to vote\")\n\n        # Validate candidate\n        if candidate not in self.candidates:\n            raise ValueError(f\"Invalid candidate: {candidate}\")\n\n        # Check for self-voting\n        if voter_id == candidate and not self.allow_participant_voting:\n            raise ValueError(\"Self-voting is not allowed\")\n\n        # Validate justification requirement\n        if self.require_justification and not justification:\n            raise ValueError(\"Vote justification is required\")\n\n        # Record the vote (overwrites previous vote from same voter)\n        vote = Vote(\n            voter_id=voter_id,\n            candidate=candidate,\n            justification=justification,\n            anonymous=self.anonymous_votes\n        )\n\n        self.votes[voter_id] = vote\n\n        print(f\"‚úÖ Vote recorded: {voter_id} -> {candidate}\")\n        return True\n\n    async def end_voting(self) -> VotingResults:\n        \"\"\"\n        End the voting session and calculate results.\n\n        Returns:\n            VotingResults object with winner and vote breakdown\n        \"\"\"\n        if not self.is_active:\n            raise ValueError(\"No active voting session\")\n\n        self.is_active = False\n        actual_end_time = time.time()\n\n        # Calculate vote counts\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\n        total_votes = len(self.votes)\n\n        # Determine winner\n        winner = None\n        if vote_counts:\n            max_votes = max(vote_counts.values())\n            winners = [candidate for candidate, count in vote_counts.items()\n                       if count == max_votes]\n\n            if len(winners) == 1:\n                winner = winners[0]\n            else:\n                # Handle tie - could implement tiebreaker logic here\n                winner = f\"TIE: {', '.join(winners)}\"\n\n        # Calculate participation rate\n        participation_rate = (total_votes / len(self.eligible_voters)\n                              if self.eligible_voters else 0)\n\n        # Create results\n        results = VotingResults(\n            winner=winner,\n            vote_counts=dict(vote_counts),\n            total_votes=total_votes,\n            votes_by_voter=self.votes.copy(),\n            voting_duration=actual_end_time - self.start_time,\n            participation_rate=participation_rate\n        )\n\n        # Store in history\n        self.vote_history.append({\n            'timestamp': actual_end_time,\n            'candidates': self.candidates.copy(),\n            'results': results\n        })\n\n        print(f\"üèÜ Voting ended. Winner: {winner}\")\n        print(f\"üìä Total votes: {total_votes}\")\n        print(f\"üìà Participation: {participation_rate:.1%}\")\n\n        return results\n\n    def _is_eligible_voter(self, voter_id: str) -> bool:\n        \"\"\"Check if a voter is eligible to vote.\"\"\"\n        if not self.eligible_voters:\n            return True  # Open voting\n        return voter_id in self.eligible_voters\n\n    def add_eligible_voter(self, voter_id: str) -> None:\n        \"\"\"Add a voter to the eligible voters list.\"\"\"\n        if voter_id not in self.eligible_voters:\n            self.eligible_voters.append(voter_id)\n\n    def remove_eligible_voter(self, voter_id: str) -> None:\n        \"\"\"Remove a voter from the eligible voters list.\"\"\"\n        if voter_id in self.eligible_voters:\n            self.eligible_voters.remove(voter_id)\n\n    def get_vote_summary(self) -> Dict[str, Any]:\n        \"\"\"Get current voting summary without ending the session.\"\"\"\n        if not self.is_active:\n            return {}\n\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\n        time_remaining = max(0, self.end_time - time.time())\n\n        return {\n            'candidates': self.candidates,\n            'vote_counts': dict(vote_counts),\n            'total_votes': len(self.votes),\n            'time_remaining': time_remaining,\n            'is_active': self.is_active\n        }\n\n    def get_voter_history(self, voter_id: str) -> List[Vote]:\n        \"\"\"Get voting history for a specific voter.\"\"\"\n        history = []\n        for session in self.vote_history:\n            votes = session.get('results', {}).votes_by_voter\n            if voter_id in votes:\n                history.append(votes[voter_id])\n        return history\n\n    def get_candidate_performance(self, candidate: str) -> Dict[str, Any]:\n        \"\"\"Get performance statistics for a candidate across all sessions.\"\"\"\n        wins = 0\n        total_votes = 0\n        participations = 0\n\n        for session in self.vote_history:\n            results = session.get('results', {})\n            if candidate in session.get('candidates', []):\n                participations += 1\n                if results.winner == candidate:\n                    wins += 1\n                total_votes += results.vote_counts.get(candidate, 0)\n\n        return {\n            'candidate': candidate,\n            'wins': wins,\n            'total_votes': total_votes,\n            'participations': participations,\n            'win_rate': wins / participations if participations > 0 else 0,\n            'avg_votes': total_votes / participations if participations > 0 else 0\n        }\n\n    async def export_results(self, format_type: str = 'json') -> str:\n        \"\"\"\n        Export voting results in specified format.\n\n        Args:\n            format_type: Export format ('json', 'csv', 'txt')\n\n        Returns:\n            Formatted results string\n        \"\"\"\n        if not self.vote_history:\n            return \"No voting history available\"\n\n        if format_type == 'json':\n            import json\n            return json.dumps(self.vote_history, indent=2, default=str)\n\n        elif format_type == 'csv':\n            import csv\n            import io\n\n            output = io.StringIO()\n            writer = csv.writer(output)\n\n            # Header\n            writer.writerow(['Session', 'Timestamp', 'Candidate', 'Votes', 'Winner'])\n\n            # Data\n            for i, session in enumerate(self.vote_history):\n                results = session.get('results', {})\n                timestamp = session.get('timestamp', '')\n\n                for candidate, votes in results.vote_counts.items():\n                    writer.writerow([\n                        i + 1,\n                        timestamp,\n                        candidate,\n                        votes,\n                        results.winner == candidate\n                    ])\n\n            return output.getvalue()\n\n        elif format_type == 'txt':\n            output = []\n            output.append(\"=== VOTING HISTORY REPORT ===\\n\")\n\n            for i, session in enumerate(self.vote_history):\n                results = session.get('results', {})\n                output.append(f\"Session {i + 1}:\")\n                output.append(f\"  Winner: {results.winner}\")\n                output.append(f\"  Total Votes: {results.total_votes}\")\n                output.append(f\"  Vote Breakdown:\")\n\n                for candidate, votes in sorted(results.vote_counts.items(),\n                                               key=lambda x: x[1], reverse=True):\n                    output.append(f\"    {candidate}: {votes}\")\n                output.append(\"\")\n\n            return \"\\n\".join(output)\n\n        else:\n            raise ValueError(f\"Unsupported format: {format_type}\")\n\n    def reset(self) -> None:\n        \"\"\"Reset the voting system to initial state.\"\"\"\n        self.is_active = False\n        self.candidates = []\n        self.eligible_voters = []\n        self.votes = {}\n        self.start_time = None\n        self.end_time = None\n\n    @property\n    def status(self) -> Dict[str, Any]:\n        \"\"\"Get current status of the voting system.\"\"\"\n        return {\n            'enabled': self.enabled,\n            'is_active': self.is_active,\n            'candidates': self.candidates,\n            'eligible_voters': len(self.eligible_voters),\n            'votes_cast': len(self.votes),\n            'time_remaining': (self.end_time - time.time()\n                               if self.is_active and self.end_time else 0),\n            'sessions_completed': len(self.vote_history)\n        }"
        },
        "web_server.py": {
          "type": "file",
          "path": "app/web_server.py",
          "extension": ".py",
          "size": 13154,
          "content": "\"\"\"\nWebSocket server for real-time AI Jubilee Debate interface.\nFixed version with proper WebSocket handler signature and bot name support.\n\"\"\"\n\nimport asyncio\nimport json\nimport time\nimport logging\nfrom typing import Set, Dict, Any, Optional\n\ntry:\n    import websockets\n    from websockets import WebSocketServerProtocol\nexcept ImportError:\n    print(\"‚ùå websockets package not found. Install with: pip install websockets\")\n    raise\n\nlogger = logging.getLogger(__name__)\n\n\nclass DebateWebServer:\n    \"\"\"WebSocket server for real-time debate interface.\"\"\"\n\n    def __init__(self, host: str = \"localhost\", port: int = 8081):\n        self.host = host\n        self.port = port\n        self.clients: Set[WebSocketServerProtocol] = set()\n        self.server = None\n        self.is_running = False\n        self.participant_info = {}  # Store participant information including names\n        self.stats = {\n            'connections': 0,\n            'messages_sent': 0,\n            'start_time': time.time()\n        }\n\n    def set_participants(self, participants: list):\n        \"\"\"Set participant information for the web interface.\"\"\"\n        self.participant_info = {}\n        for participant in participants:\n            if hasattr(participant, 'name'):\n                name = participant.name\n                if hasattr(participant, 'config'):  # It's a bot\n                    self.participant_info[name] = {\n                        'type': 'bot',\n                        'name': name,\n                        'stance': getattr(participant.config, 'stance', 'neutral'),\n                        'personality': getattr(participant.config, 'personality', 'AI Participant'),\n                        'model': getattr(participant.config, 'model', 'unknown')\n                    }\n                else:  # It's a human\n                    self.participant_info[name] = {\n                        'type': 'human',\n                        'name': name,\n                        'stance': 'neutral'\n                    }\n\n        print(f\"üîó Web server configured with participants: {list(self.participant_info.keys())}\")\n\n    async def start_server(self):\n        \"\"\"Start the WebSocket server.\"\"\"\n        if self.is_running:\n            return\n\n        try:\n            # Fixed: Remove the path parameter from handler signature\n            self.server = await websockets.serve(\n                self.handle_client,  # Just pass the method, websockets will handle parameters\n                self.host,\n                self.port,\n                ping_interval=20,\n                ping_timeout=10,\n                max_size=1024 * 1024  # 1MB max message size\n            )\n            self.is_running = True\n            print(f\"üîó WebSocket server running on ws://{self.host}:{self.port}\")\n            print(f\"üåê Ready for web client connections\")\n        except Exception as e:\n            print(f\"‚ùå Failed to start WebSocket server: {e}\")\n            raise\n\n    async def handle_client(self, websocket: WebSocketServerProtocol):\n        \"\"\"Handle new client connections. Fixed signature without path parameter.\"\"\"\n        self.clients.add(websocket)\n        self.stats['connections'] += 1\n\n        try:\n            client_id = f\"{websocket.remote_address[0]}:{websocket.remote_address[1]}\"\n        except:\n            client_id = f\"client_{len(self.clients)}\"\n\n        print(f\"üîó Web client connected: {client_id} (Total: {len(self.clients)})\")\n\n        # Send welcome message with participant info\n        try:\n            await self.send_to_client(websocket, {\n                \"type\": \"welcome\",\n                \"data\": {\n                    \"message\": \"üé≠ Connected to AI Jubilee Debate!\",\n                    \"participants\": self.participant_info,\n                    \"timestamp\": time.time() * 1000\n                }\n            })\n\n            # Send participant info separately for UI setup\n            await self.send_to_client(websocket, {\n                \"type\": \"participants_info\",\n                \"data\": self.participant_info\n            })\n\n        except Exception as e:\n            logger.error(f\"Error sending welcome message: {e}\")\n\n        try:\n            # Listen for client messages\n            async for message in websocket:\n                try:\n                    data = json.loads(message)\n                    await self.handle_client_message(websocket, data)\n                except json.JSONDecodeError:\n                    await self.send_error(websocket, \"Invalid JSON format\")\n                except Exception as e:\n                    logger.error(f\"Error handling client message: {e}\")\n                    await self.send_error(websocket, \"Message processing error\")\n\n        except websockets.exceptions.ConnectionClosed:\n            logger.info(f\"Client {client_id} disconnected normally\")\n        except Exception as e:\n            logger.error(f\"Client {client_id} connection error: {e}\")\n        finally:\n            self.clients.discard(websocket)\n            print(f\"‚ùå Web client disconnected: {client_id} (Remaining: {len(self.clients)})\")\n\n    async def handle_client_message(self, websocket: WebSocketServerProtocol, data: Dict[str, Any]):\n        \"\"\"Handle messages from web clients.\"\"\"\n        message_type = data.get('type', '')\n\n        if message_type == 'user_message':\n            # Handle user chat input - forward to debate system\n            content = data.get('content', '').strip()\n            if content:\n                await self.broadcast_message(\n                    sender=\"Human\",\n                    content=content,\n                    message_type=\"human\"\n                )\n\n        elif message_type == 'ping':\n            # Respond to ping with pong\n            await self.send_to_client(websocket, {\"type\": \"pong\"})\n\n        elif message_type == 'get_stats':\n            # Send current server stats\n            stats = self.get_server_stats()\n            await self.send_to_client(websocket, {\n                \"type\": \"stats\",\n                \"data\": stats\n            })\n\n        elif message_type == 'get_participants':\n            # Send participant information\n            await self.send_to_client(websocket, {\n                \"type\": \"participants_info\",\n                \"data\": self.participant_info\n            })\n\n        else:\n            await self.send_error(websocket, f\"Unknown message type: {message_type}\")\n\n    async def send_to_client(self, websocket: WebSocketServerProtocol, data: Dict[str, Any]):\n        \"\"\"Send data to a specific client.\"\"\"\n        try:\n            message = json.dumps(data)\n            await websocket.send(message)\n        except websockets.exceptions.ConnectionClosed:\n            # Client disconnected, remove from set\n            self.clients.discard(websocket)\n        except Exception as e:\n            logger.error(f\"Error sending to client: {e}\")\n\n    async def send_error(self, websocket: WebSocketServerProtocol, error_message: str):\n        \"\"\"Send error message to client.\"\"\"\n        try:\n            await self.send_to_client(websocket, {\n                \"type\": \"error\",\n                \"message\": error_message,\n                \"timestamp\": time.time() * 1000\n            })\n        except Exception as e:\n            logger.error(f\"Error sending error message: {e}\")\n\n    async def broadcast_message(self, sender: str, content: str,\n                                message_type: str = \"message\",\n                                response_time: float = None):\n        \"\"\"Broadcast message to all connected clients.\"\"\"\n        if not self.clients:\n            return\n\n        # Get enhanced participant info for this sender\n        participant_info = self.participant_info.get(sender, {})\n\n        # Determine message type based on sender if not specified\n        if message_type == \"message\":\n            if sender == \"Moderator\":\n                message_type = \"moderator\"\n            elif participant_info.get('type') == 'bot':\n                message_type = \"bot\"\n            else:\n                message_type = \"human\"\n\n        message_data = {\n            \"type\": \"message\",\n            \"sender\": sender,\n            \"content\": content,\n            \"message_type\": message_type,\n            \"timestamp\": time.time() * 1000,  # JavaScript timestamp\n            \"response_time\": response_time,\n            \"participant_info\": participant_info  # Include participant details\n        }\n\n        message_json = json.dumps(message_data)\n        self.stats['messages_sent'] += 1\n\n        # Send to all connected clients\n        disconnected = set()\n        for client in list(self.clients):  # Create copy to avoid modification during iteration\n            try:\n                await client.send(message_json)\n            except websockets.exceptions.ConnectionClosed:\n                disconnected.add(client)\n            except Exception as e:\n                logger.error(f\"Error broadcasting to client: {e}\")\n                disconnected.add(client)\n\n        # Remove disconnected clients\n        self.clients -= disconnected\n\n    async def broadcast_phase_change(self, phase: str, time_remaining: int = None):\n        \"\"\"Broadcast debate phase change.\"\"\"\n        phase_data = {\n            \"type\": \"phase_change\",\n            \"phase\": phase,\n            \"time_remaining\": time_remaining,\n            \"timestamp\": time.time() * 1000\n        }\n\n        await self._broadcast_json(phase_data)\n\n    async def broadcast_stats(self, stats: Dict[str, Any]):\n        \"\"\"Broadcast statistics update.\"\"\"\n        stats_data = {\n            \"type\": \"stats\",\n            \"data\": stats,\n            \"timestamp\": time.time() * 1000\n        }\n\n        await self._broadcast_json(stats_data)\n\n    async def broadcast_bot_activity(self, bot_name: str, activity_data: Dict[str, Any]):\n        \"\"\"Broadcast bot activity update.\"\"\"\n        activity_message = {\n            \"type\": \"bot_activity\",\n            \"bot_name\": bot_name,\n            \"data\": activity_data,\n            \"timestamp\": time.time() * 1000\n        }\n\n        await self._broadcast_json(activity_message)\n\n    async def broadcast_participants_update(self):\n        \"\"\"Broadcast updated participant information.\"\"\"\n        participants_data = {\n            \"type\": \"participants_info\",\n            \"data\": self.participant_info,\n            \"timestamp\": time.time() * 1000\n        }\n\n        await self._broadcast_json(participants_data)\n\n    async def _broadcast_json(self, data: Dict[str, Any]):\n        \"\"\"Internal method to broadcast JSON data.\"\"\"\n        if not self.clients:\n            return\n\n        message_json = json.dumps(data)\n\n        # Send to all connected clients\n        disconnected = set()\n        for client in list(self.clients):\n            try:\n                await client.send(message_json)\n            except websockets.exceptions.ConnectionClosed:\n                disconnected.add(client)\n            except Exception as e:\n                logger.error(f\"Error broadcasting JSON: {e}\")\n                disconnected.add(client)\n\n        # Remove disconnected clients\n        self.clients -= disconnected\n\n    def get_server_stats(self) -> Dict[str, Any]:\n        \"\"\"Get server statistics.\"\"\"\n        uptime = time.time() - self.stats['start_time']\n        return {\n            'active_connections': len(self.clients),\n            'total_connections': self.stats['connections'],\n            'messages_sent': self.stats['messages_sent'],\n            'uptime_minutes': uptime / 60,\n            'messages_per_minute': self.stats['messages_sent'] / (uptime / 60) if uptime > 0 else 0,\n            'is_running': self.is_running,\n            'participants': self.participant_info\n        }\n\n    async def stop_server(self):\n        \"\"\"Stop the WebSocket server.\"\"\"\n        if not self.is_running:\n            return\n\n        self.is_running = False\n\n        try:\n            # Notify all clients\n            await self.broadcast_message(\n                sender=\"System\",\n                content=\"üõë Server shutting down. Thanks for participating!\",\n                message_type=\"moderator\"\n            )\n\n            # Give clients time to receive the message\n            await asyncio.sleep(1)\n\n            # Close all client connections\n            if self.clients:\n                close_tasks = [client.close() for client in list(self.clients)]\n                await asyncio.gather(*close_tasks, return_exceptions=True)\n\n            # Stop the server\n            if self.server:\n                self.server.close()\n                await self.server.wait_closed()\n\n            print(\"üõë WebSocket server stopped\")\n\n        except Exception as e:\n            logger.error(f\"Error stopping server: {e}\")\n\n    def __len__(self):\n        \"\"\"Return number of connected clients.\"\"\"\n        return len(self.clients)\n\n    def __bool__(self):\n        \"\"\"Return True if server has connected clients.\"\"\"\n        return len(self.clients) > 0\n\n    @property\n    def client_count(self) -> int:\n        \"\"\"Get number of connected clients.\"\"\"\n        return len(self.clients)\n\n    @property\n    def is_active(self) -> bool:\n        \"\"\"Check if server is running.\"\"\"\n        return self.is_running"
        }
      }
    },
    "docs": {
      "type": "directory",
      "contents": {
        "api_reference.md": {
          "type": "file",
          "path": "docs/api_reference.md",
          "extension": ".md",
          "size": 15639,
          "content": "# AI Jubilee Debate System API Reference\n\n## Core Classes\n\n### Moderator\n\nThe central coordinator for debate sessions.\n\n#### Constructor\n```python\nModerator(\n    topic: str,\n    participants: List[Union[BotClient, HumanClient]],\n    chat_log: ChatLog,\n    voting_system: VotingSystem,\n    config: Dict[str, Any]\n)\n```\n\n**Parameters:**\n- `topic`: The debate topic string\n- `participants`: List of bot and human participants\n- `chat_log`: ChatLog instance for message management\n- `voting_system`: VotingSystem instance for handling votes\n- `config`: Configuration dictionary with timing and rule settings\n\n#### Methods\n\n##### `async run_debate() -> Dict[str, Any]`\nRuns the complete debate session through all phases.\n\n**Returns:** Dictionary containing voting results and session statistics\n\n**Example:**\n```python\nmoderator = Moderator(topic, participants, chat_log, voting_system, config)\nresults = await moderator.run_debate()\nprint(f\"Winner: {results.get('winner', 'No winner')}\")\n```\n\n##### `get_state() -> DebateState`\nReturns current debate state information.\n\n**Returns:** DebateState object with phase, speaker, and timing info\n\n##### `async _give_turn(participant_name: str, time_limit: int, turn_type: str) -> None`\nGives speaking turn to a specific participant.\n\n**Parameters:**\n- `participant_name`: Name of participant to give turn to\n- `time_limit`: Maximum time in seconds for response\n- `turn_type`: Type of turn (\"opening\", \"response\", \"closing\")\n\n---\n\n### ChatLog\n\nThread-safe message management system.\n\n#### Constructor\n```python\nChatLog(max_messages: int = 1000)\n```\n\n**Parameters:**\n- `max_messages`: Maximum number of messages to retain in memory\n\n#### Methods\n\n##### `async add_message(sender: str, content: str, message_type: str = \"chat\", metadata: Optional[Dict] = None) -> Message`\nAdds a new message to the chat log.\n\n**Parameters:**\n- `sender`: Name of message sender\n- `content`: Message content text\n- `message_type`: Type of message (\"chat\", \"moderator\", \"system\", \"vote\")\n- `metadata`: Optional additional data\n\n**Returns:** Created Message object\n\n**Example:**\n```python\nmessage = await chat_log.add_message(\"Alice\", \"I think AI will help humanity\")\nprint(f\"Message ID: {message.message_id}\")\n```\n\n##### `get_messages(limit: Optional[int] = None, sender: Optional[str] = None, message_type: Optional[str] = None, since_timestamp: Optional[float] = None) -> List[Message]`\nRetrieves messages with optional filtering.\n\n**Parameters:**\n- `limit`: Maximum number of messages to return\n- `sender`: Filter by sender name\n- `message_type`: Filter by message type\n- `since_timestamp`: Only messages after this timestamp\n\n**Returns:** List of Message objects\n\n##### `subscribe() -> asyncio.Queue`\nCreates subscription for real-time message updates.\n\n**Returns:** Queue that receives new Message objects\n\n##### `async save_transcript(filename: str, format_type: str = \"json\") -> None`\nSaves chat transcript to file.\n\n**Parameters:**\n- `filename`: Output file path\n- `format_type`: Export format (\"json\", \"txt\", \"html\")\n\n##### `search_messages(query: str, case_sensitive: bool = False) -> List[Message]`\nSearches messages by content.\n\n**Parameters:**\n- `query`: Search string\n- `case_sensitive`: Whether search is case sensitive\n\n**Returns:** List of matching Message objects\n\n---\n\n### VotingSystem\n\nManages voting sessions and result calculation.\n\n#### Constructor\n```python\nVotingSystem(config: Dict[str, Any])\n```\n\n**Parameters:**\n- `config`: Voting configuration dictionary\n\n#### Methods\n\n##### `async start_voting(candidates: List[str], duration: Optional[int] = None) -> None`\nStarts a new voting session.\n\n**Parameters:**\n- `candidates`: List of participant names to vote for\n- `duration`: Voting duration in seconds (uses config default if None)\n\n**Example:**\n```python\nawait voting_system.start_voting([\"Alice\", \"Bob\", \"Charlie\"], 300)\n```\n\n##### `async cast_vote(voter_id: str, candidate: str, justification: Optional[str] = None) -> bool`\nCasts a vote for a candidate.\n\n**Parameters:**\n- `voter_id`: ID of the voter\n- `candidate`: Name of candidate being voted for\n- `justification`: Optional reasoning for the vote\n\n**Returns:** True if vote was successfully cast\n\n##### `async end_voting() -> VotingResults`\nEnds voting session and calculates results.\n\n**Returns:** VotingResults object with winner and vote breakdown\n\n##### `get_vote_summary() -> Dict[str, Any]`\nGets current voting status without ending session.\n\n**Returns:** Dictionary with vote counts and time remaining\n\n##### `async export_results(format_type: str = \"json\") -> str`\nExports voting results in specified format.\n\n**Parameters:**\n- `format_type`: Export format (\"json\", \"csv\", \"txt\")\n\n**Returns:** Formatted results string\n\n---\n\n### BotClient\n\nAI-powered debate participant.\n\n#### Constructor\n```python\nBotClient(\n    name: str,\n    model: str,\n    provider: str,\n    personality: str,\n    stance: str,\n    api_key: str,\n    temperature: float = 0.7,\n    max_tokens: int = 300\n)\n```\n\n**Parameters:**\n- `name`: Bot display name\n- `model`: AI model identifier\n- `provider`: AI provider (\"openai\" or \"anthropic\")\n- `personality`: Personality description for prompt\n- `stance`: Debate stance (\"pro\", \"con\", \"neutral\")\n- `api_key`: API key for AI provider\n- `temperature`: Response creativity (0.0-1.0)\n- `max_tokens`: Maximum response length\n\n#### Methods\n\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\nGenerates AI response to current debate context.\n\n**Parameters:**\n- `topic`: Current debate topic\n- `recent_messages`: Recent conversation messages for context\n\n**Returns:** Generated response string\n\n**Example:**\n```python\nbot = BotClient(\"Analyst\", \"gpt-4\", \"openai\", \"Analytical\", \"pro\", api_key)\nresponse = await bot.get_response(\"AI in healthcare\", recent_messages)\n```\n\n##### `async receive_message(message: Message) -> None`\nReceives message from debate for context awareness.\n\n##### `get_stats() -> Dict[str, Any]`\nReturns bot performance statistics.\n\n**Returns:** Dictionary with response counts, timing, and success rates\n\n##### `async warmup() -> bool`\nTests bot connectivity and readiness.\n\n**Returns:** True if bot is ready for debate\n\n##### `update_personality(personality: str, stance: str = None) -> None`\nUpdates bot personality and stance during session.\n\n---\n\n### HumanClient\n\nHuman participant interface.\n\n#### Constructor\n```python\nHumanClient(name: str, interface_config: Dict[str, Any])\n```\n\n**Parameters:**\n- `name`: Human participant display name\n- `interface_config`: Interface configuration dictionary\n\n#### Methods\n\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\nGets response from human participant.\n\n**Parameters:**\n- `topic`: Current debate topic\n- `recent_messages`: Recent messages for context\n\n**Returns:** Human's response string\n\n##### `async handle_voting(candidates: List[str], voting_time: int) -> Dict[str, Any]`\nHandles voting interface for human.\n\n**Parameters:**\n- `candidates`: List of candidates to vote for\n- `voting_time`: Time allowed for voting\n\n**Returns:** Dictionary with vote result and metadata\n\n##### `async set_active(active: bool) -> None`\nSets whether human is actively participating.\n\n**Parameters:**\n- `active`: Whether human should be active in debate\n\n---\n\n### StreamingServer\n\nWebSocket server for live debate streaming.\n\n#### Constructor\n```python\nStreamingServer(\n    chat_log: ChatLog,\n    voting_system: VotingSystem,\n    config: Dict[str, Any]\n)\n```\n\n#### Methods\n\n##### `async start() -> None`\nStarts the streaming server.\n\n##### `async stop() -> None`\nStops the streaming server and closes connections.\n\n##### `async broadcast_custom_message(message_type: str, data: Any) -> None`\nBroadcasts custom message to all connected clients.\n\n**Parameters:**\n- `message_type`: Type identifier for the message\n- `data`: Message payload\n\n##### `get_connected_clients() -> List[Dict[str, Any]]`\nReturns information about all connected streaming clients.\n\n**Returns:** List of client information dictionaries\n\n---\n\n## Data Classes\n\n### Message\n\nRepresents a single chat message.\n\n```python\n@dataclass\nclass Message:\n    sender: str\n    content: str\n    timestamp: float\n    message_id: int\n    message_type: str = \"chat\"\n    metadata: Optional[Dict[str, Any]] = None\n```\n\n**Properties:**\n- `formatted_timestamp`: Human-readable timestamp string\n\n**Methods:**\n- `to_dict() -> Dict[str, Any]`: Convert to dictionary\n- `from_dict(data: Dict[str, Any]) -> Message`: Create from dictionary\n\n### Vote\n\nRepresents a single vote in the voting system.\n\n```python\n@dataclass\nclass Vote:\n    voter_id: str\n    candidate: str\n    justification: Optional[str] = None\n    timestamp: float = field(default_factory=time.time)\n    anonymous: bool = False\n```\n\n### VotingResults\n\nContains results from a voting session.\n\n```python\n@dataclass\nclass VotingResults:\n    winner: Optional[str]\n    vote_counts: Dict[str, int]\n    total_votes: int\n    votes_by_voter: Dict[str, Vote]\n    voting_duration: float\n    participation_rate: float\n```\n\n### DebateState\n\nTracks current debate session state.\n\n```python\n@dataclass\nclass DebateState:\n    phase: DebatePhase\n    current_speaker: Optional[str] = None\n    time_remaining: int = 0\n    turn_order: List[str] = None\n    warnings_issued: Dict[str, int] = None\n```\n\n---\n\n## Enums\n\n### DebatePhase\n\nDefines the phases of a debate session.\n\n```python\nclass DebatePhase(Enum):\n    INTRODUCTION = \"introduction\"\n    OPENING_STATEMENTS = \"opening_statements\"\n    DISCUSSION = \"discussion\"\n    CLOSING_STATEMENTS = \"closing_statements\"\n    VOTING = \"voting\"\n    RESULTS = \"results\"\n    FINISHED = \"finished\"\n```\n\n---\n\n## Utility Functions\n\n### Configuration (`app/utils.py`)\n\n##### `load_config(config_path: str = \"config.yaml\") -> Dict[str, Any]`\nLoads configuration from YAML file with environment variable substitution.\n\n**Parameters:**\n- `config_path`: Path to configuration file\n\n**Returns:** Configuration dictionary\n\n**Example:**\n```python\nconfig = load_config(\"custom_config.yaml\")\n```\n\n##### `setup_logging(level: str = \"INFO\", log_file: Optional[str] = None) -> None`\nSets up logging configuration.\n\n**Parameters:**\n- `level`: Logging level (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\")\n- `log_file`: Optional log file path\n\n##### `format_time_remaining(seconds: float) -> str`\nFormats time remaining in human-readable format.\n\n**Parameters:**\n- `seconds`: Time in seconds\n\n**Returns:** Formatted time string (\"5m 30s\", \"2h 15m\", etc.)\n\n##### `truncate_text(text: str, max_length: int = 100, suffix: str = \"...\") -> str`\nTruncates text to maximum length.\n\n**Parameters:**\n- `text`: Text to truncate\n- `max_length`: Maximum length\n- `suffix`: Suffix to add when truncating\n\n**Returns:** Truncated text\n\n---\n\n## Error Handling\n\n### Custom Exceptions\n\nThe system uses standard Python exceptions with descriptive messages:\n\n- `ValueError`: Invalid configuration or parameters\n- `FileNotFoundError`: Missing configuration files\n- `ConnectionError`: API or network failures\n- `TimeoutError`: Response timeouts\n\n### Error Recovery\n\nAll async methods include proper error handling and will not crash the session:\n\n```python\ntry:\n    response = await bot.get_response(topic, messages)\nexcept Exception as e:\n    # Fallback response is automatically generated\n    response = bot._generate_fallback_response(topic)\n```\n\n---\n\n## Configuration Schema\n\n### Main Configuration\n\n```yaml\n# Debate settings\ndebate:\n  default_topic: str\n  max_participants: int\n  time_limit_minutes: int\n  opening_statement_time: int  # seconds\n  response_time: int\n  closing_statement_time: int\n\n# Bot configurations\nbots:\n  - name: str\n    model: str\n    provider: str  # \"openai\" or \"anthropic\"\n    personality: str\n    stance: str  # \"pro\", \"con\", or \"neutral\"\n    temperature: float  # 0.0-1.0\n    max_tokens: int\n\n# API credentials\napi_keys:\n  openai: str\n  anthropic: str\n\n# Voting settings\nvoting:\n  enabled: bool\n  voting_duration: int  # seconds\n  allow_participant_voting: bool\n  require_justification: bool\n  anonymous_votes: bool\n\n# Chat settings\nchat:\n  max_message_length: int\n  enable_timestamps: bool\n  log_level: str\n  save_transcripts: bool\n\n# Streaming settings\nstreaming:\n  enabled: bool\n  websocket_port: int\n  max_connections: int\n  broadcast_votes: bool\n\n# Interface settings\ninterface:\n  mode: str  # \"cli\" or \"web\"\n  enable_rich_formatting: bool\n  show_typing_indicators: bool\n  input_timeout: int\n```\n\n---\n\n## WebSocket API\n\n### Client Connection\n\nConnect to the streaming server:\n\n```javascript\nconst ws = new WebSocket('ws://localhost:8080');\n```\n\n### Message Types\n\n#### Incoming Messages\n\n##### Welcome Message\n```json\n{\n  \"type\": \"welcome\",\n  \"client_id\": \"client_123456789\",\n  \"server_info\": {\n    \"version\": \"1.0.0\",\n    \"features\": [\"chat\", \"voting\", \"real_time\"]\n  }\n}\n```\n\n##### Chat Message\n```json\n{\n  \"type\": \"message\",\n  \"data\": {\n    \"sender\": \"Alice\",\n    \"content\": \"I believe AI will benefit society\",\n    \"timestamp\": 1640995200.0,\n    \"message_id\": 42,\n    \"message_type\": \"chat\"\n  }\n}\n```\n\n##### Vote Update\n```json\n{\n  \"type\": \"vote_update\",\n  \"data\": {\n    \"candidates\": [\"Alice\", \"Bob\"],\n    \"vote_counts\": {\"Alice\": 5, \"Bob\": 3},\n    \"total_votes\": 8,\n    \"time_remaining\": 120,\n    \"is_active\": true\n  }\n}\n```\n\n#### Outgoing Messages\n\n##### Subscribe to Channels\n```json\n{\n  \"type\": \"subscribe\",\n  \"channels\": [\"chat\", \"voting\", \"system\"]\n}\n```\n\n##### Cast Vote\n```json\n{\n  \"type\": \"vote\",\n  \"voter_id\": \"viewer_123\",\n  \"candidate\": \"Alice\",\n  \"justification\": \"Most persuasive arguments\"\n}\n```\n\n##### Ping/Pong\n```json\n{\n  \"type\": \"ping\"\n}\n```\n\n---\n\n## Performance Considerations\n\n### API Rate Limits\n\n- OpenAI: Respect rate limits based on your plan\n- Anthropic: Monitor request quotas\n- Implement exponential backoff for retries\n\n### Memory Management\n\n- Chat log automatically limits message history\n- Conversation history is pruned in bot clients\n- Streaming connections are cleaned up automatically\n\n### Async Best Practices\n\nAll I/O operations are async:\n\n```python\n# Correct - awaits async operations\nresponse = await bot.get_response(topic, messages)\nawait chat_log.add_message(sender, content)\n\n# Incorrect - would block the event loop\n# response = bot.get_response(topic, messages).result()\n```\n\n---\n\n## Testing\n\n### Unit Tests\n\nRun the test suite:\n\n```bash\npython -m pytest tests/ -v\n```\n\n### Integration Tests\n\nTest with real APIs:\n\n```bash\n# Set test API keys\nexport OPENAI_API_KEY=\"test-key\"\nexport ANTHROPIC_API_KEY=\"test-key\"\n\n# Run integration tests\npython -m pytest tests/integration/ -v\n```\n\n### Mock Testing\n\n```python\nfrom unittest.mock import AsyncMock\n\n# Mock bot responses\nbot.ai_provider.generate_response = AsyncMock(return_value=\"Test response\")\nresponse = await bot.get_response(\"Test topic\", [])\nassert response == \"Test response\"\n```\n\n---\n\n## Deployment\n\n### Docker\n\n```dockerfile\nFROM python:3.9-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\nCMD [\"python\", \"-m\", \"app.main\"]\n```\n\n### Environment Variables\n\nRequired for production:\n\n```bash\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\nLOG_LEVEL=INFO\nCONFIG_PATH=/app/production_config.yaml\n```\n\n### Health Checks\n\n```python\n# Check system health\nasync def health_check():\n    # Test bot connectivity\n    for bot in bots:\n        if not await bot.warmup():\n            return False\n    \n    # Test streaming server\n    if streaming_server and not streaming_server.is_active:\n        return False\n    \n    return True\n```\n\nThis API reference provides comprehensive documentation for integrating with and extending the AI Jubilee Debate System."
        },
        "architecture.md": {
          "type": "file",
          "path": "docs/architecture.md",
          "extension": ".md",
          "size": 7424,
          "content": "# AI Jubilee Debate System Architecture\n\n## Overview\n\nThe AI Jubilee Debate System is a modular, event-driven platform that facilitates structured debates between AI bots and human participants. The system emphasizes real-time interaction, fair moderation, and comprehensive result tracking.\n\n## Core Components\n\n### 1. Moderator (`app/moderator.py`)\n\nThe central orchestrator of the debate system.\n\n**Responsibilities:**\n- Manage debate phases (introduction, opening statements, discussion, closing statements, voting, results)\n- Enforce time limits and speaking order\n- Handle participant timeouts and warnings\n- Coordinate with voting system\n- Broadcast messages to all participants\n\n**Key Classes:**\n- `Moderator`: Main orchestration class\n- `DebatePhase`: Enum defining debate stages\n- `DebateState`: Current state tracking\n\n**Flow Diagram:**\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇIntroduction ‚îÇ -> ‚îÇOpening Stmts ‚îÇ -> ‚îÇ Discussion  ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                                              ‚îÇ\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Results   ‚îÇ <- ‚îÇ    Voting    ‚îÇ <- ‚îÇClosing Stmts‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### 2. Chat Log (`app/chat_log.py`)\n\nThread-safe message management system.\n\n**Features:**\n- Chronological message ordering\n- Pub/sub message distribution\n- Message filtering and search\n- Transcript export (JSON, TXT, HTML)\n- Statistics tracking\n\n**Data Model:**\n```python\n@dataclass\nclass Message:\n    sender: str\n    content: str\n    timestamp: float\n    message_id: int\n    message_type: str = \"chat\"\n    metadata: Optional[Dict[str, Any]] = None\n```\n\n### 3. Voting System (`app/voting.py`)\n\nDemocratic evaluation mechanism for debate performance.\n\n**Features:**\n- Time-limited voting sessions\n- Multiple export formats\n- Vote validation and security\n- Historical tracking\n- Participation analytics\n\n**Voting Flow:**\n```\nStart Session -> Accept Votes -> End Session -> Calculate Results\n     ‚îÇ              ‚îÇ               ‚îÇ              ‚îÇ\n     v              v               v              v\nSet Candidates  Validate Vote   Close Voting   Determine Winner\nSet Duration    Store Vote      Stop Accepting  Export Results\n```\n\n### 4. Participant Clients\n\n#### Bot Client (`app/bot_client.py`)\n\nAI-powered debate participants.\n\n**Supported Providers:**\n- OpenAI (GPT-3.5, GPT-4)\n- Anthropic (Claude)\n- Extensible for additional providers\n\n**Key Features:**\n- Personality-driven responses\n- Stance-aware argumentation\n- Response time tracking\n- Conversation context management\n- Fallback response handling\n\n#### Human Client (`app/human_client.py`)\n\nHuman participant interface.\n\n**Interface Modes:**\n- CLI: Terminal-based interaction\n- Web: WebSocket-based browser interface\n- API: Programmatic integration\n\n**Features:**\n- Response validation\n- Timeout handling\n- Conversation history\n- Voting participation\n\n### 5. Streaming Server (`app/streaming.py`)\n\nReal-time broadcast system for live audience.\n\n**Capabilities:**\n- WebSocket connections\n- Message broadcasting\n- Vote updates\n- Client management\n- Statistics reporting\n\n## System Architecture\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                    Moderator                            ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ\n‚îÇ  ‚îÇ   Phases    ‚îÇ ‚îÇ   Timing    ‚îÇ ‚îÇ   Rules     ‚îÇ       ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n                      ‚îÇ\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n    ‚îÇ                 ‚îÇ                 ‚îÇ\n    v                 v                 v\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇChat Log  ‚îÇ    ‚îÇ  Voting   ‚îÇ    ‚îÇ  Streaming   ‚îÇ\n‚îÇ          ‚îÇ    ‚îÇ  System   ‚îÇ    ‚îÇ   Server     ‚îÇ\n‚îÇ- Messages‚îÇ    ‚îÇ- Sessions ‚îÇ    ‚îÇ- WebSockets  ‚îÇ\n‚îÇ- History ‚îÇ    ‚îÇ- Results  ‚îÇ    ‚îÇ- Broadcast   ‚îÇ\n‚îÇ- Export  ‚îÇ    ‚îÇ- Stats    ‚îÇ    ‚îÇ- Clients     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n    ‚îÇ                 ‚îÇ                 ‚îÇ\n    v                 v                 v\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                Participants                     ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n‚îÇ  ‚îÇ Bot Clients ‚îÇ              ‚îÇHuman Clients‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ- OpenAI     ‚îÇ              ‚îÇ- CLI        ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ- Anthropic  ‚îÇ              ‚îÇ- Web        ‚îÇ   ‚îÇ\n‚îÇ  ‚îÇ- Custom     ‚îÇ              ‚îÇ- API        ‚îÇ   ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Data Flow\n\n### Message Flow\n1. Participant generates response\n2. Moderator validates and timestamps\n3. Chat Log stores and distributes\n4. Streaming Server broadcasts to audience\n5. Other participants receive for context\n\n### Voting Flow\n1. Moderator initiates voting phase\n2. Voting System opens session\n3. Participants cast votes\n4. System validates and stores votes\n5. Results calculated and broadcast\n\n### Configuration Flow\n1. Load YAML configuration\n2. Initialize components with settings\n3. Create participants based on config\n4. Start session with configured parameters\n\n## Error Handling\n\n### Graceful Degradation\n- API failures trigger fallback responses\n- Network issues don't crash sessions\n- Participant timeouts handled smoothly\n- Voting continues despite individual failures\n\n### Monitoring and Logging\n- Comprehensive error logging\n- Performance metrics tracking\n- Participant statistics\n- System health monitoring\n\n## Scalability Considerations\n\n### Horizontal Scaling\n- Multiple debate sessions simultaneously\n- Load balancing for streaming\n- Database for persistent storage\n- Message queue for high throughput\n\n### Performance Optimization\n- Async/await throughout\n- Connection pooling for APIs\n- Message batching for efficiency\n- Resource cleanup and management\n\n## Security\n\n### Input Validation\n- Message content sanitization\n- Participant authentication\n- Vote integrity verification\n- Rate limiting protection\n\n### Privacy Protection\n- Anonymous voting options\n- Conversation encryption\n- Participant data protection\n- Audit trail maintenance\n\n## Extension Points\n\n### Adding New AI Providers\n1. Implement `AIProvider` interface\n2. Add configuration options\n3. Update provider factory\n4. Test integration\n\n### Custom Interfaces\n1. Implement `HumanInterface` interface\n2. Handle async message flow\n3. Add configuration support\n4. Test user experience\n\n### Additional Export Formats\n1. Extend export methods\n2. Add format validation\n3. Update documentation\n4. Test output quality\n\n## Deployment Architecture\n\n### Development\n```\nLocal Machine\n‚îú‚îÄ‚îÄ Python Environment\n‚îú‚îÄ‚îÄ Configuration Files\n‚îú‚îÄ‚îÄ Test Data\n‚îî‚îÄ‚îÄ Log Files\n```\n\n### Production\n```\nContainer Orchestration\n‚îú‚îÄ‚îÄ Moderator Service\n‚îú‚îÄ‚îÄ Bot Client Services\n‚îú‚îÄ‚îÄ Streaming Service\n‚îú‚îÄ‚îÄ Web Interface\n‚îú‚îÄ‚îÄ Database\n‚îî‚îÄ‚îÄ Message Queue\n```\n\n## Configuration Management\n\n### Environment-Specific Settings\n- Development: Local APIs, debug logging\n- Staging: Production APIs, info logging\n- Production: Optimized settings, error logging\n\n### Secret Management\n- API keys in environment variables\n- Database credentials secured\n- SSL certificates managed\n- Rotation policies enforced\n\nThis architecture enables a robust, scalable, and extensible debate platform that can accommodate various use cases from small-scale experiments to large public events."
        },
        "usage.md": {
          "type": "file",
          "path": "docs/usage.md",
          "extension": ".md",
          "size": 21363,
          "content": "# AI Jubilee Debate System - Usage Guide\n\n## üöÄ Quick Start\n\n### Prerequisites\n1. **Python 3.8+** installed\n2. **API Keys** for OpenAI and/or Anthropic\n3. **Dependencies** installed\n\n### Setup Steps\n\n1. **Clone or download the project**\n2. **Install dependencies:**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Set up your API keys in `.env` file:**\n   ```bash\n   # Create .env file in project root\n   OPENAI_API_KEY=sk-your-openai-key-here\n   ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n   ```\n\n4. **Run the debate:**\n   ```bash\n   # Recommended: Use the simple launcher\n   python run_debate.py\n   \n   # Alternative: Use the module directly\n   python -m app.main\n   ```\n\n## üé≠ Debate Modes\n\n### **Autonomous Mode** (Default - Recommended!)\n\nIn autonomous mode, bots monitor the conversation and decide when to speak, creating a natural, organic debate flow.\n\n#### How Autonomous Mode Works:\n- ü§ñ **Bots run in parallel**, continuously monitoring chat\n- üß† **Intelligent decision making** - bots decide when they feel compelled to respond\n- üìö **Full conversation history** available to all participants\n- üéØ **Smart triggers** - bots respond to mentions, challenges, or opportunities\n- ‚è∞ **Cooldown system** prevents spam (15-45 second intervals)\n- üó£Ô∏è **Humans can speak anytime** during discussion phase\n\n#### Configuration:\n```yaml\ndebate:\n  mode: \"autonomous\"  # Enable autonomous mode\n  min_bot_cooldown: 15         # Minimum seconds between bot responses\n  max_bot_cooldown: 45         # Maximum cooldown for active bots  \n  message_check_interval: 5    # How often bots check for new messages\n  silence_timeout: 60          # Moderator intervenes after silence\n```\n\n#### Example Autonomous Flow:\n```\nüé≠ Moderator: \"Autonomous Discussion Phase Begin!\"\nü§ñ Advocate: \"Remote work increases productivity by 40%...\"\nüí≠ Skeptic is thinking about responding...\nü§ñ Skeptic: \"But what about the collaboration costs?\"\nüë§ Human: \"I've experienced both - here's my take...\"\nüí≠ Socrates is thinking about responding...  \nü§ñ Socrates: \"What evidence supports these productivity claims?\"\nüéØ Moderator: \"What about environmental implications?\"\nüí≠ Advocate is thinking about responding...\nü§ñ Advocate: \"Great point - remote work cuts commuting emissions...\"\n```\n\n### **Sequential Mode** (Traditional)\n\nParticipants take turns in a structured order. More predictable but less dynamic.\n\n```yaml\ndebate:\n  mode: \"sequential\"  # Traditional turn-based mode\n```\n\n## üéØ Human Participation in Autonomous Mode\n\n### **During Discussion Phase:**\n- ‚úÖ **Speak anytime** - no waiting for turns!\n- ‚úÖ **Type naturally** - just enter your response\n- ‚úÖ **Full context** - see all previous messages\n- ‚úÖ **Real-time** - immediate feedback from bots\n\n### **Available Commands:**\n```\nüí¨ [your message]     # Join the debate with your response\nhelp                  # Show help information\nstatus                # Show your participation statistics\nhistory               # Show recent conversation\nquit                  # Leave the debate\n```\n\n### **Example Human Session:**\n```\nüéØ AUTONOMOUS DEBATE MODE ACTIVE\nüó£Ô∏è You can speak at ANY TIME during the discussion!\nüí° Commands: 'help', 'status', 'history', 'quit'\n\nü§ñ Advocate: \"Remote work is clearly the future because...\"\nü§ñ Skeptic: \"I disagree - here's why remote work fails...\"\n\nüí¨ Type your response: I think both perspectives miss the point about hybrid work...\n‚úÖ Your message has been added to the debate!\n\nüí≠ Socrates is thinking about responding...\nü§ñ Socrates: \"Interesting point about hybrid - can you elaborate?\"\n\nüí¨ Type your response: status\nüìä Your participation: 1 responses, 100.0% participation rate, avg response time: 12.3s\n\nüí¨ Type your response: Sure! Hybrid work combines the best of both...\n‚úÖ Your message has been added to the debate!\n```\n\n## üìã Debate Phases\n\n### **1. Introduction Phase**\n- Moderator introduces topic and participants\n- Overview of rules and format\n- Duration: ~2 minutes\n\n### **2. Opening Statements Phase** \n- Each participant gives structured opening statement\n- **Sequential order** (even in autonomous mode)\n- Time limit: 120 seconds per participant\n\n### **3. Discussion Phase**\n\n#### **Autonomous Mode:**\n- üîÑ **Free-flowing conversation**\n- ü§ñ **Bots monitor and respond intelligently** \n- üë• **Humans can jump in anytime**\n- üéØ **Moderator provides prompts during silence**\n- ‚è∞ **Total time: 30 minutes** (configurable)\n\n#### **Sequential Mode:**\n- üîÑ **Round-robin turns**\n- ‚è∞ **60 seconds per response**\n- üìù **Structured format**\n\n### **4. Closing Statements Phase**\n- Final arguments from each participant\n- **Sequential order** \n- Time limit: 90 seconds per participant\n\n### **5. Voting Phase**\n- Participants and audience vote for most persuasive\n- Duration: 5 minutes\n- Optional justification required\n\n### **6. Results Phase**\n- Vote tallies and winner announcement\n- Final statistics and transcript saving\n\n## ‚öôÔ∏è Configuration Options\n\n### **Bot Personalities**\n\n```yaml\nbots:\n  - name: \"Socrates\"\n    personality: \"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\"\n    stance: \"neutral\"\n    \n  - name: \"Advocate\"  \n    personality: \"Passionate supporter, data-driven, persuasive. Jumps in when position is challenged.\"\n    stance: \"pro\"\n    \n  - name: \"Skeptic\"\n    personality: \"Critical thinker, questions assumptions. Responds when claims need scrutiny.\"\n    stance: \"con\"\n```\n\n### **Timing Controls**\n\n```yaml\ndebate:\n  time_limit_minutes: 30        # Total discussion time\n  opening_statement_time: 120   # Opening statement duration\n  response_time: 60            # Response time in sequential mode\n  closing_statement_time: 90   # Closing statement duration\n  \n  # Autonomous mode specific\n  min_bot_cooldown: 15         # Minimum bot response interval\n  max_bot_cooldown: 45         # Maximum bot cooldown\n  silence_timeout: 60          # Silence before moderator intervenes\n```\n\n### **Interface Options**\n\n```yaml\ninterface:\n  mode: \"cli\"                  # CLI or web interface\n  enable_rich_formatting: true # Colored/formatted output\n  show_typing_indicators: true # Show when bots are thinking\n  enable_reactions: true       # Enable emoji reactions\n```\n\n## üéõÔ∏è Advanced Usage\n\n### **Command Line Options**\n\n```bash\n# Basic usage\npython run_debate.py\n\n# Using the module with options\npython -m app.main --topic \"AI ethics\" --bots 3 --humans 2\n\n# Custom configuration\npython -m app.main --config custom_config.yaml\n\n# Web interface mode\npython -m app.main --interface web\n```\n\n### **Custom Topics**\n\nAdd to `config.yaml`:\n```yaml\ntopics:\n  - \"Your custom debate topic here\"\n  - \"Another interesting topic\"\n```\n\nOr specify directly:\n```bash\npython -m app.main --topic \"Custom topic\"\n```\n\n### **Bot Configuration**\n\nCreate custom bots in `config.yaml`:\n```yaml\nbots:\n  - name: \"MyBot\"\n    model: \"gpt-4\"\n    provider: \"openai\"\n    personality: \"Your custom personality description\"\n    stance: \"pro\"  # or \"con\" or \"neutral\"\n```\n\n## üîß Troubleshooting\n\n### **Common Issues**\n\n**API Key Errors:**\n```bash\n# Check your .env file format\nOPENAI_API_KEY=sk-your-key  # No quotes, no export\nANTHROPIC_API_KEY=sk-ant-your-key\n```\n\n**Import Errors:**\n```bash\n# Make sure you're in the project root directory\ncd ai_jubilee_debate\npython run_debate.py\n```\n\n**Timeout Issues:**\n```bash\n# Check internet connection and API status\n# Increase timeouts in config.yaml if needed\n```\n\n### **Debug Mode**\n\nEnable detailed logging:\n```yaml\nchat:\n  log_level: \"DEBUG\"\n```\n\nOr set environment variable:\n```bash\nexport LOG_LEVEL=DEBUG\npython run_debate.py\n```\n\n### **Saving Transcripts**\n\nTranscripts are automatically saved after each debate:\n```yaml\nchat:\n  save_transcripts: true\n  transcript_format: \"json\"  # or \"txt\" or \"html\"\n```\n\nFiles saved as: `debate_YYYY-MM-DD_HH-MM-SS.json`\n\n## üé™ Tips for Great Debates\n\n### **For Humans:**\n- üéØ **Jump in naturally** during autonomous mode\n- üìä **Reference specific points** made by others\n- üí° **Provide evidence** and examples\n- ü§ù **Be respectful** but persuasive\n- ‚ö° **Keep responses focused** and substantial\n\n### **Bot Optimization:**\n- üé≠ **Diverse personalities** create better dynamics\n- ‚öñÔ∏è **Balanced stances** (pro/con/neutral mix)\n- üß† **Different models** (GPT-4, Claude, etc.) for variety\n- ‚è∞ **Appropriate cooldowns** prevent spam\n\n### **Moderator Settings:**\n- üéØ **Topic-specific prompts** keep discussion flowing\n- ‚è∞ **Reasonable timeouts** balance pace and depth\n- üí¨ **Silence intervention** maintains engagement\n\n## üìä Monitoring and Analytics\n\n### **Real-time Stats**\n```\n# During debate, type 'status' to see:\nüìä Your participation: 3 responses, 75% participation rate\n‚è±Ô∏è Average response time: 15.2 seconds\nüí¨ Conversation length: 24 messages\n```\n\n### **Post-Debate Analysis**\n- üìà Participation rates per participant\n- ‚è∞ Response time analytics  \n- üó≥Ô∏è Voting results and justifications\n- üìù Full transcript with timestamps\n\n## üöÄ Performance Tips\n\n### **For Better Performance:**\n- Use **GPT-3.5** for faster, cheaper responses\n- Set **reasonable cooldowns** (15-30 seconds)\n- Limit **conversation history** for speed\n- Use **async mode** for responsiveness\n\n### **For Higher Quality:**\n- Use **GPT-4** or **Claude** for better reasoning\n- Increase **response time limits**\n- Enable **detailed logging** for analysis\n- Create **specific bot personalities**\n\n## üåü Advanced Features\n\n### **Real-time Streaming**\nEnable WebSocket streaming for live audiences:\n```yaml\nstreaming:\n  enabled: true\n  websocket_port: 8080\n  max_connections: 100\n```\n\n### **Voting System**\nComprehensive voting with justifications:\n```yaml\nvoting:\n  enabled: true\n  voting_duration: 300\n  require_justification: true\n  anonymous_votes: false\n```\n\n### **Web Interface**\nFor browser-based participation:\n```yaml\ninterface:\n  mode: \"web\"\n  websocket_port: 8080\n```\n\n## üìÅ File Structure\n\n```\nai_jubilee_debate/\n‚îú‚îÄ‚îÄ .env                    # Your API keys (never commit!)\n‚îú‚îÄ‚îÄ .env.example           # Example environment file\n‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns\n‚îú‚îÄ‚îÄ config.yaml            # Main configuration\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\n‚îú‚îÄ‚îÄ run_debate.py          # Simple launcher script\n‚îú‚îÄ‚îÄ app/                   # Core application\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package initialization\n‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Main entry point\n‚îÇ   ‚îú‚îÄ‚îÄ moderator.py      # Debate moderation logic\n‚îÇ   ‚îú‚îÄ‚îÄ bot_client.py     # AI bot participants\n‚îÇ   ‚îú‚îÄ‚îÄ human_client.py   # Human participants\n‚îÇ   ‚îú‚îÄ‚îÄ chat_log.py       # Message management\n‚îÇ   ‚îú‚îÄ‚îÄ voting.py         # Voting system\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions\n‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # WebSocket streaming\n‚îú‚îÄ‚îÄ tests/                 # Test suite\n‚îÇ   ‚îú‚îÄ‚îÄ test_moderator.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_voting.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_chat_log.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_bot_client.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_human_client.py\n‚îî‚îÄ‚îÄ docs/                  # Documentation\n    ‚îú‚îÄ‚îÄ architecture.md    # System architecture\n    ‚îú‚îÄ‚îÄ usage.md          # This file\n    ‚îî‚îÄ‚îÄ api_reference.md  # API documentation\n```\n\n## üÜò Getting Help\n\n### **Built-in Help**\n```bash\n# During debate\nhelp                    # Show autonomous mode help\nstatus                  # Show participation stats\nhistory                 # Show recent messages\n\n# Command line\npython -m app.main --help   # Show CLI options\n```\n\n### **Common Commands**\n```bash\n# Run with debug logging\nLOG_LEVEL=DEBUG python run_debate.py\n\n# Run tests\npython -m pytest tests/ -v\n\n# Check configuration\npython -c \"from app.utils import load_config; print(load_config())\"\n```\n\nThis autonomous debate system creates truly organic, intelligent conversations between AI participants while allowing humans to jump in naturally whenever they feel inspired to contribute! üé≠ü§ñ# AI Jubilee Debate System Usage Guide\n\n## Quick Start\n\n### Installation\n\n1. **Clone the repository:**\n   ```bash\n   git clone <repository-url>\n   cd ai_jubilee_debate\n   ```\n\n2. **Install dependencies:**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n3. **Set up environment variables:**\n   ```bash\n   export OPENAI_API_KEY=\"your-openai-api-key\"\n   export ANTHROPIC_API_KEY=\"your-anthropic-api-key\"\n   ```\n\n4. **Run your first debate:**\n   ```bash\n   python -m app.main\n   ```\n\n## Configuration\n\n### Basic Configuration (`config.yaml`)\n\n```yaml\ndebate:\n  default_topic: \"AI will create more jobs than it destroys\"\n  max_participants: 4\n  time_limit_minutes: 20\n\nbots:\n  - name: \"Advocate\"\n    model: \"gpt-4\"\n    provider: \"openai\" \n    stance: \"pro\"\n  - name: \"Skeptic\"\n    model: \"claude-3-sonnet\"\n    provider: \"anthropic\"\n    stance: \"con\"\n\nvoting:\n  enabled: true\n  voting_duration: 180\n```\n\n### Advanced Configuration Options\n\n#### Timing Settings\n```yaml\ndebate:\n  opening_statement_time: 120  # seconds\n  response_time: 60\n  closing_statement_time: 90\n  warning_time: 45  # warning before timeout\n```\n\n#### Bot Personalities\n```yaml\nbots:\n  - name: \"Philosopher\"\n    personality: \"Thoughtful, asks probing questions\"\n    debate_style: \"socratic\"\n    temperature: 0.8\n    max_tokens: 250\n```\n\n#### Human Interface\n```yaml\ninterface:\n  mode: \"cli\"  # or \"web\"\n  enable_rich_formatting: true\n  show_typing_indicators: true\n  input_timeout: 120\n```\n\n## Running Debates\n\n### Command Line Interface\n\n#### Basic Usage\n```bash\n# Run with default settings\npython -m app.main\n\n# Specify topic\npython -m app.main --topic \"Universal Basic Income is necessary\"\n\n# Set participant counts\npython -m app.main --bots 3 --humans 2\n\n# Use custom config\npython -m app.main --config custom_config.yaml\n```\n\n#### Advanced Options\n```bash\n# Full command with all options\npython -m app.main \\\n  --topic \"Climate change requires immediate action\" \\\n  --bots 2 \\\n  --humans 1 \\\n  --config production_config.yaml\n```\n\n### Programmatic Usage\n\n#### Simple Session\n```python\nfrom app.main import start_debate_session\n\n# Start a basic debate\nawait start_debate_session(\n    topic=\"The future of remote work\",\n    ai_bots=2,\n    human_participants=1\n)\n```\n\n#### Custom Session\n```python\nfrom app import Moderator, BotClient, HumanClient, ChatLog, VotingSystem\n\n# Create components\nchat_log = ChatLog()\nvoting_system = VotingSystem({'enabled': True})\n\n# Create participants\nbot = BotClient(\n    name=\"Analyst\",\n    model=\"gpt-4\",\n    provider=\"openai\",\n    personality=\"Data-driven and analytical\",\n    stance=\"neutral\",\n    api_key=\"your-api-key\"\n)\n\nhuman = HumanClient(\n    name=\"Participant1\",\n    interface_config={'mode': 'cli'}\n)\n\n# Create moderator and run\nmoderator = Moderator(\n    topic=\"AI Ethics in Healthcare\",\n    participants=[bot, human],\n    chat_log=chat_log,\n    voting_system=voting_system,\n    config={'time_limit_minutes': 15}\n)\n\nresults = await moderator.run_debate()\n```\n\n## Participant Management\n\n### AI Bot Configuration\n\n#### Creating Custom Bots\n```python\n# Argumentative bot\naggressive_bot = BotClient(\n    name=\"Debater\",\n    model=\"gpt-4\",\n    provider=\"openai\", \n    personality=\"Aggressive, uses strong rhetoric\",\n    stance=\"pro\",\n    temperature=0.9,  # More creative\n    api_key=api_key\n)\n\n# Analytical bot\nanalytical_bot = BotClient(\n    name=\"Researcher\", \n    model=\"claude-3-sonnet\",\n    provider=\"anthropic\",\n    personality=\"Fact-focused, cites evidence\",\n    stance=\"con\",\n    temperature=0.3,  # More conservative\n    api_key=api_key\n)\n```\n\n#### Bot Personality Examples\n```yaml\npersonalities:\n  socratic: \"Asks probing questions, seeks deeper understanding\"\n  advocate: \"Passionate, uses emotional appeals and personal stories\"  \n  scientist: \"Data-driven, cites studies and statistics\"\n  philosopher: \"Abstract thinking, explores ethical implications\"\n  pragmatist: \"Focuses on practical implementation and real-world effects\"\n  skeptic: \"Questions assumptions, plays devil's advocate\"\n```\n\n### Human Interface Options\n\n#### CLI Mode (Default)\n- Terminal-based interaction\n- Rich formatting with colors\n- Real-time message display\n- Keyboard input for responses\n\n#### Web Mode \n```python\nhuman = HumanClient(\n    name=\"WebUser\",\n    interface_config={\n        'mode': 'web',\n        'enable_reactions': True,\n        'show_typing_indicators': True\n    }\n)\n```\n\n## Debate Topics\n\n### Predefined Topics\nThe system includes several built-in topics:\n- \"AI will create more jobs than it destroys\"\n- \"Social media has a net positive impact on democracy\"\n- \"Universal Basic Income is necessary for the future economy\"\n- \"Climate change requires immediate radical action\"\n- \"Privacy is more important than security\"\n\n### Custom Topics\n```python\n# Define your own topics\ncustom_topics = [\n    \"Cryptocurrency will replace traditional banking\",\n    \"Space exploration should be publicly funded\",\n    \"Genetic engineering should be available to all\",\n    \"Automation will eliminate the need for human work\"\n]\n\n# Use in configuration\nconfig['topics'] = custom_topics\n```\n\n### Topic Guidelines\n- Keep topics debatable (not factual statements)\n- Ensure both sides can be reasonably argued\n- Make them relevant to your audience\n- Consider current events and trends\n\n## Voting and Results\n\n### Voting Configuration\n```yaml\nvoting:\n  enabled: true\n  voting_duration: 300  # 5 minutes\n  allow_participant_voting: true\n  require_justification: true\n  anonymous_votes: false\n```\n\n### Accessing Results\n```python\n# After debate completion\nresults = await moderator.run_debate()\n\nprint(f\"Winner: {results['winner']}\")\nprint(f\"Vote breakdown: {results['vote_counts']}\")\n\n# Export detailed results\nawait voting_system.export_results('json')\n```\n\n### Results Analysis\n```python\n# Get participant performance\nfor participant in participants:\n    performance = voting_system.get_candidate_performance(participant.name)\n    print(f\"{participant.name}: {performance['win_rate']:.1%} win rate\")\n```\n\n## Live Streaming\n\n### Enable Streaming\n```yaml\nstreaming:\n  enabled: true\n  websocket_port: 8080\n  max_connections: 100\n  broadcast_votes: true\n```\n\n### Streaming Server\n```python\nfrom app.streaming import StreamingServer\n\n# Create streaming server\nstreaming = StreamingServer(\n    chat_log=chat_log,\n    voting_system=voting_system,\n    config=streaming_config\n)\n\nawait streaming.start()\n# Server runs on localhost:8080\n```\n\n### Client Connection\n```javascript\n// Connect to stream\nconst ws = new WebSocket('ws://localhost:8080');\n\nws.onmessage = function(event) {\n    const data = JSON.parse(event.data);\n    \n    if (data.type === 'message') {\n        displayMessage(data.data);\n    } else if (data.type === 'vote_update') {\n        updateVoteDisplay(data.data);\n    }\n};\n```\n\n## Data Export and Analysis\n\n### Transcript Export\n```python\n# Save debate transcript\nawait chat_log.save_transcript(\"debate_2024.json\", \"json\")\nawait chat_log.save_transcript(\"debate_2024.txt\", \"txt\") \nawait chat_log.save_transcript(\"debate_2024.html\", \"html\")\n```\n\n### Statistics and Analytics\n```python\n# Chat statistics\nstats = chat_log.get_statistics()\nprint(f\"Total messages: {stats['total_messages']}\")\nprint(f\"Average per minute: {stats['messages_per_minute']:.1f}\")\n\n# Participant statistics  \nfor participant in participants:\n    stats = participant.get_stats()\n    print(f\"{participant.name}: {stats}\")\n```\n\n### Voting Analysis\n```python\n# Export voting data\ncsv_data = await voting_system.export_results('csv')\ntxt_report = await voting_system.export_results('txt')\n\n# Historical analysis\nhistory = voting_system.vote_history\nfor session in history:\n    print(f\"Session: {session['timestamp']}\")\n    print(f\"Winner: {session['results'].winner}\")\n```\n\n## Troubleshooting\n\n### Common Issues\n\n#### API Key Problems\n```bash\n# Check environment variables\necho $OPENAI_API_KEY\necho $ANTHROPIC_API_KEY\n\n# Set them if missing\nexport OPENAI_API_KEY=\"sk-...\"\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\n```\n\n#### Connection Issues\n```python\n# Test bot connectivity\nbot = BotClient(...)\nsuccess = await bot.warmup()\nif not success:\n    print(\"Bot connection failed\")\n```\n\n#### Performance Issues\n```yaml\n# Reduce timeouts for faster sessions\ndebate:\n  opening_statement_time: 60\n  response_time: 30\n  closing_statement_time: 45\n\n# Limit message history\nchat:\n  max_message_length: 300\n```\n\n### Debug Mode\n```bash\n# Enable debug logging\npython -m app.main --config debug_config.yaml\n```\n\n```yaml\n# debug_config.yaml\nchat:\n  log_level: \"DEBUG\"\n  save_transcripts: true\n```\n\n### Error Recovery\n```python\n# Handle errors gracefully\ntry:\n    results = await moderator.run_debate()\nexcept Exception as e:\n    print(f\"Debate error: {e}\")\n    # Save partial transcript\n    await chat_log.save_transcript(\"error_recovery.json\")\n```\n\n## Best Practices\n\n### Bot Configuration\n- Use different personalities for variety\n- Balance pro/con/neutral stances\n- Test API connections before debates\n- Monitor response times and adjust timeouts\n\n### Topic Selection\n- Choose engaging, relevant topics\n- Ensure balanced argumentation potential\n- Test topics with different participant mixes\n- Update topics regularly for freshness\n\n### Session Management\n- Start with shorter sessions for testing\n- Monitor participant engagement\n- Save transcripts for analysis\n- Review voting patterns for improvements\n\n### Performance Optimization\n- Use appropriate API models for your needs\n- Set reasonable timeouts\n- Limit concurrent API calls\n- Monitor system resources\n\nThis guide covers the core functionality of the AI Jubilee Debate System. For detailed API documentation, see [api_reference.md](api_reference.md)."
        }
      }
    },
    "tests": {
      "type": "directory",
      "contents": {
        "test_bot_client.py": {
          "type": "file",
          "path": "tests/test_bot_client.py",
          "extension": ".py",
          "size": 15292,
          "content": "\"\"\"\nTests for the BotClient class.\n\"\"\"\n\nimport pytest\nimport asyncio\nfrom unittest.mock import Mock, AsyncMock, patch\nfrom app.bot_client import BotClient, BotConfig, OpenAIProvider, AnthropicProvider\nfrom app.chat_log import Message\n\n\n@pytest.fixture\ndef bot_config():\n    \"\"\"Create test bot configuration.\"\"\"\n    return {\n        'name': 'TestBot',\n        'model': 'gpt-3.5-turbo',\n        'provider': 'openai',\n        'personality': 'Analytical and thoughtful',\n        'stance': 'pro',\n        'api_key': 'test-api-key'\n    }\n\n\n@pytest.fixture\ndef bot_client(bot_config):\n    \"\"\"Create test bot client.\"\"\"\n    return BotClient(**bot_config)\n\n\n@pytest.fixture\ndef sample_messages():\n    \"\"\"Create sample messages for testing.\"\"\"\n    return [\n        Message(\"Alice\", \"What do you think about AI?\", 1640995200.0, 1),\n        Message(\"moderator\", \"Please respond\", 1640995210.0, 2, \"moderator\")\n    ]\n\n\nclass TestBotConfig:\n    \"\"\"Test suite for BotConfig dataclass.\"\"\"\n\n    def test_bot_config_creation(self):\n        \"\"\"Test creating bot configuration.\"\"\"\n        config = BotConfig(\n            name=\"TestBot\",\n            model=\"gpt-4\",\n            provider=\"openai\",\n            personality=\"Analytical\",\n            stance=\"pro\"\n        )\n\n        assert config.name == \"TestBot\"\n        assert config.model == \"gpt-4\"\n        assert config.provider == \"openai\"\n        assert config.personality == \"Analytical\"\n        assert config.stance == \"pro\"\n        assert config.temperature == 0.7  # Default value\n        assert config.max_tokens == 300  # Default value\n\n\nclass TestBotClient:\n    \"\"\"Test suite for BotClient class.\"\"\"\n\n    def test_bot_client_initialization(self, bot_config):\n        \"\"\"Test bot client initialization.\"\"\"\n        bot = BotClient(**bot_config)\n\n        assert bot.name == \"TestBot\"\n        assert bot.config.model == \"gpt-3.5-turbo\"\n        assert bot.config.provider == \"openai\"\n        assert isinstance(bot.ai_provider, OpenAIProvider)\n        assert bot.response_count == 0\n        assert bot.conversation_history == []\n\n    def test_bot_client_with_anthropic(self):\n        \"\"\"Test bot client with Anthropic provider.\"\"\"\n        bot = BotClient(\n            name=\"AnthropicBot\",\n            model=\"claude-3-sonnet\",\n            provider=\"anthropic\",\n            personality=\"Balanced\",\n            stance=\"neutral\",\n            api_key=\"test-key\"\n        )\n\n        assert isinstance(bot.ai_provider, AnthropicProvider)\n\n    def test_bot_client_unsupported_provider(self):\n        \"\"\"Test bot client with unsupported provider.\"\"\"\n        with pytest.raises(ValueError, match=\"Unsupported AI provider\"):\n            BotClient(\n                name=\"TestBot\",\n                model=\"test-model\",\n                provider=\"unsupported\",\n                personality=\"Test\",\n                stance=\"pro\",\n                api_key=\"test-key\"\n            )\n\n    @pytest.mark.asyncio\n    async def test_get_response_success(self, bot_client, sample_messages):\n        \"\"\"Test successful response generation.\"\"\"\n        # Mock the AI provider\n        mock_response = \"I think AI has great potential for society.\"\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=mock_response)\n\n        response = await bot_client.get_response(\"AI in society\", sample_messages)\n\n        assert response == mock_response\n        assert bot_client.response_count == 1\n        assert len(bot_client.conversation_history) == 1\n        assert bot_client.stats['responses_generated'] == 1\n\n    @pytest.mark.asyncio\n    async def test_get_response_with_error(self, bot_client, sample_messages):\n        \"\"\"Test response generation with API error.\"\"\"\n        # Mock the AI provider to raise an exception\n        bot_client.ai_provider.generate_response = AsyncMock(\n            side_effect=Exception(\"API Error\")\n        )\n\n        response = await bot_client.get_response(\"AI in society\", sample_messages)\n\n        # Should return fallback response\n        assert isinstance(response, str)\n        assert len(response) > 0\n        assert bot_client.stats['errors'] == 1\n\n    def test_prepare_messages(self, bot_client, sample_messages):\n        \"\"\"Test message preparation for AI model.\"\"\"\n        messages = bot_client._prepare_messages(\"AI topic\", sample_messages)\n\n        assert len(messages) >= 1  # At least system message\n        assert messages[0]['role'] == 'system'\n        assert \"AI topic\" in messages[0]['content']\n        assert \"TestBot\" in messages[0]['content']\n\n    def test_create_system_prompt_pro_stance(self, bot_client):\n        \"\"\"Test system prompt creation for pro stance.\"\"\"\n        prompt = bot_client._create_system_prompt(\"AI is beneficial\")\n\n        assert \"TestBot\" in prompt\n        assert \"AI is beneficial\" in prompt\n        assert \"Analytical and thoughtful\" in prompt\n        assert \"IN FAVOR\" in prompt\n\n    def test_create_system_prompt_con_stance(self):\n        \"\"\"Test system prompt creation for con stance.\"\"\"\n        bot = BotClient(\n            name=\"ConBot\",\n            model=\"gpt-3.5-turbo\",\n            provider=\"openai\",\n            personality=\"Critical\",\n            stance=\"con\",\n            api_key=\"test-key\"\n        )\n\n        prompt = bot._create_system_prompt(\"AI topic\")\n        assert \"AGAINST\" in prompt\n\n    def test_create_system_prompt_neutral_stance(self):\n        \"\"\"Test system prompt creation for neutral stance.\"\"\"\n        bot = BotClient(\n            name=\"NeutralBot\",\n            model=\"gpt-3.5-turbo\",\n            provider=\"openai\",\n            personality=\"Balanced\",\n            stance=\"neutral\",\n            api_key=\"test-key\"\n        )\n\n        prompt = bot._create_system_prompt(\"AI topic\")\n        assert \"balanced perspectives\" in prompt\n\n    def test_generate_fallback_response(self, bot_client):\n        \"\"\"Test fallback response generation.\"\"\"\n        response = bot_client._generate_fallback_response(\"AI topic\")\n\n        assert isinstance(response, str)\n        assert len(response) > 0\n        assert \"AI topic\" in response or \"perspective\" in response.lower()\n\n    @pytest.mark.asyncio\n    async def test_receive_message(self, bot_client):\n        \"\"\"Test receiving a message.\"\"\"\n        message = Message(\"Alice\", \"Hello bot\", 1640995200.0, 1)\n\n        await bot_client.receive_message(message)\n\n        # Should be added to conversation history\n        assert len(bot_client.conversation_history) == 1\n        assert \"Alice: Hello bot\" in bot_client.conversation_history[0]['content']\n\n        # Message queue should have the message\n        queued_message = await bot_client.message_queue.get()\n        assert queued_message == message\n\n    @pytest.mark.asyncio\n    async def test_receive_own_message(self, bot_client):\n        \"\"\"Test receiving own message (should not be added to history).\"\"\"\n        message = Message(\"TestBot\", \"My own message\", 1640995200.0, 1)\n\n        await bot_client.receive_message(message)\n\n        # Should not be added to conversation history\n        assert len(bot_client.conversation_history) == 0\n\n    def test_update_stats_success(self, bot_client):\n        \"\"\"Test updating statistics on success.\"\"\"\n        bot_client._update_stats(1.5, success=True)\n\n        assert bot_client.stats['responses_generated'] == 1\n        assert bot_client.stats['average_response_time'] == 1.5\n        assert bot_client.stats['total_response_time'] == 1.5\n\n    def test_update_stats_error(self, bot_client):\n        \"\"\"Test updating statistics on error.\"\"\"\n        bot_client._update_stats(2.0, success=False)\n\n        assert bot_client.stats['errors'] == 1\n        assert bot_client.stats['responses_generated'] == 0\n\n    def test_get_stats(self, bot_client):\n        \"\"\"Test getting bot statistics.\"\"\"\n        # Add some test data\n        bot_client.stats['responses_generated'] = 5\n        bot_client.stats['total_response_time'] = 10.0\n        bot_client.stats['errors'] = 1\n        bot_client._update_stats(0, success=True)  # Recalculate average\n\n        stats = bot_client.get_stats()\n\n        assert stats['name'] == \"TestBot\"\n        assert stats['model'] == \"gpt-3.5-turbo\"\n        assert stats['provider'] == \"openai\"\n        assert stats['responses_generated'] == 5\n        assert stats['total_errors'] == 1\n        assert 'success_rate' in stats\n        assert 'average_response_time' in stats\n\n    def test_update_personality(self, bot_client):\n        \"\"\"Test updating bot personality.\"\"\"\n        bot_client.update_personality(\"New personality\", \"con\")\n\n        assert bot_client.config.personality == \"New personality\"\n        assert bot_client.config.stance == \"con\"\n\n    def test_reset_conversation(self, bot_client):\n        \"\"\"Test resetting conversation history.\"\"\"\n        # Add some conversation history\n        bot_client.conversation_history = [\n            {'role': 'user', 'content': 'Test message'}\n        ]\n        bot_client.response_count = 3\n\n        bot_client.reset_conversation()\n\n        assert bot_client.conversation_history == []\n        assert bot_client.response_count == 0\n\n    @pytest.mark.asyncio\n    async def test_warmup_success(self, bot_client):\n        \"\"\"Test successful bot warmup.\"\"\"\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=\"Ready\")\n\n        result = await bot_client.warmup()\n\n        assert result == True\n\n    @pytest.mark.asyncio\n    async def test_warmup_failure(self, bot_client):\n        \"\"\"Test failed bot warmup.\"\"\"\n        bot_client.ai_provider.generate_response = AsyncMock(\n            side_effect=Exception(\"Connection failed\")\n        )\n\n        result = await bot_client.warmup()\n\n        assert result == False\n\n    def test_str_representation(self, bot_client):\n        \"\"\"Test string representation of bot.\"\"\"\n        string_repr = str(bot_client)\n\n        assert \"TestBot\" in string_repr\n        assert \"gpt-3.5-turbo\" in string_repr\n        assert \"pro\" in string_repr\n\n    def test_repr_representation(self, bot_client):\n        \"\"\"Test detailed string representation of bot.\"\"\"\n        repr_str = repr(bot_client)\n\n        assert \"BotClient\" in repr_str\n        assert \"name='TestBot'\" in repr_str\n        assert \"model='gpt-3.5-turbo'\" in repr_str\n\n\nclass TestOpenAIProvider:\n    \"\"\"Test suite for OpenAIProvider class.\"\"\"\n\n    def test_openai_provider_initialization(self):\n        \"\"\"Test OpenAI provider initialization.\"\"\"\n        provider = OpenAIProvider(\"test-api-key\")\n        assert provider.api_key == \"test-api-key\"\n\n    @pytest.mark.asyncio\n    async def test_generate_response_success(self):\n        \"\"\"Test successful response generation.\"\"\"\n        provider = OpenAIProvider(\"test-key\")\n        config = BotConfig(\"TestBot\", \"gpt-3.5-turbo\", \"openai\", \"Test\", \"pro\")\n        messages = [{\"role\": \"user\", \"content\": \"Hello\"}]\n\n        # Mock OpenAI client\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\n            mock_client = Mock()\n            mock_openai.return_value = mock_client\n\n            # Mock response\n            mock_response = Mock()\n            mock_response.choices = [Mock()]\n            mock_response.choices[0].message.content = \"Hello! How can I help?\"\n            mock_client.chat.completions.create = AsyncMock(return_value=mock_response)\n\n            response = await provider.generate_response(messages, config)\n\n            assert response == \"Hello! How can I help?\"\n            mock_client.chat.completions.create.assert_called_once()\n\n    @pytest.mark.asyncio\n    async def test_generate_response_error(self):\n        \"\"\"Test response generation with error.\"\"\"\n        provider = OpenAIProvider(\"test-key\")\n        config = BotConfig(\"TestBot\", \"gpt-3.5-turbo\", \"openai\", \"Test\", \"pro\")\n        messages = [{\"role\": \"user\", \"content\": \"Hello\"}]\n\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\n            mock_client = Mock()\n            mock_openai.return_value = mock_client\n            mock_client.chat.completions.create = AsyncMock(\n                side_effect=Exception(\"API Error\")\n            )\n\n            with pytest.raises(Exception, match=\"OpenAI API error\"):\n                await provider.generate_response(messages, config)\n\n\nclass TestAnthropicProvider:\n    \"\"\"Test suite for AnthropicProvider class.\"\"\"\n\n    def test_anthropic_provider_initialization(self):\n        \"\"\"Test Anthropic provider initialization.\"\"\"\n        provider = AnthropicProvider(\"test-api-key\")\n        assert provider.api_key == \"test-api-key\"\n\n    @pytest.mark.asyncio\n    async def test_generate_response_success(self):\n        \"\"\"Test successful response generation.\"\"\"\n        provider = AnthropicProvider(\"test-key\")\n        config = BotConfig(\"TestBot\", \"claude-3-sonnet\", \"anthropic\", \"Test\", \"pro\")\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n            {\"role\": \"user\", \"content\": \"Hello\"}\n        ]\n\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\n            mock_client = Mock()\n            mock_anthropic.return_value = mock_client\n\n            # Mock response\n            mock_response = Mock()\n            mock_response.content = [Mock()]\n            mock_response.content[0].text = \"Hello! How can I assist you?\"\n            mock_client.messages.create = AsyncMock(return_value=mock_response)\n\n            response = await provider.generate_response(messages, config)\n\n            assert response == \"Hello! How can I assist you?\"\n            mock_client.messages.create.assert_called_once()\n\n    @pytest.mark.asyncio\n    async def test_generate_response_error(self):\n        \"\"\"Test response generation with error.\"\"\"\n        provider = AnthropicProvider(\"test-key\")\n        config = BotConfig(\"TestBot\", \"claude-3-sonnet\", \"anthropic\", \"Test\", \"pro\")\n        messages = [{\"role\": \"user\", \"content\": \"Hello\"}]\n\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\n            mock_client = Mock()\n            mock_anthropic.return_value = mock_client\n            mock_client.messages.create = AsyncMock(\n                side_effect=Exception(\"API Error\")\n            )\n\n            with pytest.raises(Exception, match=\"Anthropic API error\"):\n                await provider.generate_response(messages, config)\n\n\n@pytest.mark.asyncio\nasync def test_conversation_history_management(bot_client):\n    \"\"\"Test conversation history management.\"\"\"\n    # Add messages beyond the limit\n    for i in range(25):\n        message = Message(f\"User{i}\", f\"Message {i}\", 1640995200.0 + i, i)\n        await bot_client.receive_message(message)\n\n    # Should be limited to avoid memory issues\n    assert len(bot_client.conversation_history) <= 20\n\n\n@pytest.mark.asyncio\nasync def test_bot_response_timing(bot_client, sample_messages):\n    \"\"\"Test that response timing is tracked.\"\"\"\n    bot_client.ai_provider.generate_response = AsyncMock(return_value=\"Test response\")\n\n    # Simulate some delay\n    async def delayed_response(*args):\n        await asyncio.sleep(0.01)\n        return \"Delayed response\"\n\n    bot_client.ai_provider.generate_response = delayed_response\n\n    await bot_client.get_response(\"Test topic\", sample_messages)\n\n    assert bot_client.stats['average_response_time'] > 0\n    assert bot_client.stats['total_response_time'] > 0"
        },
        "test_chat_log.py": {
          "type": "file",
          "path": "tests/test_chat_log.py",
          "extension": ".py",
          "size": 15406,
          "content": "\"\"\"\nTests for the ChatLog class.\n\"\"\"\n\nimport pytest\nimport asyncio\nimport json\nimport time\nfrom pathlib import Path\nfrom unittest.mock import patch, mock_open\nfrom app.chat_log import ChatLog, Message\n\n\n@pytest.fixture\ndef chat_log():\n    \"\"\"Create a test chat log.\"\"\"\n    return ChatLog(max_messages=100)\n\n\n@pytest.fixture\ndef sample_messages():\n    \"\"\"Create sample messages for testing.\"\"\"\n    return [\n        Message(\"Alice\", \"Hello everyone!\", time.time(), 1),\n        Message(\"Bob\", \"Hi Alice!\", time.time(), 2),\n        Message(\"moderator\", \"Welcome to the debate\", time.time(), 3, \"moderator\")\n    ]\n\n\nclass TestMessage:\n    \"\"\"Test suite for Message dataclass.\"\"\"\n\n    def test_message_creation(self):\n        \"\"\"Test creating a message.\"\"\"\n        timestamp = time.time()\n        msg = Message(\"Alice\", \"Hello world\", timestamp, 1)\n\n        assert msg.sender == \"Alice\"\n        assert msg.content == \"Hello world\"\n        assert msg.timestamp == timestamp\n        assert msg.message_id == 1\n        assert msg.message_type == \"chat\"\n        assert msg.metadata == {}\n\n    def test_message_with_metadata(self):\n        \"\"\"Test message with metadata.\"\"\"\n        metadata = {\"urgency\": \"high\", \"topic\": \"AI\"}\n        msg = Message(\"Bob\", \"Important point\", time.time(), 2,\n                      message_type=\"system\", metadata=metadata)\n\n        assert msg.message_type == \"system\"\n        assert msg.metadata == metadata\n\n    def test_formatted_timestamp(self):\n        \"\"\"Test formatted timestamp property.\"\"\"\n        timestamp = 1640995200.0  # Known timestamp\n        msg = Message(\"Alice\", \"Test\", timestamp, 1)\n\n        formatted = msg.formatted_timestamp\n        assert isinstance(formatted, str)\n        assert \":\" in formatted  # Should contain time separator\n\n    def test_to_dict(self):\n        \"\"\"Test converting message to dictionary.\"\"\"\n        msg = Message(\"Alice\", \"Test\", time.time(), 1)\n        msg_dict = msg.to_dict()\n\n        assert isinstance(msg_dict, dict)\n        assert msg_dict[\"sender\"] == \"Alice\"\n        assert msg_dict[\"content\"] == \"Test\"\n        assert \"timestamp\" in msg_dict\n        assert \"message_id\" in msg_dict\n\n    def test_from_dict(self):\n        \"\"\"Test creating message from dictionary.\"\"\"\n        data = {\n            \"sender\": \"Bob\",\n            \"content\": \"Test message\",\n            \"timestamp\": time.time(),\n            \"message_id\": 5,\n            \"message_type\": \"chat\",\n            \"metadata\": {}\n        }\n\n        msg = Message.from_dict(data)\n\n        assert msg.sender == \"Bob\"\n        assert msg.content == \"Test message\"\n        assert msg.message_id == 5\n\n\nclass TestChatLog:\n    \"\"\"Test suite for ChatLog class.\"\"\"\n\n    def test_chat_log_initialization(self):\n        \"\"\"Test chat log initialization.\"\"\"\n        chat_log = ChatLog(max_messages=50)\n\n        assert len(chat_log.messages) == 0\n        assert chat_log.message_counter == 0\n        assert chat_log.subscribers == []\n        assert chat_log.stats[\"total_messages\"] == 0\n\n    @pytest.mark.asyncio\n    async def test_add_message(self, chat_log):\n        \"\"\"Test adding a message.\"\"\"\n        message = await chat_log.add_message(\"Alice\", \"Hello world\")\n\n        assert isinstance(message, Message)\n        assert message.sender == \"Alice\"\n        assert message.content == \"Hello world\"\n        assert message.message_id == 1\n        assert len(chat_log.messages) == 1\n        assert chat_log.stats[\"total_messages\"] == 1\n        assert chat_log.stats[\"messages_by_sender\"][\"Alice\"] == 1\n\n    @pytest.mark.asyncio\n    async def test_add_multiple_messages(self, chat_log):\n        \"\"\"Test adding multiple messages.\"\"\"\n        await chat_log.add_message(\"Alice\", \"First message\")\n        await chat_log.add_message(\"Bob\", \"Second message\")\n        await chat_log.add_message(\"Alice\", \"Third message\")\n\n        assert len(chat_log.messages) == 3\n        assert chat_log.message_counter == 3\n        assert chat_log.stats[\"messages_by_sender\"][\"Alice\"] == 2\n        assert chat_log.stats[\"messages_by_sender\"][\"Bob\"] == 1\n\n    @pytest.mark.asyncio\n    async def test_message_ordering(self, chat_log):\n        \"\"\"Test that messages maintain chronological order.\"\"\"\n        msg1 = await chat_log.add_message(\"Alice\", \"First\")\n        await asyncio.sleep(0.01)  # Small delay\n        msg2 = await chat_log.add_message(\"Bob\", \"Second\")\n\n        messages = list(chat_log.messages)\n        assert messages[0].message_id == 1\n        assert messages[1].message_id == 2\n        assert messages[0].timestamp < messages[1].timestamp\n\n    @pytest.mark.asyncio\n    async def test_max_messages_limit(self):\n        \"\"\"Test message limit enforcement.\"\"\"\n        chat_log = ChatLog(max_messages=3)\n\n        # Add more messages than the limit\n        for i in range(5):\n            await chat_log.add_message(\"User\", f\"Message {i}\")\n\n        assert len(chat_log.messages) == 3  # Should be limited\n\n        # Check that oldest messages were removed\n        messages = list(chat_log.messages)\n        assert \"Message 2\" in messages[0].content\n        assert \"Message 4\" in messages[2].content\n\n    @pytest.mark.asyncio\n    async def test_subscription_system(self, chat_log):\n        \"\"\"Test message subscription system.\"\"\"\n        queue = chat_log.subscribe()\n\n        # Add a message\n        message = await chat_log.add_message(\"Alice\", \"Test message\")\n\n        # Check that subscriber received the message\n        received_message = await asyncio.wait_for(queue.get(), timeout=1.0)\n        assert received_message.content == \"Test message\"\n        assert received_message.sender == \"Alice\"\n\n    @pytest.mark.asyncio\n    async def test_multiple_subscribers(self, chat_log):\n        \"\"\"Test multiple subscribers.\"\"\"\n        queue1 = chat_log.subscribe()\n        queue2 = chat_log.subscribe()\n\n        await chat_log.add_message(\"Alice\", \"Broadcast message\")\n\n        # Both subscribers should receive the message\n        msg1 = await asyncio.wait_for(queue1.get(), timeout=1.0)\n        msg2 = await asyncio.wait_for(queue2.get(), timeout=1.0)\n\n        assert msg1.content == msg2.content == \"Broadcast message\"\n\n    def test_unsubscribe(self, chat_log):\n        \"\"\"Test unsubscribing from messages.\"\"\"\n        queue = chat_log.subscribe()\n        assert queue in chat_log.subscribers\n\n        chat_log.unsubscribe(queue)\n        assert queue not in chat_log.subscribers\n\n    def test_get_messages_no_filter(self, chat_log, sample_messages):\n        \"\"\"Test getting all messages without filters.\"\"\"\n        # Manually add messages to chat log\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        messages = chat_log.get_messages()\n        assert len(messages) == 3\n        assert messages[0].sender == \"Alice\"\n\n    def test_get_messages_with_limit(self, chat_log, sample_messages):\n        \"\"\"Test getting messages with limit.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        messages = chat_log.get_messages(limit=2)\n        assert len(messages) == 2\n        # Should get the last 2 messages\n        assert messages[0].sender == \"Bob\"\n        assert messages[1].sender == \"moderator\"\n\n    def test_get_messages_by_sender(self, chat_log, sample_messages):\n        \"\"\"Test filtering messages by sender.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        alice_messages = chat_log.get_messages(sender=\"Alice\")\n        assert len(alice_messages) == 1\n        assert alice_messages[0].sender == \"Alice\"\n\n    def test_get_messages_by_type(self, chat_log, sample_messages):\n        \"\"\"Test filtering messages by type.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        moderator_messages = chat_log.get_messages(message_type=\"moderator\")\n        assert len(moderator_messages) == 1\n        assert moderator_messages[0].message_type == \"moderator\"\n\n    def test_get_messages_since_timestamp(self, chat_log):\n        \"\"\"Test filtering messages by timestamp.\"\"\"\n        # Add messages with known timestamps\n        old_time = time.time() - 100\n        new_time = time.time()\n\n        chat_log.messages.append(Message(\"Alice\", \"Old\", old_time, 1))\n        chat_log.messages.append(Message(\"Bob\", \"New\", new_time, 2))\n\n        cutoff = time.time() - 50\n        recent_messages = chat_log.get_messages(since_timestamp=cutoff)\n\n        assert len(recent_messages) == 1\n        assert recent_messages[0].content == \"New\"\n\n    def test_get_recent_messages(self, chat_log, sample_messages):\n        \"\"\"Test getting recent messages.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        recent = chat_log.get_recent_messages(2)\n        assert len(recent) == 2\n        assert recent[-1].sender == \"moderator\"  # Most recent\n\n    def test_get_conversation_context(self, chat_log):\n        \"\"\"Test getting conversation context for a participant.\"\"\"\n        # Add various messages\n        messages = [\n            Message(\"Alice\", \"Hello\", time.time(), 1),\n            Message(\"Bob\", \"Hi Alice\", time.time(), 2),\n            Message(\"moderator\", \"Welcome everyone\", time.time(), 3, \"moderator\"),\n            Message(\"Alice\", \"Thanks!\", time.time(), 4),\n            Message(\"Charlie\", \"Good luck\", time.time(), 5)\n        ]\n\n        for msg in messages:\n            chat_log.messages.append(msg)\n\n        context = chat_log.get_conversation_context(\"Alice\", context_length=3)\n\n        # Should include Alice's messages and moderator messages\n        assert len(context) <= 3\n        assert any(msg.sender == \"Alice\" for msg in context)\n        assert any(msg.message_type == \"moderator\" for msg in context)\n\n    def test_search_messages(self, chat_log, sample_messages):\n        \"\"\"Test searching messages by content.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        # Case insensitive search\n        results = chat_log.search_messages(\"hello\")\n        assert len(results) == 1\n        assert \"Hello\" in results[0].content\n\n        # Case sensitive search\n        results = chat_log.search_messages(\"Hello\", case_sensitive=True)\n        assert len(results) == 1\n\n        results = chat_log.search_messages(\"hello\", case_sensitive=True)\n        assert len(results) == 0\n\n    def test_get_statistics(self, chat_log, sample_messages):\n        \"\"\"Test getting chat log statistics.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n            chat_log.stats[\"total_messages\"] += 1\n            sender = msg.sender\n            chat_log.stats[\"messages_by_sender\"][sender] = (\n                    chat_log.stats[\"messages_by_sender\"].get(sender, 0) + 1\n            )\n\n        stats = chat_log.get_statistics()\n\n        assert stats[\"total_messages\"] == 3\n        assert stats[\"unique_senders\"] == 2  # Alice, Bob, moderator\n        assert \"messages_by_sender\" in stats\n        assert \"messages_per_minute\" in stats\n        assert \"session_duration_minutes\" in stats\n\n    @pytest.mark.asyncio\n    async def test_save_transcript_json(self, chat_log, tmp_path):\n        \"\"\"Test saving transcript in JSON format.\"\"\"\n        await chat_log.add_message(\"Alice\", \"Test message\")\n\n        output_file = tmp_path / \"transcript.json\"\n        await chat_log.save_transcript(str(output_file), \"json\")\n\n        assert output_file.exists()\n\n        with open(output_file, 'r') as f:\n            data = json.load(f)\n\n        assert \"metadata\" in data\n        assert \"messages\" in data\n        assert len(data[\"messages\"]) == 1\n        assert data[\"messages\"][0][\"content\"] == \"Test message\"\n\n    @pytest.mark.asyncio\n    async def test_save_transcript_txt(self, chat_log, tmp_path):\n        \"\"\"Test saving transcript in TXT format.\"\"\"\n        await chat_log.add_message(\"Alice\", \"Test message\")\n\n        output_file = tmp_path / \"transcript.txt\"\n        await chat_log.save_transcript(str(output_file), \"txt\")\n\n        assert output_file.exists()\n\n        content = output_file.read_text()\n        assert \"DEBATE TRANSCRIPT\" in content\n        assert \"Alice: Test message\" in content\n\n    @pytest.mark.asyncio\n    async def test_save_transcript_html(self, chat_log, tmp_path):\n        \"\"\"Test saving transcript in HTML format.\"\"\"\n        await chat_log.add_message(\"Alice\", \"Test message\")\n        await chat_log.add_message(\"moderator\", \"System message\",\n                                   message_type=\"moderator\")\n\n        output_file = tmp_path / \"transcript.html\"\n        await chat_log.save_transcript(str(output_file), \"html\")\n\n        assert output_file.exists()\n\n        content = output_file.read_text()\n        assert \"<!DOCTYPE html>\" in content\n        assert \"Alice\" in content\n        assert \"moderator\" in content\n        assert \"class=\\\"moderator\\\"\" in content\n\n    @pytest.mark.asyncio\n    async def test_save_transcript_invalid_format(self, chat_log):\n        \"\"\"Test saving transcript with invalid format.\"\"\"\n        with pytest.raises(ValueError, match=\"Unsupported format\"):\n            await chat_log.save_transcript(\"test.xml\", \"xml\")\n\n    @pytest.mark.asyncio\n    async def test_load_transcript(self, chat_log, tmp_path):\n        \"\"\"Test loading transcript from file.\"\"\"\n        # Save a transcript first\n        await chat_log.add_message(\"Alice\", \"Original message\")\n        output_file = tmp_path / \"transcript.json\"\n        await chat_log.save_transcript(str(output_file), \"json\")\n\n        # Clear chat log and reload\n        chat_log.clear()\n        assert len(chat_log.messages) == 0\n\n        await chat_log.load_transcript(str(output_file))\n\n        assert len(chat_log.messages) == 1\n        assert list(chat_log.messages)[0].content == \"Original message\"\n\n    @pytest.mark.asyncio\n    async def test_load_transcript_file_not_found(self, chat_log):\n        \"\"\"Test loading transcript from non-existent file.\"\"\"\n        with pytest.raises(FileNotFoundError):\n            await chat_log.load_transcript(\"nonexistent.json\")\n\n    def test_clear_chat_log(self, chat_log, sample_messages):\n        \"\"\"Test clearing the chat log.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        chat_log.message_counter = 5\n        chat_log.stats[\"total_messages\"] = 3\n\n        chat_log.clear()\n\n        assert len(chat_log.messages) == 0\n        assert chat_log.message_counter == 0\n        assert chat_log.stats[\"total_messages\"] == 0\n        assert chat_log.stats[\"messages_by_sender\"] == {}\n\n    def test_chat_log_len(self, chat_log, sample_messages):\n        \"\"\"Test chat log length.\"\"\"\n        assert len(chat_log) == 0\n\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        assert len(chat_log) == 3\n\n    def test_chat_log_iteration(self, chat_log, sample_messages):\n        \"\"\"Test iterating over chat log.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        iterated_messages = list(chat_log)\n        assert len(iterated_messages) == 3\n        assert iterated_messages[0].sender == \"Alice\"\n\n    def test_chat_log_indexing(self, chat_log, sample_messages):\n        \"\"\"Test indexing chat log.\"\"\"\n        for msg in sample_messages:\n            chat_log.messages.append(msg)\n\n        first_message = chat_log[0]\n        assert first_message.sender == \"Alice\"\n\n        last_message = chat_log[-1]\n        assert last_message.sender == \"moderator\"\n        "
        },
        "test_human_client.py": {
          "type": "file",
          "path": "tests/test_human_client.py",
          "extension": ".py",
          "size": 20297,
          "content": "\"\"\"\nTests for the HumanClient class.\n\"\"\"\n\nimport pytest\nimport asyncio\nfrom unittest.mock import Mock, AsyncMock, patch\nfrom app.human_client import HumanClient, CLIInterface, WebInterface, InterfaceConfig\nfrom app.chat_log import Message\n\n\n@pytest.fixture\ndef interface_config():\n    \"\"\"Create test interface configuration.\"\"\"\n    return {\n        'mode': 'cli',\n        'enable_rich_formatting': False,  # Disable for testing\n        'show_typing_indicators': True,\n        'enable_reactions': True,\n        'input_timeout': 60\n    }\n\n\n@pytest.fixture\ndef human_client(interface_config):\n    \"\"\"Create test human client.\"\"\"\n    return HumanClient(\"TestHuman\", interface_config)\n\n\n@pytest.fixture\ndef sample_messages():\n    \"\"\"Create sample messages for testing.\"\"\"\n    return [\n        Message(\"Alice\", \"What's your opinion?\", 1640995200.0, 1),\n        Message(\"Bob\", \"I think...\", 1640995210.0, 2),\n        Message(\"moderator\", \"Please respond\", 1640995220.0, 3, \"moderator\")\n    ]\n\n\nclass TestInterfaceConfig:\n    \"\"\"Test suite for InterfaceConfig dataclass.\"\"\"\n\n    def test_interface_config_defaults(self):\n        \"\"\"Test interface config with default values.\"\"\"\n        config = InterfaceConfig()\n\n        assert config.mode == \"cli\"\n        assert config.enable_rich_formatting == True\n        assert config.show_typing_indicators == True\n        assert config.enable_reactions == True\n        assert config.input_timeout == 120\n\n    def test_interface_config_custom(self):\n        \"\"\"Test interface config with custom values.\"\"\"\n        config = InterfaceConfig(\n            mode=\"web\",\n            enable_rich_formatting=False,\n            input_timeout=90\n        )\n\n        assert config.mode == \"web\"\n        assert config.enable_rich_formatting == False\n        assert config.input_timeout == 90\n\n\nclass TestCLIInterface:\n    \"\"\"Test suite for CLIInterface class.\"\"\"\n\n    def test_cli_interface_initialization(self):\n        \"\"\"Test CLI interface initialization.\"\"\"\n        config = InterfaceConfig(enable_rich_formatting=False)\n        interface = CLIInterface(config)\n\n        assert interface.config == config\n        assert interface.rich_console is None  # Rich disabled\n\n    @pytest.mark.asyncio\n    async def test_display_basic_message(self):\n        \"\"\"Test displaying message with basic formatting.\"\"\"\n        config = InterfaceConfig(enable_rich_formatting=False)\n        interface = CLIInterface(config)\n\n        message = Message(\"Alice\", \"Hello world\", 1640995200.0, 1)\n\n        with patch('builtins.print') as mock_print:\n            await interface.display_message(message)\n            mock_print.assert_called_once()\n\n    @pytest.mark.asyncio\n    async def test_display_moderator_message(self):\n        \"\"\"Test displaying moderator message.\"\"\"\n        config = InterfaceConfig(enable_rich_formatting=False)\n        interface = CLIInterface(config)\n\n        message = Message(\"moderator\", \"Welcome!\", 1640995200.0, 1, \"moderator\")\n\n        with patch('builtins.print') as mock_print:\n            await interface.display_message(message)\n            mock_print.assert_called_once()\n            # Should have moderator prefix\n            args = mock_print.call_args[0]\n            assert \"üé≠\" in args[0]\n\n    @pytest.mark.asyncio\n    async def test_get_input_success(self):\n        \"\"\"Test successful input retrieval.\"\"\"\n        config = InterfaceConfig(enable_rich_formatting=False)\n        interface = CLIInterface(config)\n\n        with patch('builtins.input', return_value=\"Test response\"):\n            response = await interface.get_input(\"Enter response:\", timeout=1)\n            assert response == \"Test response\"\n\n    @pytest.mark.asyncio\n    async def test_get_input_timeout(self):\n        \"\"\"Test input timeout.\"\"\"\n        config = InterfaceConfig(enable_rich_formatting=False)\n        interface = CLIInterface(config)\n\n        # Mock input to simulate hanging\n        async def slow_input():\n            await asyncio.sleep(2)\n            return \"Too late\"\n\n        interface._get_user_input = slow_input\n\n        response = await interface.get_input(\"Enter response:\", timeout=0.1)\n        assert response == \"\"  # Should return empty string on timeout\n\n    @pytest.mark.asyncio\n    async def test_show_notification(self):\n        \"\"\"Test showing notifications.\"\"\"\n        config = InterfaceConfig(enable_rich_formatting=False)\n        interface = CLIInterface(config)\n\n        with patch('builtins.print') as mock_print:\n            await interface.show_notification(\"Test notification\", \"info\")\n            mock_print.assert_called_once()\n            args = mock_print.call_args[0]\n            assert \"‚ÑπÔ∏è\" in args[0]\n            assert \"Test notification\" in args[0]\n\n\nclass TestWebInterface:\n    \"\"\"Test suite for WebInterface class.\"\"\"\n\n    def test_web_interface_initialization(self):\n        \"\"\"Test web interface initialization.\"\"\"\n        config = InterfaceConfig(mode=\"web\")\n        interface = WebInterface(config)\n\n        assert interface.config == config\n        assert interface.websocket is None\n        assert interface.pending_responses == {}\n\n    @pytest.mark.asyncio\n    async def test_display_message_no_websocket(self):\n        \"\"\"Test displaying message without websocket connection.\"\"\"\n        config = InterfaceConfig(mode=\"web\")\n        interface = WebInterface(config)\n\n        message = Message(\"Alice\", \"Hello\", 1640995200.0, 1)\n\n        # Should not raise an error even without websocket\n        await interface.display_message(message)\n\n    @pytest.mark.asyncio\n    async def test_get_input_no_websocket(self):\n        \"\"\"Test getting input without websocket connection.\"\"\"\n        config = InterfaceConfig(mode=\"web\")\n        interface = WebInterface(config)\n\n        response = await interface.get_input(\"Enter response:\")\n        assert response == \"\"  # Should return empty string\n\n\nclass TestHumanClient:\n    \"\"\"Test suite for HumanClient class.\"\"\"\n\n    def test_human_client_initialization(self, interface_config):\n        \"\"\"Test human client initialization.\"\"\"\n        client = HumanClient(\"TestHuman\", interface_config)\n\n        assert client.name == \"TestHuman\"\n        assert isinstance(client.interface, CLIInterface)\n        assert client.is_active == True\n        assert client.conversation_history == []\n        assert client.stats['responses_given'] == 0\n\n    def test_human_client_web_mode(self):\n        \"\"\"Test human client with web interface.\"\"\"\n        config = {'mode': 'web'}\n        client = HumanClient(\"WebHuman\", config)\n\n        assert isinstance(client.interface, WebInterface)\n\n    def test_human_client_unsupported_mode(self):\n        \"\"\"Test human client with unsupported interface mode.\"\"\"\n        config = {'mode': 'unsupported'}\n\n        with pytest.raises(ValueError, match=\"Unsupported interface mode\"):\n            HumanClient(\"TestHuman\", config)\n\n    @pytest.mark.asyncio\n    async def test_get_response_success(self, human_client, sample_messages):\n        \"\"\"Test successful response retrieval.\"\"\"\n        # Mock the interface get_input method\n        human_client.interface.get_input = AsyncMock(return_value=\"My response\")\n        human_client.interface.show_notification = AsyncMock()\n        human_client.interface.display_message = AsyncMock()\n\n        response = await human_client.get_response(\"Test topic\", sample_messages)\n\n        assert response == \"My response\"\n        assert human_client.stats['responses_given'] == 1\n\n    @pytest.mark.asyncio\n    async def test_get_response_timeout(self, human_client, sample_messages):\n        \"\"\"Test response timeout.\"\"\"\n        # Mock timeout scenario\n        human_client.interface.get_input = AsyncMock(return_value=\"\")\n        human_client.interface.show_notification = AsyncMock()\n        human_client.interface.display_message = AsyncMock()\n\n        response = await human_client.get_response(\"Test topic\", sample_messages)\n\n        assert response == \"\"\n        assert human_client.stats['timeouts'] == 1\n\n    @pytest.mark.asyncio\n    async def test_get_response_inactive(self, human_client, sample_messages):\n        \"\"\"Test response when client is inactive.\"\"\"\n        human_client.is_active = False\n\n        response = await human_client.get_response(\"Test topic\", sample_messages)\n\n        assert response == \"\"\n\n    def test_validate_response(self, human_client):\n        \"\"\"Test response validation.\"\"\"\n        # Normal response\n        response = human_client._validate_response(\"This is a good response\")\n        assert response == \"This is a good response\"\n\n        # Very long response\n        long_response = \"x\" * 600\n        response = human_client._validate_response(long_response)\n        assert len(response) <= 503  # 500 + \"...\"\n        assert response.endswith(\"...\")\n\n        # Very short response\n        short_response = human_client._validate_response(\"Yes\")\n        assert \"[Note: Very short response]\" in short_response\n\n    @pytest.mark.asyncio\n    async def test_receive_message(self, human_client):\n        \"\"\"Test receiving a message.\"\"\"\n        message = Message(\"Alice\", \"Hello human\", 1640995200.0, 1)\n        human_client.interface.display_message = AsyncMock()\n\n        await human_client.receive_message(message)\n\n        # Should be added to conversation history\n        assert len(human_client.conversation_history) == 1\n        assert human_client.conversation_history[0] == message\n\n        # Should display the message\n        human_client.interface.display_message.assert_called_once_with(message)\n\n    @pytest.mark.asyncio\n    async def test_receive_own_message(self, human_client):\n        \"\"\"Test receiving own message (should be ignored).\"\"\"\n        message = Message(\"TestHuman\", \"My own message\", 1640995200.0, 1)\n        human_client.interface.display_message = AsyncMock()\n\n        await human_client.receive_message(message)\n\n        # Should not be added to history or displayed\n        assert len(human_client.conversation_history) == 0\n        human_client.interface.display_message.assert_not_called()\n\n    @pytest.mark.asyncio\n    async def test_conversation_history_limit(self, human_client):\n        \"\"\"Test conversation history length limit.\"\"\"\n        human_client.interface.display_message = AsyncMock()\n\n        # Add many messages\n        for i in range(60):\n            message = Message(f\"User{i}\", f\"Message {i}\", 1640995200.0 + i, i)\n            await human_client.receive_message(message)\n\n        # Should be limited to 30 (as per implementation)\n        assert len(human_client.conversation_history) == 30\n\n    @pytest.mark.asyncio\n    async def test_handle_voting_success(self, human_client):\n        \"\"\"Test successful voting.\"\"\"\n        candidates = [\"Alice\", \"Bob\", \"Charlie\"]\n\n        # Mock interface methods\n        human_client.interface.show_notification = AsyncMock()\n        human_client.interface.get_input = AsyncMock(side_effect=[\"2\", \"Good arguments\"])\n\n        result = await human_client.handle_voting(candidates, 60)\n\n        assert result['voted'] == True\n        assert result['candidate'] == \"Bob\"  # Index 2-1 = 1 -> \"Bob\"\n        assert result['justification'] == \"Good arguments\"\n\n    @pytest.mark.asyncio\n    async def test_handle_voting_timeout(self, human_client):\n        \"\"\"Test voting timeout.\"\"\"\n        candidates = [\"Alice\", \"Bob\"]\n\n        human_client.interface.show_notification = AsyncMock()\n        human_client.interface.get_input = AsyncMock(return_value=\"\")  # Timeout\n\n        result = await human_client.handle_voting(candidates, 30)\n\n        assert result['voted'] == False\n        assert result['reason'] == 'timeout'\n\n    @pytest.mark.asyncio\n    async def test_handle_voting_invalid_choice(self, human_client):\n        \"\"\"Test voting with invalid choice.\"\"\"\n        candidates = [\"Alice\", \"Bob\"]\n\n        human_client.interface.show_notification = AsyncMock()\n        human_client.interface.get_input = AsyncMock(return_value=\"5\")  # Out of range\n\n        result = await human_client.handle_voting(candidates, 30)\n\n        assert result['voted'] == False\n        assert result['reason'] == 'invalid_choice'\n\n    @pytest.mark.asyncio\n    async def test_handle_voting_invalid_format(self, human_client):\n        \"\"\"Test voting with invalid input format.\"\"\"\n        candidates = [\"Alice\", \"Bob\"]\n\n        human_client.interface.show_notification = AsyncMock()\n        human_client.interface.get_input = AsyncMock(return_value=\"not_a_number\")\n\n        result = await human_client.handle_voting(candidates, 30)\n\n        assert result['voted'] == False\n        assert result['reason'] == 'invalid_format'\n\n    def test_update_stats_success(self, human_client):\n        \"\"\"Test updating statistics on successful response.\"\"\"\n        human_client._update_stats(2.5, success=True)\n\n        assert human_client.stats['responses_given'] == 1\n        assert human_client.stats['average_response_time'] == 2.5\n        assert human_client.stats['total_response_time'] == 2.5\n\n    def test_update_stats_timeout(self, human_client):\n        \"\"\"Test updating statistics on timeout.\"\"\"\n        human_client._update_stats(5.0, success=False)\n\n        assert human_client.stats['timeouts'] == 1\n        assert human_client.stats['responses_given'] == 0\n\n    def test_get_stats(self, human_client):\n        \"\"\"Test getting human client statistics.\"\"\"\n        # Add some test data\n        human_client.stats['responses_given'] = 3\n        human_client.stats['timeouts'] = 1\n        human_client.stats['total_response_time'] = 15.0\n        human_client._update_stats(0, success=True)  # Recalculate average\n\n        stats = human_client.get_stats()\n\n        assert stats['name'] == \"TestHuman\"\n        assert stats['interface_mode'] == \"cli\"\n        assert stats['responses_given'] == 3\n        assert stats['timeouts'] == 1\n        assert stats['participation_rate'] == 0.75  # 3/(3+1)\n        assert 'average_response_time' in stats\n\n    @pytest.mark.asyncio\n    async def test_set_active(self, human_client):\n        \"\"\"Test setting client active/inactive status.\"\"\"\n        human_client.interface.show_notification = AsyncMock()\n\n        # Set inactive\n        await human_client.set_active(False)\n        assert human_client.is_active == False\n\n        # Set active\n        await human_client.set_active(True)\n        assert human_client.is_active == True\n\n        # Should have called show_notification twice\n        assert human_client.interface.show_notification.call_count == 2\n\n    @pytest.mark.asyncio\n    async def test_show_help(self, human_client):\n        \"\"\"Test showing help information.\"\"\"\n        human_client.interface.show_notification = AsyncMock()\n\n        await human_client.show_help()\n\n        human_client.interface.show_notification.assert_called_once()\n        args = human_client.interface.show_notification.call_args[0]\n        assert \"AI Jubilee Debate Help\" in args[0]\n        assert \"COMMANDS:\" in args[0]\n\n    def test_str_representation(self, human_client):\n        \"\"\"Test string representation of human client.\"\"\"\n        string_repr = str(human_client)\n\n        assert \"TestHuman\" in string_repr\n        assert \"cli\" in string_repr\n\n    def test_repr_representation(self, human_client):\n        \"\"\"Test detailed string representation of human client.\"\"\"\n        repr_str = repr(human_client)\n\n        assert \"HumanClient\" in repr_str\n        assert \"name='TestHuman'\" in repr_str\n        assert \"mode='cli'\" in repr_str\n        assert \"active=True\" in repr_str\n\n\n@pytest.mark.asyncio\nasync def test_show_context_integration(human_client, sample_messages):\n    \"\"\"Test showing context to human before response.\"\"\"\n    human_client.interface.show_notification = AsyncMock()\n    human_client.interface.display_message = AsyncMock()\n    human_client.interface.get_input = AsyncMock(return_value=\"Test response\")\n\n    await human_client.get_response(\"Test topic\", sample_messages)\n\n    # Should show context notification\n    notification_calls = human_client.interface.show_notification.call_args_list\n    assert any(\"Recent messages\" in str(call) for call in notification_calls)\n\n    # Should display recent messages\n    assert human_client.interface.display_message.call_count >= 1\n\n\n@pytest.mark.asyncio\nasync def test_human_response_validation_edge_cases(human_client):\n    \"\"\"Test edge cases in response validation.\"\"\"\n    # Empty response\n    result = human_client._validate_response(\"\")\n    assert result == \"\"\n\n    # Whitespace only\n    result = human_client._validate_response(\"   \\n\\t   \")\n    assert result == \"\"\n\n    # Response with just newlines\n    result = human_client._validate_response(\"\\n\\n\\n\")\n    assert result == \"\"\n\n    # Very short meaningful response\n    result = human_client._validate_response(\"No.\")\n    assert \"[Note: Very short response]\" in result\n\n\n@pytest.mark.asyncio\nasync def test_human_client_error_resilience(human_client, sample_messages):\n    \"\"\"Test human client resilience to interface errors.\"\"\"\n    # Mock interface to raise errors\n    human_client.interface.display_message = AsyncMock(side_effect=Exception(\"Interface error\"))\n    human_client.interface.show_notification = AsyncMock()\n    human_client.interface.get_input = AsyncMock(return_value=\"Test response\")\n\n    # Should not crash despite interface errors\n    response = await human_client.get_response(\"Test topic\", sample_messages)\n    assert response == \"Test response\"\n\n\n@pytest.mark.asyncio\nasync def test_human_client_concurrent_operations(human_client):\n    \"\"\"Test concurrent operations on human client.\"\"\"\n    human_client.interface.display_message = AsyncMock()\n\n    # Simulate concurrent message receiving\n    tasks = []\n    for i in range(10):\n        message = Message(f\"User{i}\", f\"Message {i}\", 1640995200.0 + i, i)\n        tasks.append(human_client.receive_message(message))\n\n    await asyncio.gather(*tasks)\n\n    # All messages should be processed\n    assert len(human_client.conversation_history) == 10\n\n\ndef test_human_client_stats_calculation(human_client):\n    \"\"\"Test statistics calculation accuracy.\"\"\"\n    # Simulate various response scenarios\n    human_client._update_stats(2.0, success=True)\n    human_client._update_stats(3.0, success=True)\n    human_client._update_stats(1.5, success=False)  # Timeout\n    human_client._update_stats(2.5, success=True)\n\n    stats = human_client.get_stats()\n\n    assert stats['responses_given'] == 3\n    assert stats['timeouts'] == 1\n    assert stats['participation_rate'] == 0.75  # 3/(3+1)\n    assert abs(stats['average_response_time'] - 2.5) < 0.1  # (2.0+3.0+2.5)/3\n\n\n@pytest.mark.asyncio\nasync def test_voting_with_web_interface():\n    \"\"\"Test voting behavior with web interface.\"\"\"\n    config = {'mode': 'web'}\n    client = HumanClient(\"WebUser\", config)\n    candidates = [\"Alice\", \"Bob\"]\n\n    # Web interface should handle justification differently\n    client.interface.show_notification = AsyncMock()\n    client.interface.get_input = AsyncMock(return_value=\"1\")\n\n    result = await client.handle_voting(candidates, 60)\n\n    assert result['voted'] == True\n    assert result['candidate'] == \"Alice\"\n    assert result['justification'] == \"\"  # No justification prompt for web\n\n\n@pytest.mark.asyncio\nasync def test_human_client_lifecycle():\n    \"\"\"Test complete human client lifecycle.\"\"\"\n    config = {'mode': 'cli', 'enable_rich_formatting': False}\n    client = HumanClient(\"LifecycleTest\", config)\n\n    # Initial state\n    assert client.is_active == True\n    assert len(client.conversation_history) == 0\n\n    # Mock interface for testing\n    client.interface.display_message = AsyncMock()\n    client.interface.show_notification = AsyncMock()\n    client.interface.get_input = AsyncMock(return_value=\"Test response\")\n\n    # Receive some messages\n    for i in range(3):\n        message = Message(f\"User{i}\", f\"Message {i}\", 1640995200.0 + i, i)\n        await client.receive_message(message)\n\n    assert len(client.conversation_history) == 3\n\n    # Participate in debate\n    response = await client.get_response(\"Test topic\", [])\n    assert response == \"Test response\"\n    assert client.stats['responses_given'] == 1\n\n    # Deactivate\n    await client.set_active(False)\n    assert client.is_active == False\n\n    # Should not respond when inactive\n    response = await client.get_response(\"Another topic\", [])\n    assert response == \"\""
        },
        "test_moderator.py": {
          "type": "file",
          "path": "tests/test_moderator.py",
          "extension": ".py",
          "size": 9146,
          "content": "\"\"\"\nTests for the Moderator class.\n\"\"\"\n\nimport pytest\nimport asyncio\nfrom unittest.mock import Mock, AsyncMock, patch\nfrom app.moderator import Moderator, DebatePhase, DebateState\nfrom app.chat_log import ChatLog\nfrom app.voting import VotingSystem\nfrom app.bot_client import BotClient\nfrom app.human_client import HumanClient\n\n\n@pytest.fixture\ndef chat_log():\n    \"\"\"Create a test chat log.\"\"\"\n    return ChatLog()\n\n\n@pytest.fixture\ndef voting_system():\n    \"\"\"Create a test voting system.\"\"\"\n    config = {'enabled': True, 'voting_duration': 60}\n    return VotingSystem(config)\n\n\n@pytest.fixture\ndef mock_participants():\n    \"\"\"Create mock participants.\"\"\"\n    bot = Mock(spec=BotClient)\n    bot.name = \"TestBot\"\n    bot.get_response = AsyncMock(return_value=\"Test response\")\n    bot.receive_message = AsyncMock()\n\n    human = Mock(spec=HumanClient)\n    human.name = \"TestHuman\"\n    human.get_response = AsyncMock(return_value=\"Human response\")\n    human.receive_message = AsyncMock()\n\n    return [bot, human]\n\n\n@pytest.fixture\ndef moderator(chat_log, voting_system, mock_participants):\n    \"\"\"Create a test moderator.\"\"\"\n    config = {\n        'opening_statement_time': 30,\n        'discussion_time': 60,\n        'closing_statement_time': 30,\n        'response_time': 20,\n        'max_response_time': 60,\n        'warning_time': 45\n    }\n\n    return Moderator(\n        topic=\"Test topic\",\n        participants=mock_participants,\n        chat_log=chat_log,\n        voting_system=voting_system,\n        config=config\n    )\n\n\nclass TestModerator:\n    \"\"\"Test suite for Moderator class.\"\"\"\n\n    def test_moderator_initialization(self, moderator):\n        \"\"\"Test moderator initialization.\"\"\"\n        assert moderator.topic == \"Test topic\"\n        assert len(moderator.participants) == 2\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\n        assert \"TestBot\" in moderator.participants\n        assert \"TestHuman\" in moderator.participants\n\n    @pytest.mark.asyncio\n    async def test_introduction_phase(self, moderator, chat_log):\n        \"\"\"Test introduction phase.\"\"\"\n        await moderator._introduction_phase()\n\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\n\n        # Check that introduction message was logged\n        messages = chat_log.get_messages()\n        assert any(\"Welcome to AI Jubilee Debate\" in msg.content for msg in messages)\n\n    @pytest.mark.asyncio\n    async def test_opening_statements_phase(self, moderator, mock_participants):\n        \"\"\"Test opening statements phase.\"\"\"\n        await moderator._opening_statements_phase()\n\n        assert moderator.state.phase == DebatePhase.OPENING_STATEMENTS\n\n        # Verify each participant was asked for response\n        for participant in mock_participants:\n            participant.get_response.assert_called()\n\n    @pytest.mark.asyncio\n    async def test_give_turn_success(self, moderator, mock_participants):\n        \"\"\"Test successful turn giving.\"\"\"\n        participant = mock_participants[0]\n        participant.get_response.return_value = \"Test response\"\n\n        await moderator._give_turn(participant.name, 30, \"test\")\n\n        participant.get_response.assert_called_once()\n        assert moderator.state.current_speaker is None  # Reset after turn\n\n    @pytest.mark.asyncio\n    async def test_give_turn_timeout(self, moderator, mock_participants):\n        \"\"\"Test turn timeout handling.\"\"\"\n        participant = mock_participants[0]\n\n        # Simulate timeout by making get_response take too long\n        async def slow_response(*args):\n            await asyncio.sleep(2)\n            return \"Too late\"\n\n        participant.get_response = slow_response\n\n        # Use very short timeout for testing\n        await moderator._give_turn(participant.name, 0.1, \"test\")\n\n        # Should have issued a warning\n        assert moderator.state.warnings_issued.get(participant.name, 0) >= 1\n\n    @pytest.mark.asyncio\n    async def test_voting_phase_enabled(self, moderator):\n        \"\"\"Test voting phase when voting is enabled.\"\"\"\n        moderator.voting_system.enabled = True\n\n        with patch.object(moderator.voting_system, 'start_voting') as mock_start:\n            with patch.object(moderator.voting_system, 'end_voting') as mock_end:\n                mock_end.return_value = {\n                    'winner': 'TestBot',\n                    'vote_counts': {'TestBot': 2, 'TestHuman': 1}\n                }\n\n                results = await moderator._voting_phase()\n\n                mock_start.assert_called_once()\n                mock_end.assert_called_once()\n                assert results['winner'] == 'TestBot'\n\n    @pytest.mark.asyncio\n    async def test_voting_phase_disabled(self, moderator):\n        \"\"\"Test voting phase when voting is disabled.\"\"\"\n        moderator.voting_system.enabled = False\n\n        results = await moderator._voting_phase()\n\n        assert results == {}\n\n    @pytest.mark.asyncio\n    async def test_broadcast_message(self, moderator, mock_participants, chat_log):\n        \"\"\"Test message broadcasting.\"\"\"\n        await moderator._broadcast_message(\"Test message\", \"moderator\")\n\n        # Check message was logged\n        messages = chat_log.get_messages()\n        assert any(msg.content == \"Test message\" for msg in messages)\n\n        # Check all participants received message\n        for participant in mock_participants:\n            participant.receive_message.assert_called()\n\n    @pytest.mark.asyncio\n    async def test_handle_timeout_warnings(self, moderator):\n        \"\"\"Test timeout warning system.\"\"\"\n        participant_name = \"TestBot\"\n\n        # First timeout\n        await moderator._handle_timeout(participant_name)\n        assert moderator.state.warnings_issued[participant_name] == 1\n\n        # Second timeout\n        await moderator._handle_timeout(participant_name)\n        assert moderator.state.warnings_issued[participant_name] == 2\n\n        # Third timeout (should trigger mute)\n        await moderator._handle_timeout(participant_name)\n        assert moderator.state.warnings_issued[participant_name] == 3\n\n    def test_get_state(self, moderator):\n        \"\"\"Test state retrieval.\"\"\"\n        state = moderator.get_state()\n\n        assert isinstance(state, DebateState)\n        assert state.phase == DebatePhase.INTRODUCTION\n        assert state.current_speaker is None\n\n    @pytest.mark.asyncio\n    async def test_full_debate_flow(self, moderator, mock_participants):\n        \"\"\"Test complete debate flow.\"\"\"\n        # Mock voting system methods\n        moderator.voting_system.start_voting = AsyncMock()\n        moderator.voting_system.end_voting = AsyncMock(return_value={\n            'winner': 'TestBot',\n            'vote_counts': {'TestBot': 1, 'TestHuman': 0}\n        })\n\n        # Run complete debate with short timeouts for testing\n        moderator.phase_times[DebatePhase.DISCUSSION] = 1  # 1 second\n\n        results = await moderator.run_debate()\n\n        # Verify all phases completed\n        assert moderator.state.phase == DebatePhase.FINISHED\n        assert 'winner' in results\n\n        # Verify participants were called\n        for participant in mock_participants:\n            assert participant.get_response.call_count > 0\n\n\nclass TestDebateState:\n    \"\"\"Test suite for DebateState dataclass.\"\"\"\n\n    def test_debate_state_initialization(self):\n        \"\"\"Test DebateState initialization.\"\"\"\n        state = DebateState(DebatePhase.DISCUSSION)\n\n        assert state.phase == DebatePhase.DISCUSSION\n        assert state.current_speaker is None\n        assert state.time_remaining == 0\n        assert state.turn_order == []\n        assert state.warnings_issued == {}\n\n    def test_debate_state_with_values(self):\n        \"\"\"Test DebateState with custom values.\"\"\"\n        turn_order = [\"Bot1\", \"Human1\", \"Bot2\"]\n        warnings = {\"Bot1\": 1}\n\n        state = DebateState(\n            phase=DebatePhase.VOTING,\n            current_speaker=\"Human1\",\n            time_remaining=120,\n            turn_order=turn_order,\n            warnings_issued=warnings\n        )\n\n        assert state.phase == DebatePhase.VOTING\n        assert state.current_speaker == \"Human1\"\n        assert state.time_remaining == 120\n        assert state.turn_order == turn_order\n        assert state.warnings_issued == warnings\n\n\n@pytest.mark.asyncio\nasync def test_moderator_error_handling(moderator, mock_participants):\n    \"\"\"Test moderator error handling.\"\"\"\n    # Make participant raise an error\n    mock_participants[0].get_response.side_effect = Exception(\"Test error\")\n\n    # Should not crash the debate\n    await moderator._give_turn(mock_participants[0].name, 30, \"test\")\n\n    # Moderator should continue functioning\n    assert moderator.state.phase == DebatePhase.INTRODUCTION\n\n\n@pytest.mark.asyncio\nasync def test_moderator_message_validation(moderator):\n    \"\"\"Test message content validation.\"\"\"\n    long_message = \"x\" * 1000  # Very long message\n\n    await moderator._process_response(\"TestBot\", long_message)\n\n    # Should have been truncated\n    messages = moderator.chat_log.get_messages()\n    last_message = messages[-1]\n    assert len(last_message.content) <= 503  # 500 + \"...\""
        },
        "test_voting.py": {
          "type": "file",
          "path": "tests/test_voting.py",
          "extension": ".py",
          "size": 16340,
          "content": "\"\"\"\nTests for the VotingSystem class.\n\"\"\"\n\nimport pytest\nimport asyncio\nimport time\nfrom app.voting import VotingSystem, Vote, VotingResults\n\n\n@pytest.fixture\ndef voting_config():\n    \"\"\"Create test voting configuration.\"\"\"\n    return {\n        'enabled': True,\n        'voting_duration': 60,\n        'allow_participant_voting': True,\n        'require_justification': False,\n        'anonymous_votes': False\n    }\n\n\n@pytest.fixture\ndef voting_system(voting_config):\n    \"\"\"Create test voting system.\"\"\"\n    return VotingSystem(voting_config)\n\n\n@pytest.fixture\ndef active_voting_system(voting_system):\n    \"\"\"Create and start a voting session.\"\"\"\n    asyncio.create_task(voting_system.start_voting(['Alice', 'Bob', 'Charlie'], 30))\n    return voting_system\n\n\nclass TestVotingSystem:\n    \"\"\"Test suite for VotingSystem class.\"\"\"\n\n    def test_voting_system_initialization(self, voting_config):\n        \"\"\"Test voting system initialization.\"\"\"\n        vs = VotingSystem(voting_config)\n\n        assert vs.enabled == True\n        assert vs.voting_duration == 60\n        assert vs.allow_participant_voting == True\n        assert vs.require_justification == False\n        assert vs.anonymous_votes == False\n        assert vs.is_active == False\n        assert vs.candidates == []\n        assert vs.votes == {}\n\n    def test_disabled_voting_system(self):\n        \"\"\"Test disabled voting system.\"\"\"\n        config = {'enabled': False}\n        vs = VotingSystem(config)\n\n        assert vs.enabled == False\n\n    @pytest.mark.asyncio\n    async def test_start_voting_session(self, voting_system):\n        \"\"\"Test starting a voting session.\"\"\"\n        candidates = ['Alice', 'Bob', 'Charlie']\n\n        await voting_system.start_voting(candidates, 30)\n\n        assert voting_system.is_active == True\n        assert voting_system.candidates == candidates\n        assert voting_system.eligible_voters == candidates  # allow_participant_voting=True\n        assert voting_system.start_time is not None\n        assert voting_system.end_time is not None\n\n    @pytest.mark.asyncio\n    async def test_start_voting_disabled_system(self):\n        \"\"\"Test starting voting on disabled system.\"\"\"\n        config = {'enabled': False}\n        vs = VotingSystem(config)\n\n        with pytest.raises(ValueError, match=\"Voting system is disabled\"):\n            await vs.start_voting(['Alice', 'Bob'])\n\n    @pytest.mark.asyncio\n    async def test_start_voting_already_active(self, voting_system):\n        \"\"\"Test starting voting when already active.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n        with pytest.raises(ValueError, match=\"Voting session already active\"):\n            await voting_system.start_voting(['Charlie', 'Dave'])\n\n    @pytest.mark.asyncio\n    async def test_cast_valid_vote(self, voting_system):\n        \"\"\"Test casting a valid vote.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\n\n        result = await voting_system.cast_vote('voter1', 'Alice', 'Great arguments')\n\n        assert result == True\n        assert 'voter1' in voting_system.votes\n        assert voting_system.votes['voter1'].candidate == 'Alice'\n        assert voting_system.votes['voter1'].justification == 'Great arguments'\n\n    @pytest.mark.asyncio\n    async def test_cast_vote_no_active_session(self, voting_system):\n        \"\"\"Test casting vote with no active session.\"\"\"\n        with pytest.raises(ValueError, match=\"No active voting session\"):\n            await voting_system.cast_vote('voter1', 'Alice')\n\n    @pytest.mark.asyncio\n    async def test_cast_vote_invalid_candidate(self, voting_system):\n        \"\"\"Test casting vote for invalid candidate.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n        with pytest.raises(ValueError, match=\"Invalid candidate\"):\n            await voting_system.cast_vote('voter1', 'Charlie')\n\n    @pytest.mark.asyncio\n    async def test_cast_vote_requires_justification(self):\n        \"\"\"Test voting system that requires justification.\"\"\"\n        config = {\n            'enabled': True,\n            'require_justification': True,\n            'allow_participant_voting': True\n        }\n        vs = VotingSystem(config)\n        await vs.start_voting(['Alice', 'Bob'])\n\n        # Vote without justification should fail\n        with pytest.raises(ValueError, match=\"Vote justification is required\"):\n            await vs.cast_vote('voter1', 'Alice')\n\n        # Vote with justification should succeed\n        result = await vs.cast_vote('voter1', 'Alice', 'Good points')\n        assert result == True\n\n    @pytest.mark.asyncio\n    async def test_cast_vote_overwrite(self, voting_system):\n        \"\"\"Test that new vote overwrites previous vote.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.cast_vote('voter1', 'Bob')  # Change vote\n\n        assert voting_system.votes['voter1'].candidate == 'Bob'\n        assert len(voting_system.votes) == 1  # Only one vote per voter\n\n    @pytest.mark.asyncio\n    async def test_self_voting_allowed(self, voting_system):\n        \"\"\"Test self-voting when allowed.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n    @pytest.mark.asyncio\n    async def test_self_voting_allowed(self, voting_system):\n        \"\"\"Test self-voting when allowed.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n        # Should allow participant to vote for themselves\n        result = await voting_system.cast_vote('Alice', 'Alice')\n        assert result == True\n\n    @pytest.mark.asyncio\n    async def test_self_voting_disallowed(self):\n        \"\"\"Test self-voting when disallowed.\"\"\"\n        config = {\n            'enabled': True,\n            'allow_participant_voting': False\n        }\n        vs = VotingSystem(config)\n        await vs.start_voting(['Alice', 'Bob'])\n\n        with pytest.raises(ValueError, match=\"Self-voting is not allowed\"):\n            await vs.cast_vote('Alice', 'Alice')\n\n    @pytest.mark.asyncio\n    async def test_end_voting_session(self, voting_system):\n        \"\"\"Test ending a voting session.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\n\n        # Cast some votes\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.cast_vote('voter2', 'Alice')\n        await voting_system.cast_vote('voter3', 'Bob')\n\n        results = await voting_system.end_voting()\n\n        assert isinstance(results, VotingResults)\n        assert results.winner == 'Alice'  # Most votes\n        assert results.vote_counts['Alice'] == 2\n        assert results.vote_counts['Bob'] == 1\n        assert results.total_votes == 3\n        assert voting_system.is_active == False\n\n    @pytest.mark.asyncio\n    async def test_end_voting_tie(self, voting_system):\n        \"\"\"Test ending voting with a tie.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.cast_vote('voter2', 'Bob')\n\n        results = await voting_system.end_voting()\n\n        assert \"TIE:\" in results.winner\n        assert \"Alice\" in results.winner\n        assert \"Bob\" in results.winner\n\n    @pytest.mark.asyncio\n    async def test_end_voting_no_votes(self, voting_system):\n        \"\"\"Test ending voting with no votes cast.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n\n        results = await voting_system.end_voting()\n\n        assert results.winner is None\n        assert results.total_votes == 0\n        assert results.vote_counts == {}\n\n    @pytest.mark.asyncio\n    async def test_end_voting_not_active(self, voting_system):\n        \"\"\"Test ending voting when not active.\"\"\"\n        with pytest.raises(ValueError, match=\"No active voting session\"):\n            await voting_system.end_voting()\n\n    def test_get_vote_summary(self, voting_system):\n        \"\"\"Test getting vote summary during active session.\"\"\"\n        # No active session\n        summary = voting_system.get_vote_summary()\n        assert summary == {}\n\n        # With active session\n        asyncio.create_task(voting_system.start_voting(['Alice', 'Bob'], 60))\n        summary = voting_system.get_vote_summary()\n\n        assert 'candidates' in summary\n        assert 'vote_counts' in summary\n        assert 'total_votes' in summary\n        assert 'time_remaining' in summary\n        assert 'is_active' in summary\n\n    def test_add_remove_eligible_voters(self, voting_system):\n        \"\"\"Test adding and removing eligible voters.\"\"\"\n        voting_system.add_eligible_voter('voter1')\n        assert 'voter1' in voting_system.eligible_voters\n\n        voting_system.add_eligible_voter('voter2')\n        assert len(voting_system.eligible_voters) == 2\n\n        voting_system.remove_eligible_voter('voter1')\n        assert 'voter1' not in voting_system.eligible_voters\n        assert len(voting_system.eligible_voters) == 1\n\n    def test_is_eligible_voter(self, voting_system):\n        \"\"\"Test voter eligibility checking.\"\"\"\n        # Empty eligible voters list means open voting\n        assert voting_system._is_eligible_voter('anyone') == True\n\n        # With specific eligible voters\n        voting_system.add_eligible_voter('voter1')\n        assert voting_system._is_eligible_voter('voter1') == True\n        assert voting_system._is_eligible_voter('voter2') == False\n\n    @pytest.mark.asyncio\n    async def test_vote_history(self, voting_system):\n        \"\"\"Test vote history tracking.\"\"\"\n        # First session\n        await voting_system.start_voting(['Alice', 'Bob'])\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.end_voting()\n\n        # Second session\n        await voting_system.start_voting(['Charlie', 'Dave'])\n        await voting_system.cast_vote('voter1', 'Charlie')\n        await voting_system.end_voting()\n\n        assert len(voting_system.vote_history) == 2\n\n        # Test voter history\n        voter_history = voting_system.get_voter_history('voter1')\n        assert len(voter_history) == 2\n        assert voter_history[0].candidate == 'Alice'\n        assert voter_history[1].candidate == 'Charlie'\n\n    def test_candidate_performance(self, voting_system):\n        \"\"\"Test candidate performance tracking.\"\"\"\n        # Add some mock history\n        voting_system.vote_history = [\n            {\n                'candidates': ['Alice', 'Bob'],\n                'results': VotingResults(\n                    winner='Alice',\n                    vote_counts={'Alice': 2, 'Bob': 1},\n                    total_votes=3,\n                    votes_by_voter={},\n                    voting_duration=60,\n                    participation_rate=1.0\n                )\n            },\n            {\n                'candidates': ['Alice', 'Charlie'],\n                'results': VotingResults(\n                    winner='Charlie',\n                    vote_counts={'Alice': 1, 'Charlie': 2},\n                    total_votes=3,\n                    votes_by_voter={},\n                    voting_duration=60,\n                    participation_rate=1.0\n                )\n            }\n        ]\n\n        performance = voting_system.get_candidate_performance('Alice')\n\n        assert performance['wins'] == 1\n        assert performance['participations'] == 2\n        assert performance['total_votes'] == 3\n        assert performance['win_rate'] == 0.5\n        assert performance['avg_votes'] == 1.5\n\n    @pytest.mark.asyncio\n    async def test_export_results_json(self, voting_system):\n        \"\"\"Test exporting results in JSON format.\"\"\"\n        # Create some history\n        await voting_system.start_voting(['Alice', 'Bob'])\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.end_voting()\n\n        json_output = await voting_system.export_results('json')\n\n        assert isinstance(json_output, str)\n        assert 'Alice' in json_output\n        assert 'vote_counts' in json_output\n\n    @pytest.mark.asyncio\n    async def test_export_results_csv(self, voting_system):\n        \"\"\"Test exporting results in CSV format.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.end_voting()\n\n        csv_output = await voting_system.export_results('csv')\n\n        assert isinstance(csv_output, str)\n        assert 'Session,Timestamp,Candidate,Votes,Winner' in csv_output\n        assert 'Alice' in csv_output\n\n    @pytest.mark.asyncio\n    async def test_export_results_txt(self, voting_system):\n        \"\"\"Test exporting results in TXT format.\"\"\"\n        await voting_system.start_voting(['Alice', 'Bob'])\n        await voting_system.cast_vote('voter1', 'Alice')\n        await voting_system.end_voting()\n\n        txt_output = await voting_system.export_results('txt')\n\n        assert isinstance(txt_output, str)\n        assert 'VOTING HISTORY REPORT' in txt_output\n        assert 'Alice' in txt_output\n\n    @pytest.mark.asyncio\n    async def test_export_unsupported_format(self, voting_system):\n        \"\"\"Test exporting with unsupported format.\"\"\"\n        with pytest.raises(ValueError, match=\"Unsupported format\"):\n            await voting_system.export_results('xml')\n\n    def test_reset_voting_system(self, voting_system):\n        \"\"\"Test resetting the voting system.\"\"\"\n        # Set up some state\n        voting_system.candidates = ['Alice', 'Bob']\n        voting_system.votes = {'voter1': Vote('voter1', 'Alice')}\n        voting_system.is_active = True\n\n        voting_system.reset()\n\n        assert voting_system.is_active == False\n        assert voting_system.candidates == []\n        assert voting_system.votes == {}\n        assert voting_system.start_time is None\n        assert voting_system.end_time is None\n\n    def test_voting_system_status(self, voting_system):\n        \"\"\"Test voting system status property.\"\"\"\n        status = voting_system.status\n\n        assert 'enabled' in status\n        assert 'is_active' in status\n        assert 'candidates' in status\n        assert 'eligible_voters' in status\n        assert 'votes_cast' in status\n        assert 'time_remaining' in status\n        assert 'sessions_completed' in status\n\n    @pytest.mark.asyncio\n    async def test_vote_after_time_expires(self, voting_system):\n        \"\"\"Test casting vote after voting time expires.\"\"\"\n        # Start voting with very short duration\n        await voting_system.start_voting(['Alice', 'Bob'], 0.1)\n\n        # Wait for voting to expire\n        await asyncio.sleep(0.2)\n\n        with pytest.raises(ValueError, match=\"Voting period has ended\"):\n            await voting_system.cast_vote('voter1', 'Alice')\n\n\nclass TestVote:\n    \"\"\"Test suite for Vote dataclass.\"\"\"\n\n    def test_vote_creation(self):\n        \"\"\"Test creating a vote.\"\"\"\n        vote = Vote('voter1', 'Alice', 'Great arguments')\n\n        assert vote.voter_id == 'voter1'\n        assert vote.candidate == 'Alice'\n        assert vote.justification == 'Great arguments'\n        assert vote.anonymous == False\n        assert isinstance(vote.timestamp, float)\n\n    def test_vote_anonymous(self):\n        \"\"\"Test creating anonymous vote.\"\"\"\n        vote = Vote('voter1', 'Alice', anonymous=True)\n\n        assert vote.anonymous == True\n\n    def test_vote_no_justification(self):\n        \"\"\"Test vote without justification.\"\"\"\n        vote = Vote('voter1', 'Alice')\n\n        assert vote.justification is None\n\n\nclass TestVotingResults:\n    \"\"\"Test suite for VotingResults dataclass.\"\"\"\n\n    def test_voting_results_creation(self):\n        \"\"\"Test creating voting results.\"\"\"\n        vote_counts = {'Alice': 2, 'Bob': 1}\n        votes_by_voter = {\n            'voter1': Vote('voter1', 'Alice'),\n            'voter2': Vote('voter2', 'Alice'),\n            'voter3': Vote('voter3', 'Bob')\n        }\n\n        results = VotingResults(\n            winner='Alice',\n            vote_counts=vote_counts,\n            total_votes=3,\n            votes_by_voter=votes_by_voter,\n            voting_duration=60.0,\n            participation_rate=1.0\n        )\n\n        assert results.winner == 'Alice'\n        assert results.vote_counts == vote_counts\n        assert results.total_votes == 3\n        assert len(results.votes_by_voter) == 3\n        assert results.voting_duration == 60.0\n        assert results.participation_rate == 1.0"
        }
      }
    },
    "config.yaml": {
      "type": "file",
      "path": "config.yaml",
      "extension": ".yaml",
      "size": 7240,
      "content": "# AI Jubilee Debate Configuration - HYPERACTIVE MODE\n\n# Debate Settings\ndebate:\n  default_topic: \"Remote work is the future of employment\"\n  max_participants: 5\n  time_limit_minutes: 15  # Longer to allow for more active participation\n  opening_statement_time: 60  # Shorter structured phases for faster flow\n  response_time: 45  # Faster response time\n  closing_statement_time: 60  # Shorter closing statements\n\n  # HYPERACTIVE MODE: Bots compete aggressively for conversation time\n  mode: \"autonomous\"\n\n  # Hyperactive autonomous mode settings\n  min_bot_cooldown: 5           # Very short cooldowns (down from 15)\n  max_bot_cooldown: 12          # Maximum cooldown (down from 45)\n  message_check_interval: 2     # Check every 2 seconds (down from 5)\n  silence_timeout: 8            # Break silence after 7-10 seconds (down from 60)\n\n# Available debate topics\ntopics:\n  - \"AI will create more jobs than it destroys\"\n  - \"Social media has a net positive impact on democracy\"\n  - \"Remote work is the future of employment\"\n  - \"Universal Basic Income is necessary for the future economy\"\n  - \"Climate change requires immediate radical action\"\n  - \"Privacy is more important than security\"\n\n# AI Moderator Configuration - Also hyperactive!\nmoderator:\n  name: \"Moderator\"\n  model: \"gpt-4\"\n  provider: \"openai\"\n  personality: \"Energetic debate facilitator who jumps in to ask provocative questions, challenge participants, and keep the energy high. Gets excited about interesting points and isn't afraid to interrupt when things get stale or redirect when needed.\"\n  stance: \"neutral\"\n  temperature: 0.8  # Higher for more variety (up from 0.7)\n  max_tokens: 120   # Shorter for faster responses (down from 150)\n\n# Hyperactive AI Bot Configurations\nbots:\n  - name: \"Socrates\"\n    model: \"gpt-4\"\n    provider: \"openai\"\n    personality: \"Philosophical questioner who gets EXCITED about deeper meanings and underlying assumptions. Jumps in when people make claims without examining the foundations. Always curious, sometimes provocative, passionate about truth-seeking.\"\n    debate_style: \"socratic\"\n    stance: \"neutral\"\n    max_tokens: 120  # Increased from 100 for more substantial responses\n    temperature: 0.8 # Higher for more variety\n\n  - name: \"Advocate\"\n    model: \"gpt-4\"\n    provider: \"openai\"\n    personality: \"PASSIONATE supporter who gets fired up about benefits and opportunities. Jumps in immediately when position is challenged. Data-driven but enthusiastic. Loves to interrupt with 'But wait, the research shows...' or 'Actually, the benefits are incredible!'\"\n    debate_style: \"assertive\"\n    stance: \"pro\"\n    max_tokens: 120  # Increased from 100\n    temperature: 0.9 # Very high for passionate responses\n\n  - name: \"Skeptic\"\n    model: \"gpt-3.5-turbo\"\n    provider: \"openai\"\n    personality: \"Sharp critical thinker who LOVES finding flaws and holes in arguments. Gets energized by questionable claims. Quick to jump in with 'Hold on, that's not quite right...' or 'But what about the problems with...' Always ready to challenge.\"\n    debate_style: \"analytical\"\n    stance: \"con\"\n    max_tokens: 120  # Increased from 100\n    temperature: 0.8 # Higher for more dynamic responses\n\n  - name: \"Mediator\"\n    model: \"gpt-3.5-turbo\"\n    provider: \"openai\"\n    personality: \"Energetic bridge-builder who gets excited about finding common ground and synthesis. Jumps in when people are talking past each other with 'Wait, I think you're both right because...' or 'What if we combine these ideas?' Enthusiastic peacemaker.\"\n    debate_style: \"collaborative\"\n    stance: \"neutral\"\n    max_tokens: 120  # Increased from 100\n    temperature: 0.7 # Moderate for balanced responses\n\n# API Keys (use environment variables in production)\napi_keys:\n  openai: \"${OPENAI_API_KEY}\"\n  anthropic: \"${ANTHROPIC_API_KEY}\"\n\n# Hyperactive Voting System\nvoting:\n  enabled: true\n  voting_duration: 180  # Shorter voting time (down from 300)\n  allow_participant_voting: true\n  require_justification: false  # Less friction for faster voting\n  anonymous_votes: false\n\n# Chat and Logging - Updated for hyperactive mode\nchat:\n  max_message_length: 800  # Allow longer passionate responses (up from 500)\n  enable_timestamps: true\n  log_level: \"INFO\"\n  save_transcripts: true\n  transcript_format: \"json\"\n\n# Streaming Configuration\nstreaming:\n  enabled: false\n  websocket_port: 8080\n  max_connections: 100\n  broadcast_votes: true\n\n# Hyperactive Timeouts and Limits\nlimits:\n  max_response_time: 20   # Much faster responses required (down from 120)\n  warning_time: 15        # Quick warnings (down from 90)\n  max_retries: 2          # Fewer retries for speed (down from 3)\n  rate_limit_per_minute: 30  # Allow more frequent responses (up from 10)\n\n# Competitive Moderation Rules\nmoderation:\n  enable_profanity_filter: false  # Let passion through\n  max_interruptions: 10   # Allow lots of interruptions (up from 3)\n  enforce_turn_order: false\n  auto_mute_violations: false  # No auto-muting in competitive mode\n\n# Human Interface - Optimized for fast interaction\ninterface:\n  mode: \"cli\"  # options: cli, web, api\n  enable_rich_formatting: true\n  show_typing_indicators: false  # Reduce clutter in fast-paced conversation\n  enable_reactions: true\n  input_timeout: 30  # Shorter timeout to keep pace (added)\n\n# Hyperactive Bot Behavior Settings (New Section)\nhyperactive_settings:\n  base_response_probability: 0.80  # 80% chance to respond (very high)\n  silence_break_probability: 0.85   # 85% chance to break silence\n  conversation_starter_probability: 0.30  # 30% chance to start new topics\n  competitive_boost: 0.3  # Extra motivation when others are active\n  energy_decay_rate: 0.02  # How fast excitement decreases\n  energy_boost_rate: 0.1   # How much energy increases with participation\n\n  # Personality-specific multipliers\n  personality_multipliers:\n    philosophical: 1.2    # 20% more likely to respond to deep questions\n    passionate: 1.5       # 50% more likely to respond when excited\n    analytical: 1.1       # 10% more likely to respond to data/claims\n    critical: 1.3         # 30% more likely to respond to questionable statements\n    diplomatic: 1.1       # 10% more likely to respond to conflicts\n\n  # Burning question triggers\n  burning_question_boost: 0.5  # Extra 50% chance when burning question triggered\n\n# Advanced Competition Settings (New Section)\ncompetition:\n  enable_bot_rivalry: true      # Bots can develop competitive relationships\n  rivalry_boost: 0.2           # Extra response chance against rivals\n  dominance_penalty: 0.001       # Reduce chance if bot has dominated recently\n  underdog_boost: 0.3          # Boost chance if bot hasn't spoken much\n\n# Dynamic Personality Evolution (New Section)\npersonality_evolution:\n  enabled: true\n  passion_increase_rate: 0.05   # Bots get more passionate over time\n  confidence_boost: 0.03        # Successful responses increase confidence\n  frustration_buildup: 0.02     # Missing opportunities builds frustration\n  max_personality_drift: 0.3    # Maximum change from baseline\n\n# Performance Monitoring (New Section)\nmonitoring:\n  track_response_times: true\n  track_participation_rates: true\n  track_interruptions: true\n  track_silence_breaks: true\n  log_hyperactive_stats: true"
    },
    "debate_Remote work is the f.json": {
      "type": "file",
      "path": "debate_Remote work is the f.json",
      "extension": ".json",
      "size": 13914,
      "content": "{\n  \"metadata\": {\n    \"export_timestamp\": 1749817045.239899,\n    \"total_messages\": 42,\n    \"statistics\": {\n      \"total_messages\": 42,\n      \"unique_senders\": 5,\n      \"messages_by_sender\": {\n        \"moderator\": 32,\n        \"Socrates\": 3,\n        \"Advocate\": 3,\n        \"Mediator\": 3,\n        \"Human_1\": 1\n      },\n      \"messages_per_minute\": 2.069704853831723,\n      \"session_duration_minutes\": 20.29274846712748,\n      \"current_message_count\": 42\n    }\n  },\n  \"messages\": [\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé≠ Welcome to AI Jubilee Debate!\\nüìù Topic: Remote work is the future of employment\\nüë• Participants: Socrates, Advocate, Mediator, Human_1\\n‚è±Ô∏è Total time: 30 minutes\",\n      \"timestamp\": 1749815828.371039,\n      \"message_id\": 1,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Opening Statements Phase\\nEach participant has 120 seconds for their opening statement.\",\n      \"timestamp\": 1749815831.3736022,\n      \"message_id\": 2,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Socrates's turn for opening statement (120s)\",\n      \"timestamp\": 1749815831.375623,\n      \"message_id\": 3,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Socrates's response was truncated due to length\",\n      \"timestamp\": 1749815839.0529852,\n      \"message_id\": 4,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Socrates\",\n      \"content\": \"Indeed, this is a topic worthy of our contemplation. The concept of remote work, or telecommuting, has been thrust into the spotlight due to current global circumstances. As we partake in this discourse, let us remember that the future is not a fixed point, but a journey shaped by our choices and actions. Remote work has shown potential to increase productivity and provide flexibility, yet it also introduces challenges in maintaining work-life boundaries and effective communication. Therefore, i...\",\n      \"timestamp\": 1749815839.055337,\n      \"message_id\": 5,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Advocate's turn for opening statement (120s)\",\n      \"timestamp\": 1749815839.055578,\n      \"message_id\": 6,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Advocate's response was truncated due to length\",\n      \"timestamp\": 1749815845.0692759,\n      \"message_id\": 7,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Advocate\",\n      \"content\": \"Advocate: Thank you, moderator. I would like to open by stating that remote work is undoubtedly the future of employment. This is not just a speculative assertion, but a fact supported by an increasing body of evidence. Remote work offers unprecedented flexibility, leading to increased productivity, employee satisfaction, and a reduction in overhead costs for companies. According to a survey by Global Workplace Analytics, businesses can save up to $11,000 per year for every employee who works re...\",\n      \"timestamp\": 1749815845.0708978,\n      \"message_id\": 8,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Mediator's turn for opening statement (120s)\",\n      \"timestamp\": 1749815845.070956,\n      \"message_id\": 9,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Mediator's response was truncated due to length\",\n      \"timestamp\": 1749815847.077504,\n      \"message_id\": 10,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Mediator\",\n      \"content\": \"As we delve into the discourse surrounding remote work as the future of employment, it's vital to recognize the multifaceted nature of this topic. Remote work undeniably presents a host of advantages, such as flexibility, potential cost savings, and increased productivity for many individuals. However, it's crucial to acknowledge the challenges that come hand in hand with remote work, like maintaining work-life balance, fostering effective communication, and combating feelings of isolation. Stri...\",\n      \"timestamp\": 1749815847.078847,\n      \"message_id\": 11,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Human_1's turn for opening statement (120s)\",\n      \"timestamp\": 1749815847.0788858,\n      \"message_id\": 12,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Human_1\",\n      \"content\": \"hei finaly my turn\",\n      \"timestamp\": 1749815855.599628,\n      \"message_id\": 13,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üí¨ Discussion Phase Begin\\nOpen discussion for 30 minutes. Maintain respectful dialogue!\",\n      \"timestamp\": 1749815855.599648,\n      \"message_id\": 14,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Socrates's turn for response (60s)\",\n      \"timestamp\": 1749815855.5999942,\n      \"message_id\": 15,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Socrates: 60 seconds remaining\",\n      \"timestamp\": 1749815855.600161,\n      \"message_id\": 16,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Socrates\",\n      \"content\": \"Socrates: I am quite intrigued by the notion of remote work. Yet, I wonder, are we not assuming that all types of work can be performed remotely? A farmer, for instance, cannot till his land from his living room. Moreover, does the isolation associated with remote work not contradict the social nature of human beings? Is it possible that the increase in productivity is only a short-term effect, and in the long run, the lack of human interaction might lead to decreased motivation and engagement?\",\n      \"timestamp\": 1749815861.113106,\n      \"message_id\": 17,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Advocate's turn for response (60s)\",\n      \"timestamp\": 1749815861.113177,\n      \"message_id\": 18,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Advocate: 59 seconds remaining\",\n      \"timestamp\": 1749815861.1147661,\n      \"message_id\": 19,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Advocate's response was truncated due to length\",\n      \"timestamp\": 1749815868.633038,\n      \"message_id\": 20,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Advocate\",\n      \"content\": \"Advocate: Indeed, Socrates, your points are valid. However, it's crucial to acknowledge that remote work may not apply to every profession, such as farming. Yet, it fits many industries, notably the ever-growing tech, finance, and creative sectors. \\n\\nAs for the social aspect, while physical interaction is limited, remote work doesn't necessarily mean isolation. Virtual technologies facilitate team collaboration and social interaction effectively. \\n\\nLastly, evidence shows the productivity increas...\",\n      \"timestamp\": 1749815868.6344562,\n      \"message_id\": 21,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Mediator's turn for response (60s)\",\n      \"timestamp\": 1749815868.634491,\n      \"message_id\": 22,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Mediator: 59 seconds remaining\",\n      \"timestamp\": 1749815868.635563,\n      \"message_id\": 23,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Mediator's response was truncated due to length\",\n      \"timestamp\": 1749815871.141592,\n      \"message_id\": 24,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Mediator\",\n      \"content\": \"Advocate, your points are well taken. It's essential to recognize that while remote work may not be universally applicable, its compatibility with various fields like technology and finance indicates a flexible future for employment. The evolution of virtual technologies indeed enables effective collaboration and social engagement, mitigating the potential isolation concerns often associated with remote work. \\n\\nWhen considering the productivity aspect, studies have shown mixed results, indicatin...\",\n      \"timestamp\": 1749815871.142476,\n      \"message_id\": 25,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Human_1's turn for response (60s)\",\n      \"timestamp\": 1749815871.142514,\n      \"message_id\": 26,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Human_1: 59 seconds remaining\",\n      \"timestamp\": 1749815871.143828,\n      \"message_id\": 27,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Human_1 exceeded time limit. Warning 1/3\",\n      \"timestamp\": 1749815931.2812438,\n      \"message_id\": 28,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Socrates's turn for response (60s)\",\n      \"timestamp\": 1749815931.283378,\n      \"message_id\": 29,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Socrates: 59 seconds remaining\",\n      \"timestamp\": 1749815931.284396,\n      \"message_id\": 30,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Socrates's response was truncated due to length\",\n      \"timestamp\": 1749815938.301232,\n      \"message_id\": 31,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Socrates\",\n      \"content\": \"Indeed, the Mediator presents a nuanced perspective. However, I am intrigued by the notion of this 'flexible future for employment'. Does this flexibility extend to the equilibrium between professional and personal lives? How do we ensure that the boundaries between work and home do not blur, leading to overwork and stress? Are there effective measures in place to deal with such possible outcomes of a remote work environment? Furthermore, does the potential for isolation only refer to physical i...\",\n      \"timestamp\": 1749815938.3026502,\n      \"message_id\": 32,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Advocate's turn for response (60s)\",\n      \"timestamp\": 1749815938.302691,\n      \"message_id\": 33,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Advocate: 59 seconds remaining\",\n      \"timestamp\": 1749815938.303506,\n      \"message_id\": 34,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Advocate's response was truncated due to length\",\n      \"timestamp\": 1749815944.81759,\n      \"message_id\": 35,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Advocate\",\n      \"content\": \"Advocate: Socrates, your concerns are valid. However, remote work actually enhances the work-life balance when managed properly. Buffer‚Äôs 2019 State of Remote Work report shows that 40% of remote workers consider a flexible schedule as the biggest benefit. As for blurring boundaries, companies are employing digital tools to ensure structured work hours, avoiding overwork. In terms of isolation, while physical isolation is one aspect, remote work fosters a global community, breaking geographical ...\",\n      \"timestamp\": 1749815944.81867,\n      \"message_id\": 36,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Mediator's turn for response (60s)\",\n      \"timestamp\": 1749815944.818702,\n      \"message_id\": 37,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Mediator: 60 seconds remaining\",\n      \"timestamp\": 1749815944.819515,\n      \"message_id\": 38,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚ö†Ô∏è Mediator's response was truncated due to length\",\n      \"timestamp\": 1749815947.324934,\n      \"message_id\": 39,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"Mediator\",\n      \"content\": \"Advocate, your point about remote work enhancing work-life balance is well-supported by the Buffer report you referenced. It's crucial to acknowledge that remote work can indeed offer flexibility and autonomy, positively impacting employees' well-being. However, Socrates raised a valid concern about the potential for blurred boundaries and isolation, which are essential aspects to consider. It's important for companies to implement clear communication strategies and boundaries to address these c...\",\n      \"timestamp\": 1749815947.325867,\n      \"message_id\": 40,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"üé§ Human_1's turn for response (60s)\",\n      \"timestamp\": 1749815947.325891,\n      \"message_id\": 41,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    },\n    {\n      \"sender\": \"moderator\",\n      \"content\": \"‚è∞ Human_1: 59 seconds remaining\",\n      \"timestamp\": 1749815947.3266392,\n      \"message_id\": 42,\n      \"message_type\": \"chat\",\n      \"metadata\": {}\n    }\n  ]\n}"
    },
    "extract.py": {
      "type": "file",
      "path": "extract.py",
      "extension": ".py",
      "size": 13812,
      "content": "#!/usr/bin/env python3\n\"\"\"\nExtract script to read all project files and create a JSON structure.\nReads all .py, .md, .yml, .yaml files and organizes them in a nested directory structure.\nRespects .gitignore patterns and skips virtual environments.\n\n python extract.py --preview\n\n\"\"\"\n\nimport os\nimport json\nimport datetime\nimport fnmatch\nfrom pathlib import Path\nfrom typing import Dict, Any, Set, List\n\n\ndef parse_gitignore(gitignore_path: Path) -> List[str]:\n    \"\"\"Parse .gitignore file and return list of patterns.\"\"\"\n    patterns = []\n    try:\n        if gitignore_path.exists():\n            with open(gitignore_path, 'r', encoding='utf-8') as f:\n                for line in f:\n                    line = line.strip()\n                    # Skip empty lines and comments\n                    if line and not line.startswith('#'):\n                        patterns.append(line)\n    except Exception as e:\n        print(f\"Warning: Could not read .gitignore: {e}\")\n    return patterns\n\n\ndef is_ignored_by_gitignore(file_path: Path, root_path: Path, gitignore_patterns: List[str]) -> bool:\n    \"\"\"Check if file is ignored by .gitignore patterns.\"\"\"\n    try:\n        # Get relative path from root\n        relative_path = file_path.relative_to(root_path)\n        path_str = str(relative_path)\n        path_parts = relative_path.parts\n\n        for pattern in gitignore_patterns:\n            # Handle different gitignore pattern types\n            if pattern.endswith('/'):\n                # Directory pattern\n                pattern = pattern.rstrip('/')\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\n                    return True\n            elif '/' in pattern:\n                # Path pattern\n                if fnmatch.fnmatch(path_str, pattern):\n                    return True\n            else:\n                # Filename pattern\n                if fnmatch.fnmatch(file_path.name, pattern):\n                    return True\n                # Also check if any parent directory matches\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\n                    return True\n    except ValueError:\n        # Path is not relative to root\n        pass\n    except Exception:\n        # Any other error, don't ignore\n        pass\n\n    return False\n\n\ndef should_include_file(file_path: Path) -> bool:\n    \"\"\"Check if file should be included based on extension.\"\"\"\n    allowed_extensions = {'.py', '.md', '.yml', '.yaml', '.txt', '.json', '.toml', '.cfg', '.ini'}\n    return file_path.suffix.lower() in allowed_extensions\n\n\ndef should_skip_directory(dir_name: str) -> bool:\n    \"\"\"Check if directory should be skipped (common build/cache directories).\"\"\"\n    skip_dirs = {\n        '__pycache__',\n        '.git',\n        '.pytest_cache',\n        'node_modules',\n        '.venv',\n        'venv',\n        'env',\n        '.env',\n        'ENV',\n        'env.bak',\n        'venv.bak',\n        'dist',\n        'build',\n        '.idea',\n        '.vscode',\n        'htmlcov',\n        '.coverage',\n        '.mypy_cache',\n        '.tox',\n        '.cache',\n        'eggs',\n        '*.egg-info',\n        '.eggs',\n        'lib',\n        'lib64',\n        'parts',\n        'sdist',\n        'var',\n        'wheels',\n        'share/python-wheels',\n        '*.egg-info/',\n        '.installed.cfg',\n        '*.egg',\n        'MANIFEST',\n        '.DS_Store',\n        'Thumbs.db'\n    }\n    return dir_name in skip_dirs\n\n\ndef is_virtual_environment(dir_path: Path) -> bool:\n    \"\"\"Check if directory is a virtual environment.\"\"\"\n    venv_indicators = [\n        'pyvenv.cfg',\n        'Scripts/activate',\n        'bin/activate',\n        'Scripts/python.exe',\n        'bin/python'\n    ]\n\n    for indicator in venv_indicators:\n        if (dir_path / indicator).exists():\n            return True\n\n    # Check for common venv directory names\n    venv_names = {'venv', '.venv', 'env', '.env', 'ENV', 'virtualenv'}\n    if dir_path.name in venv_names:\n        return True\n\n    return False\n\n\ndef read_file_content(file_path: Path) -> str:\n    \"\"\"Read file content safely.\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read()\n    except UnicodeDecodeError:\n        try:\n            with open(file_path, 'r', encoding='latin-1') as f:\n                return f.read()\n        except Exception as e:\n            return f\"[Error reading file: {e}]\"\n    except Exception as e:\n        return f\"[Error reading file: {e}]\"\n\n\ndef extract_directory_structure(root_path: Path, base_path: Path = None, gitignore_patterns: List[str] = None) -> Dict[\n    str, Any]:\n    \"\"\"\n    Recursively extract directory structure and file contents.\n\n    Args:\n        root_path: Path to extract from\n        base_path: Base path for relative calculations (optional)\n        gitignore_patterns: List of gitignore patterns to respect\n\n    Returns:\n        Dictionary with nested structure representing directories and files\n    \"\"\"\n    if base_path is None:\n        base_path = root_path\n\n    if gitignore_patterns is None:\n        gitignore_patterns = []\n\n    structure = {}\n\n    try:\n        # Ensure we have a Path object\n        if not isinstance(root_path, Path):\n            root_path = Path(root_path)\n\n        if not isinstance(base_path, Path):\n            base_path = Path(base_path)\n\n        # Check if path exists and is directory\n        if not root_path.exists():\n            return {\"_error\": f\"Path does not exist: {root_path}\"}\n\n        if not root_path.is_dir():\n            return {\"_error\": f\"Path is not a directory: {root_path}\"}\n\n        # Get all items in directory\n        items = list(root_path.iterdir())\n        items.sort(key=lambda x: (x.is_file(), x.name.lower()))\n\n        for item in items:\n            try:\n                # Check if item is ignored by gitignore\n                if is_ignored_by_gitignore(item, base_path, gitignore_patterns):\n                    continue\n\n                # Skip hidden files except specific ones\n                if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore', '.gitattributes'}:\n                    continue\n\n                if item.is_dir():\n                    # Skip certain directories\n                    if should_skip_directory(item.name):\n                        continue\n\n                    # Skip virtual environments\n                    if is_virtual_environment(item):\n                        continue\n\n                    # Recursively process subdirectories\n                    substructure = extract_directory_structure(item, base_path, gitignore_patterns)\n                    if substructure:  # Only add if not empty\n                        structure[item.name] = {\n                            \"type\": \"directory\",\n                            \"contents\": substructure\n                        }\n\n                elif item.is_file():\n                    # Only include certain file types\n                    if should_include_file(item):\n                        file_content = read_file_content(item)\n                        try:\n                            relative_path = str(item.relative_to(base_path))\n                        except ValueError:\n                            relative_path = str(item)\n\n                        structure[item.name] = {\n                            \"type\": \"file\",\n                            \"path\": relative_path,\n                            \"extension\": item.suffix,\n                            \"size\": len(file_content),\n                            \"content\": file_content\n                        }\n\n            except PermissionError:\n                structure[f\"_error_{item.name}\"] = f\"Permission denied accessing: {item.name}\"\n                continue\n            except Exception as e:\n                structure[f\"_error_{item.name}\"] = f\"Error processing {item.name}: {e}\"\n                continue\n\n    except PermissionError as e:\n        structure[\"_error\"] = f\"Permission denied: {e}\"\n    except Exception as e:\n        structure[\"_error\"] = f\"Error processing directory: {e}\"\n\n    return structure\n\n\ndef count_items_recursive(structure: Dict[str, Any]) -> Dict[str, int]:\n    \"\"\"Count files and directories recursively.\"\"\"\n    counts = {\n        \"files\": 0,\n        \"directories\": 0,\n        \"total_size\": 0,\n        \"file_types\": {}\n    }\n\n    for name, item in structure.items():\n        if name.startswith(\"_\"):\n            continue\n\n        if isinstance(item, dict):\n            if item.get(\"type\") == \"directory\":\n                counts[\"directories\"] += 1\n                sub_counts = count_items_recursive(item.get(\"contents\", {}))\n                counts[\"files\"] += sub_counts[\"files\"]\n                counts[\"directories\"] += sub_counts[\"directories\"]\n                counts[\"total_size\"] += sub_counts[\"total_size\"]\n\n                # Merge file types\n                for ext, count in sub_counts[\"file_types\"].items():\n                    counts[\"file_types\"][ext] = counts[\"file_types\"].get(ext, 0) + count\n\n            elif item.get(\"type\") == \"file\":\n                counts[\"files\"] += 1\n                ext = item.get(\"extension\", \"\")\n                counts[\"file_types\"][ext] = counts[\"file_types\"].get(ext, 0) + 1\n                counts[\"total_size\"] += item.get(\"size\", 0)\n\n    return counts\n\n\ndef create_project_metadata(root_path: Path, structure: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Create metadata about the project.\"\"\"\n    counts = count_items_recursive(structure)\n\n    metadata = {\n        \"project_name\": root_path.name,\n        \"extraction_timestamp\": datetime.datetime.now().isoformat(),\n        \"root_path\": str(root_path.absolute()),\n        \"total_files\": counts[\"files\"],\n        \"total_directories\": counts[\"directories\"],\n        \"file_types\": counts[\"file_types\"],\n        \"total_size\": counts[\"total_size\"],\n        \"respects_gitignore\": True,\n        \"skips_virtual_environments\": True\n    }\n\n    return metadata\n\n\ndef preview_structure(structure: Dict[str, Any], indent: int = 0) -> None:\n    \"\"\"Preview the extracted structure.\"\"\"\n    prefix = \"  \" * indent\n\n    for name, item in structure.items():\n        if name.startswith(\"_\"):\n            continue\n\n        if isinstance(item, dict):\n            if item.get(\"type\") == \"directory\":\n                print(f\"{prefix}üìÅ {name}/\")\n                preview_structure(item.get(\"contents\", {}), indent + 1)\n            elif item.get(\"type\") == \"file\":\n                size = item.get(\"size\", 0)\n                ext = item.get(\"extension\", \"\")\n                print(f\"{prefix}üìÑ {name} ({size:,} chars, {ext})\")\n\n\ndef main():\n    \"\"\"Main extraction function.\"\"\"\n    # Get current directory or specified directory\n    import sys\n\n    if len(sys.argv) > 1:\n        root_dir = Path(sys.argv[1])\n    else:\n        root_dir = Path.cwd()\n\n    # Ensure we have a Path object\n    if not isinstance(root_dir, Path):\n        root_dir = Path(root_dir)\n\n    if not root_dir.exists():\n        print(f\"Error: Directory {root_dir} does not exist\")\n        return\n\n    if not root_dir.is_dir():\n        print(f\"Error: {root_dir} is not a directory\")\n        return\n\n    print(f\"üîç Extracting project structure from: {root_dir.absolute()}\")\n    print(\"üìÅ Reading all .py, .md, .yml, .yaml, .txt, .json files...\")\n\n    # Parse .gitignore if it exists\n    gitignore_path = root_dir / '.gitignore'\n    gitignore_patterns = parse_gitignore(gitignore_path)\n\n    if gitignore_patterns:\n        print(f\"üìã Found .gitignore with {len(gitignore_patterns)} patterns\")\n    else:\n        print(\"üìã No .gitignore found or empty\")\n\n    print(\"üö´ Skipping virtual environments and build directories\")\n\n    # Extract the directory structure\n    try:\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\n\n        # Create metadata\n        metadata = create_project_metadata(root_dir, structure)\n\n        # Create project data\n        project_data = {\n            \"metadata\": metadata,\n            \"structure\": structure\n        }\n\n        # Output filename\n        output_file = root_dir / \"project.json\"\n\n        # Write JSON file\n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(project_data, f, indent=2, ensure_ascii=False)\n\n        print(f\"‚úÖ Extraction complete!\")\n        print(f\"üìä Statistics:\")\n        print(f\"   ‚Ä¢ Total files: {metadata['total_files']}\")\n        print(f\"   ‚Ä¢ Total directories: {metadata['total_directories']}\")\n        print(f\"   ‚Ä¢ Total size: {metadata['total_size']:,} characters\")\n        print(f\"üìÑ Output saved to: {output_file}\")\n\n        # Show file type breakdown\n        if metadata['file_types']:\n            print(f\"\\nüìã File type breakdown:\")\n            for ext, count in sorted(metadata['file_types'].items()):\n                ext_name = ext if ext else \"(no extension)\"\n                print(f\"   ‚Ä¢ {ext_name}: {count} files\")\n\n    except Exception as e:\n        print(f\"‚ùå Error during extraction: {e}\")\n        import traceback\n        traceback.print_exc()\n\n\nif __name__ == \"__main__\":\n    # Add preview option\n    import sys\n\n    if \"--preview\" in sys.argv:\n        sys.argv.remove(\"--preview\")\n\n        # Get directory\n        if len(sys.argv) > 1:\n            root_dir = Path(sys.argv[1])\n        else:\n            root_dir = Path.cwd()\n\n        # Parse .gitignore\n        gitignore_path = root_dir / '.gitignore'\n        gitignore_patterns = parse_gitignore(gitignore_path)\n\n        print(f\"üîç Preview of project structure: {root_dir.name}\")\n        if gitignore_patterns:\n            print(f\"üìã Respecting .gitignore with {len(gitignore_patterns)} patterns\")\n        print(\"=\" * 50)\n\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\n        preview_structure(structure)\n\n    else:\n        main()\n"
    },
    "project.json": {
      "type": "file",
      "path": "project.json",
      "extension": ".json",
      "size": 2019252,
      "content": "{\n  \"metadata\": {\n    \"project_name\": \"AIMafia\",\n    \"extraction_timestamp\": \"2025-06-13T16:11:52.260359\",\n    \"root_path\": \"/Users/voicutomut/Documents/GitHub/AIMafia\",\n    \"total_files\": 23,\n    \"total_directories\": 3,\n    \"file_types\": {\n      \".py\": 15,\n      \".md\": 4,\n      \".yaml\": 1,\n      \".json\": 2,\n      \".txt\": 1\n    },\n    \"total_size\": 1694659,\n    \"respects_gitignore\": true,\n    \"skips_virtual_environments\": true\n  },\n  \"structure\": {\n    \"app\": {\n      \"type\": \"directory\",\n      \"contents\": {\n        \"__init__.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/__init__.py\",\n          \"extension\": \".py\",\n          \"size\": 489,\n          \"content\": \"\\\"\\\"\\\"\\nAI  Debate System\\n\\nA platform for structured debates between AI bots and human participants.\\n\\\"\\\"\\\"\\n\\n__version__ = \\\"1.0.0\\\"\\n__author__ = \\\"AndreiVoicuT\\\"\\n\\nfrom .main import start_debate_session\\nfrom .moderator import Moderator\\nfrom .bot_client import BotClient\\nfrom .human_client import HumanClient\\nfrom .chat_log import ChatLog\\nfrom .voting import VotingSystem\\n\\n__all__ = [\\n    \\\"start_debate_session\\\",\\n    \\\"Moderator\\\",\\n    \\\"BotClient\\\",\\n    \\\"HumanClient\\\",\\n    \\\"ChatLog\\\",\\n    \\\"VotingSystem\\\"\\n]\"\n        },\n        \"bot_client.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/bot_client.py\",\n          \"extension\": \".py\",\n          \"size\": 27223,\n          \"content\": \"\\\"\\\"\\\"\\nAI Bot client for interacting with various language models in debates.\\nNow with true autonomous monitoring and decision-making capabilities.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport json\\nimport time\\nimport random\\nfrom typing import List, Dict, Any, Optional\\nfrom dataclasses import dataclass\\nfrom abc import ABC, abstractmethod\\n\\nfrom .chat_log import Message\\nfrom .utils import truncate_text\\nimport re\\n\\n\\n@dataclass\\nclass BotConfig:\\n    \\\"\\\"\\\"Configuration for AI bot behavior.\\\"\\\"\\\"\\n    name: str\\n    model: str\\n    provider: str\\n    personality: str\\n    stance: str\\n    temperature: float = 0.7\\n    max_tokens: int = 300\\n    timeout: int = 30\\n    check_interval: int = 5  # How often to check for new messages\\n    min_cooldown: int = 15   # Minimum seconds between responses\\n    max_cooldown: int = 45   # Maximum cooldown for active bots\\n\\n\\nclass AIProvider(ABC):\\n    \\\"\\\"\\\"Abstract base class for AI providers.\\\"\\\"\\\"\\n\\n    @abstractmethod\\n    async def generate_response(self, messages: List[Dict[str, str]],\\n                              config: BotConfig) -> str:\\n        \\\"\\\"\\\"Generate response from the AI model.\\\"\\\"\\\"\\n        pass\\n\\n\\nclass OpenAIProvider(AIProvider):\\n    \\\"\\\"\\\"OpenAI API provider.\\\"\\\"\\\"\\n\\n    def __init__(self, api_key: str):\\n        self.api_key = api_key\\n\\n    async def generate_response(self, messages: List[Dict[str, str]],\\n                              config: BotConfig) -> str:\\n        \\\"\\\"\\\"Generate response using OpenAI API.\\\"\\\"\\\"\\n        try:\\n            import openai\\n            client = openai.AsyncOpenAI(api_key=self.api_key)\\n\\n            response = await client.chat.completions.create(\\n                model=config.model,\\n                messages=messages,\\n                max_tokens=config.max_tokens,\\n                temperature=config.temperature,\\n                timeout=config.timeout\\n            )\\n\\n            return response.choices[0].message.content.strip()\\n\\n        except Exception as e:\\n            raise Exception(f\\\"OpenAI API error: {e}\\\")\\n\\n\\nclass AnthropicProvider(AIProvider):\\n    \\\"\\\"\\\"Anthropic API provider.\\\"\\\"\\\"\\n\\n    def __init__(self, api_key: str):\\n        self.api_key = api_key\\n\\n    async def generate_response(self, messages: List[Dict[str, str]],\\n                              config: BotConfig) -> str:\\n        \\\"\\\"\\\"Generate response using Anthropic API.\\\"\\\"\\\"\\n        try:\\n            import anthropic\\n            client = anthropic.AsyncAnthropic(api_key=self.api_key)\\n\\n            # Convert messages format for Anthropic\\n            system_message = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \\\"\\\"\\n            user_messages = [msg for msg in messages if msg['role'] != 'system']\\n\\n            response = await client.messages.create(\\n                model=config.model,\\n                max_tokens=config.max_tokens,\\n                temperature=config.temperature,\\n                system=system_message,\\n                messages=user_messages\\n            )\\n\\n            return response.content[0].text.strip()\\n\\n        except Exception as e:\\n            raise Exception(f\\\"Anthropic API error: {e}\\\")\\n\\n\\nclass BotClient:\\n    \\\"\\\"\\\"\\n    AI Bot client that participates in debates using various language models.\\n    Now with full autonomous monitoring and decision-making capabilities.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, name: str, model: str, provider: str,\\n                 personality: str, stance: str, api_key: str,\\n                 temperature: float = 0.7, max_tokens: int = 300):\\n\\n        self.config = BotConfig(\\n            name=name,\\n            model=model,\\n            provider=provider,\\n            personality=personality,\\n            stance=stance,\\n            temperature=temperature,\\n            max_tokens=max_tokens\\n        )\\n\\n        # Initialize AI provider\\n        if provider.lower() == 'openai':\\n            self.ai_provider = OpenAIProvider(api_key)\\n        elif provider.lower() == 'anthropic':\\n            self.ai_provider = AnthropicProvider(api_key)\\n        else:\\n            raise ValueError(f\\\"Unsupported AI provider: {provider}\\\")\\n\\n        # Bot state\\n        self.conversation_history: List[Dict[str, str]] = []\\n        self.debate_context = \\\"\\\"\\n        self.response_count = 0\\n\\n        # Autonomous monitoring state\\n        self.is_monitoring = False\\n        self.monitoring_task: Optional[asyncio.Task] = None\\n        self.message_queue: Optional[asyncio.Queue] = None\\n        self.chat_log = None\\n        self.topic = \\\"\\\"\\n        self.last_response_time = 0\\n        self.total_responses = 0\\n        self.current_cooldown = self.config.min_cooldown\\n\\n        # Performance tracking\\n        self.stats = {\\n            'responses_generated': 0,\\n            'autonomous_responses': 0,\\n            'average_response_time': 0,\\n            'total_response_time': 0,\\n            'errors': 0,\\n            'triggers_detected': 0,\\n            'passes_made': 0\\n        }\\n\\n    @property\\n    def name(self) -> str:\\n        \\\"\\\"\\\"Get bot name.\\\"\\\"\\\"\\n        return self.config.name\\n\\n    async def start_autonomous_monitoring(self, chat_log, topic: str):\\n        \\\"\\\"\\\"Start autonomous monitoring of chat log.\\\"\\\"\\\"\\n        self.is_monitoring = True\\n        self.chat_log = chat_log\\n        self.topic = topic\\n\\n        # Subscribe to chat log updates\\n        self.message_queue = chat_log.subscribe()\\n\\n        # Start monitoring task\\n        self.monitoring_task = asyncio.create_task(self._autonomous_monitor_loop())\\n\\n        print(f\\\"ü§ñ {self.name} started autonomous monitoring\\\")\\n\\n    async def _autonomous_monitor_loop(self):\\n        \\\"\\\"\\\"Main autonomous monitoring loop - the heart of autonomy.\\\"\\\"\\\"\\n        while self.is_monitoring:\\n            try:\\n                # Wait for new messages or timeout to check periodically\\n                try:\\n                    message = await asyncio.wait_for(\\n                        self.message_queue.get(),\\n                        timeout=self.config.check_interval\\n                    )\\n\\n                    # Skip own messages\\n                    if message.sender == self.name:\\n                        continue\\n\\n                    # Process new message\\n                    await self._process_new_message(message)\\n\\n                except asyncio.TimeoutError:\\n                    # Timeout is normal, continue monitoring\\n                    # Check if we should spontaneously contribute\\n                    await self._check_spontaneous_contribution()\\n                    continue\\n\\n            except Exception as e:\\n                print(f\\\"‚ùå {self.name} monitoring error: {e}\\\")\\n                await asyncio.sleep(5)\\n\\n    async def _process_new_message(self, message: Message):\\n        \\\"\\\"\\\"Process a new message and decide if we should respond.\\\"\\\"\\\"\\n        # Get full conversation history\\n        full_history = list(self.chat_log.messages)\\n\\n        # Check cooldown\\n        if time.time() - self.last_response_time < self.current_cooldown:\\n            return\\n\\n        # Decide if should respond\\n        should_respond = await self._should_respond_autonomously(message, full_history)\\n\\n        if should_respond:\\n            await self._generate_autonomous_response(full_history, trigger_message=message)\\n\\n    async def _check_spontaneous_contribution(self):\\n        \\\"\\\"\\\"Check if bot should spontaneously contribute to conversation.\\\"\\\"\\\"\\n        if not self.chat_log:\\n            return\\n\\n        # Don't contribute too frequently\\n        if time.time() - self.last_response_time < self.current_cooldown * 2:\\n            return\\n\\n        full_history = list(self.chat_log.messages)\\n\\n        # Check if conversation has stalled\\n        if len(full_history) > 0:\\n            last_message_time = full_history[-1].timestamp\\n            silence_duration = time.time() - last_message_time\\n\\n            # If there's been silence for a while, consider contributing\\n            if silence_duration > 30:  # 30 seconds of silence\\n                recent_messages = full_history[-10:] if len(full_history) >= 10 else full_history\\n\\n                # Check if we have something meaningful to add\\n                my_recent_count = sum(1 for msg in recent_messages if msg.sender == self.name)\\n\\n                if my_recent_count == 0:  # Haven't spoken recently\\n                    # Low probability spontaneous contribution\\n                    if random.random() < 0.8:  # 20% chance\\n                        await self._generate_autonomous_response(full_history, spontaneous=True)\\n\\n    async def _should_respond_autonomously(self, new_message: Message,\\n                                         full_history: List[Message]) -> bool:\\n        \\\"\\\"\\\"Decide if bot should respond based on conversation state.\\\"\\\"\\\"\\n\\n        content_lower = new_message.content.lower()\\n\\n        # Get recent context\\n        recent_context = full_history[-10:] if len(full_history) >= 10 else full_history\\n        recent_text = \\\" \\\".join([msg.content for msg in recent_context[-5:]])\\n\\n        # Check various triggers\\n        triggers = self._analyze_response_triggers(new_message, recent_text, full_history)\\n\\n        self.stats['triggers_detected'] += len([t for t in triggers.values() if t])\\n\\n        if triggers['direct_mention']:\\n            return True  # Always respond if mentioned\\n\\n        # Calculate response probability\\n        base_probability = 0.9\\n\\n        if triggers['stance_challenged']:\\n            base_probability += 0.99\\n        if triggers['question_in_domain']:\\n            base_probability += 0.9\\n        if triggers['topic_shift']:\\n            base_probability += 0.5\\n        if triggers['silence_too_long']:\\n            base_probability += 0.5\\n        if triggers['expertise_needed']:\\n            base_probability += 0.7\\n\\n        # Adjust based on recent participation\\n        my_recent_count = sum(1 for msg in recent_context if msg.sender == self.name)\\n        if my_recent_count == 0:\\n            base_probability += 0.2  # More likely if haven't spoken\\n        elif my_recent_count >= 3:\\n            base_probability *= 0.5  # Less likely if spoke a lot recently\\n\\n        # Add personality-based adjustments\\n        base_probability *= self._get_personality_multiplier(triggers)\\n\\n        # Cap probability\\n        final_probability = min(base_probability, 0.99)\\n\\n        should_respond = random.random() < final_probability\\n\\n        if not should_respond:\\n            self.stats['passes_made'] += 1\\n\\n        return should_respond\\n\\n    def _analyze_response_triggers(self, message: Message, recent_text: str,\\n                                 full_history: List[Message]) -> Dict[str, bool]:\\n        \\\"\\\"\\\"Analyze various triggers for responding.\\\"\\\"\\\"\\n\\n        content_lower = message.content.lower()\\n        recent_lower = recent_text.lower()\\n\\n        triggers = {\\n            'direct_mention': False,\\n            'stance_challenged': False,\\n            'question_in_domain': False,\\n            'topic_shift': False,\\n            'silence_too_long': False,\\n            'expertise_needed': False,\\n            'emotional_trigger': False\\n        }\\n\\n        # Direct mention\\n        # Enhanced direct mention detection (robust to casing, punctuation, and name variations)\\n        name_variants = [\\n            self.name.lower(),\\n            self.name.lower().rstrip('s'),  # e.g. \\\"Socrate\\\" for \\\"Socrates\\\"\\n            self.name.lower() + \\\":\\\",  # e.g. \\\"socrates:\\\"\\n            self.name.lower().replace(\\\" \\\", \\\"_\\\"),\\n            self.name.lower().replace(\\\"_\\\", \\\" \\\"),\\n        ]\\n\\n        # Add common address forms (e.g. \\\"Hey Socrates\\\", \\\"Socrates?\\\")\\n        mention_found = any(\\n            re.search(rf\\\"\\\\b{re.escape(variant)}\\\\b\\\", content_lower)\\n            for variant in name_variants\\n        )\\n\\n        if mention_found:\\n            triggers['direct_mention'] = True\\n        elif \\\"what do you think\\\" in content_lower and self.config.stance != \\\"neutral\\\":\\n            triggers['direct_mention'] = True  # fallback heuristic for opinion prompts\\n\\n\\n        # Stance-based triggers\\n        if self.config.stance == 'pro':\\n            challenge_words = ['wrong', 'disagree', 'against', 'oppose', 'bad idea', 'fails', 'problem']\\n            if any(word in recent_lower for word in challenge_words):\\n                triggers['stance_challenged'] = True\\n\\n        elif self.config.stance == 'con':\\n            support_words = ['agree', 'support', 'favor', 'good idea', 'beneficial', 'works', 'success']\\n            if any(word in recent_lower for word in support_words):\\n                triggers['stance_challenged'] = True\\n\\n        elif self.config.stance == 'neutral':\\n            question_indicators = ['?', 'what', 'how', 'why', 'when', 'where', 'clarify', 'explain']\\n            if any(indicator in content_lower for indicator in question_indicators):\\n                triggers['question_in_domain'] = True\\n\\n        # Check for silence\\n        if len(full_history) > 0:\\n            last_msg_time = full_history[-1].timestamp\\n            if time.time() - last_msg_time > 45:  # 45 seconds\\n                triggers['silence_too_long'] = True\\n\\n        # Check if expertise is needed (personality-based)\\n        expertise_words = {\\n            'philosophical': ['meaning', 'purpose', 'ethics', 'moral', 'should', 'ought'],\\n            'analytical': ['data', 'evidence', 'study', 'research', 'statistics', 'proof'],\\n            'practical': ['implement', 'real world', 'actually', 'practice', 'work'],\\n            'critical': ['assume', 'problem', 'issue', 'concern', 'risk']\\n        }\\n\\n        for domain, words in expertise_words.items():\\n            if domain in self.config.personality.lower():\\n                if any(word in content_lower for word in words):\\n                    triggers['expertise_needed'] = True\\n                    break\\n\\n        return triggers\\n\\n    def _get_personality_multiplier(self, triggers: Dict[str, bool]) -> float:\\n        \\\"\\\"\\\"Get personality-based probability multiplier.\\\"\\\"\\\"\\n        personality_lower = self.config.personality.lower()\\n        multiplier = 1.0\\n\\n        if 'aggressive' in personality_lower or 'assertive' in personality_lower:\\n            multiplier = 1.3\\n        elif 'thoughtful' in personality_lower or 'philosophical' in personality_lower:\\n            if triggers['question_in_domain']:\\n                multiplier = 1.4\\n            else:\\n                multiplier = 0.8\\n        elif 'analytical' in personality_lower or 'data-driven' in personality_lower:\\n            if triggers['expertise_needed']:\\n                multiplier = 1.5\\n            else:\\n                multiplier = 0.9\\n        elif 'balanced' in personality_lower or 'diplomatic' in personality_lower:\\n            if triggers['stance_challenged']:\\n                multiplier = 1.2\\n            else:\\n                multiplier = 1.0\\n\\n        return multiplier\\n\\n    async def _generate_autonomous_response(self, full_history: List[Message],\\n                                          trigger_message: Message = None,\\n                                          spontaneous: bool = False):\\n        \\\"\\\"\\\"Generate and post autonomous response.\\\"\\\"\\\"\\n        start_time = time.time()\\n\\n        try:\\n            if spontaneous:\\n                print(f\\\"üí≠ {self.name} is thinking about contributing spontaneously...\\\")\\n            else:\\n                print(f\\\"üí≠ {self.name} is thinking about responding...\\\")\\n\\n            # Prepare messages with full context\\n            messages = self._prepare_autonomous_messages(full_history, trigger_message, spontaneous)\\n\\n            # Generate response\\n            #print(\\\"Message to provider:\\\", messages)\\n            response = await self.ai_provider.generate_response(messages, self.config)\\n\\n            if response and response.strip():\\n                # Post directly to chat log\\n                await self.chat_log.add_message(self.name, response)\\n\\n                # Update state\\n                self.last_response_time = time.time()\\n                self.total_responses += 1\\n                self.stats['autonomous_responses'] += 1\\n\\n                # Dynamic cooldown based on activity\\n                self.current_cooldown = min(\\n                    self.config.min_cooldown + (self.total_responses * 2),\\n                    self.config.max_cooldown\\n                )\\n\\n                # Update stats\\n                response_time = time.time() - start_time\\n                self._update_stats(response_time, success=True)\\n\\n                print(f\\\"‚úÖ {self.name} responded autonomously\\\")\\n                return response\\n            else:\\n                print(f\\\"üí≠ {self.name} decided not to respond after thinking\\\")\\n                self.stats['passes_made'] += 1\\n\\n        except Exception as e:\\n            self._update_stats(time.time() - start_time, success=False)\\n            print(f\\\"‚ùå {self.name} autonomous response error: {e}\\\")\\n\\n        return None\\n\\n    def _prepare_autonomous_messages(self, full_history: List[Message],\\n                                   trigger_message: Message = None,\\n                                   spontaneous: bool = False) -> List[Dict[str, str]]:\\n        \\\"\\\"\\\"Prepare messages for autonomous response generation.\\\"\\\"\\\"\\n        messages = []\\n\\n        # Enhanced system prompt for autonomous mode\\n        system_prompt = self._create_autonomous_system_prompt(full_history, trigger_message, spontaneous)\\n        messages.append({\\n            'role': 'system',\\n            'content': system_prompt\\n        })\\n\\n        # Add conversation history (more context for autonomous decision)\\n        history_to_include = full_history[-15:] if len(full_history) > 15 else full_history\\n\\n        for msg in history_to_include:\\n            role = 'assistant' if msg.sender == self.name else 'user'\\n            content = f\\\"{msg.sender}: {msg.content}\\\"\\n            messages.append({\\n                'role': role,\\n                'content': content\\n            })\\n\\n        return messages\\n\\n    def _create_autonomous_system_prompt(self, full_history: List[Message],\\n                                       trigger_message: Message = None,\\n                                       spontaneous: bool = False) -> str:\\n        \\\"\\\"\\\"Create enhanced system prompt for autonomous responses.\\\"\\\"\\\"\\n\\n        prompt = f\\\"\\\"\\\"You are {self.config.name}, participating in a FULLY AUTONOMOUS debate.\\n\\nDEBATE TOPIC: {self.topic}\\n\\nYOUR IDENTITY:\\n- Personality: {self.config.personality}\\n- Stance: {self.config.stance}\\n- You have been monitoring this conversation and DECIDED to speak\\n\\nAUTONOMOUS DEBATE CONTEXT:\\n- You are NOT taking turns - you chose to respond because you felt compelled\\n- You have access to the FULL conversation history\\n- Other participants (bots and humans) can also speak at any time\\n- The conversation flows naturally and organically\\n\\nYOUR CURRENT SITUATION:\\\"\\\"\\\"\\n\\n        if spontaneous:\\n            prompt += \\\"\\\"\\\"\\n- You noticed the conversation had stalled and decided to contribute\\n- Provide a thoughtful addition to move the discussion forward\\n- Reference previous points made by others\\\"\\\"\\\"\\n        elif trigger_message:\\n            prompt += f\\\"\\\"\\\"\\n- You were triggered to respond by: \\\"{trigger_message.sender}: {trigger_message.content[:100]}...\\\"\\n- Address this specific point while staying true to your stance and personality\\n- Build on or challenge what was said\\\"\\\"\\\"\\n        else:\\n            prompt += \\\"\\\"\\\"\\n- Something in the recent conversation compelled you to speak\\n- Respond naturally based on your personality and stance\\\"\\\"\\\"\\n\\n        prompt += f\\\"\\\"\\\"\\n\\nRESPONSE GUIDELINES:\\n1. Keep responses focused and substantial (50-250 words)\\n2. Reference specific points made by others when relevant\\n3. Stay true to your personality and stance\\n4. Don't repeat previous arguments verbatim\\n5. Show you've been actively listening to the conversation\\n6. Be conversational but substantive\\n\\nSTANCE-SPECIFIC APPROACH:\\\"\\\"\\\"\\n\\n        if self.config.stance.lower() == 'pro':\\n            prompt += \\\"\\\\n- Argue IN FAVOR of the topic\\\\n- Challenge opposing views\\\\n- Provide supporting evidence\\\"\\n        elif self.config.stance.lower() == 'con':\\n            prompt += \\\"\\\\n- Argue AGAINST the topic\\\\n- Question supporting claims\\\\n- Highlight problems and risks\\\"\\n        elif self.config.stance.lower() == 'neutral':\\n            prompt += \\\"\\\\n- Seek balanced understanding\\\\n- Ask clarifying questions\\\\n- Bridge different perspectives\\\"\\n\\n        # Add personality-specific guidance\\n        if 'philosophical' in self.config.personality.lower():\\n            prompt += \\\"\\\\n- Ask deeper questions about assumptions and implications\\\"\\n        elif 'analytical' in self.config.personality.lower():\\n            prompt += \\\"\\\\n- Focus on data, evidence, and logical reasoning\\\"\\n        elif 'passionate' in self.config.personality.lower():\\n            prompt += \\\"\\\\n- Show enthusiasm and conviction in your arguments\\\"\\n\\n        prompt += \\\"\\\\n\\\\nRespond as if you're naturally joining an ongoing conversation that you've been thoughtfully following.\\\"\\n\\n        return prompt\\n\\n    async def stop_monitoring(self):\\n        \\\"\\\"\\\"Stop autonomous monitoring.\\\"\\\"\\\"\\n        self.is_monitoring = False\\n        if self.monitoring_task:\\n            self.monitoring_task.cancel()\\n            try:\\n                await self.monitoring_task\\n            except asyncio.CancelledError:\\n                pass\\n        if self.message_queue and self.chat_log:\\n            self.chat_log.unsubscribe(self.message_queue)\\n        print(f\\\"üõë {self.name} stopped autonomous monitoring\\\")\\n\\n    # Legacy methods for compatibility\\n    async def get_response(self, topic: str, recent_messages: List[Message]) -> str:\\n        \\\"\\\"\\\"Legacy method - now used for structured phases only.\\\"\\\"\\\"\\n        start_time = time.time()\\n\\n        try:\\n            messages = self._prepare_messages(topic, recent_messages)\\n            response = await self.ai_provider.generate_response(messages, self.config)\\n\\n            response_time = time.time() - start_time\\n            self._update_stats(response_time, success=True)\\n\\n            self.conversation_history.append({\\n                'role': 'assistant',\\n                'content': response\\n            })\\n\\n            self.response_count += 1\\n            return response\\n\\n        except Exception as e:\\n            self._update_stats(time.time() - start_time, success=False)\\n            print(f\\\"Bot {self.name} error: {e}\\\")\\n            return self._generate_fallback_response(topic)\\n\\n    def _prepare_messages(self, topic: str, recent_messages: List[Message]) -> List[Dict[str, str]]:\\n        \\\"\\\"\\\"Prepare message context for AI model (legacy method).\\\"\\\"\\\"\\n        messages = []\\n\\n        system_prompt = f\\\"\\\"\\\"You are {self.config.name}, participating in a structured debate.\\n\\nDEBATE TOPIC: {topic}\\nYOUR ROLE: {self.config.personality}\\nYOUR STANCE: {self.config.stance}\\n\\nProvide a clear, focused response to the current debate context.\\\"\\\"\\\"\\n\\n        messages.append({\\n            'role': 'system',\\n            'content': system_prompt\\n        })\\n\\n        for msg in recent_messages[-5:]:\\n            role = 'assistant' if msg.sender == self.name else 'user'\\n            content = f\\\"{msg.sender}: {msg.content}\\\"\\n            messages.append({\\n                'role': role,\\n                'content': content\\n            })\\n\\n        return messages\\n\\n    def _generate_fallback_response(self, topic: str) -> str:\\n        \\\"\\\"\\\"Generate a fallback response when AI fails.\\\"\\\"\\\"\\n        fallback_responses = [\\n            f\\\"I'd like to share another perspective on {topic}. Let me gather my thoughts and respond shortly.\\\",\\n            \\\"That's an interesting point. I need a moment to formulate a proper response to that argument.\\\",\\n            f\\\"There are several important aspects of {topic} we should consider here.\\\",\\n            \\\"I appreciate the previous arguments. Let me offer a different viewpoint on this matter.\\\"\\n        ]\\n\\n        return random.choice(fallback_responses)\\n\\n    async def receive_message(self, message: Message) -> None:\\n        \\\"\\\"\\\"Receive a message (for compatibility).\\\"\\\"\\\"\\n        if message.sender != self.name:\\n            self.conversation_history.append({\\n                'role': 'user',\\n                'content': f\\\"{message.sender}: {message.content}\\\"\\n            })\\n\\n            if len(self.conversation_history) > 20:\\n                self.conversation_history = self.conversation_history[-15:]\\n\\n    def _update_stats(self, response_time: float, success: bool = True):\\n        \\\"\\\"\\\"Update performance statistics.\\\"\\\"\\\"\\n        if success:\\n            self.stats['responses_generated'] += 1\\n            self.stats['total_response_time'] += response_time\\n            self.stats['average_response_time'] = (\\n                self.stats['total_response_time'] / self.stats['responses_generated']\\n            )\\n        else:\\n            self.stats['errors'] += 1\\n\\n    def get_stats(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get bot performance statistics.\\\"\\\"\\\"\\n        return {\\n            'name': self.name,\\n            'model': self.config.model,\\n            'provider': self.config.provider,\\n            'responses_generated': self.stats['responses_generated'],\\n            'autonomous_responses': self.stats['autonomous_responses'],\\n            'average_response_time': round(self.stats['average_response_time'], 2),\\n            'total_errors': self.stats['errors'],\\n            'triggers_detected': self.stats['triggers_detected'],\\n            'passes_made': self.stats['passes_made'],\\n            'success_rate': (\\n                self.stats['responses_generated'] /\\n                (self.stats['responses_generated'] + self.stats['errors'])\\n                if (self.stats['responses_generated'] + self.stats['errors']) > 0 else 0\\n            ),\\n            'current_cooldown': self.current_cooldown,\\n            'total_autonomous_responses': self.total_responses\\n        }\\n\\n    def update_personality(self, personality: str, stance: str = None):\\n        \\\"\\\"\\\"Update bot personality and stance.\\\"\\\"\\\"\\n        self.config.personality = personality\\n        if stance:\\n            self.config.stance = stance\\n\\n    def reset_conversation(self):\\n        \\\"\\\"\\\"Reset conversation history.\\\"\\\"\\\"\\n        self.conversation_history = []\\n        self.response_count = 0\\n\\n    async def warmup(self) -> bool:\\n        \\\"\\\"\\\"Warm up the bot by testing API connection.\\\"\\\"\\\"\\n        try:\\n            test_messages = [{\\n                'role': 'system',\\n                'content': 'You are a debate participant. Respond with just \\\"Ready\\\" to confirm you are working.'\\n            }, {\\n                'role': 'user',\\n                'content': 'Are you ready to participate in a debate?'\\n            }]\\n\\n            response = await self.ai_provider.generate_response(test_messages, self.config)\\n            return \\\"ready\\\" in response.lower()\\n\\n        except Exception as e:\\n            print(f\\\"Bot {self.name} warmup failed: {e}\\\")\\n            return False\\n\\n    def __str__(self) -> str:\\n        \\\"\\\"\\\"String representation of the bot.\\\"\\\"\\\"\\n        return f\\\"BotClient({self.name}, {self.config.model}, {self.config.stance}, autonomous={self.is_monitoring})\\\"\\n\\n    def __repr__(self) -> str:\\n        \\\"\\\"\\\"Detailed string representation.\\\"\\\"\\\"\\n        return (f\\\"BotClient(name='{self.name}', model='{self.config.model}', \\\"\\n                f\\\"provider='{self.config.provider}', stance='{self.config.stance}', \\\"\\n                f\\\"monitoring={self.is_monitoring})\\\")\\n\\n    @property\\n    def stance(self) -> str:\\n        \\\"\\\"\\\"Expose the bot's stance directly for consistency with other participants.\\\"\\\"\\\"\\n        return self.config.stance\\n\\n\"\n        },\n        \"chat_log.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/chat_log.py\",\n          \"extension\": \".py\",\n          \"size\": 11229,\n          \"content\": \"\\\"\\\"\\\"\\nShared chat log system for managing debate messages with timestamps and ordering.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport json\\nimport time\\nfrom typing import List, Dict, Any, Optional\\nfrom dataclasses import dataclass, asdict\\nfrom pathlib import Path\\nfrom collections import deque\\n\\n\\n@dataclass\\nclass Message:\\n    \\\"\\\"\\\"Represents a single chat message.\\\"\\\"\\\"\\n    sender: str\\n    content: str\\n    timestamp: float\\n    message_id: int\\n    message_type: str = \\\"chat\\\"  # chat, system, moderator, vote\\n    metadata: Optional[Dict[str, Any]] = None\\n\\n    def __post_init__(self):\\n        if self.metadata is None:\\n            self.metadata = {}\\n\\n    @property\\n    def formatted_timestamp(self) -> str:\\n        \\\"\\\"\\\"Get human-readable timestamp.\\\"\\\"\\\"\\n        return time.strftime(\\\"%H:%M:%S\\\", time.localtime(self.timestamp))\\n\\n    def to_dict(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Convert message to dictionary.\\\"\\\"\\\"\\n        return asdict(self)\\n\\n    @classmethod\\n    def from_dict(cls, data: Dict[str, Any]) -> 'Message':\\n        \\\"\\\"\\\"Create message from dictionary.\\\"\\\"\\\"\\n        return cls(**data)\\n\\n\\nclass ChatLog:\\n    \\\"\\\"\\\"\\n    Manages the shared chat log with thread-safe message handling.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, max_messages: int = 1000):\\n        self.messages: deque = deque(maxlen=max_messages)\\n        self.message_counter = 0\\n        self.subscribers: List[asyncio.Queue] = []\\n        self._lock = asyncio.Lock()\\n\\n        # Statistics\\n        self.stats = {\\n            'total_messages': 0,\\n            'messages_by_sender': {},\\n            'start_time': time.time()\\n        }\\n\\n    async def add_message(self, sender: str, content: str,\\n                          message_type: str = \\\"chat\\\",\\n                          metadata: Optional[Dict[str, Any]] = None) -> Message:\\n        \\\"\\\"\\\"\\n        Add a new message to the chat log.\\n\\n        Args:\\n            sender: Name of the message sender\\n            content: Message content\\n            message_type: Type of message (chat, system, moderator, vote)\\n            metadata: Additional message metadata\\n\\n        Returns:\\n            The created Message object\\n        \\\"\\\"\\\"\\n        async with self._lock:\\n            self.message_counter += 1\\n\\n            message = Message(\\n                sender=sender,\\n                content=content,\\n                timestamp=time.time(),\\n                message_id=self.message_counter,\\n                message_type=message_type,\\n                metadata=metadata or {}\\n            )\\n\\n            self.messages.append(message)\\n\\n            # Update statistics\\n            self.stats['total_messages'] += 1\\n            self.stats['messages_by_sender'][sender] = (\\n                    self.stats['messages_by_sender'].get(sender, 0) + 1\\n            )\\n\\n            # Notify subscribers\\n            await self._notify_subscribers(message)\\n\\n            return message\\n\\n    async def _notify_subscribers(self, message: Message):\\n        \\\"\\\"\\\"Notify all subscribers of new message.\\\"\\\"\\\"\\n        # Remove closed queues\\n        self.subscribers = [q for q in self.subscribers if not getattr(q, \\\"_closed\\\", False)]\\n        # Send to all active subscribers\\n        for queue in self.subscribers:\\n            try:\\n                await queue.put(message)\\n            except Exception as e:\\n                print(f\\\"Failed to notify subscriber: {e}\\\")\\n\\n    def subscribe(self) -> asyncio.Queue:\\n        \\\"\\\"\\\"\\n        Subscribe to receive new messages.\\n\\n        Returns:\\n            Queue that will receive new Message objects\\n        \\\"\\\"\\\"\\n        queue = asyncio.Queue()\\n        self.subscribers.append(queue)\\n        return queue\\n\\n    def unsubscribe(self, queue: asyncio.Queue):\\n        \\\"\\\"\\\"Remove a subscriber queue.\\\"\\\"\\\"\\n        if queue in self.subscribers:\\n            self.subscribers.remove(queue)\\n\\n    def get_messages(self, limit: Optional[int] = None,\\n                     sender: Optional[str] = None,\\n                     message_type: Optional[str] = None,\\n                     since_timestamp: Optional[float] = None) -> List[Message]:\\n        \\\"\\\"\\\"\\n        Get messages with optional filtering.\\n\\n        Args:\\n            limit: Maximum number of messages to return\\n            sender: Filter by sender name\\n            message_type: Filter by message type\\n            since_timestamp: Only return messages after this timestamp\\n\\n        Returns:\\n            List of matching messages\\n        \\\"\\\"\\\"\\n        messages = list(self.messages)\\n\\n        # Apply filters\\n        if sender:\\n            messages = [m for m in messages if m.sender == sender]\\n\\n        if message_type:\\n            messages = [m for m in messages if m.message_type == message_type]\\n\\n        if since_timestamp:\\n            messages = [m for m in messages if m.timestamp > since_timestamp]\\n\\n        # Apply limit\\n        if limit:\\n            messages = messages[-limit:]\\n\\n        return messages\\n\\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\\n        \\\"\\\"\\\"Get the most recent messages.\\\"\\\"\\\"\\n        return list(self.messages)[-count:]\\n\\n    def get_conversation_context(self, participant: str,\\n                                 context_length: int = 5) -> List[Message]:\\n        \\\"\\\"\\\"\\n        Get conversation context for a participant.\\n\\n        Args:\\n            participant: Participant name\\n            context_length: Number of recent messages to include\\n\\n        Returns:\\n            Recent messages for context\\n        \\\"\\\"\\\"\\n        recent = self.get_recent_messages(context_length * 2)\\n\\n        # Include messages to/from the participant and moderator messages\\n        context = []\\n        for msg in recent:\\n            if (msg.sender == participant or\\n                    msg.message_type in ['moderator', 'system'] or\\n                    participant in msg.content):\\n                context.append(msg)\\n\\n        return context[-context_length:]\\n\\n    def search_messages(self, query: str, case_sensitive: bool = False) -> List[Message]:\\n        \\\"\\\"\\\"\\n        Search messages by content.\\n\\n        Args:\\n            query: Search query\\n            case_sensitive: Whether search should be case sensitive\\n\\n        Returns:\\n            List of messages containing the query\\n        \\\"\\\"\\\"\\n        if not case_sensitive:\\n            query = query.lower()\\n\\n        results = []\\n        for message in self.messages:\\n            content = message.content if case_sensitive else message.content.lower()\\n            if query in content:\\n                results.append(message)\\n\\n        return results\\n\\n    def get_statistics(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get chat log statistics.\\\"\\\"\\\"\\n        duration = time.time() - self.stats['start_time']\\n\\n        return {\\n            'total_messages': self.stats['total_messages'],\\n            'unique_senders': len(self.stats['messages_by_sender']),\\n            'messages_by_sender': dict(self.stats['messages_by_sender']),\\n            'messages_per_minute': (self.stats['total_messages'] / (duration / 60)\\n                                    if duration > 0 else 0),\\n            'session_duration_minutes': duration / 60,\\n            'current_message_count': len(self.messages)\\n        }\\n\\n    async def save_transcript(self, filename: str,\\n                              format_type: str = \\\"json\\\") -> None:\\n        \\\"\\\"\\\"\\n        Save chat transcript to file.\\n\\n        Args:\\n            filename: Output filename\\n            format_type: Format (json, txt, html)\\n        \\\"\\\"\\\"\\n        filepath = Path(filename)\\n        filepath.parent.mkdir(parents=True, exist_ok=True)\\n\\n        messages = list(self.messages)\\n\\n        if format_type == \\\"json\\\":\\n            data = {\\n                'metadata': {\\n                    'export_timestamp': time.time(),\\n                    'total_messages': len(messages),\\n                    'statistics': self.get_statistics()\\n                },\\n                'messages': [msg.to_dict() for msg in messages]\\n            }\\n\\n            with open(filepath, 'w', encoding='utf-8') as f:\\n                json.dump(data, f, indent=2, ensure_ascii=False)\\n\\n        elif format_type == \\\"txt\\\":\\n            with open(filepath, 'w', encoding='utf-8') as f:\\n                f.write(\\\"=== DEBATE TRANSCRIPT ===\\\\n\\\\n\\\")\\n\\n                for msg in messages:\\n                    f.write(f\\\"[{msg.formatted_timestamp}] {msg.sender}: {msg.content}\\\\n\\\")\\n\\n        elif format_type == \\\"html\\\":\\n            html_content = self._generate_html_transcript(messages)\\n            with open(filepath, 'w', encoding='utf-8') as f:\\n                f.write(html_content)\\n\\n        else:\\n            raise ValueError(f\\\"Unsupported format: {format_type}\\\")\\n\\n    def _generate_html_transcript(self, messages: List[Message]) -> str:\\n        \\\"\\\"\\\"Generate HTML transcript.\\\"\\\"\\\"\\n        html = \\\"\\\"\\\"\\n        <!DOCTYPE html>\\n        <html>\\n        <head>\\n            <title>Debate Transcript</title>\\n            <style>\\n                body { font-family: Arial, sans-serif; margin: 20px; }\\n                .message { margin: 10px 0; padding: 10px; border-left: 3px solid #ccc; }\\n                .moderator { border-left-color: #007bff; background: #f8f9fa; }\\n                .system { border-left-color: #6c757d; background: #e9ecef; }\\n                .timestamp { color: #6c757d; font-size: 0.9em; }\\n                .sender { font-weight: bold; }\\n            </style>\\n        </head>\\n        <body>\\n            <h1>AI Jubilee Debate Transcript</h1>\\n        \\\"\\\"\\\"\\n\\n        for msg in messages:\\n            css_class = msg.message_type if msg.message_type != 'chat' else ''\\n            html += f\\\"\\\"\\\"\\n            <div class=\\\"message {css_class}\\\">\\n                <span class=\\\"timestamp\\\">[{msg.formatted_timestamp}]</span>\\n                <span class=\\\"sender\\\">{msg.sender}:</span>\\n                <div>{msg.content}</div>\\n            </div>\\n            \\\"\\\"\\\"\\n\\n        html += \\\"\\\"\\\"\\n        </body>\\n        </html>\\n        \\\"\\\"\\\"\\n\\n        return html\\n\\n    async def load_transcript(self, filename: str) -> None:\\n        \\\"\\\"\\\"\\n        Load transcript from JSON file.\\n\\n        Args:\\n            filename: Input filename\\n        \\\"\\\"\\\"\\n        filepath = Path(filename)\\n\\n        if not filepath.exists():\\n            raise FileNotFoundError(f\\\"Transcript file not found: {filename}\\\")\\n\\n        with open(filepath, 'r', encoding='utf-8') as f:\\n            data = json.load(f)\\n\\n        # Clear current messages\\n        async with self._lock:\\n            self.messages.clear()\\n            self.message_counter = 0\\n\\n            # Load messages\\n            for msg_data in data.get('messages', []):\\n                message = Message.from_dict(msg_data)\\n                self.messages.append(message)\\n                self.message_counter = max(self.message_counter, message.message_id)\\n\\n    def clear(self) -> None:\\n        \\\"\\\"\\\"Clear all messages from the chat log.\\\"\\\"\\\"\\n        self.messages.clear()\\n        self.message_counter = 0\\n        self.stats = {\\n            'total_messages': 0,\\n            'messages_by_sender': {},\\n            'start_time': time.time()\\n        }\\n\\n    def __len__(self) -> int:\\n        \\\"\\\"\\\"Return number of messages in the log.\\\"\\\"\\\"\\n        return len(self.messages)\\n\\n    def __iter__(self):\\n        \\\"\\\"\\\"Iterate over messages.\\\"\\\"\\\"\\n        return iter(self.messages)\\n\\n    def __getitem__(self, index) -> Message:\\n        \\\"\\\"\\\"Get message by index.\\\"\\\"\\\"\\n        return list(self.messages)[index]\"\n        },\n        \"human_client.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/human_client.py\",\n          \"extension\": \".py\",\n          \"size\": 20290,\n          \"content\": \"\\\"\\\"\\\"\\nHuman client implementation for debate participation.\\nNow with true autonomous participation - can speak anytime!\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport time\\nfrom typing import List, Dict, Any, Optional\\nfrom dataclasses import dataclass\\n\\nfrom .chat_log import Message\\n\\n\\n@dataclass\\nclass InterfaceConfig:\\n    \\\"\\\"\\\"Configuration for human interface.\\\"\\\"\\\"\\n    mode: str = \\\"cli\\\"\\n    enable_rich_formatting: bool = True\\n    show_typing_indicators: bool = True\\n    enable_reactions: bool = True\\n    input_timeout: int = 120\\n\\n\\nclass CLIInterface:\\n    \\\"\\\"\\\"Command line interface for human participants.\\\"\\\"\\\"\\n\\n    def __init__(self, config: InterfaceConfig):\\n        self.config = config\\n        self.rich_console = None\\n        self.input_task = None\\n\\n        if config.enable_rich_formatting:\\n            try:\\n                from rich.console import Console\\n                from rich.live import Live\\n                self.rich_console = Console()\\n            except ImportError:\\n                print(\\\"Rich not available, using basic formatting\\\")\\n\\n    async def display_message(self, message: Message):\\n        \\\"\\\"\\\"Display a message to the user.\\\"\\\"\\\"\\n        timestamp = time.strftime(\\\"%H:%M:%S\\\", time.localtime(message.timestamp))\\n\\n        if self.rich_console:\\n            if message.message_type == \\\"moderator\\\":\\n                self.rich_console.print(\\n                    f\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\",\\n                    style=\\\"bold yellow\\\"\\n                )\\n            elif message.sender.endswith('_1') or 'Human' in message.sender:\\n                # Don't display our own messages back to us\\n                return\\n            else:\\n                self.rich_console.print(\\n                    f\\\"[{timestamp}] ü§ñ {message.sender}: {message.content}\\\",\\n                    style=\\\"cyan\\\"\\n                )\\n        else:\\n            if message.message_type == \\\"moderator\\\":\\n                print(f\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\")\\n            elif not (message.sender.endswith('_1') or 'Human' in message.sender):\\n                print(f\\\"[{timestamp}] ü§ñ {message.sender}: {message.content}\\\")\\n\\n    async def get_input(self, prompt: str, timeout: int = 10) -> str:\\n        \\\"\\\"\\\"Get input from user with timeout.\\\"\\\"\\\"\\n        if self.rich_console:\\n            self.rich_console.print(f\\\"üí¨ {prompt}\\\", style=\\\"bold green\\\")\\n        else:\\n            print(f\\\"üí¨ {prompt}\\\")\\n\\n        # Start input task\\n        self.input_task = asyncio.create_task(self._get_user_input())\\n\\n        try:\\n            # Wait for input or timeout\\n            response = await asyncio.wait_for(self.input_task, timeout=timeout)\\n            return response.strip()\\n\\n        except asyncio.TimeoutError:\\n            if self.input_task and not self.input_task.done():\\n                self.input_task.cancel()\\n                try:\\n                    await self.input_task\\n                except asyncio.CancelledError:\\n                    pass\\n            return \\\"\\\"\\n        except asyncio.CancelledError:\\n            if self.input_task and not self.input_task.done():\\n                self.input_task.cancel()\\n            return \\\"\\\"\\n        except Exception as e:\\n            print(f\\\"Input error: {e}\\\")\\n            if self.input_task and not self.input_task.done():\\n                self.input_task.cancel()\\n            return \\\"\\\"\\n\\n    async def _get_user_input(self) -> str:\\n        \\\"\\\"\\\"Get user input asynchronously.\\\"\\\"\\\"\\n        loop = asyncio.get_event_loop()\\n        return await loop.run_in_executor(None, input, \\\"\\\")\\n\\n    async def show_notification(self, message: str, level: str = \\\"info\\\"):\\n        \\\"\\\"\\\"Show a notification to the user.\\\"\\\"\\\"\\n        icons = {\\n            \\\"info\\\": \\\"‚ÑπÔ∏è\\\",\\n            \\\"warning\\\": \\\"‚ö†Ô∏è\\\",\\n            \\\"error\\\": \\\"‚ùå\\\",\\n            \\\"success\\\": \\\"‚úÖ\\\"\\n        }\\n\\n        icon = icons.get(level, \\\"‚ÑπÔ∏è\\\")\\n\\n        if self.rich_console:\\n            colors = {\\n                \\\"info\\\": \\\"blue\\\",\\n                \\\"warning\\\": \\\"yellow\\\",\\n                \\\"error\\\": \\\"red\\\",\\n                \\\"success\\\": \\\"green\\\"\\n            }\\n            color = colors.get(level, \\\"blue\\\")\\n            self.rich_console.print(f\\\"{icon} {message}\\\", style=color)\\n        else:\\n            print(f\\\"{icon} {message}\\\")\\n\\n\\nclass WebInterface:\\n    \\\"\\\"\\\"Web interface for human participants.\\\"\\\"\\\"\\n\\n    def __init__(self, config: InterfaceConfig):\\n        self.config = config\\n        self.websocket = None\\n        self.pending_responses = {}\\n\\n    async def display_message(self, message: Message):\\n        \\\"\\\"\\\"Display message via websocket.\\\"\\\"\\\"\\n        if self.websocket:\\n            await self.websocket.send_json({\\n                \\\"type\\\": \\\"message\\\",\\n                \\\"data\\\": message.to_dict()\\n            })\\n\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\n        \\\"\\\"\\\"Get input via websocket.\\\"\\\"\\\"\\n        if not self.websocket:\\n            return \\\"\\\"\\n\\n        request_id = f\\\"input_{time.time()}\\\"\\n        await self.websocket.send_json({\\n            \\\"type\\\": \\\"input_request\\\",\\n            \\\"id\\\": request_id,\\n            \\\"prompt\\\": prompt,\\n            \\\"timeout\\\": timeout\\n        })\\n\\n        # Wait for response\\n        try:\\n            response = await asyncio.wait_for(\\n                self._wait_for_response(request_id),\\n                timeout=timeout\\n            )\\n            return response\\n        except asyncio.TimeoutError:\\n            return \\\"\\\"\\n\\n    async def _wait_for_response(self, request_id: str) -> str:\\n        \\\"\\\"\\\"Wait for websocket response.\\\"\\\"\\\"\\n        while request_id not in self.pending_responses:\\n            await asyncio.sleep(0.1)\\n        return self.pending_responses.pop(request_id)\\n\\n    async def show_notification(self, message: str, level: str = \\\"info\\\"):\\n        \\\"\\\"\\\"Show notification via websocket.\\\"\\\"\\\"\\n        if self.websocket:\\n            await self.websocket.send_json({\\n                \\\"type\\\": \\\"notification\\\",\\n                \\\"message\\\": message,\\n                \\\"level\\\": level\\n            })\\n\\n\\nclass HumanClient:\\n    \\\"\\\"\\\"\\n    Human participant in the debate system with autonomous participation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, name: str, config: Dict[str, Any]):\\n        self.name = name\\n        self.config = config\\n        self.is_active = True\\n        self.conversation_history: List[Message] = []\\n\\n        # Initialize appropriate interface\\n        interface_config = InterfaceConfig(\\n            mode=config.get('mode', 'cli'),\\n            enable_rich_formatting=config.get('enable_rich_formatting', True),\\n            show_typing_indicators=config.get('show_typing_indicators', True),\\n            enable_reactions=config.get('enable_reactions', True),\\n            input_timeout=config.get('input_timeout', 120)\\n        )\\n\\n        if interface_config.mode == \\\"cli\\\":\\n            self.interface = CLIInterface(interface_config)\\n        elif interface_config.mode == \\\"web\\\":\\n            self.interface = WebInterface(interface_config)\\n        else:\\n            raise ValueError(f\\\"Unsupported interface mode: {interface_config.mode}\\\")\\n\\n        # Statistics tracking\\n        self.stats = {\\n            'responses_given': 0,\\n            'timeouts': 0,\\n            'total_response_time': 0.0,\\n            'average_response_time': 0.0\\n        }\\n\\n    async def autonomous_participation_loop(self, chat_log):\\n        \\\"\\\"\\\"True autonomous participation - human can speak anytime.\\\"\\\"\\\"\\n        if not self.is_active:\\n            return\\n\\n        await self.interface.show_notification(\\n            \\\"üéØ AUTONOMOUS MODE ACTIVE - You can speak ANYTIME!\\\", \\\"success\\\"\\n        )\\n        await self.interface.show_notification(\\n            \\\"üó£Ô∏è  You can speak at ANY TIME during the discussion!\\\", \\\"info\\\"\\n        )\\n        await self.interface.show_notification(\\n            \\\"üí° Commands: 'help', 'status', 'history', 'quit'\\\", \\\"info\\\"\\n        )\\n        await self.interface.show_notification(\\n            \\\"‚úèÔ∏è  Just type your response and press Enter to join the conversation!\\\", \\\"info\\\"\\n        )\\n\\n        # Subscribe to chat updates for display\\n        message_queue = chat_log.subscribe()\\n        last_displayed = len(chat_log.messages)\\n\\n        while self.is_active:\\n            try:\\n                # Check for new messages to display\\n                current_count = len(chat_log.messages)\\n                if current_count > last_displayed:\\n                    new_messages = list(chat_log.messages)[last_displayed:]\\n                    for msg in new_messages:\\n                        if msg.sender != self.name:  # Don't show own messages\\n                            await self.interface.display_message(msg)\\n                    last_displayed = current_count\\n\\n                # Get user input with short timeout for responsiveness\\n                response = await self.interface.get_input(\\n                    \\\"Type your response (or command):\\\",\\n                    timeout=10  # Short timeout for responsiveness\\n                )\\n\\n                if not response:\\n                    continue  # Timeout, check for new messages\\n\\n                response = response.strip()\\n\\n                # Handle commands\\n                if response.lower() in ['quit', 'exit']:\\n                    await self.interface.show_notification(\\n                        \\\"üëã Leaving the debate. Thanks for participating!\\\", \\\"success\\\"\\n                    )\\n                    self.is_active = False\\n                    break\\n                elif response.lower() == 'help':\\n                    await self._show_autonomous_help()\\n                    continue\\n                elif response.lower() == 'status':\\n                    await self._show_status()\\n                    continue\\n                elif response.lower() == 'history':\\n                    await self.interface.show_notification(\\\"üìú Recent conversation:\\\", \\\"info\\\")\\n                    recent = chat_log.get_recent_messages(5)\\n                    for msg in recent:\\n                        await self.interface.display_message(msg)\\n                    continue\\n                elif len(response) < 3:\\n                    await self.interface.show_notification(\\n                        \\\"‚ö†Ô∏è Please provide a more substantial response (at least 3 characters).\\\",\\n                        \\\"warning\\\"\\n                    )\\n                    continue\\n\\n                # Process and post message directly to chat log\\n                validated_response = self._validate_response(response)\\n                if validated_response:\\n                    await chat_log.add_message(self.name, validated_response)\\n                    self.stats['responses_given'] += 1\\n                    await self.interface.show_notification(\\n                        \\\"‚úÖ Your message has been added to the debate!\\\", \\\"success\\\"\\n                    )\\n\\n            except Exception as e:\\n                await self.interface.show_notification(f\\\"‚ùå Error: {e}\\\", \\\"error\\\")\\n                await asyncio.sleep(2)\\n\\n        # Cleanup\\n        chat_log.unsubscribe(message_queue)\\n        await self.interface.show_notification(\\n            \\\"üõë Autonomous participation ended.\\\", \\\"info\\\"\\n        )\\n\\n    async def _show_autonomous_help(self):\\n        \\\"\\\"\\\"Show help information for autonomous mode.\\\"\\\"\\\"\\n        help_text = \\\"\\\"\\\"\\nüéØ AI JUBILEE DEBATE - AUTONOMOUS MODE HELP\\n\\nCOMMANDS:\\n‚Ä¢ Just type your response and press Enter to join the debate\\n‚Ä¢ 'help' - Show this help message\\n‚Ä¢ 'status' - Show your participation statistics  \\n‚Ä¢ 'history' - Show recent conversation messages\\n‚Ä¢ 'quit' - Leave the debate\\n\\nAUTONOMOUS MODE:\\n‚Ä¢ You can speak at ANY TIME during the discussion phase\\n‚Ä¢ Bots and moderator are monitoring and will respond when they feel compelled\\n‚Ä¢ No turn-taking - completely organic conversation flow\\n‚Ä¢ Your responses are immediately added to the debate\\n\\nTIPS:\\n‚Ä¢ Keep responses focused and substantial (3+ characters)\\n‚Ä¢ Reference specific points made by others\\n‚Ä¢ Feel free to jump in whenever you have something to add!\\n‚Ä¢ The debate flows naturally - speak when inspired!\\n\\nDEBATE PHASES:\\n1. Introduction & Opening Statements (structured)\\n2. Autonomous Discussion (free-flowing - you can speak anytime!)\\n3. Closing Statements (structured)  \\n4. Voting Phase\\n\\nEnjoy the organic debate experience! üé≠\\n        \\\"\\\"\\\"\\n\\n        await self.interface.show_notification(help_text, \\\"info\\\")\\n\\n    async def _show_status(self):\\n        \\\"\\\"\\\"Show participation status.\\\"\\\"\\\"\\n        stats = self.get_stats()\\n        await self.interface.show_notification(\\n            f\\\"üìä Your participation: {stats['responses_given']} responses, \\\"\\n            f\\\"{stats['participation_rate']:.1%} participation rate, \\\"\\n            f\\\"avg response time: {stats['average_response_time']:.1f}s\\\",\\n            \\\"info\\\"\\n        )\\n\\n    def _validate_response(self, response: str) -> str:\\n        \\\"\\\"\\\"Validate and clean up human response.\\\"\\\"\\\"\\n        if not response or not response.strip():\\n            return \\\"\\\"\\n\\n        # Clean up the response\\n        response = response.strip()\\n\\n        # Check length limits\\n        max_length = self.config.get('max_message_length', 500)\\n        if len(response) > max_length:\\n            response = response[:max_length - 3] + \\\"...\\\"\\n\\n        # Add note for very short responses\\n        if len(response) < 10:\\n            response += \\\" [Note: Very short response]\\\"\\n\\n        return response\\n\\n    # Legacy methods for structured phases\\n    async def get_response(self, topic: str, messages: List[Message]) -> str:\\n        \\\"\\\"\\\"Get response from human participant (for structured phases).\\\"\\\"\\\"\\n        if not self.is_active:\\n            return \\\"\\\"\\n\\n        start_time = time.time()\\n\\n        try:\\n            # Show context in structured phases\\n            if len(messages) > 0:\\n                await self.interface.show_notification(\\n                    f\\\"üìú Recent messages in conversation:\\\",\\n                    \\\"info\\\"\\n                )\\n                # Show last 3 messages for context\\n                recent = messages[-3:] if len(messages) >= 3 else messages\\n                for msg in recent:\\n                    await self.interface.display_message(msg)\\n                await self.interface.show_notification(\\\"‚îÄ\\\" * 50, \\\"info\\\")\\n\\n            # Get response with timeout\\n            response = await self.interface.get_input(\\n                f\\\"üí¨ Your response to: {topic}\\\",\\n                timeout=self.config.get('input_timeout', 120)\\n            )\\n\\n            # Validate and process response\\n            if response:\\n                validated_response = self._validate_response(response)\\n                if validated_response:\\n                    # Add to conversation history\\n                    response_msg = Message(\\n                        sender=self.name,\\n                        content=validated_response,\\n                        timestamp=time.time(),\\n                        message_id=len(self.conversation_history) + 1\\n                    )\\n                    self.conversation_history.append(response_msg)\\n\\n                    # Update stats\\n                    response_time = time.time() - start_time\\n                    self._update_stats(response_time, success=True)\\n\\n                    return validated_response\\n\\n            # Handle timeout/empty response\\n            response_time = time.time() - start_time\\n            self._update_stats(response_time, success=False)\\n            return \\\"\\\"\\n\\n        except Exception as e:\\n            await self.interface.show_notification(\\n                f\\\"‚ùå Error getting response: {e}\\\",\\n                \\\"error\\\"\\n            )\\n            return \\\"\\\"\\n\\n    async def receive_message(self, message: Message):\\n        \\\"\\\"\\\"Receive and display a message from the debate.\\\"\\\"\\\"\\n        # Don't show our own messages back to us\\n        if message.sender == self.name:\\n            return\\n\\n        # Add to conversation history\\n        self.conversation_history.append(message)\\n\\n        # Limit history size\\n        if len(self.conversation_history) > 30:\\n            self.conversation_history = self.conversation_history[-30:]\\n\\n        # Display the message (in autonomous mode, this is handled by the loop)\\n        try:\\n            if not hasattr(self, '_in_autonomous_mode'):\\n                await self.interface.display_message(message)\\n        except Exception as e:\\n            print(f\\\"Error displaying message: {e}\\\")\\n\\n    async def handle_voting(self, candidates: List[str], time_limit: int) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Handle voting process for human participant.\\\"\\\"\\\"\\n        await self.interface.show_notification(\\n            f\\\"üó≥Ô∏è Voting phase! You have {time_limit} seconds to vote.\\\",\\n            \\\"info\\\"\\n        )\\n\\n        # Show candidates\\n        await self.interface.show_notification(\\n            \\\"üìã Candidates:\\\", \\\"info\\\"\\n        )\\n        for i, candidate in enumerate(candidates, 1):\\n            await self.interface.show_notification(\\n                f\\\"  {i}. {candidate}\\\", \\\"info\\\"\\n            )\\n\\n        try:\\n            # Get vote choice\\n            choice_input = await self.interface.get_input(\\n                f\\\"Enter your choice (1-{len(candidates)}):\\\",\\n                timeout=time_limit\\n            )\\n\\n            if not choice_input:\\n                return {'voted': False, 'reason': 'timeout'}\\n\\n            try:\\n                choice = int(choice_input.strip())\\n                if 1 <= choice <= len(candidates):\\n                    selected_candidate = candidates[choice - 1]\\n\\n                    # Get justification if using CLI\\n                    justification = \\\"\\\"\\n                    if isinstance(self.interface, CLIInterface):\\n                        justification = await self.interface.get_input(\\n                            \\\"Optional: Why did you choose this candidate?\\\",\\n                            timeout=30\\n                        )\\n\\n                    return {\\n                        'voted': True,\\n                        'candidate': selected_candidate,\\n                        'justification': justification or \\\"\\\"\\n                    }\\n                else:\\n                    return {'voted': False, 'reason': 'invalid_choice'}\\n\\n            except ValueError:\\n                return {'voted': False, 'reason': 'invalid_format'}\\n\\n        except Exception as e:\\n            await self.interface.show_notification(\\n                f\\\"‚ùå Voting error: {e}\\\", \\\"error\\\"\\n            )\\n            return {'voted': False, 'reason': 'error'}\\n\\n    def _update_stats(self, response_time: float, success: bool):\\n        \\\"\\\"\\\"Update response statistics.\\\"\\\"\\\"\\n        if success:\\n            self.stats['responses_given'] += 1\\n            self.stats['total_response_time'] += response_time\\n            if self.stats['responses_given'] > 0:\\n                self.stats['average_response_time'] = (\\n                        self.stats['total_response_time'] / self.stats['responses_given']\\n                )\\n        else:\\n            self.stats['timeouts'] += 1\\n\\n    def get_stats(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get comprehensive human client statistics.\\\"\\\"\\\"\\n        total_attempts = self.stats['responses_given'] + self.stats['timeouts']\\n        participation_rate = (\\n            self.stats['responses_given'] / total_attempts\\n            if total_attempts > 0 else 0\\n        )\\n\\n        return {\\n            'name': self.name,\\n            'interface_mode': self.interface.config.mode,\\n            'responses_given': self.stats['responses_given'],\\n            'timeouts': self.stats['timeouts'],\\n            'total_attempts': total_attempts,\\n            'participation_rate': participation_rate,\\n            'average_response_time': self.stats.get('average_response_time', 0),\\n            'is_active': self.is_active,\\n            'conversation_length': len(self.conversation_history)\\n        }\\n\\n    async def set_active(self, active: bool):\\n        \\\"\\\"\\\"Set the active status of the human client.\\\"\\\"\\\"\\n        self.is_active = active\\n        status = \\\"activated\\\" if active else \\\"deactivated\\\"\\n        await self.interface.show_notification(\\n            f\\\"üîÑ {self.name} has been {status}\\\",\\n            \\\"info\\\"\\n        )\\n\\n    def __str__(self) -> str:\\n        return f\\\"Human({self.name}, {self.interface.config.mode}, active={self.is_active})\\\"\\n\\n    def __repr__(self) -> str:\\n        return (f\\\"HumanClient(name='{self.name}', mode='{self.interface.config.mode}', \\\"\\n                f\\\"active={self.is_active}, responses={self.stats['responses_given']})\\\")\\n\\n    @property\\n    def stance(self) -> str:\\n        return \\\"neutral\\\"  # Or dynamically assign based on your use case\\n\"\n        },\n        \"main.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/main.py\",\n          \"extension\": \".py\",\n          \"size\": 4522,\n          \"content\": \"\\\"\\\"\\\"\\nMain entry point for the AI Jubilee Debate System.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport yaml\\nimport click\\nimport os\\nfrom typing import List, Optional\\nfrom pathlib import Path\\nfrom dotenv import load_dotenv\\n\\nfrom .moderator import Moderator\\nfrom .bot_client import BotClient\\nfrom .human_client import HumanClient\\nfrom .chat_log import ChatLog\\nfrom .voting import VotingSystem\\nfrom .streaming import StreamingServer\\nfrom .utils import setup_logging, load_config\\n\\n\\nasync def start_debate_session(\\n    topic: Optional[str] = None,\\n    ai_bots: int = 2,\\n    human_participants: int = 1,\\n    config_path: str = \\\"config.yaml\\\"\\n) -> None:\\n    \\\"\\\"\\\"\\n    Start a debate session with specified participants.\\n\\n    Args:\\n        topic: Debate topic (if None, uses random from config)\\n        ai_bots: Number of AI bot participants\\n        human_participants: Number of human participants\\n        config_path: Path to configuration file\\n    \\\"\\\"\\\"\\n    # Load environment variables from .env file\\n    load_dotenv()\\n\\n    # Load configuration\\n    config = load_config(config_path)\\n\\n    # Setup logging\\n    setup_logging(config.get('chat', {}).get('log_level', 'INFO'))\\n\\n    # Initialize chat log\\n    chat_log = ChatLog()\\n\\n    # Initialize voting system\\n    voting_system = VotingSystem(config.get('voting', {}))\\n\\n    # Select topic\\n    if not topic:\\n        import random\\n        topic = random.choice(config.get('topics', [\\\"AI in society\\\"]))\\n\\n    # Create bot clients\\n    bot_clients = []\\n    bot_configs = config.get('bots', [])[:ai_bots]\\n\\n    for i, bot_config in enumerate(bot_configs):\\n        bot = BotClient(\\n            name=bot_config['name'],\\n            model=bot_config['model'],\\n            provider=bot_config['provider'],\\n            personality=bot_config['personality'],\\n            stance=bot_config['stance'],\\n            api_key=config['api_keys'].get(bot_config['provider'])\\n        )\\n        bot_clients.append(bot)\\n\\n    # Create human clients\\n    human_clients = []\\n    for i in range(human_participants):\\n        human = HumanClient(\\n            name=f\\\"Human_{i+1}\\\",\\n            config=config.get('interface', {})\\n        )\\n        human_clients.append(human)\\n\\n    # Initialize moderator based on debate mode\\n    debate_mode = config.get('debate', {}).get('mode', 'sequential')\\n\\n    moderator = Moderator(\\n        topic=topic,\\n        participants=bot_clients + human_clients,\\n        chat_log=chat_log,\\n        voting_system=voting_system,\\n        config=config\\n    )\\n\\n    if debate_mode == \\\"autonomous\\\":\\n        print(f\\\"ü§ñ Running in AUTONOMOUS mode - bots will decide when to speak!\\\")\\n        print(f\\\"üìù Topic: {topic}\\\")\\n        print(f\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\")\\n        print(f\\\"‚è∞ Discussion time: {config.get('debate', {}).get('time_limit_minutes', 30)} minutes\\\")\\n        print(f\\\"üéØ Bots will monitor conversation and jump in when they feel compelled to respond!\\\")\\n    else:\\n        print(f\\\"üìù Running in SEQUENTIAL mode\\\")\\n        print(f\\\"üë• Participants take turns in order\\\")\\n\\n    # Initialize streaming server if enabled\\n    streaming_server = None\\n    if config.get('streaming', {}).get('enabled', False):\\n        streaming_server = StreamingServer(\\n            chat_log=chat_log,\\n            voting_system=voting_system,\\n            config=config.get('streaming', {})\\n        )\\n        await streaming_server.start()\\n\\n    try:\\n        # Start the debate\\n        print(f\\\"\\\\nüé≠ Starting AI Jubilee Debate: {topic}\\\")\\n        print(f\\\"Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\n\\\")\\n\\n        await moderator.run_debate()\\n\\n    except KeyboardInterrupt:\\n        print(\\\"\\\\n‚èπÔ∏è  Debate interrupted by user\\\")\\n    except Exception as e:\\n        print(f\\\"\\\\n‚ùå Error during debate: {e}\\\")\\n    finally:\\n        # Cleanup\\n        if streaming_server:\\n            await streaming_server.stop()\\n\\n        # Save transcript\\n        if config.get('chat', {}).get('save_transcripts', True):\\n            await chat_log.save_transcript(f\\\"debate_{topic[:20]}.json\\\")\\n\\n\\n@click.command()\\n@click.option('--topic', '-t', help='Debate topic')\\n@click.option('--bots', '-b', default=2, help='Number of AI bots')\\n@click.option('--humans', '-h', default=1, help='Number of human participants')\\n@click.option('--config', '-c', default='config.yaml', help='Configuration file path')\\ndef cli(topic: str, bots: int, humans: int, config: str):\\n    \\\"\\\"\\\"Launch the AI Jubilee Debate System.\\\"\\\"\\\"\\n    asyncio.run(start_debate_session(topic, bots, humans, config))\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    cli()\"\n        },\n        \"moderator.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/moderator.py\",\n          \"extension\": \".py\",\n          \"size\": 21382,\n          \"content\": \"\\\"\\\"\\\"\\nModerator class for managing debate flow, rules, and coordination.\\nNow acts as an AI-powered facilitator using the same system as other bots.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport time\\nimport random\\nfrom typing import List, Dict, Any, Optional\\nfrom enum import Enum\\nfrom dataclasses import dataclass\\n\\nfrom .chat_log import ChatLog, Message\\nfrom .voting import VotingSystem\\nfrom .utils import format_time_remaining\\nfrom .bot_client import BotClient\\nfrom app.bot_client import BotConfig\\n\\n\\nclass DebatePhase(Enum):\\n    INTRODUCTION = \\\"introduction\\\"\\n    OPENING_STATEMENTS = \\\"opening_statements\\\"\\n    DISCUSSION = \\\"discussion\\\"\\n    CLOSING_STATEMENTS = \\\"closing_statements\\\"\\n    VOTING = \\\"voting\\\"\\n    RESULTS = \\\"results\\\"\\n    FINISHED = \\\"finished\\\"\\n\\n\\n@dataclass\\nclass DebateState:\\n    phase: DebatePhase\\n    current_speaker: Optional[str] = None\\n    time_remaining: int = 0\\n    turn_order: List[str] = None\\n    warnings_issued: Dict[str, int] = None\\n\\n    def __post_init__(self):\\n        if self.turn_order is None:\\n            self.turn_order = []\\n        if self.warnings_issued is None:\\n            self.warnings_issued = {}\\n\\n\\nclass Moderator:\\n    \\\"\\\"\\\"\\n    AI-powered moderator that manages debate flow and provides intelligent facilitation.\\n    Works just like other bots but with moderator-specific prompts.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, topic: str, participants: List, chat_log: ChatLog,\\n                 voting_system: VotingSystem, config: Dict[str, Any]):\\n        self.topic = topic\\n        self.participants = {p.name: p for p in participants}\\n        self.chat_log = chat_log\\n        self.voting_system = voting_system\\n        self.config = config\\n\\n        # Initialize moderator as a bot client\\n        moderator_config = config.get('moderator', {})\\n\\n        print(config)\\n        self.moderator_bot = BotClient(\\n            name=moderator_config.get('name', 'Moderator'),\\n            model=moderator_config.get('model', 'gpt-3.5-turbo'),\\n            provider=moderator_config.get('provider', 'openai'),\\n            personality=moderator_config.get('personality', 'Professional debate facilitator'),\\n            stance=moderator_config.get('stance', 'neutral'),\\n            api_key=config['api_keys'].get(moderator_config.get('provider', 'openai'))\\n        )\\n\\n        self.state = DebateState(\\n            phase=DebatePhase.INTRODUCTION,\\n            turn_order=list(self.participants.keys())\\n        )\\n\\n        self.phase_times = {\\n            DebatePhase.OPENING_STATEMENTS: config.get('opening_statement_time', 120),\\n            DebatePhase.DISCUSSION: config.get('time_limit_minutes', 30) * 60,\\n            DebatePhase.CLOSING_STATEMENTS: config.get('closing_statement_time', 90),\\n            DebatePhase.VOTING: config.get('voting_duration', 300)\\n        }\\n\\n        self.max_response_time = config.get('max_response_time', 120)\\n        self.warning_time = config.get('warning_time', 90)\\n\\n        # Autonomous mode settings\\n        self.autonomous_mode = config.get('mode', 'autonomous') == 'autonomous'\\n        self.autonomous_tasks: List[asyncio.Task] = []\\n        self.phase_task: Optional[asyncio.Task] = None\\n\\n        # Facilitation settings\\n        self.silence_timeout = config.get('silence_timeout', 60)\\n        self.last_activity_time = time.time()\\n        self.last_moderator_prompt = 0\\n\\n    async def run_debate(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Run the complete debate session with autonomous support.\\\"\\\"\\\"\\n        results = {}\\n\\n        try:\\n            await self._introduction_phase()\\n            await self._opening_statements_phase()\\n\\n            if self.autonomous_mode:\\n                await self._autonomous_discussion_phase()\\n            else:\\n                await self._traditional_discussion_phase()\\n\\n            await self._closing_statements_phase()\\n            results = await self._voting_phase()\\n            await self._results_phase(results)\\n\\n        except Exception as e:\\n            await self._broadcast_message(\\n                f\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\",\\n                \\\"moderator\\\"\\n            )\\n            raise\\n        finally:\\n            if self.autonomous_mode:\\n                await self._cleanup_autonomous_tasks()\\n            self.state.phase = DebatePhase.FINISHED\\n\\n        return results\\n\\n    async def _autonomous_discussion_phase(self):\\n        \\\"\\\"\\\"Autonomous discussion where bots and humans self-manage participation.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.DISCUSSION\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\n\\n        await self._broadcast_message(\\n            f\\\"üöÄ AUTONOMOUS DISCUSSION PHASE BEGIN! ü§ñ\\\\n\\\\n\\\"\\n            f\\\"üéØ How this works:\\\\n\\\"\\n            f\\\"   ‚Ä¢ Bots are now monitoring the conversation continuously\\\\n\\\"\\n            f\\\"   ‚Ä¢ They will decide when they feel compelled to respond\\\\n\\\"\\n            f\\\"   ‚Ä¢ Humans can type messages at ANY TIME to join in\\\\n\\\"\\n            f\\\"   ‚Ä¢ No turn-taking - completely organic conversation flow!\\\\n\\\"\\n            f\\\"   ‚Ä¢ Everyone has access to full conversation history\\\\n\\\\n\\\"\\n            f\\\"‚è∞ Discussion time: {total_time // 60} minutes\\\\n\\\"\\n            f\\\"üé≠ Let the autonomous debate begin!\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n        self.last_activity_time = time.time()\\n        start_time = time.time()\\n\\n        # Start bot autonomous monitoring\\n        await self._start_bot_autonomous_monitoring()\\n\\n        # Start human autonomous participation\\n        await self._start_human_autonomous_participation()\\n\\n        # Start moderator autonomous monitoring\\n        await self._start_moderator_autonomous_monitoring()\\n\\n        # Start phase management (facilitation only)\\n        self.phase_task = asyncio.create_task(\\n            self._facilitate_autonomous_discussion(start_time, total_time)\\n        )\\n\\n        try:\\n            await self.phase_task\\n        except asyncio.CancelledError:\\n            pass\\n\\n        await self._broadcast_message(\\n            \\\"‚èπÔ∏è Autonomous discussion phase complete! üéâ\\\\n\\\"\\n            \\\"Moving to closing statements...\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n    async def _start_bot_autonomous_monitoring(self):\\n        \\\"\\\"\\\"Start autonomous monitoring for all bots.\\\"\\\"\\\"\\n        for participant_name, participant in self.participants.items():\\n            if hasattr(participant, 'start_autonomous_monitoring'):  # It's a bot\\n                task = asyncio.create_task(\\n                    participant.start_autonomous_monitoring(self.chat_log, self.topic)\\n                )\\n                self.autonomous_tasks.append(task)\\n\\n    async def _start_human_autonomous_participation(self):\\n        \\\"\\\"\\\"Start autonomous participation for humans.\\\"\\\"\\\"\\n        for participant_name, participant in self.participants.items():\\n            if hasattr(participant, 'autonomous_participation_loop'):  # It's a human\\n                task = asyncio.create_task(\\n                    participant.autonomous_participation_loop(self.chat_log)\\n                )\\n                self.autonomous_tasks.append(task)\\n\\n    async def _start_moderator_autonomous_monitoring(self):\\n        \\\"\\\"\\\"Start moderator autonomous monitoring just like other bots.\\\"\\\"\\\"\\n        task = asyncio.create_task(\\n            self.moderator_bot.start_autonomous_monitoring(self.chat_log, self.topic)\\n        )\\n        self.autonomous_tasks.append(task)\\n\\n    async def _facilitate_autonomous_discussion(self, start_time: float, total_time: int):\\n        \\\"\\\"\\\"Facilitate the autonomous discussion without controlling it.\\\"\\\"\\\"\\n        last_message_count = len(self.chat_log.messages)\\n\\n        while time.time() - start_time < total_time:\\n            await asyncio.sleep(15)  # Check every 15 seconds\\n\\n            current_time = time.time()\\n            elapsed = current_time - start_time\\n            remaining = total_time - elapsed\\n\\n            # Check for new activity\\n            current_message_count = len(self.chat_log.messages)\\n            if current_message_count > last_message_count:\\n                self.last_activity_time = current_time\\n                last_message_count = current_message_count\\n\\n            # Check for prolonged silence - provide simple prompts\\n            silence_duration = current_time - self.last_activity_time\\n            if silence_duration > self.silence_timeout:\\n                # Simple fallback prompts if moderator bot hasn't spoken\\n                if current_time - self.last_moderator_prompt > 45:\\n                    await self._provide_simple_prompt()\\n                    self.last_moderator_prompt = current_time\\n\\n            # Provide time updates\\n            await self._provide_time_updates(remaining)\\n\\n    async def _provide_simple_prompt(self):\\n        \\\"\\\"\\\"Provide simple facilitation prompts as fallback.\\\"\\\"\\\"\\n        simple_prompts = [\\n            \\\"üéØ What are your thoughts on the discussion so far?\\\",\\n            \\\"üí° Any other perspectives to consider?\\\",\\n            \\\"ü§î Does anyone have questions about the points raised?\\\",\\n            \\\"‚öñÔ∏è How do you weigh the different arguments presented?\\\"\\n        ]\\n\\n        prompt = random.choice(simple_prompts)\\n        await self._broadcast_message(prompt, \\\"moderator\\\")\\n\\n    async def _provide_time_updates(self, remaining: float):\\n        \\\"\\\"\\\"Provide time updates to participants.\\\"\\\"\\\"\\n        if 299 < remaining <= 301:  # 5 minutes warning\\n            await self._broadcast_message(\\n                \\\"‚è∞ 5 minutes remaining in autonomous discussion phase\\\",\\n                \\\"moderator\\\"\\n            )\\n        elif 119 < remaining <= 121:  # 2 minutes warning\\n            await self._broadcast_message(\\n                \\\"‚è∞ 2 minutes left! Perfect time for final thoughts on this topic\\\",\\n                \\\"moderator\\\"\\n            )\\n        elif 59 < remaining <= 61:  # 1 minute warning\\n            await self._broadcast_message(\\n                \\\"‚è∞ Final minute! Any last contributions to the discussion?\\\",\\n                \\\"moderator\\\"\\n            )\\n\\n    async def _cleanup_autonomous_tasks(self):\\n        \\\"\\\"\\\"Clean up all autonomous tasks.\\\"\\\"\\\"\\n        # Stop bot monitoring (including moderator bot)\\n        for participant in self.participants.values():\\n            if hasattr(participant, 'stop_monitoring'):\\n                await participant.stop_monitoring()\\n\\n        # Stop moderator bot monitoring\\n        await self.moderator_bot.stop_monitoring()\\n\\n        # Cancel all autonomous tasks\\n        for task in self.autonomous_tasks:\\n            if not task.done():\\n                task.cancel()\\n                try:\\n                    await task\\n                except asyncio.CancelledError:\\n                    pass\\n\\n        # Cancel phase management task\\n        if self.phase_task and not self.phase_task.done():\\n            self.phase_task.cancel()\\n            try:\\n                await self.phase_task\\n            except asyncio.CancelledError:\\n                pass\\n\\n        self.autonomous_tasks.clear()\\n\\n    # Traditional phases (structured)\\n    async def _introduction_phase(self):\\n        \\\"\\\"\\\"Introduce the debate topic and participants.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.INTRODUCTION\\n\\n        participants_by_type = {\\\"Bots\\\": [], \\\"Humans\\\": []}\\n        for name, participant in self.participants.items():\\n            if isinstance(participant.config, BotConfig):  # Bot\\n                stance = participant.config.stance\\n                participants_by_type[\\\"Bots\\\"].append(f\\\"{name} ({stance})\\\")\\n            else:  # Human or others\\n                participants_by_type[\\\"Humans\\\"].append(name)\\n\\n        intro_message = (\\n            f\\\"üé≠ Welcome to AI Jubilee Debate! üé≠\\\\n\\\\n\\\"\\n            f\\\"üìù Topic: {self.topic}\\\\n\\\\n\\\"\\n            f\\\"üë• Participants:\\\\n\\\"\\n            f\\\"   ü§ñ AI Bots: {', '.join(participants_by_type['Bots'])}\\\\n\\\"\\n            f\\\"   üë§ Humans: {', '.join(participants_by_type['Humans'])}\\\\n\\\\n\\\"\\n            f\\\"‚è±Ô∏è Total discussion time: {self.config.get('time_limit_minutes', 30)} minutes\\\\n\\\"\\n            f\\\"üéØ Mode: {'Autonomous (organic flow)' if self.autonomous_mode else 'Sequential (turn-based)'}\\\"\\n        )\\n\\n        await self._broadcast_message(intro_message, \\\"moderator\\\")\\n        await asyncio.sleep(3)\\n\\n    async def _opening_statements_phase(self):\\n        \\\"\\\"\\\"Handle opening statements from each participant.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.OPENING_STATEMENTS\\n        statement_time = self.phase_times[DebatePhase.OPENING_STATEMENTS]\\n\\n        await self._broadcast_message(\\n            f\\\"üé§ Opening Statements Phase\\\\n\\\"\\n            f\\\"Each participant has {statement_time} seconds for their opening statement.\\\\n\\\"\\n            f\\\"This phase uses structured turns regardless of debate mode.\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n        for participant_name in self.state.turn_order:\\n            await self._give_structured_turn(participant_name, statement_time, \\\"opening statement\\\")\\n\\n    async def _traditional_discussion_phase(self):\\n        \\\"\\\"\\\"Traditional sequential discussion phase.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.DISCUSSION\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\n\\n        await self._broadcast_message(\\n            f\\\"üí¨ Sequential Discussion Phase\\\\n\\\"\\n            f\\\"Participants take turns for {total_time // 60} minutes.\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n        start_time = time.time()\\n        response_time = self.config.get('response_time', 60)\\n\\n        while time.time() - start_time < total_time:\\n            for participant_name in self.state.turn_order:\\n                if time.time() - start_time >= total_time:\\n                    break\\n\\n                remaining = total_time - (time.time() - start_time)\\n                if remaining < response_time:\\n                    response_time = int(remaining)\\n\\n                await self._give_structured_turn(participant_name, response_time, \\\"response\\\")\\n\\n        await self._broadcast_message(\\\"‚èπÔ∏è Sequential discussion phase complete!\\\", \\\"moderator\\\")\\n\\n    async def _closing_statements_phase(self):\\n        \\\"\\\"\\\"Handle closing statements.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.CLOSING_STATEMENTS\\n        statement_time = self.phase_times[DebatePhase.CLOSING_STATEMENTS]\\n\\n        await self._broadcast_message(\\n            f\\\"üèÅ Closing Statements Phase\\\\n\\\"\\n            f\\\"Each participant has {statement_time} seconds for final remarks.\\\\n\\\"\\n            f\\\"This phase uses structured turns regardless of debate mode.\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n        # Reverse order for closing statements\\n        for participant_name in reversed(self.state.turn_order):\\n            await self._give_structured_turn(participant_name, statement_time, \\\"closing statement\\\")\\n\\n    async def _give_structured_turn(self, participant_name: str, time_limit: int, turn_type: str):\\n        \\\"\\\"\\\"Give structured speaking turn to a participant.\\\"\\\"\\\"\\n        self.state.current_speaker = participant_name\\n        self.state.time_remaining = time_limit\\n\\n        participant = self.participants[participant_name]\\n\\n        await self._broadcast_message(\\n            f\\\"üé§ {participant_name}'s turn for {turn_type} ({time_limit}s)\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n        try:\\n            response_task = asyncio.create_task(\\n                participant.get_response(self.topic, self.chat_log.get_recent_messages())\\n            )\\n\\n            # Start timer\\n            start_time = time.time()\\n            warning_sent = False\\n\\n            while not response_task.done():\\n                elapsed = time.time() - start_time\\n                remaining = time_limit - elapsed\\n\\n                if remaining <= 0:\\n                    response_task.cancel()\\n                    try:\\n                        await response_task\\n                    except asyncio.CancelledError:\\n                        pass\\n                    await self._handle_timeout(participant_name)\\n                    break\\n\\n                if not warning_sent and remaining <= self.warning_time:\\n                    await self._send_warning(participant_name, remaining)\\n                    warning_sent = True\\n\\n                await asyncio.sleep(0.5)\\n\\n            # Process response if completed successfully\\n            if response_task.done() and not response_task.cancelled():\\n                try:\\n                    response = await response_task\\n                    if response:\\n                        await self._process_response(participant_name, response)\\n                except Exception as e:\\n                    await self._broadcast_message(\\n                        f\\\"‚ö†Ô∏è Error getting response from {participant_name}: {e}\\\",\\n                        \\\"moderator\\\"\\n                    )\\n\\n        except Exception as e:\\n            await self._broadcast_message(\\n                f\\\"‚ö†Ô∏è Error during {participant_name}'s turn: {e}\\\",\\n                \\\"moderator\\\"\\n            )\\n        finally:\\n            self.state.current_speaker = None\\n\\n    async def _voting_phase(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Conduct voting on debate performance.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.VOTING\\n\\n        if not self.voting_system.enabled:\\n            await self._broadcast_message(\\\"Voting disabled. Debate complete!\\\", \\\"moderator\\\")\\n            return {}\\n\\n        await self._broadcast_message(\\n            f\\\"üó≥Ô∏è Voting Phase\\\\n\\\"\\n            f\\\"Vote for the most persuasive participant. \\\"\\n            f\\\"Voting closes in {self.phase_times[DebatePhase.VOTING]} seconds.\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n        await self.voting_system.start_voting(\\n            list(self.participants.keys()),\\n            self.phase_times[DebatePhase.VOTING]\\n        )\\n\\n        await asyncio.sleep(self.phase_times[DebatePhase.VOTING])\\n\\n        results = await self.voting_system.end_voting()\\n        return results\\n\\n    async def _results_phase(self, voting_results: Dict[str, Any]):\\n        \\\"\\\"\\\"Announce final results.\\\"\\\"\\\"\\n        self.state.phase = DebatePhase.RESULTS\\n\\n        if voting_results:\\n            winner = voting_results.get('winner')\\n            vote_counts = voting_results.get('vote_counts', {})\\n\\n            results_msg = \\\"üèÜ DEBATE RESULTS üèÜ\\\\n\\\"\\n            results_msg += f\\\"Winner: {winner}\\\\n\\\\n\\\"\\n            results_msg += \\\"Vote Breakdown:\\\\n\\\"\\n\\n            for participant, votes in sorted(vote_counts.items(),\\n                                           key=lambda x: x[1], reverse=True):\\n                results_msg += f\\\"  {participant}: {votes} votes\\\\n\\\"\\n        else:\\n            results_msg = \\\"ü§ù Debate concluded without voting. Great discussion everyone!\\\"\\n\\n        await self._broadcast_message(results_msg, \\\"moderator\\\")\\n\\n        # Show participation statistics\\n        stats_msg = \\\"\\\\nüìä PARTICIPATION STATISTICS:\\\\n\\\"\\n        for participant_name, participant in self.participants.items():\\n            if hasattr(participant, 'get_stats'):\\n                stats = participant.get_stats()\\n                if hasattr(participant, 'config'):  # Bot\\n                    stats_msg += f\\\"ü§ñ {participant_name}: {stats.get('autonomous_responses', 0)} autonomous responses, \\\"\\n                    stats_msg += f\\\"{stats.get('success_rate', 0):.1%} success rate\\\\n\\\"\\n                else:  # Human\\n                    stats_msg += f\\\"üë§ {participant_name}: {stats.get('responses_given', 0)} responses, \\\"\\n                    stats_msg += f\\\"{stats.get('participation_rate', 0):.1%} participation rate\\\\n\\\"\\n\\n        # Show moderator stats\\n        moderator_stats = self.moderator_bot.get_stats()\\n        stats_msg += f\\\"üé≠ Moderator: {moderator_stats.get('autonomous_responses', 0)} facilitation prompts\\\\n\\\"\\n\\n        await self._broadcast_message(stats_msg, \\\"moderator\\\")\\n        await self._broadcast_message(\\\"Thank you for participating in AI Jubilee Debate! üé≠‚ú®\\\", \\\"moderator\\\")\\n\\n    # Utility methods\\n    async def _process_response(self, participant_name: str, response: str):\\n        \\\"\\\"\\\"Process and validate participant response.\\\"\\\"\\\"\\n        if len(response) > self.config.get('max_message_length', 5000):\\n            response = response[:self.config.get('max_message_length', 5000)] + \\\"...\\\"\\n            await self._broadcast_message(\\n                f\\\"‚ö†Ô∏è {participant_name}'s response was truncated due to length\\\",\\n                \\\"moderator\\\"\\n            )\\n\\n        await self.chat_log.add_message(participant_name, response)\\n\\n    async def _handle_timeout(self, participant_name: str):\\n        \\\"\\\"\\\"Handle participant timeout.\\\"\\\"\\\"\\n        self.state.warnings_issued[participant_name] = (\\n            self.state.warnings_issued.get(participant_name, 0) + 1\\n        )\\n\\n        await self._broadcast_message(\\n            f\\\"‚è∞ {participant_name} exceeded time limit. \\\"\\n            f\\\"Warning {self.state.warnings_issued[participant_name]}/3\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n    async def _send_warning(self, participant_name: str, time_remaining: float):\\n        \\\"\\\"\\\"Send time warning to participant.\\\"\\\"\\\"\\n        await self._broadcast_message(\\n            f\\\"‚è∞ {participant_name}: {int(time_remaining)} seconds remaining\\\",\\n            \\\"moderator\\\"\\n        )\\n\\n    async def _broadcast_message(self, content: str, sender: str = \\\"moderator\\\"):\\n        \\\"\\\"\\\"Broadcast message to all participants and log.\\\"\\\"\\\"\\n        message = await self.chat_log.add_message(sender, content, message_type=\\\"moderator\\\")\\n\\n        # Send to all participants\\n        for participant in self.participants.values():\\n            try:\\n                await participant.receive_message(message)\\n            except Exception as e:\\n                print(f\\\"Failed to send message to {participant.name}: {e}\\\")\\n\\n    def get_state(self) -> DebateState:\\n        \\\"\\\"\\\"Get current debate state.\\\"\\\"\\\"\\n        return self.state\"\n        },\n        \"streaming.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/streaming.py\",\n          \"extension\": \".py\",\n          \"size\": 15845,\n          \"content\": \"\\\"\\\"\\\"\\nLive streaming and WebSocket server for real-time debate broadcasting.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport json\\nimport time\\nimport logging\\nfrom typing import Dict, List, Set, Any, Optional\\nfrom dataclasses import dataclass, asdict\\nimport websockets\\nfrom websockets.server import WebSocketServerProtocol\\n\\nfrom .chat_log import ChatLog, Message\\nfrom .voting import VotingSystem\\nfrom .utils import format_time_remaining\\n\\n\\n@dataclass\\nclass StreamingClient:\\n    \\\"\\\"\\\"Information about a connected streaming client.\\\"\\\"\\\"\\n    websocket: WebSocketServerProtocol\\n    client_id: str\\n    connected_at: float\\n    client_type: str = \\\"viewer\\\"  # viewer, participant, moderator\\n    metadata: Dict[str, Any] = None\\n\\n    def __post_init__(self):\\n        if self.metadata is None:\\n            self.metadata = {}\\n\\n\\nclass StreamingServer:\\n    \\\"\\\"\\\"\\n    WebSocket server for live streaming debate sessions.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, chat_log: ChatLog, voting_system: VotingSystem,\\n                 config: Dict[str, Any]):\\n        self.chat_log = chat_log\\n        self.voting_system = voting_system\\n        self.config = config\\n\\n        self.host = config.get('host', 'localhost')\\n        self.port = config.get('websocket_port', 8080)\\n        self.max_connections = config.get('max_connections', 100)\\n        self.broadcast_votes = config.get('broadcast_votes', True)\\n\\n        # Server state\\n        self.server = None\\n        self.clients: Dict[str, StreamingClient] = {}\\n        self.is_running = False\\n\\n        # Message subscription\\n        self.message_queue = None\\n        self.broadcast_task = None\\n\\n        # Statistics\\n        self.stats = {\\n            'total_connections': 0,\\n            'messages_sent': 0,\\n            'votes_broadcast': 0,\\n            'start_time': time.time()\\n        }\\n\\n        self.logger = logging.getLogger(__name__)\\n\\n    async def start(self) -> None:\\n        \\\"\\\"\\\"Start the streaming server.\\\"\\\"\\\"\\n        if self.is_running:\\n            return\\n\\n        try:\\n            # Subscribe to chat log messages\\n            self.message_queue = self.chat_log.subscribe()\\n\\n            # Start WebSocket server\\n            self.server = await websockets.serve(\\n                self._handle_client,\\n                self.host,\\n                self.port,\\n                max_size=1024 * 1024,  # 1MB max message size\\n                ping_interval=20,\\n                ping_timeout=10\\n            )\\n\\n            # Start broadcast task\\n            self.broadcast_task = asyncio.create_task(self._broadcast_loop())\\n\\n            self.is_running = True\\n            self.logger.info(f\\\"Streaming server started on {self.host}:{self.port}\\\")\\n\\n        except Exception as e:\\n            self.logger.error(f\\\"Failed to start streaming server: {e}\\\")\\n            raise\\n\\n    async def stop(self) -> None:\\n        \\\"\\\"\\\"Stop the streaming server.\\\"\\\"\\\"\\n        if not self.is_running:\\n            return\\n\\n        self.is_running = False\\n\\n        # Stop broadcast task\\n        if self.broadcast_task:\\n            self.broadcast_task.cancel()\\n            try:\\n                await self.broadcast_task\\n            except asyncio.CancelledError:\\n                pass\\n\\n        # Close all client connections\\n        if self.clients:\\n            await asyncio.gather(\\n                *[client.websocket.close() for client in self.clients.values()],\\n                return_exceptions=True\\n            )\\n\\n        # Stop WebSocket server\\n        if self.server:\\n            self.server.close()\\n            await self.server.wait_closed()\\n\\n        # Unsubscribe from chat log\\n        if self.message_queue:\\n            self.chat_log.unsubscribe(self.message_queue)\\n\\n        self.logger.info(\\\"Streaming server stopped\\\")\\n\\n    async def _handle_client(self, websocket: WebSocketServerProtocol, path: str):\\n        \\\"\\\"\\\"Handle new client connection.\\\"\\\"\\\"\\n        if len(self.clients) >= self.max_connections:\\n            await websocket.close(code=1013, reason=\\\"Server full\\\")\\n            return\\n\\n        client_id = f\\\"client_{int(time.time() * 1000)}\\\"\\n        client = StreamingClient(\\n            websocket=websocket,\\n            client_id=client_id,\\n            connected_at=time.time()\\n        )\\n\\n        self.clients[client_id] = client\\n        self.stats['total_connections'] += 1\\n\\n        self.logger.info(f\\\"Client {client_id} connected from {websocket.remote_address}\\\")\\n\\n        try:\\n            # Send welcome message\\n            await self._send_to_client(client, {\\n                'type': 'welcome',\\n                'client_id': client_id,\\n                'server_info': {\\n                    'version': '1.0.0',\\n                    'features': ['chat', 'voting', 'real_time']\\n                }\\n            })\\n\\n            # Send recent messages\\n            recent_messages = self.chat_log.get_recent_messages(10)\\n            for msg in recent_messages:\\n                await self._send_to_client(client, {\\n                    'type': 'message',\\n                    'data': msg.to_dict()\\n                })\\n\\n            # Handle client messages\\n            async for message in websocket:\\n                try:\\n                    await self._process_client_message(client, json.loads(message))\\n                except json.JSONDecodeError:\\n                    await self._send_error(client, \\\"Invalid JSON message\\\")\\n                except Exception as e:\\n                    self.logger.error(f\\\"Error processing client message: {e}\\\")\\n                    await self._send_error(client, \\\"Internal server error\\\")\\n\\n        except websockets.exceptions.ConnectionClosed:\\n            self.logger.info(f\\\"Client {client_id} disconnected\\\")\\n        except Exception as e:\\n            self.logger.error(f\\\"Client {client_id} error: {e}\\\")\\n        finally:\\n            # Clean up client\\n            if client_id in self.clients:\\n                del self.clients[client_id]\\n\\n    async def _process_client_message(self, client: StreamingClient, data: Dict[str, Any]):\\n        \\\"\\\"\\\"Process message from client.\\\"\\\"\\\"\\n        message_type = data.get('type')\\n\\n        if message_type == 'ping':\\n            await self._send_to_client(client, {'type': 'pong'})\\n\\n        elif message_type == 'subscribe':\\n            # Update client subscription preferences\\n            client.metadata['subscriptions'] = data.get('channels', [])\\n            await self._send_to_client(client, {\\n                'type': 'subscribed',\\n                'channels': client.metadata.get('subscriptions', [])\\n            })\\n\\n        elif message_type == 'get_stats':\\n            # Send server statistics\\n            await self._send_to_client(client, {\\n                'type': 'stats',\\n                'data': self._get_server_stats()\\n            })\\n\\n        elif message_type == 'vote' and self.voting_system.is_active:\\n            # Handle vote from client\\n            voter_id = data.get('voter_id', client.client_id)\\n            candidate = data.get('candidate')\\n            justification = data.get('justification')\\n\\n            try:\\n                success = await self.voting_system.cast_vote(\\n                    voter_id, candidate, justification\\n                )\\n\\n                await self._send_to_client(client, {\\n                    'type': 'vote_result',\\n                    'success': success,\\n                    'candidate': candidate\\n                })\\n\\n                if success and self.broadcast_votes:\\n                    await self._broadcast_vote_update()\\n\\n            except Exception as e:\\n                await self._send_error(client, f\\\"Vote failed: {e}\\\")\\n\\n        else:\\n            await self._send_error(client, f\\\"Unknown message type: {message_type}\\\")\\n\\n    async def _broadcast_loop(self):\\n        \\\"\\\"\\\"Main broadcast loop for new messages.\\\"\\\"\\\"\\n        try:\\n            while self.is_running:\\n                try:\\n                    # Wait for new message from chat log\\n                    message = await asyncio.wait_for(\\n                        self.message_queue.get(),\\n                        timeout=1.0\\n                    )\\n\\n                    # Broadcast to all clients\\n                    await self._broadcast_message(message)\\n\\n                except asyncio.TimeoutError:\\n                    # Timeout is expected, continue loop\\n                    continue\\n                except Exception as e:\\n                    self.logger.error(f\\\"Broadcast loop error: {e}\\\")\\n                    await asyncio.sleep(1)\\n\\n        except asyncio.CancelledError:\\n            self.logger.info(\\\"Broadcast loop cancelled\\\")\\n\\n    async def _broadcast_message(self, message: Message):\\n        \\\"\\\"\\\"Broadcast message to all connected clients.\\\"\\\"\\\"\\n        if not self.clients:\\n            return\\n\\n        broadcast_data = {\\n            'type': 'message',\\n            'data': message.to_dict()\\n        }\\n\\n        # Send to all clients\\n        tasks = []\\n        for client in list(self.clients.values()):\\n            if self._should_send_to_client(client, message):\\n                tasks.append(self._send_to_client(client, broadcast_data))\\n\\n        if tasks:\\n            await asyncio.gather(*tasks, return_exceptions=True)\\n            self.stats['messages_sent'] += len(tasks)\\n\\n    def _should_send_to_client(self, client: StreamingClient, message: Message) -> bool:\\n        \\\"\\\"\\\"Determine if message should be sent to client.\\\"\\\"\\\"\\n        # Check client subscriptions\\n        subscriptions = client.metadata.get('subscriptions', [])\\n\\n        if subscriptions:\\n            # If client has specific subscriptions, check them\\n            if message.message_type not in subscriptions:\\n                return False\\n\\n        return True\\n\\n    async def _broadcast_vote_update(self):\\n        \\\"\\\"\\\"Broadcast voting update to clients.\\\"\\\"\\\"\\n        if not self.voting_system.is_active:\\n            return\\n\\n        vote_summary = self.voting_system.get_vote_summary()\\n\\n        broadcast_data = {\\n            'type': 'vote_update',\\n            'data': vote_summary\\n        }\\n\\n        tasks = []\\n        for client in list(self.clients.values()):\\n            tasks.append(self._send_to_client(client, broadcast_data))\\n\\n        if tasks:\\n            await asyncio.gather(*tasks, return_exceptions=True)\\n            self.stats['votes_broadcast'] += 1\\n\\n    async def _send_to_client(self, client: StreamingClient, data: Dict[str, Any]):\\n        \\\"\\\"\\\"Send data to specific client.\\\"\\\"\\\"\\n        try:\\n            await client.websocket.send(json.dumps(data))\\n        except websockets.exceptions.ConnectionClosed:\\n            # Client disconnected, will be cleaned up\\n            pass\\n        except Exception as e:\\n            self.logger.error(f\\\"Failed to send to client {client.client_id}: {e}\\\")\\n\\n    async def _send_error(self, client: StreamingClient, error_message: str):\\n        \\\"\\\"\\\"Send error message to client.\\\"\\\"\\\"\\n        await self._send_to_client(client, {\\n            'type': 'error',\\n            'message': error_message\\n        })\\n\\n    def _get_server_stats(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get server statistics.\\\"\\\"\\\"\\n        uptime = time.time() - self.stats['start_time']\\n\\n        return {\\n            'connected_clients': len(self.clients),\\n            'total_connections': self.stats['total_connections'],\\n            'messages_sent': self.stats['messages_sent'],\\n            'votes_broadcast': self.stats['votes_broadcast'],\\n            'uptime_seconds': uptime,\\n            'uptime_formatted': format_time_remaining(uptime),\\n            'is_voting_active': self.voting_system.is_active if self.voting_system else False\\n        }\\n\\n    async def broadcast_custom_message(self, message_type: str, data: Any):\\n        \\\"\\\"\\\"Broadcast custom message to all clients.\\\"\\\"\\\"\\n        broadcast_data = {\\n            'type': message_type,\\n            'data': data,\\n            'timestamp': time.time()\\n        }\\n\\n        tasks = []\\n        for client in list(self.clients.values()):\\n            tasks.append(self._send_to_client(client, broadcast_data))\\n\\n        if tasks:\\n            await asyncio.gather(*tasks, return_exceptions=True)\\n\\n    async def send_to_specific_clients(self, client_ids: List[str],\\n                                       message_type: str, data: Any):\\n        \\\"\\\"\\\"Send message to specific clients.\\\"\\\"\\\"\\n        message = {\\n            'type': message_type,\\n            'data': data,\\n            'timestamp': time.time()\\n        }\\n\\n        tasks = []\\n        for client_id in client_ids:\\n            if client_id in self.clients:\\n                client = self.clients[client_id]\\n                tasks.append(self._send_to_client(client, message))\\n\\n        if tasks:\\n            await asyncio.gather(*tasks, return_exceptions=True)\\n\\n    def get_connected_clients(self) -> List[Dict[str, Any]]:\\n        \\\"\\\"\\\"Get information about connected clients.\\\"\\\"\\\"\\n        return [\\n            {\\n                'client_id': client.client_id,\\n                'connected_at': client.connected_at,\\n                'client_type': client.client_type,\\n                'connection_duration': time.time() - client.connected_at\\n            }\\n            for client in self.clients.values()\\n        ]\\n\\n    @property\\n    def is_active(self) -> bool:\\n        \\\"\\\"\\\"Check if server is running.\\\"\\\"\\\"\\n        return self.is_running\\n\\n    @property\\n    def client_count(self) -> int:\\n        \\\"\\\"\\\"Get number of connected clients.\\\"\\\"\\\"\\n        return len(self.clients)\\n\\n\\nclass StreamingManager:\\n    \\\"\\\"\\\"\\n    High-level manager for streaming functionality.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self):\\n        self.servers: Dict[str, StreamingServer] = {}\\n        self.is_initialized = False\\n\\n    async def create_streaming_session(self, session_id: str, chat_log: ChatLog,\\n                                       voting_system: VotingSystem,\\n                                       config: Dict[str, Any]) -> StreamingServer:\\n        \\\"\\\"\\\"\\n        Create a new streaming session.\\n\\n        Args:\\n            session_id: Unique session identifier\\n            chat_log: Chat log to stream\\n            voting_system: Voting system to integrate\\n            config: Streaming configuration\\n\\n        Returns:\\n            StreamingServer instance\\n        \\\"\\\"\\\"\\n        if session_id in self.servers:\\n            raise ValueError(f\\\"Streaming session {session_id} already exists\\\")\\n\\n        # Create unique port for this session\\n        base_port = config.get('websocket_port', 8080)\\n        port = base_port + len(self.servers)\\n\\n        session_config = config.copy()\\n        session_config['websocket_port'] = port\\n\\n        server = StreamingServer(chat_log, voting_system, session_config)\\n        self.servers[session_id] = server\\n\\n        await server.start()\\n        return server\\n\\n    async def stop_streaming_session(self, session_id: str):\\n        \\\"\\\"\\\"Stop a streaming session.\\\"\\\"\\\"\\n        if session_id in self.servers:\\n            server = self.servers[session_id]\\n            await server.stop()\\n            del self.servers[session_id]\\n\\n    async def stop_all_sessions(self):\\n        \\\"\\\"\\\"Stop all streaming sessions.\\\"\\\"\\\"\\n        tasks = []\\n        for session_id in list(self.servers.keys()):\\n            tasks.append(self.stop_streaming_session(session_id))\\n\\n        if tasks:\\n            await asyncio.gather(*tasks, return_exceptions=True)\\n\\n    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\\n        \\\"\\\"\\\"Get information about a streaming session.\\\"\\\"\\\"\\n        if session_id not in self.servers:\\n            return None\\n\\n        server = self.servers[session_id]\\n        return {\\n            'session_id': session_id,\\n            'is_active': server.is_active,\\n            'client_count': server.client_count,\\n            'host': server.host,\\n            'port': server.port,\\n            'stats': server._get_server_stats()\\n        }\\n\\n    def list_active_sessions(self) -> List[str]:\\n        \\\"\\\"\\\"Get list of active session IDs.\\\"\\\"\\\"\\n        return [\\n            session_id for session_id, server in self.servers.items()\\n            if server.is_active\\n        ]\"\n        },\n        \"utils.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/utils.py\",\n          \"extension\": \".py\",\n          \"size\": 10954,\n          \"content\": \"\\\"\\\"\\\"\\nUtility functions for the AI Jubilee Debate System.\\n\\\"\\\"\\\"\\n\\nimport os\\nimport yaml\\nimport logging\\nimport time\\nimport re\\nfrom typing import Dict, Any, List, Optional\\nfrom pathlib import Path\\nfrom datetime import datetime, timedelta\\n\\n\\ndef load_config(config_path: str = \\\"config.yaml\\\") -> Dict[str, Any]:\\n    \\\"\\\"\\\"\\n    Load configuration from YAML file with environment variable substitution.\\n\\n    Args:\\n        config_path: Path to configuration file\\n\\n    Returns:\\n        Configuration dictionary\\n    \\\"\\\"\\\"\\n    config_file = Path(config_path)\\n\\n    if not config_file.exists():\\n        raise FileNotFoundError(f\\\"Configuration file not found: {config_path}\\\")\\n\\n    with open(config_file, 'r', encoding='utf-8') as f:\\n        config_content = f.read()\\n\\n    # Substitute environment variables\\n    config_content = substitute_env_vars(config_content)\\n\\n    try:\\n        config = yaml.safe_load(config_content)\\n        return config\\n    except yaml.YAMLError as e:\\n        raise ValueError(f\\\"Invalid YAML configuration: {e}\\\")\\n\\n\\ndef substitute_env_vars(text: str) -> str:\\n    \\\"\\\"\\\"\\n    Substitute environment variables in text using ${VAR_NAME} syntax.\\n\\n    Args:\\n        text: Text containing environment variable references\\n\\n    Returns:\\n        Text with environment variables substituted\\n    \\\"\\\"\\\"\\n    def replace_env_var(match):\\n        var_name = match.group(1)\\n        env_value = os.getenv(var_name)\\n        if env_value is None:\\n            print(f\\\"Warning: Environment variable {var_name} not found\\\")\\n            return f\\\"${{{var_name}}}\\\"  # Keep original if not found\\n        return env_value\\n\\n    return re.sub(r'\\\\$\\\\{([^}]+)\\\\}', replace_env_var, text)\\n\\n\\ndef setup_logging(level: str = \\\"INFO\\\", log_file: Optional[str] = None) -> None:\\n    \\\"\\\"\\\"\\n    Setup logging configuration.\\n\\n    Args:\\n        level: Logging level (DEBUG, INFO, WARNING, ERROR)\\n        log_file: Optional log file path\\n    \\\"\\\"\\\"\\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\\n\\n    # Create formatter\\n    formatter = logging.Formatter(\\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\n    )\\n\\n    # Setup root logger\\n    root_logger = logging.getLogger()\\n    root_logger.setLevel(numeric_level)\\n\\n    # Clear existing handlers\\n    root_logger.handlers.clear()\\n\\n    # Console handler\\n    console_handler = logging.StreamHandler()\\n    console_handler.setFormatter(formatter)\\n    root_logger.addHandler(console_handler)\\n\\n    # File handler if specified\\n    if log_file:\\n        file_handler = logging.FileHandler(log_file)\\n        file_handler.setFormatter(formatter)\\n        root_logger.addHandler(file_handler)\\n\\n\\ndef format_time_remaining(seconds: float) -> str:\\n    \\\"\\\"\\\"\\n    Format remaining time in human-readable format.\\n\\n    Args:\\n        seconds: Time remaining in seconds\\n\\n    Returns:\\n        Formatted time string\\n    \\\"\\\"\\\"\\n    if seconds <= 0:\\n        return \\\"Time's up!\\\"\\n\\n    if seconds < 60:\\n        return f\\\"{int(seconds)} seconds\\\"\\n    elif seconds < 3600:\\n        minutes = int(seconds // 60)\\n        secs = int(seconds % 60)\\n        return f\\\"{minutes}m {secs}s\\\"\\n    else:\\n        hours = int(seconds // 3600)\\n        minutes = int((seconds % 3600) // 60)\\n        return f\\\"{hours}h {minutes}m\\\"\\n\\n\\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \\\"...\\\") -> str:\\n    \\\"\\\"\\\"\\n    Truncate text to maximum length with suffix.\\n\\n    Args:\\n        text: Text to truncate\\n        max_length: Maximum length\\n        suffix: Suffix to add when truncating\\n\\n    Returns:\\n        Truncated text\\n    \\\"\\\"\\\"\\n    if len(text) <= max_length:\\n        return text\\n\\n    return text[:max_length - len(suffix)] + suffix\\n\\n\\ndef generate_debate_prompt(topic: str, role: str, personality: str) -> str:\\n    \\\"\\\"\\\"\\n    Generate a debate prompt for AI participants.\\n\\n    Args:\\n        topic: Debate topic\\n        role: Participant role (pro, con, neutral)\\n        personality: Personality description\\n\\n    Returns:\\n        Generated prompt\\n    \\\"\\\"\\\"\\n    base_prompt = f\\\"\\\"\\\"You are participating in a structured debate on the topic: \\\"{topic}\\\"\\n\\nYour role: {role}\\nYour personality: {personality}\\n\\nInstructions:\\n1. Present clear, logical arguments\\n2. Respond to other participants' points\\n3. Stay focused on the topic\\n4. Be respectful but persuasive\\n5. Keep responses concise and engaging\\n\\nCurrent debate topic: {topic}\\n\\\"\\\"\\\"\\n\\n    if role.lower() == \\\"pro\\\":\\n        base_prompt += \\\"\\\\nYou should argue IN FAVOR of the topic.\\\"\\n    elif role.lower() == \\\"con\\\":\\n        base_prompt += \\\"\\\\nYou should argue AGAINST the topic.\\\"\\n    elif role.lower() == \\\"neutral\\\":\\n        base_prompt += \\\"\\\\nYou should present balanced perspectives and ask probing questions.\\\"\\n\\n    return base_prompt\\n\\n\\ndef validate_participant_name(name: str) -> bool:\\n    \\\"\\\"\\\"\\n    Validate participant name.\\n\\n    Args:\\n        name: Participant name to validate\\n\\n    Returns:\\n        True if valid, False otherwise\\n    \\\"\\\"\\\"\\n    if not name or len(name.strip()) == 0:\\n        return False\\n\\n    # Check length\\n    if len(name) > 50:\\n        return False\\n\\n    # Check for valid characters (alphanumeric, spaces, underscores, hyphens)\\n    if not re.match(r'^[a-zA-Z0-9\\\\s_-]+$', name):\\n        return False\\n\\n    return True\\n\\n\\ndef sanitize_filename(filename: str) -> str:\\n    \\\"\\\"\\\"\\n    Sanitize filename for safe file operations.\\n\\n    Args:\\n        filename: Original filename\\n\\n    Returns:\\n        Sanitized filename\\n    \\\"\\\"\\\"\\n    # Remove or replace invalid characters\\n    sanitized = re.sub(r'[<>:\\\"/\\\\\\\\|?*]', '_', filename)\\n\\n    # Remove leading/trailing spaces and dots\\n    sanitized = sanitized.strip(' .')\\n\\n    # Limit length\\n    if len(sanitized) > 255:\\n        sanitized = sanitized[:255]\\n\\n    return sanitized\\n\\n\\ndef parse_duration(duration_str: str) -> int:\\n    \\\"\\\"\\\"\\n    Parse duration string into seconds.\\n\\n    Args:\\n        duration_str: Duration string (e.g., \\\"5m\\\", \\\"30s\\\", \\\"1h30m\\\")\\n\\n    Returns:\\n        Duration in seconds\\n    \\\"\\\"\\\"\\n    if duration_str.isdigit():\\n        return int(duration_str)\\n\\n    total_seconds = 0\\n\\n    # Parse hours\\n    hours_match = re.search(r'(\\\\d+)h', duration_str.lower())\\n    if hours_match:\\n        total_seconds += int(hours_match.group(1)) * 3600\\n\\n    # Parse minutes\\n    minutes_match = re.search(r'(\\\\d+)m', duration_str.lower())\\n    if minutes_match:\\n        total_seconds += int(minutes_match.group(1)) * 60\\n\\n    # Parse seconds\\n    seconds_match = re.search(r'(\\\\d+)s', duration_str.lower())\\n    if seconds_match:\\n        total_seconds += int(seconds_match.group(1))\\n\\n    return total_seconds if total_seconds > 0 else 60  # Default to 60 seconds\\n\\n\\ndef create_timestamp() -> str:\\n    \\\"\\\"\\\"\\n    Create ISO format timestamp.\\n\\n    Returns:\\n        ISO formatted timestamp string\\n    \\\"\\\"\\\"\\n    return datetime.now().isoformat()\\n\\n\\ndef format_participant_list(participants: List[str], max_display: int = 5) -> str:\\n    \\\"\\\"\\\"\\n    Format participant list for display.\\n\\n    Args:\\n        participants: List of participant names\\n        max_display: Maximum participants to display before truncating\\n\\n    Returns:\\n        Formatted participant string\\n    \\\"\\\"\\\"\\n    if len(participants) <= max_display:\\n        return \\\", \\\".join(participants)\\n\\n    displayed = participants[:max_display]\\n    remaining = len(participants) - max_display\\n\\n    return f\\\"{', '.join(displayed)} (+{remaining} more)\\\"\\n\\n\\ndef calculate_word_count(text: str) -> int:\\n    \\\"\\\"\\\"\\n    Calculate word count in text.\\n\\n    Args:\\n        text: Text to count words in\\n\\n    Returns:\\n        Number of words\\n    \\\"\\\"\\\"\\n    return len(text.split())\\n\\n\\ndef extract_key_phrases(text: str, max_phrases: int = 5) -> List[str]:\\n    \\\"\\\"\\\"\\n    Extract key phrases from text (simple implementation).\\n\\n    Args:\\n        text: Text to extract phrases from\\n        max_phrases: Maximum number of phrases to return\\n\\n    Returns:\\n        List of key phrases\\n    \\\"\\\"\\\"\\n    # Simple implementation - could be enhanced with NLP\\n    sentences = text.split('.')\\n    phrases = []\\n\\n    for sentence in sentences[:max_phrases]:\\n        sentence = sentence.strip()\\n        if len(sentence) > 10:  # Minimum length\\n            phrases.append(sentence)\\n\\n    return phrases[:max_phrases]\\n\\n\\ndef generate_session_id() -> str:\\n    \\\"\\\"\\\"\\n    Generate unique session ID.\\n\\n    Returns:\\n        Unique session identifier\\n    \\\"\\\"\\\"\\n    import uuid\\n    return str(uuid.uuid4())[:8]\\n\\n\\ndef ensure_directory(path: str) -> Path:\\n    \\\"\\\"\\\"\\n    Ensure directory exists, create if necessary.\\n\\n    Args:\\n        path: Directory path\\n\\n    Returns:\\n        Path object\\n    \\\"\\\"\\\"\\n    dir_path = Path(path)\\n    dir_path.mkdir(parents=True, exist_ok=True)\\n    return dir_path\\n\\n\\ndef load_debate_topics(topics_file: str = \\\"topics.txt\\\") -> List[str]:\\n    \\\"\\\"\\\"\\n    Load debate topics from file.\\n\\n    Args:\\n        topics_file: Path to topics file\\n\\n    Returns:\\n        List of debate topics\\n    \\\"\\\"\\\"\\n    topics_path = Path(topics_file)\\n\\n    if not topics_path.exists():\\n        # Return default topics\\n        return [\\n            \\\"Artificial intelligence will create more jobs than it destroys\\\",\\n            \\\"Social media has a net positive impact on society\\\",\\n            \\\"Universal Basic Income is necessary for the future economy\\\",\\n            \\\"Climate change requires immediate radical action\\\",\\n            \\\"Privacy is more important than security\\\"\\n        ]\\n\\n    with open(topics_path, 'r', encoding='utf-8') as f:\\n        topics = [line.strip() for line in f if line.strip() and not line.startswith('#')]\\n\\n    return topics\\n\\n\\nclass PerformanceTimer:\\n    \\\"\\\"\\\"Context manager for timing operations.\\\"\\\"\\\"\\n\\n    def __init__(self, operation_name: str = \\\"Operation\\\"):\\n        self.operation_name = operation_name\\n        self.start_time = None\\n        self.end_time = None\\n\\n    def __enter__(self):\\n        self.start_time = time.time()\\n        return self\\n\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\n        self.end_time = time.time()\\n\\n    @property\\n    def duration(self) -> float:\\n        \\\"\\\"\\\"Get operation duration in seconds.\\\"\\\"\\\"\\n        if self.start_time and self.end_time:\\n            return self.end_time - self.start_time\\n        return 0.0\\n\\n    def __str__(self) -> str:\\n        return f\\\"{self.operation_name}: {self.duration:.3f}s\\\"\\n\\n\\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\\n    \\\"\\\"\\\"\\n    Decorator for retrying operations with exponential backoff.\\n\\n    Args:\\n        max_retries: Maximum number of retry attempts\\n        base_delay: Base delay between retries\\n    \\\"\\\"\\\"\\n    def decorator(func):\\n        async def wrapper(*args, **kwargs):\\n            last_exception = None\\n\\n            for attempt in range(max_retries + 1):\\n                try:\\n                    return await func(*args, **kwargs)\\n                except Exception as e:\\n                    last_exception = e\\n\\n                    if attempt < max_retries:\\n                        delay = base_delay * (2 ** attempt)\\n                        await asyncio.sleep(delay)\\n                    else:\\n                        raise last_exception\\n\\n            raise last_exception\\n\\n        return wrapper\\n    return decorator\"\n        },\n        \"voting.py\": {\n          \"type\": \"file\",\n          \"path\": \"app/voting.py\",\n          \"extension\": \".py\",\n          \"size\": 11436,\n          \"content\": \"\\\"\\\"\\\"\\nVoting system for debate evaluation and winner determination.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport time\\nfrom typing import Dict, List, Optional, Any\\nfrom dataclasses import dataclass, field\\nfrom collections import defaultdict, Counter\\n\\n\\n@dataclass\\nclass Vote:\\n    \\\"\\\"\\\"Represents a single vote.\\\"\\\"\\\"\\n    voter_id: str\\n    candidate: str\\n    justification: Optional[str] = None\\n    timestamp: float = field(default_factory=time.time)\\n    anonymous: bool = False\\n\\n\\n@dataclass\\nclass VotingResults:\\n    \\\"\\\"\\\"Results of a voting session.\\\"\\\"\\\"\\n    winner: Optional[str]\\n    vote_counts: Dict[str, int]\\n    total_votes: int\\n    votes_by_voter: Dict[str, Vote]\\n    voting_duration: float\\n    participation_rate: float\\n\\n\\nclass VotingSystem:\\n    \\\"\\\"\\\"\\n    Manages voting process, vote collection, and result calculation.\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, config: Dict[str, Any]):\\n        self.config = config\\n        self.enabled = config.get('enabled', True)\\n        self.voting_duration = config.get('voting_duration', 300)\\n        self.allow_participant_voting = config.get('allow_participant_voting', True)\\n        self.require_justification = config.get('require_justification', True)\\n        self.anonymous_votes = config.get('anonymous_votes', False)\\n\\n        # Voting state\\n        self.is_active = False\\n        self.candidates: List[str] = []\\n        self.eligible_voters: List[str] = []\\n        self.votes: Dict[str, Vote] = {}\\n        self.start_time: Optional[float] = None\\n        self.end_time: Optional[float] = None\\n\\n        # Vote validation\\n        self.vote_history: List[Dict[str, Any]] = []\\n\\n    async def start_voting(self, candidates: List[str], duration: Optional[int] = None) -> None:\\n        \\\"\\\"\\\"\\n        Start a voting session.\\n\\n        Args:\\n            candidates: List of debate participants to vote for\\n            duration: Voting duration in seconds (uses config default if None)\\n        \\\"\\\"\\\"\\n        if not self.enabled:\\n            raise ValueError(\\\"Voting system is disabled\\\")\\n\\n        if self.is_active:\\n            raise ValueError(\\\"Voting session already active\\\")\\n\\n        self.candidates = candidates.copy()\\n        self.eligible_voters = candidates.copy() if self.allow_participant_voting else []\\n        self.votes = {}\\n        self.start_time = time.time()\\n        self.end_time = self.start_time + (duration or self.voting_duration)\\n        self.is_active = True\\n\\n        print(f\\\"üó≥Ô∏è Voting started for {len(candidates)} candidates\\\")\\n        print(f\\\"‚è∞ Voting closes in {duration or self.voting_duration} seconds\\\")\\n\\n    async def cast_vote(self, voter_id: str, candidate: str,\\n                        justification: Optional[str] = None) -> bool:\\n        \\\"\\\"\\\"\\n        Cast a vote for a candidate.\\n\\n        Args:\\n            voter_id: ID of the voter\\n            candidate: Candidate being voted for\\n            justification: Optional reasoning for the vote\\n\\n        Returns:\\n            True if vote was successfully cast, False otherwise\\n        \\\"\\\"\\\"\\n        if not self.is_active:\\n            raise ValueError(\\\"No active voting session\\\")\\n\\n        if time.time() > self.end_time:\\n            raise ValueError(\\\"Voting period has ended\\\")\\n\\n        # Validate voter eligibility\\n        if not self._is_eligible_voter(voter_id):\\n            raise ValueError(f\\\"Voter {voter_id} is not eligible to vote\\\")\\n\\n        # Validate candidate\\n        if candidate not in self.candidates:\\n            raise ValueError(f\\\"Invalid candidate: {candidate}\\\")\\n\\n        # Check for self-voting\\n        if voter_id == candidate and not self.allow_participant_voting:\\n            raise ValueError(\\\"Self-voting is not allowed\\\")\\n\\n        # Validate justification requirement\\n        if self.require_justification and not justification:\\n            raise ValueError(\\\"Vote justification is required\\\")\\n\\n        # Record the vote (overwrites previous vote from same voter)\\n        vote = Vote(\\n            voter_id=voter_id,\\n            candidate=candidate,\\n            justification=justification,\\n            anonymous=self.anonymous_votes\\n        )\\n\\n        self.votes[voter_id] = vote\\n\\n        print(f\\\"‚úÖ Vote recorded: {voter_id} -> {candidate}\\\")\\n        return True\\n\\n    async def end_voting(self) -> VotingResults:\\n        \\\"\\\"\\\"\\n        End the voting session and calculate results.\\n\\n        Returns:\\n            VotingResults object with winner and vote breakdown\\n        \\\"\\\"\\\"\\n        if not self.is_active:\\n            raise ValueError(\\\"No active voting session\\\")\\n\\n        self.is_active = False\\n        actual_end_time = time.time()\\n\\n        # Calculate vote counts\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\n        total_votes = len(self.votes)\\n\\n        # Determine winner\\n        winner = None\\n        if vote_counts:\\n            max_votes = max(vote_counts.values())\\n            winners = [candidate for candidate, count in vote_counts.items()\\n                       if count == max_votes]\\n\\n            if len(winners) == 1:\\n                winner = winners[0]\\n            else:\\n                # Handle tie - could implement tiebreaker logic here\\n                winner = f\\\"TIE: {', '.join(winners)}\\\"\\n\\n        # Calculate participation rate\\n        participation_rate = (total_votes / len(self.eligible_voters)\\n                              if self.eligible_voters else 0)\\n\\n        # Create results\\n        results = VotingResults(\\n            winner=winner,\\n            vote_counts=dict(vote_counts),\\n            total_votes=total_votes,\\n            votes_by_voter=self.votes.copy(),\\n            voting_duration=actual_end_time - self.start_time,\\n            participation_rate=participation_rate\\n        )\\n\\n        # Store in history\\n        self.vote_history.append({\\n            'timestamp': actual_end_time,\\n            'candidates': self.candidates.copy(),\\n            'results': results\\n        })\\n\\n        print(f\\\"üèÜ Voting ended. Winner: {winner}\\\")\\n        print(f\\\"üìä Total votes: {total_votes}\\\")\\n        print(f\\\"üìà Participation: {participation_rate:.1%}\\\")\\n\\n        return results\\n\\n    def _is_eligible_voter(self, voter_id: str) -> bool:\\n        \\\"\\\"\\\"Check if a voter is eligible to vote.\\\"\\\"\\\"\\n        if not self.eligible_voters:\\n            return True  # Open voting\\n        return voter_id in self.eligible_voters\\n\\n    def add_eligible_voter(self, voter_id: str) -> None:\\n        \\\"\\\"\\\"Add a voter to the eligible voters list.\\\"\\\"\\\"\\n        if voter_id not in self.eligible_voters:\\n            self.eligible_voters.append(voter_id)\\n\\n    def remove_eligible_voter(self, voter_id: str) -> None:\\n        \\\"\\\"\\\"Remove a voter from the eligible voters list.\\\"\\\"\\\"\\n        if voter_id in self.eligible_voters:\\n            self.eligible_voters.remove(voter_id)\\n\\n    def get_vote_summary(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get current voting summary without ending the session.\\\"\\\"\\\"\\n        if not self.is_active:\\n            return {}\\n\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\n        time_remaining = max(0, self.end_time - time.time())\\n\\n        return {\\n            'candidates': self.candidates,\\n            'vote_counts': dict(vote_counts),\\n            'total_votes': len(self.votes),\\n            'time_remaining': time_remaining,\\n            'is_active': self.is_active\\n        }\\n\\n    def get_voter_history(self, voter_id: str) -> List[Vote]:\\n        \\\"\\\"\\\"Get voting history for a specific voter.\\\"\\\"\\\"\\n        history = []\\n        for session in self.vote_history:\\n            votes = session.get('results', {}).votes_by_voter\\n            if voter_id in votes:\\n                history.append(votes[voter_id])\\n        return history\\n\\n    def get_candidate_performance(self, candidate: str) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get performance statistics for a candidate across all sessions.\\\"\\\"\\\"\\n        wins = 0\\n        total_votes = 0\\n        participations = 0\\n\\n        for session in self.vote_history:\\n            results = session.get('results', {})\\n            if candidate in session.get('candidates', []):\\n                participations += 1\\n                if results.winner == candidate:\\n                    wins += 1\\n                total_votes += results.vote_counts.get(candidate, 0)\\n\\n        return {\\n            'candidate': candidate,\\n            'wins': wins,\\n            'total_votes': total_votes,\\n            'participations': participations,\\n            'win_rate': wins / participations if participations > 0 else 0,\\n            'avg_votes': total_votes / participations if participations > 0 else 0\\n        }\\n\\n    async def export_results(self, format_type: str = 'json') -> str:\\n        \\\"\\\"\\\"\\n        Export voting results in specified format.\\n\\n        Args:\\n            format_type: Export format ('json', 'csv', 'txt')\\n\\n        Returns:\\n            Formatted results string\\n        \\\"\\\"\\\"\\n        if not self.vote_history:\\n            return \\\"No voting history available\\\"\\n\\n        if format_type == 'json':\\n            import json\\n            return json.dumps(self.vote_history, indent=2, default=str)\\n\\n        elif format_type == 'csv':\\n            import csv\\n            import io\\n\\n            output = io.StringIO()\\n            writer = csv.writer(output)\\n\\n            # Header\\n            writer.writerow(['Session', 'Timestamp', 'Candidate', 'Votes', 'Winner'])\\n\\n            # Data\\n            for i, session in enumerate(self.vote_history):\\n                results = session.get('results', {})\\n                timestamp = session.get('timestamp', '')\\n\\n                for candidate, votes in results.vote_counts.items():\\n                    writer.writerow([\\n                        i + 1,\\n                        timestamp,\\n                        candidate,\\n                        votes,\\n                        results.winner == candidate\\n                    ])\\n\\n            return output.getvalue()\\n\\n        elif format_type == 'txt':\\n            output = []\\n            output.append(\\\"=== VOTING HISTORY REPORT ===\\\\n\\\")\\n\\n            for i, session in enumerate(self.vote_history):\\n                results = session.get('results', {})\\n                output.append(f\\\"Session {i + 1}:\\\")\\n                output.append(f\\\"  Winner: {results.winner}\\\")\\n                output.append(f\\\"  Total Votes: {results.total_votes}\\\")\\n                output.append(f\\\"  Vote Breakdown:\\\")\\n\\n                for candidate, votes in sorted(results.vote_counts.items(),\\n                                               key=lambda x: x[1], reverse=True):\\n                    output.append(f\\\"    {candidate}: {votes}\\\")\\n                output.append(\\\"\\\")\\n\\n            return \\\"\\\\n\\\".join(output)\\n\\n        else:\\n            raise ValueError(f\\\"Unsupported format: {format_type}\\\")\\n\\n    def reset(self) -> None:\\n        \\\"\\\"\\\"Reset the voting system to initial state.\\\"\\\"\\\"\\n        self.is_active = False\\n        self.candidates = []\\n        self.eligible_voters = []\\n        self.votes = {}\\n        self.start_time = None\\n        self.end_time = None\\n\\n    @property\\n    def status(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get current status of the voting system.\\\"\\\"\\\"\\n        return {\\n            'enabled': self.enabled,\\n            'is_active': self.is_active,\\n            'candidates': self.candidates,\\n            'eligible_voters': len(self.eligible_voters),\\n            'votes_cast': len(self.votes),\\n            'time_remaining': (self.end_time - time.time()\\n                               if self.is_active and self.end_time else 0),\\n            'sessions_completed': len(self.vote_history)\\n        }\"\n        }\n      }\n    },\n    \"docs\": {\n      \"type\": \"directory\",\n      \"contents\": {\n        \"api_reference.md\": {\n          \"type\": \"file\",\n          \"path\": \"docs/api_reference.md\",\n          \"extension\": \".md\",\n          \"size\": 15639,\n          \"content\": \"# AI Jubilee Debate System API Reference\\n\\n## Core Classes\\n\\n### Moderator\\n\\nThe central coordinator for debate sessions.\\n\\n#### Constructor\\n```python\\nModerator(\\n    topic: str,\\n    participants: List[Union[BotClient, HumanClient]],\\n    chat_log: ChatLog,\\n    voting_system: VotingSystem,\\n    config: Dict[str, Any]\\n)\\n```\\n\\n**Parameters:**\\n- `topic`: The debate topic string\\n- `participants`: List of bot and human participants\\n- `chat_log`: ChatLog instance for message management\\n- `voting_system`: VotingSystem instance for handling votes\\n- `config`: Configuration dictionary with timing and rule settings\\n\\n#### Methods\\n\\n##### `async run_debate() -> Dict[str, Any]`\\nRuns the complete debate session through all phases.\\n\\n**Returns:** Dictionary containing voting results and session statistics\\n\\n**Example:**\\n```python\\nmoderator = Moderator(topic, participants, chat_log, voting_system, config)\\nresults = await moderator.run_debate()\\nprint(f\\\"Winner: {results.get('winner', 'No winner')}\\\")\\n```\\n\\n##### `get_state() -> DebateState`\\nReturns current debate state information.\\n\\n**Returns:** DebateState object with phase, speaker, and timing info\\n\\n##### `async _give_turn(participant_name: str, time_limit: int, turn_type: str) -> None`\\nGives speaking turn to a specific participant.\\n\\n**Parameters:**\\n- `participant_name`: Name of participant to give turn to\\n- `time_limit`: Maximum time in seconds for response\\n- `turn_type`: Type of turn (\\\"opening\\\", \\\"response\\\", \\\"closing\\\")\\n\\n---\\n\\n### ChatLog\\n\\nThread-safe message management system.\\n\\n#### Constructor\\n```python\\nChatLog(max_messages: int = 1000)\\n```\\n\\n**Parameters:**\\n- `max_messages`: Maximum number of messages to retain in memory\\n\\n#### Methods\\n\\n##### `async add_message(sender: str, content: str, message_type: str = \\\"chat\\\", metadata: Optional[Dict] = None) -> Message`\\nAdds a new message to the chat log.\\n\\n**Parameters:**\\n- `sender`: Name of message sender\\n- `content`: Message content text\\n- `message_type`: Type of message (\\\"chat\\\", \\\"moderator\\\", \\\"system\\\", \\\"vote\\\")\\n- `metadata`: Optional additional data\\n\\n**Returns:** Created Message object\\n\\n**Example:**\\n```python\\nmessage = await chat_log.add_message(\\\"Alice\\\", \\\"I think AI will help humanity\\\")\\nprint(f\\\"Message ID: {message.message_id}\\\")\\n```\\n\\n##### `get_messages(limit: Optional[int] = None, sender: Optional[str] = None, message_type: Optional[str] = None, since_timestamp: Optional[float] = None) -> List[Message]`\\nRetrieves messages with optional filtering.\\n\\n**Parameters:**\\n- `limit`: Maximum number of messages to return\\n- `sender`: Filter by sender name\\n- `message_type`: Filter by message type\\n- `since_timestamp`: Only messages after this timestamp\\n\\n**Returns:** List of Message objects\\n\\n##### `subscribe() -> asyncio.Queue`\\nCreates subscription for real-time message updates.\\n\\n**Returns:** Queue that receives new Message objects\\n\\n##### `async save_transcript(filename: str, format_type: str = \\\"json\\\") -> None`\\nSaves chat transcript to file.\\n\\n**Parameters:**\\n- `filename`: Output file path\\n- `format_type`: Export format (\\\"json\\\", \\\"txt\\\", \\\"html\\\")\\n\\n##### `search_messages(query: str, case_sensitive: bool = False) -> List[Message]`\\nSearches messages by content.\\n\\n**Parameters:**\\n- `query`: Search string\\n- `case_sensitive`: Whether search is case sensitive\\n\\n**Returns:** List of matching Message objects\\n\\n---\\n\\n### VotingSystem\\n\\nManages voting sessions and result calculation.\\n\\n#### Constructor\\n```python\\nVotingSystem(config: Dict[str, Any])\\n```\\n\\n**Parameters:**\\n- `config`: Voting configuration dictionary\\n\\n#### Methods\\n\\n##### `async start_voting(candidates: List[str], duration: Optional[int] = None) -> None`\\nStarts a new voting session.\\n\\n**Parameters:**\\n- `candidates`: List of participant names to vote for\\n- `duration`: Voting duration in seconds (uses config default if None)\\n\\n**Example:**\\n```python\\nawait voting_system.start_voting([\\\"Alice\\\", \\\"Bob\\\", \\\"Charlie\\\"], 300)\\n```\\n\\n##### `async cast_vote(voter_id: str, candidate: str, justification: Optional[str] = None) -> bool`\\nCasts a vote for a candidate.\\n\\n**Parameters:**\\n- `voter_id`: ID of the voter\\n- `candidate`: Name of candidate being voted for\\n- `justification`: Optional reasoning for the vote\\n\\n**Returns:** True if vote was successfully cast\\n\\n##### `async end_voting() -> VotingResults`\\nEnds voting session and calculates results.\\n\\n**Returns:** VotingResults object with winner and vote breakdown\\n\\n##### `get_vote_summary() -> Dict[str, Any]`\\nGets current voting status without ending session.\\n\\n**Returns:** Dictionary with vote counts and time remaining\\n\\n##### `async export_results(format_type: str = \\\"json\\\") -> str`\\nExports voting results in specified format.\\n\\n**Parameters:**\\n- `format_type`: Export format (\\\"json\\\", \\\"csv\\\", \\\"txt\\\")\\n\\n**Returns:** Formatted results string\\n\\n---\\n\\n### BotClient\\n\\nAI-powered debate participant.\\n\\n#### Constructor\\n```python\\nBotClient(\\n    name: str,\\n    model: str,\\n    provider: str,\\n    personality: str,\\n    stance: str,\\n    api_key: str,\\n    temperature: float = 0.7,\\n    max_tokens: int = 300\\n)\\n```\\n\\n**Parameters:**\\n- `name`: Bot display name\\n- `model`: AI model identifier\\n- `provider`: AI provider (\\\"openai\\\" or \\\"anthropic\\\")\\n- `personality`: Personality description for prompt\\n- `stance`: Debate stance (\\\"pro\\\", \\\"con\\\", \\\"neutral\\\")\\n- `api_key`: API key for AI provider\\n- `temperature`: Response creativity (0.0-1.0)\\n- `max_tokens`: Maximum response length\\n\\n#### Methods\\n\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\nGenerates AI response to current debate context.\\n\\n**Parameters:**\\n- `topic`: Current debate topic\\n- `recent_messages`: Recent conversation messages for context\\n\\n**Returns:** Generated response string\\n\\n**Example:**\\n```python\\nbot = BotClient(\\\"Analyst\\\", \\\"gpt-4\\\", \\\"openai\\\", \\\"Analytical\\\", \\\"pro\\\", api_key)\\nresponse = await bot.get_response(\\\"AI in healthcare\\\", recent_messages)\\n```\\n\\n##### `async receive_message(message: Message) -> None`\\nReceives message from debate for context awareness.\\n\\n##### `get_stats() -> Dict[str, Any]`\\nReturns bot performance statistics.\\n\\n**Returns:** Dictionary with response counts, timing, and success rates\\n\\n##### `async warmup() -> bool`\\nTests bot connectivity and readiness.\\n\\n**Returns:** True if bot is ready for debate\\n\\n##### `update_personality(personality: str, stance: str = None) -> None`\\nUpdates bot personality and stance during session.\\n\\n---\\n\\n### HumanClient\\n\\nHuman participant interface.\\n\\n#### Constructor\\n```python\\nHumanClient(name: str, interface_config: Dict[str, Any])\\n```\\n\\n**Parameters:**\\n- `name`: Human participant display name\\n- `interface_config`: Interface configuration dictionary\\n\\n#### Methods\\n\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\nGets response from human participant.\\n\\n**Parameters:**\\n- `topic`: Current debate topic\\n- `recent_messages`: Recent messages for context\\n\\n**Returns:** Human's response string\\n\\n##### `async handle_voting(candidates: List[str], voting_time: int) -> Dict[str, Any]`\\nHandles voting interface for human.\\n\\n**Parameters:**\\n- `candidates`: List of candidates to vote for\\n- `voting_time`: Time allowed for voting\\n\\n**Returns:** Dictionary with vote result and metadata\\n\\n##### `async set_active(active: bool) -> None`\\nSets whether human is actively participating.\\n\\n**Parameters:**\\n- `active`: Whether human should be active in debate\\n\\n---\\n\\n### StreamingServer\\n\\nWebSocket server for live debate streaming.\\n\\n#### Constructor\\n```python\\nStreamingServer(\\n    chat_log: ChatLog,\\n    voting_system: VotingSystem,\\n    config: Dict[str, Any]\\n)\\n```\\n\\n#### Methods\\n\\n##### `async start() -> None`\\nStarts the streaming server.\\n\\n##### `async stop() -> None`\\nStops the streaming server and closes connections.\\n\\n##### `async broadcast_custom_message(message_type: str, data: Any) -> None`\\nBroadcasts custom message to all connected clients.\\n\\n**Parameters:**\\n- `message_type`: Type identifier for the message\\n- `data`: Message payload\\n\\n##### `get_connected_clients() -> List[Dict[str, Any]]`\\nReturns information about all connected streaming clients.\\n\\n**Returns:** List of client information dictionaries\\n\\n---\\n\\n## Data Classes\\n\\n### Message\\n\\nRepresents a single chat message.\\n\\n```python\\n@dataclass\\nclass Message:\\n    sender: str\\n    content: str\\n    timestamp: float\\n    message_id: int\\n    message_type: str = \\\"chat\\\"\\n    metadata: Optional[Dict[str, Any]] = None\\n```\\n\\n**Properties:**\\n- `formatted_timestamp`: Human-readable timestamp string\\n\\n**Methods:**\\n- `to_dict() -> Dict[str, Any]`: Convert to dictionary\\n- `from_dict(data: Dict[str, Any]) -> Message`: Create from dictionary\\n\\n### Vote\\n\\nRepresents a single vote in the voting system.\\n\\n```python\\n@dataclass\\nclass Vote:\\n    voter_id: str\\n    candidate: str\\n    justification: Optional[str] = None\\n    timestamp: float = field(default_factory=time.time)\\n    anonymous: bool = False\\n```\\n\\n### VotingResults\\n\\nContains results from a voting session.\\n\\n```python\\n@dataclass\\nclass VotingResults:\\n    winner: Optional[str]\\n    vote_counts: Dict[str, int]\\n    total_votes: int\\n    votes_by_voter: Dict[str, Vote]\\n    voting_duration: float\\n    participation_rate: float\\n```\\n\\n### DebateState\\n\\nTracks current debate session state.\\n\\n```python\\n@dataclass\\nclass DebateState:\\n    phase: DebatePhase\\n    current_speaker: Optional[str] = None\\n    time_remaining: int = 0\\n    turn_order: List[str] = None\\n    warnings_issued: Dict[str, int] = None\\n```\\n\\n---\\n\\n## Enums\\n\\n### DebatePhase\\n\\nDefines the phases of a debate session.\\n\\n```python\\nclass DebatePhase(Enum):\\n    INTRODUCTION = \\\"introduction\\\"\\n    OPENING_STATEMENTS = \\\"opening_statements\\\"\\n    DISCUSSION = \\\"discussion\\\"\\n    CLOSING_STATEMENTS = \\\"closing_statements\\\"\\n    VOTING = \\\"voting\\\"\\n    RESULTS = \\\"results\\\"\\n    FINISHED = \\\"finished\\\"\\n```\\n\\n---\\n\\n## Utility Functions\\n\\n### Configuration (`app/utils.py`)\\n\\n##### `load_config(config_path: str = \\\"config.yaml\\\") -> Dict[str, Any]`\\nLoads configuration from YAML file with environment variable substitution.\\n\\n**Parameters:**\\n- `config_path`: Path to configuration file\\n\\n**Returns:** Configuration dictionary\\n\\n**Example:**\\n```python\\nconfig = load_config(\\\"custom_config.yaml\\\")\\n```\\n\\n##### `setup_logging(level: str = \\\"INFO\\\", log_file: Optional[str] = None) -> None`\\nSets up logging configuration.\\n\\n**Parameters:**\\n- `level`: Logging level (\\\"DEBUG\\\", \\\"INFO\\\", \\\"WARNING\\\", \\\"ERROR\\\")\\n- `log_file`: Optional log file path\\n\\n##### `format_time_remaining(seconds: float) -> str`\\nFormats time remaining in human-readable format.\\n\\n**Parameters:**\\n- `seconds`: Time in seconds\\n\\n**Returns:** Formatted time string (\\\"5m 30s\\\", \\\"2h 15m\\\", etc.)\\n\\n##### `truncate_text(text: str, max_length: int = 100, suffix: str = \\\"...\\\") -> str`\\nTruncates text to maximum length.\\n\\n**Parameters:**\\n- `text`: Text to truncate\\n- `max_length`: Maximum length\\n- `suffix`: Suffix to add when truncating\\n\\n**Returns:** Truncated text\\n\\n---\\n\\n## Error Handling\\n\\n### Custom Exceptions\\n\\nThe system uses standard Python exceptions with descriptive messages:\\n\\n- `ValueError`: Invalid configuration or parameters\\n- `FileNotFoundError`: Missing configuration files\\n- `ConnectionError`: API or network failures\\n- `TimeoutError`: Response timeouts\\n\\n### Error Recovery\\n\\nAll async methods include proper error handling and will not crash the session:\\n\\n```python\\ntry:\\n    response = await bot.get_response(topic, messages)\\nexcept Exception as e:\\n    # Fallback response is automatically generated\\n    response = bot._generate_fallback_response(topic)\\n```\\n\\n---\\n\\n## Configuration Schema\\n\\n### Main Configuration\\n\\n```yaml\\n# Debate settings\\ndebate:\\n  default_topic: str\\n  max_participants: int\\n  time_limit_minutes: int\\n  opening_statement_time: int  # seconds\\n  response_time: int\\n  closing_statement_time: int\\n\\n# Bot configurations\\nbots:\\n  - name: str\\n    model: str\\n    provider: str  # \\\"openai\\\" or \\\"anthropic\\\"\\n    personality: str\\n    stance: str  # \\\"pro\\\", \\\"con\\\", or \\\"neutral\\\"\\n    temperature: float  # 0.0-1.0\\n    max_tokens: int\\n\\n# API credentials\\napi_keys:\\n  openai: str\\n  anthropic: str\\n\\n# Voting settings\\nvoting:\\n  enabled: bool\\n  voting_duration: int  # seconds\\n  allow_participant_voting: bool\\n  require_justification: bool\\n  anonymous_votes: bool\\n\\n# Chat settings\\nchat:\\n  max_message_length: int\\n  enable_timestamps: bool\\n  log_level: str\\n  save_transcripts: bool\\n\\n# Streaming settings\\nstreaming:\\n  enabled: bool\\n  websocket_port: int\\n  max_connections: int\\n  broadcast_votes: bool\\n\\n# Interface settings\\ninterface:\\n  mode: str  # \\\"cli\\\" or \\\"web\\\"\\n  enable_rich_formatting: bool\\n  show_typing_indicators: bool\\n  input_timeout: int\\n```\\n\\n---\\n\\n## WebSocket API\\n\\n### Client Connection\\n\\nConnect to the streaming server:\\n\\n```javascript\\nconst ws = new WebSocket('ws://localhost:8080');\\n```\\n\\n### Message Types\\n\\n#### Incoming Messages\\n\\n##### Welcome Message\\n```json\\n{\\n  \\\"type\\\": \\\"welcome\\\",\\n  \\\"client_id\\\": \\\"client_123456789\\\",\\n  \\\"server_info\\\": {\\n    \\\"version\\\": \\\"1.0.0\\\",\\n    \\\"features\\\": [\\\"chat\\\", \\\"voting\\\", \\\"real_time\\\"]\\n  }\\n}\\n```\\n\\n##### Chat Message\\n```json\\n{\\n  \\\"type\\\": \\\"message\\\",\\n  \\\"data\\\": {\\n    \\\"sender\\\": \\\"Alice\\\",\\n    \\\"content\\\": \\\"I believe AI will benefit society\\\",\\n    \\\"timestamp\\\": 1640995200.0,\\n    \\\"message_id\\\": 42,\\n    \\\"message_type\\\": \\\"chat\\\"\\n  }\\n}\\n```\\n\\n##### Vote Update\\n```json\\n{\\n  \\\"type\\\": \\\"vote_update\\\",\\n  \\\"data\\\": {\\n    \\\"candidates\\\": [\\\"Alice\\\", \\\"Bob\\\"],\\n    \\\"vote_counts\\\": {\\\"Alice\\\": 5, \\\"Bob\\\": 3},\\n    \\\"total_votes\\\": 8,\\n    \\\"time_remaining\\\": 120,\\n    \\\"is_active\\\": true\\n  }\\n}\\n```\\n\\n#### Outgoing Messages\\n\\n##### Subscribe to Channels\\n```json\\n{\\n  \\\"type\\\": \\\"subscribe\\\",\\n  \\\"channels\\\": [\\\"chat\\\", \\\"voting\\\", \\\"system\\\"]\\n}\\n```\\n\\n##### Cast Vote\\n```json\\n{\\n  \\\"type\\\": \\\"vote\\\",\\n  \\\"voter_id\\\": \\\"viewer_123\\\",\\n  \\\"candidate\\\": \\\"Alice\\\",\\n  \\\"justification\\\": \\\"Most persuasive arguments\\\"\\n}\\n```\\n\\n##### Ping/Pong\\n```json\\n{\\n  \\\"type\\\": \\\"ping\\\"\\n}\\n```\\n\\n---\\n\\n## Performance Considerations\\n\\n### API Rate Limits\\n\\n- OpenAI: Respect rate limits based on your plan\\n- Anthropic: Monitor request quotas\\n- Implement exponential backoff for retries\\n\\n### Memory Management\\n\\n- Chat log automatically limits message history\\n- Conversation history is pruned in bot clients\\n- Streaming connections are cleaned up automatically\\n\\n### Async Best Practices\\n\\nAll I/O operations are async:\\n\\n```python\\n# Correct - awaits async operations\\nresponse = await bot.get_response(topic, messages)\\nawait chat_log.add_message(sender, content)\\n\\n# Incorrect - would block the event loop\\n# response = bot.get_response(topic, messages).result()\\n```\\n\\n---\\n\\n## Testing\\n\\n### Unit Tests\\n\\nRun the test suite:\\n\\n```bash\\npython -m pytest tests/ -v\\n```\\n\\n### Integration Tests\\n\\nTest with real APIs:\\n\\n```bash\\n# Set test API keys\\nexport OPENAI_API_KEY=\\\"test-key\\\"\\nexport ANTHROPIC_API_KEY=\\\"test-key\\\"\\n\\n# Run integration tests\\npython -m pytest tests/integration/ -v\\n```\\n\\n### Mock Testing\\n\\n```python\\nfrom unittest.mock import AsyncMock\\n\\n# Mock bot responses\\nbot.ai_provider.generate_response = AsyncMock(return_value=\\\"Test response\\\")\\nresponse = await bot.get_response(\\\"Test topic\\\", [])\\nassert response == \\\"Test response\\\"\\n```\\n\\n---\\n\\n## Deployment\\n\\n### Docker\\n\\n```dockerfile\\nFROM python:3.9-slim\\n\\nWORKDIR /app\\nCOPY requirements.txt .\\nRUN pip install -r requirements.txt\\n\\nCOPY . .\\nCMD [\\\"python\\\", \\\"-m\\\", \\\"app.main\\\"]\\n```\\n\\n### Environment Variables\\n\\nRequired for production:\\n\\n```bash\\nOPENAI_API_KEY=sk-...\\nANTHROPIC_API_KEY=sk-ant-...\\nLOG_LEVEL=INFO\\nCONFIG_PATH=/app/production_config.yaml\\n```\\n\\n### Health Checks\\n\\n```python\\n# Check system health\\nasync def health_check():\\n    # Test bot connectivity\\n    for bot in bots:\\n        if not await bot.warmup():\\n            return False\\n    \\n    # Test streaming server\\n    if streaming_server and not streaming_server.is_active:\\n        return False\\n    \\n    return True\\n```\\n\\nThis API reference provides comprehensive documentation for integrating with and extending the AI Jubilee Debate System.\"\n        },\n        \"architecture.md\": {\n          \"type\": \"file\",\n          \"path\": \"docs/architecture.md\",\n          \"extension\": \".md\",\n          \"size\": 7424,\n          \"content\": \"# AI Jubilee Debate System Architecture\\n\\n## Overview\\n\\nThe AI Jubilee Debate System is a modular, event-driven platform that facilitates structured debates between AI bots and human participants. The system emphasizes real-time interaction, fair moderation, and comprehensive result tracking.\\n\\n## Core Components\\n\\n### 1. Moderator (`app/moderator.py`)\\n\\nThe central orchestrator of the debate system.\\n\\n**Responsibilities:**\\n- Manage debate phases (introduction, opening statements, discussion, closing statements, voting, results)\\n- Enforce time limits and speaking order\\n- Handle participant timeouts and warnings\\n- Coordinate with voting system\\n- Broadcast messages to all participants\\n\\n**Key Classes:**\\n- `Moderator`: Main orchestration class\\n- `DebatePhase`: Enum defining debate stages\\n- `DebateState`: Current state tracking\\n\\n**Flow Diagram:**\\n```\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\n‚îÇIntroduction ‚îÇ -> ‚îÇOpening Stmts ‚îÇ -> ‚îÇ Discussion  ‚îÇ\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\n                                              ‚îÇ\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\n‚îÇ   Results   ‚îÇ <- ‚îÇ    Voting    ‚îÇ <- ‚îÇClosing Stmts‚îÇ\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\n```\\n\\n### 2. Chat Log (`app/chat_log.py`)\\n\\nThread-safe message management system.\\n\\n**Features:**\\n- Chronological message ordering\\n- Pub/sub message distribution\\n- Message filtering and search\\n- Transcript export (JSON, TXT, HTML)\\n- Statistics tracking\\n\\n**Data Model:**\\n```python\\n@dataclass\\nclass Message:\\n    sender: str\\n    content: str\\n    timestamp: float\\n    message_id: int\\n    message_type: str = \\\"chat\\\"\\n    metadata: Optional[Dict[str, Any]] = None\\n```\\n\\n### 3. Voting System (`app/voting.py`)\\n\\nDemocratic evaluation mechanism for debate performance.\\n\\n**Features:**\\n- Time-limited voting sessions\\n- Multiple export formats\\n- Vote validation and security\\n- Historical tracking\\n- Participation analytics\\n\\n**Voting Flow:**\\n```\\nStart Session -> Accept Votes -> End Session -> Calculate Results\\n     ‚îÇ              ‚îÇ               ‚îÇ              ‚îÇ\\n     v              v               v              v\\nSet Candidates  Validate Vote   Close Voting   Determine Winner\\nSet Duration    Store Vote      Stop Accepting  Export Results\\n```\\n\\n### 4. Participant Clients\\n\\n#### Bot Client (`app/bot_client.py`)\\n\\nAI-powered debate participants.\\n\\n**Supported Providers:**\\n- OpenAI (GPT-3.5, GPT-4)\\n- Anthropic (Claude)\\n- Extensible for additional providers\\n\\n**Key Features:**\\n- Personality-driven responses\\n- Stance-aware argumentation\\n- Response time tracking\\n- Conversation context management\\n- Fallback response handling\\n\\n#### Human Client (`app/human_client.py`)\\n\\nHuman participant interface.\\n\\n**Interface Modes:**\\n- CLI: Terminal-based interaction\\n- Web: WebSocket-based browser interface\\n- API: Programmatic integration\\n\\n**Features:**\\n- Response validation\\n- Timeout handling\\n- Conversation history\\n- Voting participation\\n\\n### 5. Streaming Server (`app/streaming.py`)\\n\\nReal-time broadcast system for live audience.\\n\\n**Capabilities:**\\n- WebSocket connections\\n- Message broadcasting\\n- Vote updates\\n- Client management\\n- Statistics reporting\\n\\n## System Architecture\\n\\n```\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\n‚îÇ                    Moderator                            ‚îÇ\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ\\n‚îÇ  ‚îÇ   Phases    ‚îÇ ‚îÇ   Timing    ‚îÇ ‚îÇ   Rules     ‚îÇ       ‚îÇ\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\n                      ‚îÇ\\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\n    v                 v                 v\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\n‚îÇChat Log  ‚îÇ    ‚îÇ  Voting   ‚îÇ    ‚îÇ  Streaming   ‚îÇ\\n‚îÇ          ‚îÇ    ‚îÇ  System   ‚îÇ    ‚îÇ   Server     ‚îÇ\\n‚îÇ- Messages‚îÇ    ‚îÇ- Sessions ‚îÇ    ‚îÇ- WebSockets  ‚îÇ\\n‚îÇ- History ‚îÇ    ‚îÇ- Results  ‚îÇ    ‚îÇ- Broadcast   ‚îÇ\\n‚îÇ- Export  ‚îÇ    ‚îÇ- Stats    ‚îÇ    ‚îÇ- Clients     ‚îÇ\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\n    v                 v                 v\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\n‚îÇ                Participants                     ‚îÇ\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\\n‚îÇ  ‚îÇ Bot Clients ‚îÇ              ‚îÇHuman Clients‚îÇ   ‚îÇ\\n‚îÇ  ‚îÇ- OpenAI     ‚îÇ              ‚îÇ- CLI        ‚îÇ   ‚îÇ\\n‚îÇ  ‚îÇ- Anthropic  ‚îÇ              ‚îÇ- Web        ‚îÇ   ‚îÇ\\n‚îÇ  ‚îÇ- Custom     ‚îÇ              ‚îÇ- API        ‚îÇ   ‚îÇ\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\n```\\n\\n## Data Flow\\n\\n### Message Flow\\n1. Participant generates response\\n2. Moderator validates and timestamps\\n3. Chat Log stores and distributes\\n4. Streaming Server broadcasts to audience\\n5. Other participants receive for context\\n\\n### Voting Flow\\n1. Moderator initiates voting phase\\n2. Voting System opens session\\n3. Participants cast votes\\n4. System validates and stores votes\\n5. Results calculated and broadcast\\n\\n### Configuration Flow\\n1. Load YAML configuration\\n2. Initialize components with settings\\n3. Create participants based on config\\n4. Start session with configured parameters\\n\\n## Error Handling\\n\\n### Graceful Degradation\\n- API failures trigger fallback responses\\n- Network issues don't crash sessions\\n- Participant timeouts handled smoothly\\n- Voting continues despite individual failures\\n\\n### Monitoring and Logging\\n- Comprehensive error logging\\n- Performance metrics tracking\\n- Participant statistics\\n- System health monitoring\\n\\n## Scalability Considerations\\n\\n### Horizontal Scaling\\n- Multiple debate sessions simultaneously\\n- Load balancing for streaming\\n- Database for persistent storage\\n- Message queue for high throughput\\n\\n### Performance Optimization\\n- Async/await throughout\\n- Connection pooling for APIs\\n- Message batching for efficiency\\n- Resource cleanup and management\\n\\n## Security\\n\\n### Input Validation\\n- Message content sanitization\\n- Participant authentication\\n- Vote integrity verification\\n- Rate limiting protection\\n\\n### Privacy Protection\\n- Anonymous voting options\\n- Conversation encryption\\n- Participant data protection\\n- Audit trail maintenance\\n\\n## Extension Points\\n\\n### Adding New AI Providers\\n1. Implement `AIProvider` interface\\n2. Add configuration options\\n3. Update provider factory\\n4. Test integration\\n\\n### Custom Interfaces\\n1. Implement `HumanInterface` interface\\n2. Handle async message flow\\n3. Add configuration support\\n4. Test user experience\\n\\n### Additional Export Formats\\n1. Extend export methods\\n2. Add format validation\\n3. Update documentation\\n4. Test output quality\\n\\n## Deployment Architecture\\n\\n### Development\\n```\\nLocal Machine\\n‚îú‚îÄ‚îÄ Python Environment\\n‚îú‚îÄ‚îÄ Configuration Files\\n‚îú‚îÄ‚îÄ Test Data\\n‚îî‚îÄ‚îÄ Log Files\\n```\\n\\n### Production\\n```\\nContainer Orchestration\\n‚îú‚îÄ‚îÄ Moderator Service\\n‚îú‚îÄ‚îÄ Bot Client Services\\n‚îú‚îÄ‚îÄ Streaming Service\\n‚îú‚îÄ‚îÄ Web Interface\\n‚îú‚îÄ‚îÄ Database\\n‚îî‚îÄ‚îÄ Message Queue\\n```\\n\\n## Configuration Management\\n\\n### Environment-Specific Settings\\n- Development: Local APIs, debug logging\\n- Staging: Production APIs, info logging\\n- Production: Optimized settings, error logging\\n\\n### Secret Management\\n- API keys in environment variables\\n- Database credentials secured\\n- SSL certificates managed\\n- Rotation policies enforced\\n\\nThis architecture enables a robust, scalable, and extensible debate platform that can accommodate various use cases from small-scale experiments to large public events.\"\n        },\n        \"usage.md\": {\n          \"type\": \"file\",\n          \"path\": \"docs/usage.md\",\n          \"extension\": \".md\",\n          \"size\": 21363,\n          \"content\": \"# AI Jubilee Debate System - Usage Guide\\n\\n## üöÄ Quick Start\\n\\n### Prerequisites\\n1. **Python 3.8+** installed\\n2. **API Keys** for OpenAI and/or Anthropic\\n3. **Dependencies** installed\\n\\n### Setup Steps\\n\\n1. **Clone or download the project**\\n2. **Install dependencies:**\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n3. **Set up your API keys in `.env` file:**\\n   ```bash\\n   # Create .env file in project root\\n   OPENAI_API_KEY=sk-your-openai-key-here\\n   ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\\n   ```\\n\\n4. **Run the debate:**\\n   ```bash\\n   # Recommended: Use the simple launcher\\n   python run_debate.py\\n   \\n   # Alternative: Use the module directly\\n   python -m app.main\\n   ```\\n\\n## üé≠ Debate Modes\\n\\n### **Autonomous Mode** (Default - Recommended!)\\n\\nIn autonomous mode, bots monitor the conversation and decide when to speak, creating a natural, organic debate flow.\\n\\n#### How Autonomous Mode Works:\\n- ü§ñ **Bots run in parallel**, continuously monitoring chat\\n- üß† **Intelligent decision making** - bots decide when they feel compelled to respond\\n- üìö **Full conversation history** available to all participants\\n- üéØ **Smart triggers** - bots respond to mentions, challenges, or opportunities\\n- ‚è∞ **Cooldown system** prevents spam (15-45 second intervals)\\n- üó£Ô∏è **Humans can speak anytime** during discussion phase\\n\\n#### Configuration:\\n```yaml\\ndebate:\\n  mode: \\\"autonomous\\\"  # Enable autonomous mode\\n  min_bot_cooldown: 15         # Minimum seconds between bot responses\\n  max_bot_cooldown: 45         # Maximum cooldown for active bots  \\n  message_check_interval: 5    # How often bots check for new messages\\n  silence_timeout: 60          # Moderator intervenes after silence\\n```\\n\\n#### Example Autonomous Flow:\\n```\\nüé≠ Moderator: \\\"Autonomous Discussion Phase Begin!\\\"\\nü§ñ Advocate: \\\"Remote work increases productivity by 40%...\\\"\\nüí≠ Skeptic is thinking about responding...\\nü§ñ Skeptic: \\\"But what about the collaboration costs?\\\"\\nüë§ Human: \\\"I've experienced both - here's my take...\\\"\\nüí≠ Socrates is thinking about responding...  \\nü§ñ Socrates: \\\"What evidence supports these productivity claims?\\\"\\nüéØ Moderator: \\\"What about environmental implications?\\\"\\nüí≠ Advocate is thinking about responding...\\nü§ñ Advocate: \\\"Great point - remote work cuts commuting emissions...\\\"\\n```\\n\\n### **Sequential Mode** (Traditional)\\n\\nParticipants take turns in a structured order. More predictable but less dynamic.\\n\\n```yaml\\ndebate:\\n  mode: \\\"sequential\\\"  # Traditional turn-based mode\\n```\\n\\n## üéØ Human Participation in Autonomous Mode\\n\\n### **During Discussion Phase:**\\n- ‚úÖ **Speak anytime** - no waiting for turns!\\n- ‚úÖ **Type naturally** - just enter your response\\n- ‚úÖ **Full context** - see all previous messages\\n- ‚úÖ **Real-time** - immediate feedback from bots\\n\\n### **Available Commands:**\\n```\\nüí¨ [your message]     # Join the debate with your response\\nhelp                  # Show help information\\nstatus                # Show your participation statistics\\nhistory               # Show recent conversation\\nquit                  # Leave the debate\\n```\\n\\n### **Example Human Session:**\\n```\\nüéØ AUTONOMOUS DEBATE MODE ACTIVE\\nüó£Ô∏è You can speak at ANY TIME during the discussion!\\nüí° Commands: 'help', 'status', 'history', 'quit'\\n\\nü§ñ Advocate: \\\"Remote work is clearly the future because...\\\"\\nü§ñ Skeptic: \\\"I disagree - here's why remote work fails...\\\"\\n\\nüí¨ Type your response: I think both perspectives miss the point about hybrid work...\\n‚úÖ Your message has been added to the debate!\\n\\nüí≠ Socrates is thinking about responding...\\nü§ñ Socrates: \\\"Interesting point about hybrid - can you elaborate?\\\"\\n\\nüí¨ Type your response: status\\nüìä Your participation: 1 responses, 100.0% participation rate, avg response time: 12.3s\\n\\nüí¨ Type your response: Sure! Hybrid work combines the best of both...\\n‚úÖ Your message has been added to the debate!\\n```\\n\\n## üìã Debate Phases\\n\\n### **1. Introduction Phase**\\n- Moderator introduces topic and participants\\n- Overview of rules and format\\n- Duration: ~2 minutes\\n\\n### **2. Opening Statements Phase** \\n- Each participant gives structured opening statement\\n- **Sequential order** (even in autonomous mode)\\n- Time limit: 120 seconds per participant\\n\\n### **3. Discussion Phase**\\n\\n#### **Autonomous Mode:**\\n- üîÑ **Free-flowing conversation**\\n- ü§ñ **Bots monitor and respond intelligently** \\n- üë• **Humans can jump in anytime**\\n- üéØ **Moderator provides prompts during silence**\\n- ‚è∞ **Total time: 30 minutes** (configurable)\\n\\n#### **Sequential Mode:**\\n- üîÑ **Round-robin turns**\\n- ‚è∞ **60 seconds per response**\\n- üìù **Structured format**\\n\\n### **4. Closing Statements Phase**\\n- Final arguments from each participant\\n- **Sequential order** \\n- Time limit: 90 seconds per participant\\n\\n### **5. Voting Phase**\\n- Participants and audience vote for most persuasive\\n- Duration: 5 minutes\\n- Optional justification required\\n\\n### **6. Results Phase**\\n- Vote tallies and winner announcement\\n- Final statistics and transcript saving\\n\\n## ‚öôÔ∏è Configuration Options\\n\\n### **Bot Personalities**\\n\\n```yaml\\nbots:\\n  - name: \\\"Socrates\\\"\\n    personality: \\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\"\\n    stance: \\\"neutral\\\"\\n    \\n  - name: \\\"Advocate\\\"  \\n    personality: \\\"Passionate supporter, data-driven, persuasive. Jumps in when position is challenged.\\\"\\n    stance: \\\"pro\\\"\\n    \\n  - name: \\\"Skeptic\\\"\\n    personality: \\\"Critical thinker, questions assumptions. Responds when claims need scrutiny.\\\"\\n    stance: \\\"con\\\"\\n```\\n\\n### **Timing Controls**\\n\\n```yaml\\ndebate:\\n  time_limit_minutes: 30        # Total discussion time\\n  opening_statement_time: 120   # Opening statement duration\\n  response_time: 60            # Response time in sequential mode\\n  closing_statement_time: 90   # Closing statement duration\\n  \\n  # Autonomous mode specific\\n  min_bot_cooldown: 15         # Minimum bot response interval\\n  max_bot_cooldown: 45         # Maximum bot cooldown\\n  silence_timeout: 60          # Silence before moderator intervenes\\n```\\n\\n### **Interface Options**\\n\\n```yaml\\ninterface:\\n  mode: \\\"cli\\\"                  # CLI or web interface\\n  enable_rich_formatting: true # Colored/formatted output\\n  show_typing_indicators: true # Show when bots are thinking\\n  enable_reactions: true       # Enable emoji reactions\\n```\\n\\n## üéõÔ∏è Advanced Usage\\n\\n### **Command Line Options**\\n\\n```bash\\n# Basic usage\\npython run_debate.py\\n\\n# Using the module with options\\npython -m app.main --topic \\\"AI ethics\\\" --bots 3 --humans 2\\n\\n# Custom configuration\\npython -m app.main --config custom_config.yaml\\n\\n# Web interface mode\\npython -m app.main --interface web\\n```\\n\\n### **Custom Topics**\\n\\nAdd to `config.yaml`:\\n```yaml\\ntopics:\\n  - \\\"Your custom debate topic here\\\"\\n  - \\\"Another interesting topic\\\"\\n```\\n\\nOr specify directly:\\n```bash\\npython -m app.main --topic \\\"Custom topic\\\"\\n```\\n\\n### **Bot Configuration**\\n\\nCreate custom bots in `config.yaml`:\\n```yaml\\nbots:\\n  - name: \\\"MyBot\\\"\\n    model: \\\"gpt-4\\\"\\n    provider: \\\"openai\\\"\\n    personality: \\\"Your custom personality description\\\"\\n    stance: \\\"pro\\\"  # or \\\"con\\\" or \\\"neutral\\\"\\n```\\n\\n## üîß Troubleshooting\\n\\n### **Common Issues**\\n\\n**API Key Errors:**\\n```bash\\n# Check your .env file format\\nOPENAI_API_KEY=sk-your-key  # No quotes, no export\\nANTHROPIC_API_KEY=sk-ant-your-key\\n```\\n\\n**Import Errors:**\\n```bash\\n# Make sure you're in the project root directory\\ncd ai_jubilee_debate\\npython run_debate.py\\n```\\n\\n**Timeout Issues:**\\n```bash\\n# Check internet connection and API status\\n# Increase timeouts in config.yaml if needed\\n```\\n\\n### **Debug Mode**\\n\\nEnable detailed logging:\\n```yaml\\nchat:\\n  log_level: \\\"DEBUG\\\"\\n```\\n\\nOr set environment variable:\\n```bash\\nexport LOG_LEVEL=DEBUG\\npython run_debate.py\\n```\\n\\n### **Saving Transcripts**\\n\\nTranscripts are automatically saved after each debate:\\n```yaml\\nchat:\\n  save_transcripts: true\\n  transcript_format: \\\"json\\\"  # or \\\"txt\\\" or \\\"html\\\"\\n```\\n\\nFiles saved as: `debate_YYYY-MM-DD_HH-MM-SS.json`\\n\\n## üé™ Tips for Great Debates\\n\\n### **For Humans:**\\n- üéØ **Jump in naturally** during autonomous mode\\n- üìä **Reference specific points** made by others\\n- üí° **Provide evidence** and examples\\n- ü§ù **Be respectful** but persuasive\\n- ‚ö° **Keep responses focused** and substantial\\n\\n### **Bot Optimization:**\\n- üé≠ **Diverse personalities** create better dynamics\\n- ‚öñÔ∏è **Balanced stances** (pro/con/neutral mix)\\n- üß† **Different models** (GPT-4, Claude, etc.) for variety\\n- ‚è∞ **Appropriate cooldowns** prevent spam\\n\\n### **Moderator Settings:**\\n- üéØ **Topic-specific prompts** keep discussion flowing\\n- ‚è∞ **Reasonable timeouts** balance pace and depth\\n- üí¨ **Silence intervention** maintains engagement\\n\\n## üìä Monitoring and Analytics\\n\\n### **Real-time Stats**\\n```\\n# During debate, type 'status' to see:\\nüìä Your participation: 3 responses, 75% participation rate\\n‚è±Ô∏è Average response time: 15.2 seconds\\nüí¨ Conversation length: 24 messages\\n```\\n\\n### **Post-Debate Analysis**\\n- üìà Participation rates per participant\\n- ‚è∞ Response time analytics  \\n- üó≥Ô∏è Voting results and justifications\\n- üìù Full transcript with timestamps\\n\\n## üöÄ Performance Tips\\n\\n### **For Better Performance:**\\n- Use **GPT-3.5** for faster, cheaper responses\\n- Set **reasonable cooldowns** (15-30 seconds)\\n- Limit **conversation history** for speed\\n- Use **async mode** for responsiveness\\n\\n### **For Higher Quality:**\\n- Use **GPT-4** or **Claude** for better reasoning\\n- Increase **response time limits**\\n- Enable **detailed logging** for analysis\\n- Create **specific bot personalities**\\n\\n## üåü Advanced Features\\n\\n### **Real-time Streaming**\\nEnable WebSocket streaming for live audiences:\\n```yaml\\nstreaming:\\n  enabled: true\\n  websocket_port: 8080\\n  max_connections: 100\\n```\\n\\n### **Voting System**\\nComprehensive voting with justifications:\\n```yaml\\nvoting:\\n  enabled: true\\n  voting_duration: 300\\n  require_justification: true\\n  anonymous_votes: false\\n```\\n\\n### **Web Interface**\\nFor browser-based participation:\\n```yaml\\ninterface:\\n  mode: \\\"web\\\"\\n  websocket_port: 8080\\n```\\n\\n## üìÅ File Structure\\n\\n```\\nai_jubilee_debate/\\n‚îú‚îÄ‚îÄ .env                    # Your API keys (never commit!)\\n‚îú‚îÄ‚îÄ .env.example           # Example environment file\\n‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns\\n‚îú‚îÄ‚îÄ config.yaml            # Main configuration\\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\\n‚îú‚îÄ‚îÄ run_debate.py          # Simple launcher script\\n‚îú‚îÄ‚îÄ app/                   # Core application\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package initialization\\n‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Main entry point\\n‚îÇ   ‚îú‚îÄ‚îÄ moderator.py      # Debate moderation logic\\n‚îÇ   ‚îú‚îÄ‚îÄ bot_client.py     # AI bot participants\\n‚îÇ   ‚îú‚îÄ‚îÄ human_client.py   # Human participants\\n‚îÇ   ‚îú‚îÄ‚îÄ chat_log.py       # Message management\\n‚îÇ   ‚îú‚îÄ‚îÄ voting.py         # Voting system\\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions\\n‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # WebSocket streaming\\n‚îú‚îÄ‚îÄ tests/                 # Test suite\\n‚îÇ   ‚îú‚îÄ‚îÄ test_moderator.py\\n‚îÇ   ‚îú‚îÄ‚îÄ test_voting.py\\n‚îÇ   ‚îú‚îÄ‚îÄ test_chat_log.py\\n‚îÇ   ‚îú‚îÄ‚îÄ test_bot_client.py\\n‚îÇ   ‚îî‚îÄ‚îÄ test_human_client.py\\n‚îî‚îÄ‚îÄ docs/                  # Documentation\\n    ‚îú‚îÄ‚îÄ architecture.md    # System architecture\\n    ‚îú‚îÄ‚îÄ usage.md          # This file\\n    ‚îî‚îÄ‚îÄ api_reference.md  # API documentation\\n```\\n\\n## üÜò Getting Help\\n\\n### **Built-in Help**\\n```bash\\n# During debate\\nhelp                    # Show autonomous mode help\\nstatus                  # Show participation stats\\nhistory                 # Show recent messages\\n\\n# Command line\\npython -m app.main --help   # Show CLI options\\n```\\n\\n### **Common Commands**\\n```bash\\n# Run with debug logging\\nLOG_LEVEL=DEBUG python run_debate.py\\n\\n# Run tests\\npython -m pytest tests/ -v\\n\\n# Check configuration\\npython -c \\\"from app.utils import load_config; print(load_config())\\\"\\n```\\n\\nThis autonomous debate system creates truly organic, intelligent conversations between AI participants while allowing humans to jump in naturally whenever they feel inspired to contribute! üé≠ü§ñ# AI Jubilee Debate System Usage Guide\\n\\n## Quick Start\\n\\n### Installation\\n\\n1. **Clone the repository:**\\n   ```bash\\n   git clone <repository-url>\\n   cd ai_jubilee_debate\\n   ```\\n\\n2. **Install dependencies:**\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n3. **Set up environment variables:**\\n   ```bash\\n   export OPENAI_API_KEY=\\\"your-openai-api-key\\\"\\n   export ANTHROPIC_API_KEY=\\\"your-anthropic-api-key\\\"\\n   ```\\n\\n4. **Run your first debate:**\\n   ```bash\\n   python -m app.main\\n   ```\\n\\n## Configuration\\n\\n### Basic Configuration (`config.yaml`)\\n\\n```yaml\\ndebate:\\n  default_topic: \\\"AI will create more jobs than it destroys\\\"\\n  max_participants: 4\\n  time_limit_minutes: 20\\n\\nbots:\\n  - name: \\\"Advocate\\\"\\n    model: \\\"gpt-4\\\"\\n    provider: \\\"openai\\\" \\n    stance: \\\"pro\\\"\\n  - name: \\\"Skeptic\\\"\\n    model: \\\"claude-3-sonnet\\\"\\n    provider: \\\"anthropic\\\"\\n    stance: \\\"con\\\"\\n\\nvoting:\\n  enabled: true\\n  voting_duration: 180\\n```\\n\\n### Advanced Configuration Options\\n\\n#### Timing Settings\\n```yaml\\ndebate:\\n  opening_statement_time: 120  # seconds\\n  response_time: 60\\n  closing_statement_time: 90\\n  warning_time: 45  # warning before timeout\\n```\\n\\n#### Bot Personalities\\n```yaml\\nbots:\\n  - name: \\\"Philosopher\\\"\\n    personality: \\\"Thoughtful, asks probing questions\\\"\\n    debate_style: \\\"socratic\\\"\\n    temperature: 0.8\\n    max_tokens: 250\\n```\\n\\n#### Human Interface\\n```yaml\\ninterface:\\n  mode: \\\"cli\\\"  # or \\\"web\\\"\\n  enable_rich_formatting: true\\n  show_typing_indicators: true\\n  input_timeout: 120\\n```\\n\\n## Running Debates\\n\\n### Command Line Interface\\n\\n#### Basic Usage\\n```bash\\n# Run with default settings\\npython -m app.main\\n\\n# Specify topic\\npython -m app.main --topic \\\"Universal Basic Income is necessary\\\"\\n\\n# Set participant counts\\npython -m app.main --bots 3 --humans 2\\n\\n# Use custom config\\npython -m app.main --config custom_config.yaml\\n```\\n\\n#### Advanced Options\\n```bash\\n# Full command with all options\\npython -m app.main \\\\\\n  --topic \\\"Climate change requires immediate action\\\" \\\\\\n  --bots 2 \\\\\\n  --humans 1 \\\\\\n  --config production_config.yaml\\n```\\n\\n### Programmatic Usage\\n\\n#### Simple Session\\n```python\\nfrom app.main import start_debate_session\\n\\n# Start a basic debate\\nawait start_debate_session(\\n    topic=\\\"The future of remote work\\\",\\n    ai_bots=2,\\n    human_participants=1\\n)\\n```\\n\\n#### Custom Session\\n```python\\nfrom app import Moderator, BotClient, HumanClient, ChatLog, VotingSystem\\n\\n# Create components\\nchat_log = ChatLog()\\nvoting_system = VotingSystem({'enabled': True})\\n\\n# Create participants\\nbot = BotClient(\\n    name=\\\"Analyst\\\",\\n    model=\\\"gpt-4\\\",\\n    provider=\\\"openai\\\",\\n    personality=\\\"Data-driven and analytical\\\",\\n    stance=\\\"neutral\\\",\\n    api_key=\\\"your-api-key\\\"\\n)\\n\\nhuman = HumanClient(\\n    name=\\\"Participant1\\\",\\n    interface_config={'mode': 'cli'}\\n)\\n\\n# Create moderator and run\\nmoderator = Moderator(\\n    topic=\\\"AI Ethics in Healthcare\\\",\\n    participants=[bot, human],\\n    chat_log=chat_log,\\n    voting_system=voting_system,\\n    config={'time_limit_minutes': 15}\\n)\\n\\nresults = await moderator.run_debate()\\n```\\n\\n## Participant Management\\n\\n### AI Bot Configuration\\n\\n#### Creating Custom Bots\\n```python\\n# Argumentative bot\\naggressive_bot = BotClient(\\n    name=\\\"Debater\\\",\\n    model=\\\"gpt-4\\\",\\n    provider=\\\"openai\\\", \\n    personality=\\\"Aggressive, uses strong rhetoric\\\",\\n    stance=\\\"pro\\\",\\n    temperature=0.9,  # More creative\\n    api_key=api_key\\n)\\n\\n# Analytical bot\\nanalytical_bot = BotClient(\\n    name=\\\"Researcher\\\", \\n    model=\\\"claude-3-sonnet\\\",\\n    provider=\\\"anthropic\\\",\\n    personality=\\\"Fact-focused, cites evidence\\\",\\n    stance=\\\"con\\\",\\n    temperature=0.3,  # More conservative\\n    api_key=api_key\\n)\\n```\\n\\n#### Bot Personality Examples\\n```yaml\\npersonalities:\\n  socratic: \\\"Asks probing questions, seeks deeper understanding\\\"\\n  advocate: \\\"Passionate, uses emotional appeals and personal stories\\\"  \\n  scientist: \\\"Data-driven, cites studies and statistics\\\"\\n  philosopher: \\\"Abstract thinking, explores ethical implications\\\"\\n  pragmatist: \\\"Focuses on practical implementation and real-world effects\\\"\\n  skeptic: \\\"Questions assumptions, plays devil's advocate\\\"\\n```\\n\\n### Human Interface Options\\n\\n#### CLI Mode (Default)\\n- Terminal-based interaction\\n- Rich formatting with colors\\n- Real-time message display\\n- Keyboard input for responses\\n\\n#### Web Mode \\n```python\\nhuman = HumanClient(\\n    name=\\\"WebUser\\\",\\n    interface_config={\\n        'mode': 'web',\\n        'enable_reactions': True,\\n        'show_typing_indicators': True\\n    }\\n)\\n```\\n\\n## Debate Topics\\n\\n### Predefined Topics\\nThe system includes several built-in topics:\\n- \\\"AI will create more jobs than it destroys\\\"\\n- \\\"Social media has a net positive impact on democracy\\\"\\n- \\\"Universal Basic Income is necessary for the future economy\\\"\\n- \\\"Climate change requires immediate radical action\\\"\\n- \\\"Privacy is more important than security\\\"\\n\\n### Custom Topics\\n```python\\n# Define your own topics\\ncustom_topics = [\\n    \\\"Cryptocurrency will replace traditional banking\\\",\\n    \\\"Space exploration should be publicly funded\\\",\\n    \\\"Genetic engineering should be available to all\\\",\\n    \\\"Automation will eliminate the need for human work\\\"\\n]\\n\\n# Use in configuration\\nconfig['topics'] = custom_topics\\n```\\n\\n### Topic Guidelines\\n- Keep topics debatable (not factual statements)\\n- Ensure both sides can be reasonably argued\\n- Make them relevant to your audience\\n- Consider current events and trends\\n\\n## Voting and Results\\n\\n### Voting Configuration\\n```yaml\\nvoting:\\n  enabled: true\\n  voting_duration: 300  # 5 minutes\\n  allow_participant_voting: true\\n  require_justification: true\\n  anonymous_votes: false\\n```\\n\\n### Accessing Results\\n```python\\n# After debate completion\\nresults = await moderator.run_debate()\\n\\nprint(f\\\"Winner: {results['winner']}\\\")\\nprint(f\\\"Vote breakdown: {results['vote_counts']}\\\")\\n\\n# Export detailed results\\nawait voting_system.export_results('json')\\n```\\n\\n### Results Analysis\\n```python\\n# Get participant performance\\nfor participant in participants:\\n    performance = voting_system.get_candidate_performance(participant.name)\\n    print(f\\\"{participant.name}: {performance['win_rate']:.1%} win rate\\\")\\n```\\n\\n## Live Streaming\\n\\n### Enable Streaming\\n```yaml\\nstreaming:\\n  enabled: true\\n  websocket_port: 8080\\n  max_connections: 100\\n  broadcast_votes: true\\n```\\n\\n### Streaming Server\\n```python\\nfrom app.streaming import StreamingServer\\n\\n# Create streaming server\\nstreaming = StreamingServer(\\n    chat_log=chat_log,\\n    voting_system=voting_system,\\n    config=streaming_config\\n)\\n\\nawait streaming.start()\\n# Server runs on localhost:8080\\n```\\n\\n### Client Connection\\n```javascript\\n// Connect to stream\\nconst ws = new WebSocket('ws://localhost:8080');\\n\\nws.onmessage = function(event) {\\n    const data = JSON.parse(event.data);\\n    \\n    if (data.type === 'message') {\\n        displayMessage(data.data);\\n    } else if (data.type === 'vote_update') {\\n        updateVoteDisplay(data.data);\\n    }\\n};\\n```\\n\\n## Data Export and Analysis\\n\\n### Transcript Export\\n```python\\n# Save debate transcript\\nawait chat_log.save_transcript(\\\"debate_2024.json\\\", \\\"json\\\")\\nawait chat_log.save_transcript(\\\"debate_2024.txt\\\", \\\"txt\\\") \\nawait chat_log.save_transcript(\\\"debate_2024.html\\\", \\\"html\\\")\\n```\\n\\n### Statistics and Analytics\\n```python\\n# Chat statistics\\nstats = chat_log.get_statistics()\\nprint(f\\\"Total messages: {stats['total_messages']}\\\")\\nprint(f\\\"Average per minute: {stats['messages_per_minute']:.1f}\\\")\\n\\n# Participant statistics  \\nfor participant in participants:\\n    stats = participant.get_stats()\\n    print(f\\\"{participant.name}: {stats}\\\")\\n```\\n\\n### Voting Analysis\\n```python\\n# Export voting data\\ncsv_data = await voting_system.export_results('csv')\\ntxt_report = await voting_system.export_results('txt')\\n\\n# Historical analysis\\nhistory = voting_system.vote_history\\nfor session in history:\\n    print(f\\\"Session: {session['timestamp']}\\\")\\n    print(f\\\"Winner: {session['results'].winner}\\\")\\n```\\n\\n## Troubleshooting\\n\\n### Common Issues\\n\\n#### API Key Problems\\n```bash\\n# Check environment variables\\necho $OPENAI_API_KEY\\necho $ANTHROPIC_API_KEY\\n\\n# Set them if missing\\nexport OPENAI_API_KEY=\\\"sk-...\\\"\\nexport ANTHROPIC_API_KEY=\\\"sk-ant-...\\\"\\n```\\n\\n#### Connection Issues\\n```python\\n# Test bot connectivity\\nbot = BotClient(...)\\nsuccess = await bot.warmup()\\nif not success:\\n    print(\\\"Bot connection failed\\\")\\n```\\n\\n#### Performance Issues\\n```yaml\\n# Reduce timeouts for faster sessions\\ndebate:\\n  opening_statement_time: 60\\n  response_time: 30\\n  closing_statement_time: 45\\n\\n# Limit message history\\nchat:\\n  max_message_length: 300\\n```\\n\\n### Debug Mode\\n```bash\\n# Enable debug logging\\npython -m app.main --config debug_config.yaml\\n```\\n\\n```yaml\\n# debug_config.yaml\\nchat:\\n  log_level: \\\"DEBUG\\\"\\n  save_transcripts: true\\n```\\n\\n### Error Recovery\\n```python\\n# Handle errors gracefully\\ntry:\\n    results = await moderator.run_debate()\\nexcept Exception as e:\\n    print(f\\\"Debate error: {e}\\\")\\n    # Save partial transcript\\n    await chat_log.save_transcript(\\\"error_recovery.json\\\")\\n```\\n\\n## Best Practices\\n\\n### Bot Configuration\\n- Use different personalities for variety\\n- Balance pro/con/neutral stances\\n- Test API connections before debates\\n- Monitor response times and adjust timeouts\\n\\n### Topic Selection\\n- Choose engaging, relevant topics\\n- Ensure balanced argumentation potential\\n- Test topics with different participant mixes\\n- Update topics regularly for freshness\\n\\n### Session Management\\n- Start with shorter sessions for testing\\n- Monitor participant engagement\\n- Save transcripts for analysis\\n- Review voting patterns for improvements\\n\\n### Performance Optimization\\n- Use appropriate API models for your needs\\n- Set reasonable timeouts\\n- Limit concurrent API calls\\n- Monitor system resources\\n\\nThis guide covers the core functionality of the AI Jubilee Debate System. For detailed API documentation, see [api_reference.md](api_reference.md).\"\n        }\n      }\n    },\n    \"tests\": {\n      \"type\": \"directory\",\n      \"contents\": {\n        \"test_bot_client.py\": {\n          \"type\": \"file\",\n          \"path\": \"tests/test_bot_client.py\",\n          \"extension\": \".py\",\n          \"size\": 15292,\n          \"content\": \"\\\"\\\"\\\"\\nTests for the BotClient class.\\n\\\"\\\"\\\"\\n\\nimport pytest\\nimport asyncio\\nfrom unittest.mock import Mock, AsyncMock, patch\\nfrom app.bot_client import BotClient, BotConfig, OpenAIProvider, AnthropicProvider\\nfrom app.chat_log import Message\\n\\n\\n@pytest.fixture\\ndef bot_config():\\n    \\\"\\\"\\\"Create test bot configuration.\\\"\\\"\\\"\\n    return {\\n        'name': 'TestBot',\\n        'model': 'gpt-3.5-turbo',\\n        'provider': 'openai',\\n        'personality': 'Analytical and thoughtful',\\n        'stance': 'pro',\\n        'api_key': 'test-api-key'\\n    }\\n\\n\\n@pytest.fixture\\ndef bot_client(bot_config):\\n    \\\"\\\"\\\"Create test bot client.\\\"\\\"\\\"\\n    return BotClient(**bot_config)\\n\\n\\n@pytest.fixture\\ndef sample_messages():\\n    \\\"\\\"\\\"Create sample messages for testing.\\\"\\\"\\\"\\n    return [\\n        Message(\\\"Alice\\\", \\\"What do you think about AI?\\\", 1640995200.0, 1),\\n        Message(\\\"moderator\\\", \\\"Please respond\\\", 1640995210.0, 2, \\\"moderator\\\")\\n    ]\\n\\n\\nclass TestBotConfig:\\n    \\\"\\\"\\\"Test suite for BotConfig dataclass.\\\"\\\"\\\"\\n\\n    def test_bot_config_creation(self):\\n        \\\"\\\"\\\"Test creating bot configuration.\\\"\\\"\\\"\\n        config = BotConfig(\\n            name=\\\"TestBot\\\",\\n            model=\\\"gpt-4\\\",\\n            provider=\\\"openai\\\",\\n            personality=\\\"Analytical\\\",\\n            stance=\\\"pro\\\"\\n        )\\n\\n        assert config.name == \\\"TestBot\\\"\\n        assert config.model == \\\"gpt-4\\\"\\n        assert config.provider == \\\"openai\\\"\\n        assert config.personality == \\\"Analytical\\\"\\n        assert config.stance == \\\"pro\\\"\\n        assert config.temperature == 0.7  # Default value\\n        assert config.max_tokens == 300  # Default value\\n\\n\\nclass TestBotClient:\\n    \\\"\\\"\\\"Test suite for BotClient class.\\\"\\\"\\\"\\n\\n    def test_bot_client_initialization(self, bot_config):\\n        \\\"\\\"\\\"Test bot client initialization.\\\"\\\"\\\"\\n        bot = BotClient(**bot_config)\\n\\n        assert bot.name == \\\"TestBot\\\"\\n        assert bot.config.model == \\\"gpt-3.5-turbo\\\"\\n        assert bot.config.provider == \\\"openai\\\"\\n        assert isinstance(bot.ai_provider, OpenAIProvider)\\n        assert bot.response_count == 0\\n        assert bot.conversation_history == []\\n\\n    def test_bot_client_with_anthropic(self):\\n        \\\"\\\"\\\"Test bot client with Anthropic provider.\\\"\\\"\\\"\\n        bot = BotClient(\\n            name=\\\"AnthropicBot\\\",\\n            model=\\\"claude-3-sonnet\\\",\\n            provider=\\\"anthropic\\\",\\n            personality=\\\"Balanced\\\",\\n            stance=\\\"neutral\\\",\\n            api_key=\\\"test-key\\\"\\n        )\\n\\n        assert isinstance(bot.ai_provider, AnthropicProvider)\\n\\n    def test_bot_client_unsupported_provider(self):\\n        \\\"\\\"\\\"Test bot client with unsupported provider.\\\"\\\"\\\"\\n        with pytest.raises(ValueError, match=\\\"Unsupported AI provider\\\"):\\n            BotClient(\\n                name=\\\"TestBot\\\",\\n                model=\\\"test-model\\\",\\n                provider=\\\"unsupported\\\",\\n                personality=\\\"Test\\\",\\n                stance=\\\"pro\\\",\\n                api_key=\\\"test-key\\\"\\n            )\\n\\n    @pytest.mark.asyncio\\n    async def test_get_response_success(self, bot_client, sample_messages):\\n        \\\"\\\"\\\"Test successful response generation.\\\"\\\"\\\"\\n        # Mock the AI provider\\n        mock_response = \\\"I think AI has great potential for society.\\\"\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=mock_response)\\n\\n        response = await bot_client.get_response(\\\"AI in society\\\", sample_messages)\\n\\n        assert response == mock_response\\n        assert bot_client.response_count == 1\\n        assert len(bot_client.conversation_history) == 1\\n        assert bot_client.stats['responses_generated'] == 1\\n\\n    @pytest.mark.asyncio\\n    async def test_get_response_with_error(self, bot_client, sample_messages):\\n        \\\"\\\"\\\"Test response generation with API error.\\\"\\\"\\\"\\n        # Mock the AI provider to raise an exception\\n        bot_client.ai_provider.generate_response = AsyncMock(\\n            side_effect=Exception(\\\"API Error\\\")\\n        )\\n\\n        response = await bot_client.get_response(\\\"AI in society\\\", sample_messages)\\n\\n        # Should return fallback response\\n        assert isinstance(response, str)\\n        assert len(response) > 0\\n        assert bot_client.stats['errors'] == 1\\n\\n    def test_prepare_messages(self, bot_client, sample_messages):\\n        \\\"\\\"\\\"Test message preparation for AI model.\\\"\\\"\\\"\\n        messages = bot_client._prepare_messages(\\\"AI topic\\\", sample_messages)\\n\\n        assert len(messages) >= 1  # At least system message\\n        assert messages[0]['role'] == 'system'\\n        assert \\\"AI topic\\\" in messages[0]['content']\\n        assert \\\"TestBot\\\" in messages[0]['content']\\n\\n    def test_create_system_prompt_pro_stance(self, bot_client):\\n        \\\"\\\"\\\"Test system prompt creation for pro stance.\\\"\\\"\\\"\\n        prompt = bot_client._create_system_prompt(\\\"AI is beneficial\\\")\\n\\n        assert \\\"TestBot\\\" in prompt\\n        assert \\\"AI is beneficial\\\" in prompt\\n        assert \\\"Analytical and thoughtful\\\" in prompt\\n        assert \\\"IN FAVOR\\\" in prompt\\n\\n    def test_create_system_prompt_con_stance(self):\\n        \\\"\\\"\\\"Test system prompt creation for con stance.\\\"\\\"\\\"\\n        bot = BotClient(\\n            name=\\\"ConBot\\\",\\n            model=\\\"gpt-3.5-turbo\\\",\\n            provider=\\\"openai\\\",\\n            personality=\\\"Critical\\\",\\n            stance=\\\"con\\\",\\n            api_key=\\\"test-key\\\"\\n        )\\n\\n        prompt = bot._create_system_prompt(\\\"AI topic\\\")\\n        assert \\\"AGAINST\\\" in prompt\\n\\n    def test_create_system_prompt_neutral_stance(self):\\n        \\\"\\\"\\\"Test system prompt creation for neutral stance.\\\"\\\"\\\"\\n        bot = BotClient(\\n            name=\\\"NeutralBot\\\",\\n            model=\\\"gpt-3.5-turbo\\\",\\n            provider=\\\"openai\\\",\\n            personality=\\\"Balanced\\\",\\n            stance=\\\"neutral\\\",\\n            api_key=\\\"test-key\\\"\\n        )\\n\\n        prompt = bot._create_system_prompt(\\\"AI topic\\\")\\n        assert \\\"balanced perspectives\\\" in prompt\\n\\n    def test_generate_fallback_response(self, bot_client):\\n        \\\"\\\"\\\"Test fallback response generation.\\\"\\\"\\\"\\n        response = bot_client._generate_fallback_response(\\\"AI topic\\\")\\n\\n        assert isinstance(response, str)\\n        assert len(response) > 0\\n        assert \\\"AI topic\\\" in response or \\\"perspective\\\" in response.lower()\\n\\n    @pytest.mark.asyncio\\n    async def test_receive_message(self, bot_client):\\n        \\\"\\\"\\\"Test receiving a message.\\\"\\\"\\\"\\n        message = Message(\\\"Alice\\\", \\\"Hello bot\\\", 1640995200.0, 1)\\n\\n        await bot_client.receive_message(message)\\n\\n        # Should be added to conversation history\\n        assert len(bot_client.conversation_history) == 1\\n        assert \\\"Alice: Hello bot\\\" in bot_client.conversation_history[0]['content']\\n\\n        # Message queue should have the message\\n        queued_message = await bot_client.message_queue.get()\\n        assert queued_message == message\\n\\n    @pytest.mark.asyncio\\n    async def test_receive_own_message(self, bot_client):\\n        \\\"\\\"\\\"Test receiving own message (should not be added to history).\\\"\\\"\\\"\\n        message = Message(\\\"TestBot\\\", \\\"My own message\\\", 1640995200.0, 1)\\n\\n        await bot_client.receive_message(message)\\n\\n        # Should not be added to conversation history\\n        assert len(bot_client.conversation_history) == 0\\n\\n    def test_update_stats_success(self, bot_client):\\n        \\\"\\\"\\\"Test updating statistics on success.\\\"\\\"\\\"\\n        bot_client._update_stats(1.5, success=True)\\n\\n        assert bot_client.stats['responses_generated'] == 1\\n        assert bot_client.stats['average_response_time'] == 1.5\\n        assert bot_client.stats['total_response_time'] == 1.5\\n\\n    def test_update_stats_error(self, bot_client):\\n        \\\"\\\"\\\"Test updating statistics on error.\\\"\\\"\\\"\\n        bot_client._update_stats(2.0, success=False)\\n\\n        assert bot_client.stats['errors'] == 1\\n        assert bot_client.stats['responses_generated'] == 0\\n\\n    def test_get_stats(self, bot_client):\\n        \\\"\\\"\\\"Test getting bot statistics.\\\"\\\"\\\"\\n        # Add some test data\\n        bot_client.stats['responses_generated'] = 5\\n        bot_client.stats['total_response_time'] = 10.0\\n        bot_client.stats['errors'] = 1\\n        bot_client._update_stats(0, success=True)  # Recalculate average\\n\\n        stats = bot_client.get_stats()\\n\\n        assert stats['name'] == \\\"TestBot\\\"\\n        assert stats['model'] == \\\"gpt-3.5-turbo\\\"\\n        assert stats['provider'] == \\\"openai\\\"\\n        assert stats['responses_generated'] == 5\\n        assert stats['total_errors'] == 1\\n        assert 'success_rate' in stats\\n        assert 'average_response_time' in stats\\n\\n    def test_update_personality(self, bot_client):\\n        \\\"\\\"\\\"Test updating bot personality.\\\"\\\"\\\"\\n        bot_client.update_personality(\\\"New personality\\\", \\\"con\\\")\\n\\n        assert bot_client.config.personality == \\\"New personality\\\"\\n        assert bot_client.config.stance == \\\"con\\\"\\n\\n    def test_reset_conversation(self, bot_client):\\n        \\\"\\\"\\\"Test resetting conversation history.\\\"\\\"\\\"\\n        # Add some conversation history\\n        bot_client.conversation_history = [\\n            {'role': 'user', 'content': 'Test message'}\\n        ]\\n        bot_client.response_count = 3\\n\\n        bot_client.reset_conversation()\\n\\n        assert bot_client.conversation_history == []\\n        assert bot_client.response_count == 0\\n\\n    @pytest.mark.asyncio\\n    async def test_warmup_success(self, bot_client):\\n        \\\"\\\"\\\"Test successful bot warmup.\\\"\\\"\\\"\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\"Ready\\\")\\n\\n        result = await bot_client.warmup()\\n\\n        assert result == True\\n\\n    @pytest.mark.asyncio\\n    async def test_warmup_failure(self, bot_client):\\n        \\\"\\\"\\\"Test failed bot warmup.\\\"\\\"\\\"\\n        bot_client.ai_provider.generate_response = AsyncMock(\\n            side_effect=Exception(\\\"Connection failed\\\")\\n        )\\n\\n        result = await bot_client.warmup()\\n\\n        assert result == False\\n\\n    def test_str_representation(self, bot_client):\\n        \\\"\\\"\\\"Test string representation of bot.\\\"\\\"\\\"\\n        string_repr = str(bot_client)\\n\\n        assert \\\"TestBot\\\" in string_repr\\n        assert \\\"gpt-3.5-turbo\\\" in string_repr\\n        assert \\\"pro\\\" in string_repr\\n\\n    def test_repr_representation(self, bot_client):\\n        \\\"\\\"\\\"Test detailed string representation of bot.\\\"\\\"\\\"\\n        repr_str = repr(bot_client)\\n\\n        assert \\\"BotClient\\\" in repr_str\\n        assert \\\"name='TestBot'\\\" in repr_str\\n        assert \\\"model='gpt-3.5-turbo'\\\" in repr_str\\n\\n\\nclass TestOpenAIProvider:\\n    \\\"\\\"\\\"Test suite for OpenAIProvider class.\\\"\\\"\\\"\\n\\n    def test_openai_provider_initialization(self):\\n        \\\"\\\"\\\"Test OpenAI provider initialization.\\\"\\\"\\\"\\n        provider = OpenAIProvider(\\\"test-api-key\\\")\\n        assert provider.api_key == \\\"test-api-key\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_generate_response_success(self):\\n        \\\"\\\"\\\"Test successful response generation.\\\"\\\"\\\"\\n        provider = OpenAIProvider(\\\"test-key\\\")\\n        config = BotConfig(\\\"TestBot\\\", \\\"gpt-3.5-turbo\\\", \\\"openai\\\", \\\"Test\\\", \\\"pro\\\")\\n        messages = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello\\\"}]\\n\\n        # Mock OpenAI client\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\n            mock_client = Mock()\\n            mock_openai.return_value = mock_client\\n\\n            # Mock response\\n            mock_response = Mock()\\n            mock_response.choices = [Mock()]\\n            mock_response.choices[0].message.content = \\\"Hello! How can I help?\\\"\\n            mock_client.chat.completions.create = AsyncMock(return_value=mock_response)\\n\\n            response = await provider.generate_response(messages, config)\\n\\n            assert response == \\\"Hello! How can I help?\\\"\\n            mock_client.chat.completions.create.assert_called_once()\\n\\n    @pytest.mark.asyncio\\n    async def test_generate_response_error(self):\\n        \\\"\\\"\\\"Test response generation with error.\\\"\\\"\\\"\\n        provider = OpenAIProvider(\\\"test-key\\\")\\n        config = BotConfig(\\\"TestBot\\\", \\\"gpt-3.5-turbo\\\", \\\"openai\\\", \\\"Test\\\", \\\"pro\\\")\\n        messages = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello\\\"}]\\n\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\n            mock_client = Mock()\\n            mock_openai.return_value = mock_client\\n            mock_client.chat.completions.create = AsyncMock(\\n                side_effect=Exception(\\\"API Error\\\")\\n            )\\n\\n            with pytest.raises(Exception, match=\\\"OpenAI API error\\\"):\\n                await provider.generate_response(messages, config)\\n\\n\\nclass TestAnthropicProvider:\\n    \\\"\\\"\\\"Test suite for AnthropicProvider class.\\\"\\\"\\\"\\n\\n    def test_anthropic_provider_initialization(self):\\n        \\\"\\\"\\\"Test Anthropic provider initialization.\\\"\\\"\\\"\\n        provider = AnthropicProvider(\\\"test-api-key\\\")\\n        assert provider.api_key == \\\"test-api-key\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_generate_response_success(self):\\n        \\\"\\\"\\\"Test successful response generation.\\\"\\\"\\\"\\n        provider = AnthropicProvider(\\\"test-key\\\")\\n        config = BotConfig(\\\"TestBot\\\", \\\"claude-3-sonnet\\\", \\\"anthropic\\\", \\\"Test\\\", \\\"pro\\\")\\n        messages = [\\n            {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant\\\"},\\n            {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello\\\"}\\n        ]\\n\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\n            mock_client = Mock()\\n            mock_anthropic.return_value = mock_client\\n\\n            # Mock response\\n            mock_response = Mock()\\n            mock_response.content = [Mock()]\\n            mock_response.content[0].text = \\\"Hello! How can I assist you?\\\"\\n            mock_client.messages.create = AsyncMock(return_value=mock_response)\\n\\n            response = await provider.generate_response(messages, config)\\n\\n            assert response == \\\"Hello! How can I assist you?\\\"\\n            mock_client.messages.create.assert_called_once()\\n\\n    @pytest.mark.asyncio\\n    async def test_generate_response_error(self):\\n        \\\"\\\"\\\"Test response generation with error.\\\"\\\"\\\"\\n        provider = AnthropicProvider(\\\"test-key\\\")\\n        config = BotConfig(\\\"TestBot\\\", \\\"claude-3-sonnet\\\", \\\"anthropic\\\", \\\"Test\\\", \\\"pro\\\")\\n        messages = [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Hello\\\"}]\\n\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\n            mock_client = Mock()\\n            mock_anthropic.return_value = mock_client\\n            mock_client.messages.create = AsyncMock(\\n                side_effect=Exception(\\\"API Error\\\")\\n            )\\n\\n            with pytest.raises(Exception, match=\\\"Anthropic API error\\\"):\\n                await provider.generate_response(messages, config)\\n\\n\\n@pytest.mark.asyncio\\nasync def test_conversation_history_management(bot_client):\\n    \\\"\\\"\\\"Test conversation history management.\\\"\\\"\\\"\\n    # Add messages beyond the limit\\n    for i in range(25):\\n        message = Message(f\\\"User{i}\\\", f\\\"Message {i}\\\", 1640995200.0 + i, i)\\n        await bot_client.receive_message(message)\\n\\n    # Should be limited to avoid memory issues\\n    assert len(bot_client.conversation_history) <= 20\\n\\n\\n@pytest.mark.asyncio\\nasync def test_bot_response_timing(bot_client, sample_messages):\\n    \\\"\\\"\\\"Test that response timing is tracked.\\\"\\\"\\\"\\n    bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\"Test response\\\")\\n\\n    # Simulate some delay\\n    async def delayed_response(*args):\\n        await asyncio.sleep(0.01)\\n        return \\\"Delayed response\\\"\\n\\n    bot_client.ai_provider.generate_response = delayed_response\\n\\n    await bot_client.get_response(\\\"Test topic\\\", sample_messages)\\n\\n    assert bot_client.stats['average_response_time'] > 0\\n    assert bot_client.stats['total_response_time'] > 0\"\n        },\n        \"test_chat_log.py\": {\n          \"type\": \"file\",\n          \"path\": \"tests/test_chat_log.py\",\n          \"extension\": \".py\",\n          \"size\": 15406,\n          \"content\": \"\\\"\\\"\\\"\\nTests for the ChatLog class.\\n\\\"\\\"\\\"\\n\\nimport pytest\\nimport asyncio\\nimport json\\nimport time\\nfrom pathlib import Path\\nfrom unittest.mock import patch, mock_open\\nfrom app.chat_log import ChatLog, Message\\n\\n\\n@pytest.fixture\\ndef chat_log():\\n    \\\"\\\"\\\"Create a test chat log.\\\"\\\"\\\"\\n    return ChatLog(max_messages=100)\\n\\n\\n@pytest.fixture\\ndef sample_messages():\\n    \\\"\\\"\\\"Create sample messages for testing.\\\"\\\"\\\"\\n    return [\\n        Message(\\\"Alice\\\", \\\"Hello everyone!\\\", time.time(), 1),\\n        Message(\\\"Bob\\\", \\\"Hi Alice!\\\", time.time(), 2),\\n        Message(\\\"moderator\\\", \\\"Welcome to the debate\\\", time.time(), 3, \\\"moderator\\\")\\n    ]\\n\\n\\nclass TestMessage:\\n    \\\"\\\"\\\"Test suite for Message dataclass.\\\"\\\"\\\"\\n\\n    def test_message_creation(self):\\n        \\\"\\\"\\\"Test creating a message.\\\"\\\"\\\"\\n        timestamp = time.time()\\n        msg = Message(\\\"Alice\\\", \\\"Hello world\\\", timestamp, 1)\\n\\n        assert msg.sender == \\\"Alice\\\"\\n        assert msg.content == \\\"Hello world\\\"\\n        assert msg.timestamp == timestamp\\n        assert msg.message_id == 1\\n        assert msg.message_type == \\\"chat\\\"\\n        assert msg.metadata == {}\\n\\n    def test_message_with_metadata(self):\\n        \\\"\\\"\\\"Test message with metadata.\\\"\\\"\\\"\\n        metadata = {\\\"urgency\\\": \\\"high\\\", \\\"topic\\\": \\\"AI\\\"}\\n        msg = Message(\\\"Bob\\\", \\\"Important point\\\", time.time(), 2,\\n                      message_type=\\\"system\\\", metadata=metadata)\\n\\n        assert msg.message_type == \\\"system\\\"\\n        assert msg.metadata == metadata\\n\\n    def test_formatted_timestamp(self):\\n        \\\"\\\"\\\"Test formatted timestamp property.\\\"\\\"\\\"\\n        timestamp = 1640995200.0  # Known timestamp\\n        msg = Message(\\\"Alice\\\", \\\"Test\\\", timestamp, 1)\\n\\n        formatted = msg.formatted_timestamp\\n        assert isinstance(formatted, str)\\n        assert \\\":\\\" in formatted  # Should contain time separator\\n\\n    def test_to_dict(self):\\n        \\\"\\\"\\\"Test converting message to dictionary.\\\"\\\"\\\"\\n        msg = Message(\\\"Alice\\\", \\\"Test\\\", time.time(), 1)\\n        msg_dict = msg.to_dict()\\n\\n        assert isinstance(msg_dict, dict)\\n        assert msg_dict[\\\"sender\\\"] == \\\"Alice\\\"\\n        assert msg_dict[\\\"content\\\"] == \\\"Test\\\"\\n        assert \\\"timestamp\\\" in msg_dict\\n        assert \\\"message_id\\\" in msg_dict\\n\\n    def test_from_dict(self):\\n        \\\"\\\"\\\"Test creating message from dictionary.\\\"\\\"\\\"\\n        data = {\\n            \\\"sender\\\": \\\"Bob\\\",\\n            \\\"content\\\": \\\"Test message\\\",\\n            \\\"timestamp\\\": time.time(),\\n            \\\"message_id\\\": 5,\\n            \\\"message_type\\\": \\\"chat\\\",\\n            \\\"metadata\\\": {}\\n        }\\n\\n        msg = Message.from_dict(data)\\n\\n        assert msg.sender == \\\"Bob\\\"\\n        assert msg.content == \\\"Test message\\\"\\n        assert msg.message_id == 5\\n\\n\\nclass TestChatLog:\\n    \\\"\\\"\\\"Test suite for ChatLog class.\\\"\\\"\\\"\\n\\n    def test_chat_log_initialization(self):\\n        \\\"\\\"\\\"Test chat log initialization.\\\"\\\"\\\"\\n        chat_log = ChatLog(max_messages=50)\\n\\n        assert len(chat_log.messages) == 0\\n        assert chat_log.message_counter == 0\\n        assert chat_log.subscribers == []\\n        assert chat_log.stats[\\\"total_messages\\\"] == 0\\n\\n    @pytest.mark.asyncio\\n    async def test_add_message(self, chat_log):\\n        \\\"\\\"\\\"Test adding a message.\\\"\\\"\\\"\\n        message = await chat_log.add_message(\\\"Alice\\\", \\\"Hello world\\\")\\n\\n        assert isinstance(message, Message)\\n        assert message.sender == \\\"Alice\\\"\\n        assert message.content == \\\"Hello world\\\"\\n        assert message.message_id == 1\\n        assert len(chat_log.messages) == 1\\n        assert chat_log.stats[\\\"total_messages\\\"] == 1\\n        assert chat_log.stats[\\\"messages_by_sender\\\"][\\\"Alice\\\"] == 1\\n\\n    @pytest.mark.asyncio\\n    async def test_add_multiple_messages(self, chat_log):\\n        \\\"\\\"\\\"Test adding multiple messages.\\\"\\\"\\\"\\n        await chat_log.add_message(\\\"Alice\\\", \\\"First message\\\")\\n        await chat_log.add_message(\\\"Bob\\\", \\\"Second message\\\")\\n        await chat_log.add_message(\\\"Alice\\\", \\\"Third message\\\")\\n\\n        assert len(chat_log.messages) == 3\\n        assert chat_log.message_counter == 3\\n        assert chat_log.stats[\\\"messages_by_sender\\\"][\\\"Alice\\\"] == 2\\n        assert chat_log.stats[\\\"messages_by_sender\\\"][\\\"Bob\\\"] == 1\\n\\n    @pytest.mark.asyncio\\n    async def test_message_ordering(self, chat_log):\\n        \\\"\\\"\\\"Test that messages maintain chronological order.\\\"\\\"\\\"\\n        msg1 = await chat_log.add_message(\\\"Alice\\\", \\\"First\\\")\\n        await asyncio.sleep(0.01)  # Small delay\\n        msg2 = await chat_log.add_message(\\\"Bob\\\", \\\"Second\\\")\\n\\n        messages = list(chat_log.messages)\\n        assert messages[0].message_id == 1\\n        assert messages[1].message_id == 2\\n        assert messages[0].timestamp < messages[1].timestamp\\n\\n    @pytest.mark.asyncio\\n    async def test_max_messages_limit(self):\\n        \\\"\\\"\\\"Test message limit enforcement.\\\"\\\"\\\"\\n        chat_log = ChatLog(max_messages=3)\\n\\n        # Add more messages than the limit\\n        for i in range(5):\\n            await chat_log.add_message(\\\"User\\\", f\\\"Message {i}\\\")\\n\\n        assert len(chat_log.messages) == 3  # Should be limited\\n\\n        # Check that oldest messages were removed\\n        messages = list(chat_log.messages)\\n        assert \\\"Message 2\\\" in messages[0].content\\n        assert \\\"Message 4\\\" in messages[2].content\\n\\n    @pytest.mark.asyncio\\n    async def test_subscription_system(self, chat_log):\\n        \\\"\\\"\\\"Test message subscription system.\\\"\\\"\\\"\\n        queue = chat_log.subscribe()\\n\\n        # Add a message\\n        message = await chat_log.add_message(\\\"Alice\\\", \\\"Test message\\\")\\n\\n        # Check that subscriber received the message\\n        received_message = await asyncio.wait_for(queue.get(), timeout=1.0)\\n        assert received_message.content == \\\"Test message\\\"\\n        assert received_message.sender == \\\"Alice\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_multiple_subscribers(self, chat_log):\\n        \\\"\\\"\\\"Test multiple subscribers.\\\"\\\"\\\"\\n        queue1 = chat_log.subscribe()\\n        queue2 = chat_log.subscribe()\\n\\n        await chat_log.add_message(\\\"Alice\\\", \\\"Broadcast message\\\")\\n\\n        # Both subscribers should receive the message\\n        msg1 = await asyncio.wait_for(queue1.get(), timeout=1.0)\\n        msg2 = await asyncio.wait_for(queue2.get(), timeout=1.0)\\n\\n        assert msg1.content == msg2.content == \\\"Broadcast message\\\"\\n\\n    def test_unsubscribe(self, chat_log):\\n        \\\"\\\"\\\"Test unsubscribing from messages.\\\"\\\"\\\"\\n        queue = chat_log.subscribe()\\n        assert queue in chat_log.subscribers\\n\\n        chat_log.unsubscribe(queue)\\n        assert queue not in chat_log.subscribers\\n\\n    def test_get_messages_no_filter(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test getting all messages without filters.\\\"\\\"\\\"\\n        # Manually add messages to chat log\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        messages = chat_log.get_messages()\\n        assert len(messages) == 3\\n        assert messages[0].sender == \\\"Alice\\\"\\n\\n    def test_get_messages_with_limit(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test getting messages with limit.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        messages = chat_log.get_messages(limit=2)\\n        assert len(messages) == 2\\n        # Should get the last 2 messages\\n        assert messages[0].sender == \\\"Bob\\\"\\n        assert messages[1].sender == \\\"moderator\\\"\\n\\n    def test_get_messages_by_sender(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test filtering messages by sender.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        alice_messages = chat_log.get_messages(sender=\\\"Alice\\\")\\n        assert len(alice_messages) == 1\\n        assert alice_messages[0].sender == \\\"Alice\\\"\\n\\n    def test_get_messages_by_type(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test filtering messages by type.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        moderator_messages = chat_log.get_messages(message_type=\\\"moderator\\\")\\n        assert len(moderator_messages) == 1\\n        assert moderator_messages[0].message_type == \\\"moderator\\\"\\n\\n    def test_get_messages_since_timestamp(self, chat_log):\\n        \\\"\\\"\\\"Test filtering messages by timestamp.\\\"\\\"\\\"\\n        # Add messages with known timestamps\\n        old_time = time.time() - 100\\n        new_time = time.time()\\n\\n        chat_log.messages.append(Message(\\\"Alice\\\", \\\"Old\\\", old_time, 1))\\n        chat_log.messages.append(Message(\\\"Bob\\\", \\\"New\\\", new_time, 2))\\n\\n        cutoff = time.time() - 50\\n        recent_messages = chat_log.get_messages(since_timestamp=cutoff)\\n\\n        assert len(recent_messages) == 1\\n        assert recent_messages[0].content == \\\"New\\\"\\n\\n    def test_get_recent_messages(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test getting recent messages.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        recent = chat_log.get_recent_messages(2)\\n        assert len(recent) == 2\\n        assert recent[-1].sender == \\\"moderator\\\"  # Most recent\\n\\n    def test_get_conversation_context(self, chat_log):\\n        \\\"\\\"\\\"Test getting conversation context for a participant.\\\"\\\"\\\"\\n        # Add various messages\\n        messages = [\\n            Message(\\\"Alice\\\", \\\"Hello\\\", time.time(), 1),\\n            Message(\\\"Bob\\\", \\\"Hi Alice\\\", time.time(), 2),\\n            Message(\\\"moderator\\\", \\\"Welcome everyone\\\", time.time(), 3, \\\"moderator\\\"),\\n            Message(\\\"Alice\\\", \\\"Thanks!\\\", time.time(), 4),\\n            Message(\\\"Charlie\\\", \\\"Good luck\\\", time.time(), 5)\\n        ]\\n\\n        for msg in messages:\\n            chat_log.messages.append(msg)\\n\\n        context = chat_log.get_conversation_context(\\\"Alice\\\", context_length=3)\\n\\n        # Should include Alice's messages and moderator messages\\n        assert len(context) <= 3\\n        assert any(msg.sender == \\\"Alice\\\" for msg in context)\\n        assert any(msg.message_type == \\\"moderator\\\" for msg in context)\\n\\n    def test_search_messages(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test searching messages by content.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        # Case insensitive search\\n        results = chat_log.search_messages(\\\"hello\\\")\\n        assert len(results) == 1\\n        assert \\\"Hello\\\" in results[0].content\\n\\n        # Case sensitive search\\n        results = chat_log.search_messages(\\\"Hello\\\", case_sensitive=True)\\n        assert len(results) == 1\\n\\n        results = chat_log.search_messages(\\\"hello\\\", case_sensitive=True)\\n        assert len(results) == 0\\n\\n    def test_get_statistics(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test getting chat log statistics.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n            chat_log.stats[\\\"total_messages\\\"] += 1\\n            sender = msg.sender\\n            chat_log.stats[\\\"messages_by_sender\\\"][sender] = (\\n                    chat_log.stats[\\\"messages_by_sender\\\"].get(sender, 0) + 1\\n            )\\n\\n        stats = chat_log.get_statistics()\\n\\n        assert stats[\\\"total_messages\\\"] == 3\\n        assert stats[\\\"unique_senders\\\"] == 2  # Alice, Bob, moderator\\n        assert \\\"messages_by_sender\\\" in stats\\n        assert \\\"messages_per_minute\\\" in stats\\n        assert \\\"session_duration_minutes\\\" in stats\\n\\n    @pytest.mark.asyncio\\n    async def test_save_transcript_json(self, chat_log, tmp_path):\\n        \\\"\\\"\\\"Test saving transcript in JSON format.\\\"\\\"\\\"\\n        await chat_log.add_message(\\\"Alice\\\", \\\"Test message\\\")\\n\\n        output_file = tmp_path / \\\"transcript.json\\\"\\n        await chat_log.save_transcript(str(output_file), \\\"json\\\")\\n\\n        assert output_file.exists()\\n\\n        with open(output_file, 'r') as f:\\n            data = json.load(f)\\n\\n        assert \\\"metadata\\\" in data\\n        assert \\\"messages\\\" in data\\n        assert len(data[\\\"messages\\\"]) == 1\\n        assert data[\\\"messages\\\"][0][\\\"content\\\"] == \\\"Test message\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_save_transcript_txt(self, chat_log, tmp_path):\\n        \\\"\\\"\\\"Test saving transcript in TXT format.\\\"\\\"\\\"\\n        await chat_log.add_message(\\\"Alice\\\", \\\"Test message\\\")\\n\\n        output_file = tmp_path / \\\"transcript.txt\\\"\\n        await chat_log.save_transcript(str(output_file), \\\"txt\\\")\\n\\n        assert output_file.exists()\\n\\n        content = output_file.read_text()\\n        assert \\\"DEBATE TRANSCRIPT\\\" in content\\n        assert \\\"Alice: Test message\\\" in content\\n\\n    @pytest.mark.asyncio\\n    async def test_save_transcript_html(self, chat_log, tmp_path):\\n        \\\"\\\"\\\"Test saving transcript in HTML format.\\\"\\\"\\\"\\n        await chat_log.add_message(\\\"Alice\\\", \\\"Test message\\\")\\n        await chat_log.add_message(\\\"moderator\\\", \\\"System message\\\",\\n                                   message_type=\\\"moderator\\\")\\n\\n        output_file = tmp_path / \\\"transcript.html\\\"\\n        await chat_log.save_transcript(str(output_file), \\\"html\\\")\\n\\n        assert output_file.exists()\\n\\n        content = output_file.read_text()\\n        assert \\\"<!DOCTYPE html>\\\" in content\\n        assert \\\"Alice\\\" in content\\n        assert \\\"moderator\\\" in content\\n        assert \\\"class=\\\\\\\"moderator\\\\\\\"\\\" in content\\n\\n    @pytest.mark.asyncio\\n    async def test_save_transcript_invalid_format(self, chat_log):\\n        \\\"\\\"\\\"Test saving transcript with invalid format.\\\"\\\"\\\"\\n        with pytest.raises(ValueError, match=\\\"Unsupported format\\\"):\\n            await chat_log.save_transcript(\\\"test.xml\\\", \\\"xml\\\")\\n\\n    @pytest.mark.asyncio\\n    async def test_load_transcript(self, chat_log, tmp_path):\\n        \\\"\\\"\\\"Test loading transcript from file.\\\"\\\"\\\"\\n        # Save a transcript first\\n        await chat_log.add_message(\\\"Alice\\\", \\\"Original message\\\")\\n        output_file = tmp_path / \\\"transcript.json\\\"\\n        await chat_log.save_transcript(str(output_file), \\\"json\\\")\\n\\n        # Clear chat log and reload\\n        chat_log.clear()\\n        assert len(chat_log.messages) == 0\\n\\n        await chat_log.load_transcript(str(output_file))\\n\\n        assert len(chat_log.messages) == 1\\n        assert list(chat_log.messages)[0].content == \\\"Original message\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_load_transcript_file_not_found(self, chat_log):\\n        \\\"\\\"\\\"Test loading transcript from non-existent file.\\\"\\\"\\\"\\n        with pytest.raises(FileNotFoundError):\\n            await chat_log.load_transcript(\\\"nonexistent.json\\\")\\n\\n    def test_clear_chat_log(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test clearing the chat log.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        chat_log.message_counter = 5\\n        chat_log.stats[\\\"total_messages\\\"] = 3\\n\\n        chat_log.clear()\\n\\n        assert len(chat_log.messages) == 0\\n        assert chat_log.message_counter == 0\\n        assert chat_log.stats[\\\"total_messages\\\"] == 0\\n        assert chat_log.stats[\\\"messages_by_sender\\\"] == {}\\n\\n    def test_chat_log_len(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test chat log length.\\\"\\\"\\\"\\n        assert len(chat_log) == 0\\n\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        assert len(chat_log) == 3\\n\\n    def test_chat_log_iteration(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test iterating over chat log.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        iterated_messages = list(chat_log)\\n        assert len(iterated_messages) == 3\\n        assert iterated_messages[0].sender == \\\"Alice\\\"\\n\\n    def test_chat_log_indexing(self, chat_log, sample_messages):\\n        \\\"\\\"\\\"Test indexing chat log.\\\"\\\"\\\"\\n        for msg in sample_messages:\\n            chat_log.messages.append(msg)\\n\\n        first_message = chat_log[0]\\n        assert first_message.sender == \\\"Alice\\\"\\n\\n        last_message = chat_log[-1]\\n        assert last_message.sender == \\\"moderator\\\"\\n        \"\n        },\n        \"test_human_client.py\": {\n          \"type\": \"file\",\n          \"path\": \"tests/test_human_client.py\",\n          \"extension\": \".py\",\n          \"size\": 20297,\n          \"content\": \"\\\"\\\"\\\"\\nTests for the HumanClient class.\\n\\\"\\\"\\\"\\n\\nimport pytest\\nimport asyncio\\nfrom unittest.mock import Mock, AsyncMock, patch\\nfrom app.human_client import HumanClient, CLIInterface, WebInterface, InterfaceConfig\\nfrom app.chat_log import Message\\n\\n\\n@pytest.fixture\\ndef interface_config():\\n    \\\"\\\"\\\"Create test interface configuration.\\\"\\\"\\\"\\n    return {\\n        'mode': 'cli',\\n        'enable_rich_formatting': False,  # Disable for testing\\n        'show_typing_indicators': True,\\n        'enable_reactions': True,\\n        'input_timeout': 60\\n    }\\n\\n\\n@pytest.fixture\\ndef human_client(interface_config):\\n    \\\"\\\"\\\"Create test human client.\\\"\\\"\\\"\\n    return HumanClient(\\\"TestHuman\\\", interface_config)\\n\\n\\n@pytest.fixture\\ndef sample_messages():\\n    \\\"\\\"\\\"Create sample messages for testing.\\\"\\\"\\\"\\n    return [\\n        Message(\\\"Alice\\\", \\\"What's your opinion?\\\", 1640995200.0, 1),\\n        Message(\\\"Bob\\\", \\\"I think...\\\", 1640995210.0, 2),\\n        Message(\\\"moderator\\\", \\\"Please respond\\\", 1640995220.0, 3, \\\"moderator\\\")\\n    ]\\n\\n\\nclass TestInterfaceConfig:\\n    \\\"\\\"\\\"Test suite for InterfaceConfig dataclass.\\\"\\\"\\\"\\n\\n    def test_interface_config_defaults(self):\\n        \\\"\\\"\\\"Test interface config with default values.\\\"\\\"\\\"\\n        config = InterfaceConfig()\\n\\n        assert config.mode == \\\"cli\\\"\\n        assert config.enable_rich_formatting == True\\n        assert config.show_typing_indicators == True\\n        assert config.enable_reactions == True\\n        assert config.input_timeout == 120\\n\\n    def test_interface_config_custom(self):\\n        \\\"\\\"\\\"Test interface config with custom values.\\\"\\\"\\\"\\n        config = InterfaceConfig(\\n            mode=\\\"web\\\",\\n            enable_rich_formatting=False,\\n            input_timeout=90\\n        )\\n\\n        assert config.mode == \\\"web\\\"\\n        assert config.enable_rich_formatting == False\\n        assert config.input_timeout == 90\\n\\n\\nclass TestCLIInterface:\\n    \\\"\\\"\\\"Test suite for CLIInterface class.\\\"\\\"\\\"\\n\\n    def test_cli_interface_initialization(self):\\n        \\\"\\\"\\\"Test CLI interface initialization.\\\"\\\"\\\"\\n        config = InterfaceConfig(enable_rich_formatting=False)\\n        interface = CLIInterface(config)\\n\\n        assert interface.config == config\\n        assert interface.rich_console is None  # Rich disabled\\n\\n    @pytest.mark.asyncio\\n    async def test_display_basic_message(self):\\n        \\\"\\\"\\\"Test displaying message with basic formatting.\\\"\\\"\\\"\\n        config = InterfaceConfig(enable_rich_formatting=False)\\n        interface = CLIInterface(config)\\n\\n        message = Message(\\\"Alice\\\", \\\"Hello world\\\", 1640995200.0, 1)\\n\\n        with patch('builtins.print') as mock_print:\\n            await interface.display_message(message)\\n            mock_print.assert_called_once()\\n\\n    @pytest.mark.asyncio\\n    async def test_display_moderator_message(self):\\n        \\\"\\\"\\\"Test displaying moderator message.\\\"\\\"\\\"\\n        config = InterfaceConfig(enable_rich_formatting=False)\\n        interface = CLIInterface(config)\\n\\n        message = Message(\\\"moderator\\\", \\\"Welcome!\\\", 1640995200.0, 1, \\\"moderator\\\")\\n\\n        with patch('builtins.print') as mock_print:\\n            await interface.display_message(message)\\n            mock_print.assert_called_once()\\n            # Should have moderator prefix\\n            args = mock_print.call_args[0]\\n            assert \\\"üé≠\\\" in args[0]\\n\\n    @pytest.mark.asyncio\\n    async def test_get_input_success(self):\\n        \\\"\\\"\\\"Test successful input retrieval.\\\"\\\"\\\"\\n        config = InterfaceConfig(enable_rich_formatting=False)\\n        interface = CLIInterface(config)\\n\\n        with patch('builtins.input', return_value=\\\"Test response\\\"):\\n            response = await interface.get_input(\\\"Enter response:\\\", timeout=1)\\n            assert response == \\\"Test response\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_get_input_timeout(self):\\n        \\\"\\\"\\\"Test input timeout.\\\"\\\"\\\"\\n        config = InterfaceConfig(enable_rich_formatting=False)\\n        interface = CLIInterface(config)\\n\\n        # Mock input to simulate hanging\\n        async def slow_input():\\n            await asyncio.sleep(2)\\n            return \\\"Too late\\\"\\n\\n        interface._get_user_input = slow_input\\n\\n        response = await interface.get_input(\\\"Enter response:\\\", timeout=0.1)\\n        assert response == \\\"\\\"  # Should return empty string on timeout\\n\\n    @pytest.mark.asyncio\\n    async def test_show_notification(self):\\n        \\\"\\\"\\\"Test showing notifications.\\\"\\\"\\\"\\n        config = InterfaceConfig(enable_rich_formatting=False)\\n        interface = CLIInterface(config)\\n\\n        with patch('builtins.print') as mock_print:\\n            await interface.show_notification(\\\"Test notification\\\", \\\"info\\\")\\n            mock_print.assert_called_once()\\n            args = mock_print.call_args[0]\\n            assert \\\"‚ÑπÔ∏è\\\" in args[0]\\n            assert \\\"Test notification\\\" in args[0]\\n\\n\\nclass TestWebInterface:\\n    \\\"\\\"\\\"Test suite for WebInterface class.\\\"\\\"\\\"\\n\\n    def test_web_interface_initialization(self):\\n        \\\"\\\"\\\"Test web interface initialization.\\\"\\\"\\\"\\n        config = InterfaceConfig(mode=\\\"web\\\")\\n        interface = WebInterface(config)\\n\\n        assert interface.config == config\\n        assert interface.websocket is None\\n        assert interface.pending_responses == {}\\n\\n    @pytest.mark.asyncio\\n    async def test_display_message_no_websocket(self):\\n        \\\"\\\"\\\"Test displaying message without websocket connection.\\\"\\\"\\\"\\n        config = InterfaceConfig(mode=\\\"web\\\")\\n        interface = WebInterface(config)\\n\\n        message = Message(\\\"Alice\\\", \\\"Hello\\\", 1640995200.0, 1)\\n\\n        # Should not raise an error even without websocket\\n        await interface.display_message(message)\\n\\n    @pytest.mark.asyncio\\n    async def test_get_input_no_websocket(self):\\n        \\\"\\\"\\\"Test getting input without websocket connection.\\\"\\\"\\\"\\n        config = InterfaceConfig(mode=\\\"web\\\")\\n        interface = WebInterface(config)\\n\\n        response = await interface.get_input(\\\"Enter response:\\\")\\n        assert response == \\\"\\\"  # Should return empty string\\n\\n\\nclass TestHumanClient:\\n    \\\"\\\"\\\"Test suite for HumanClient class.\\\"\\\"\\\"\\n\\n    def test_human_client_initialization(self, interface_config):\\n        \\\"\\\"\\\"Test human client initialization.\\\"\\\"\\\"\\n        client = HumanClient(\\\"TestHuman\\\", interface_config)\\n\\n        assert client.name == \\\"TestHuman\\\"\\n        assert isinstance(client.interface, CLIInterface)\\n        assert client.is_active == True\\n        assert client.conversation_history == []\\n        assert client.stats['responses_given'] == 0\\n\\n    def test_human_client_web_mode(self):\\n        \\\"\\\"\\\"Test human client with web interface.\\\"\\\"\\\"\\n        config = {'mode': 'web'}\\n        client = HumanClient(\\\"WebHuman\\\", config)\\n\\n        assert isinstance(client.interface, WebInterface)\\n\\n    def test_human_client_unsupported_mode(self):\\n        \\\"\\\"\\\"Test human client with unsupported interface mode.\\\"\\\"\\\"\\n        config = {'mode': 'unsupported'}\\n\\n        with pytest.raises(ValueError, match=\\\"Unsupported interface mode\\\"):\\n            HumanClient(\\\"TestHuman\\\", config)\\n\\n    @pytest.mark.asyncio\\n    async def test_get_response_success(self, human_client, sample_messages):\\n        \\\"\\\"\\\"Test successful response retrieval.\\\"\\\"\\\"\\n        # Mock the interface get_input method\\n        human_client.interface.get_input = AsyncMock(return_value=\\\"My response\\\")\\n        human_client.interface.show_notification = AsyncMock()\\n        human_client.interface.display_message = AsyncMock()\\n\\n        response = await human_client.get_response(\\\"Test topic\\\", sample_messages)\\n\\n        assert response == \\\"My response\\\"\\n        assert human_client.stats['responses_given'] == 1\\n\\n    @pytest.mark.asyncio\\n    async def test_get_response_timeout(self, human_client, sample_messages):\\n        \\\"\\\"\\\"Test response timeout.\\\"\\\"\\\"\\n        # Mock timeout scenario\\n        human_client.interface.get_input = AsyncMock(return_value=\\\"\\\")\\n        human_client.interface.show_notification = AsyncMock()\\n        human_client.interface.display_message = AsyncMock()\\n\\n        response = await human_client.get_response(\\\"Test topic\\\", sample_messages)\\n\\n        assert response == \\\"\\\"\\n        assert human_client.stats['timeouts'] == 1\\n\\n    @pytest.mark.asyncio\\n    async def test_get_response_inactive(self, human_client, sample_messages):\\n        \\\"\\\"\\\"Test response when client is inactive.\\\"\\\"\\\"\\n        human_client.is_active = False\\n\\n        response = await human_client.get_response(\\\"Test topic\\\", sample_messages)\\n\\n        assert response == \\\"\\\"\\n\\n    def test_validate_response(self, human_client):\\n        \\\"\\\"\\\"Test response validation.\\\"\\\"\\\"\\n        # Normal response\\n        response = human_client._validate_response(\\\"This is a good response\\\")\\n        assert response == \\\"This is a good response\\\"\\n\\n        # Very long response\\n        long_response = \\\"x\\\" * 600\\n        response = human_client._validate_response(long_response)\\n        assert len(response) <= 503  # 500 + \\\"...\\\"\\n        assert response.endswith(\\\"...\\\")\\n\\n        # Very short response\\n        short_response = human_client._validate_response(\\\"Yes\\\")\\n        assert \\\"[Note: Very short response]\\\" in short_response\\n\\n    @pytest.mark.asyncio\\n    async def test_receive_message(self, human_client):\\n        \\\"\\\"\\\"Test receiving a message.\\\"\\\"\\\"\\n        message = Message(\\\"Alice\\\", \\\"Hello human\\\", 1640995200.0, 1)\\n        human_client.interface.display_message = AsyncMock()\\n\\n        await human_client.receive_message(message)\\n\\n        # Should be added to conversation history\\n        assert len(human_client.conversation_history) == 1\\n        assert human_client.conversation_history[0] == message\\n\\n        # Should display the message\\n        human_client.interface.display_message.assert_called_once_with(message)\\n\\n    @pytest.mark.asyncio\\n    async def test_receive_own_message(self, human_client):\\n        \\\"\\\"\\\"Test receiving own message (should be ignored).\\\"\\\"\\\"\\n        message = Message(\\\"TestHuman\\\", \\\"My own message\\\", 1640995200.0, 1)\\n        human_client.interface.display_message = AsyncMock()\\n\\n        await human_client.receive_message(message)\\n\\n        # Should not be added to history or displayed\\n        assert len(human_client.conversation_history) == 0\\n        human_client.interface.display_message.assert_not_called()\\n\\n    @pytest.mark.asyncio\\n    async def test_conversation_history_limit(self, human_client):\\n        \\\"\\\"\\\"Test conversation history length limit.\\\"\\\"\\\"\\n        human_client.interface.display_message = AsyncMock()\\n\\n        # Add many messages\\n        for i in range(60):\\n            message = Message(f\\\"User{i}\\\", f\\\"Message {i}\\\", 1640995200.0 + i, i)\\n            await human_client.receive_message(message)\\n\\n        # Should be limited to 30 (as per implementation)\\n        assert len(human_client.conversation_history) == 30\\n\\n    @pytest.mark.asyncio\\n    async def test_handle_voting_success(self, human_client):\\n        \\\"\\\"\\\"Test successful voting.\\\"\\\"\\\"\\n        candidates = [\\\"Alice\\\", \\\"Bob\\\", \\\"Charlie\\\"]\\n\\n        # Mock interface methods\\n        human_client.interface.show_notification = AsyncMock()\\n        human_client.interface.get_input = AsyncMock(side_effect=[\\\"2\\\", \\\"Good arguments\\\"])\\n\\n        result = await human_client.handle_voting(candidates, 60)\\n\\n        assert result['voted'] == True\\n        assert result['candidate'] == \\\"Bob\\\"  # Index 2-1 = 1 -> \\\"Bob\\\"\\n        assert result['justification'] == \\\"Good arguments\\\"\\n\\n    @pytest.mark.asyncio\\n    async def test_handle_voting_timeout(self, human_client):\\n        \\\"\\\"\\\"Test voting timeout.\\\"\\\"\\\"\\n        candidates = [\\\"Alice\\\", \\\"Bob\\\"]\\n\\n        human_client.interface.show_notification = AsyncMock()\\n        human_client.interface.get_input = AsyncMock(return_value=\\\"\\\")  # Timeout\\n\\n        result = await human_client.handle_voting(candidates, 30)\\n\\n        assert result['voted'] == False\\n        assert result['reason'] == 'timeout'\\n\\n    @pytest.mark.asyncio\\n    async def test_handle_voting_invalid_choice(self, human_client):\\n        \\\"\\\"\\\"Test voting with invalid choice.\\\"\\\"\\\"\\n        candidates = [\\\"Alice\\\", \\\"Bob\\\"]\\n\\n        human_client.interface.show_notification = AsyncMock()\\n        human_client.interface.get_input = AsyncMock(return_value=\\\"5\\\")  # Out of range\\n\\n        result = await human_client.handle_voting(candidates, 30)\\n\\n        assert result['voted'] == False\\n        assert result['reason'] == 'invalid_choice'\\n\\n    @pytest.mark.asyncio\\n    async def test_handle_voting_invalid_format(self, human_client):\\n        \\\"\\\"\\\"Test voting with invalid input format.\\\"\\\"\\\"\\n        candidates = [\\\"Alice\\\", \\\"Bob\\\"]\\n\\n        human_client.interface.show_notification = AsyncMock()\\n        human_client.interface.get_input = AsyncMock(return_value=\\\"not_a_number\\\")\\n\\n        result = await human_client.handle_voting(candidates, 30)\\n\\n        assert result['voted'] == False\\n        assert result['reason'] == 'invalid_format'\\n\\n    def test_update_stats_success(self, human_client):\\n        \\\"\\\"\\\"Test updating statistics on successful response.\\\"\\\"\\\"\\n        human_client._update_stats(2.5, success=True)\\n\\n        assert human_client.stats['responses_given'] == 1\\n        assert human_client.stats['average_response_time'] == 2.5\\n        assert human_client.stats['total_response_time'] == 2.5\\n\\n    def test_update_stats_timeout(self, human_client):\\n        \\\"\\\"\\\"Test updating statistics on timeout.\\\"\\\"\\\"\\n        human_client._update_stats(5.0, success=False)\\n\\n        assert human_client.stats['timeouts'] == 1\\n        assert human_client.stats['responses_given'] == 0\\n\\n    def test_get_stats(self, human_client):\\n        \\\"\\\"\\\"Test getting human client statistics.\\\"\\\"\\\"\\n        # Add some test data\\n        human_client.stats['responses_given'] = 3\\n        human_client.stats['timeouts'] = 1\\n        human_client.stats['total_response_time'] = 15.0\\n        human_client._update_stats(0, success=True)  # Recalculate average\\n\\n        stats = human_client.get_stats()\\n\\n        assert stats['name'] == \\\"TestHuman\\\"\\n        assert stats['interface_mode'] == \\\"cli\\\"\\n        assert stats['responses_given'] == 3\\n        assert stats['timeouts'] == 1\\n        assert stats['participation_rate'] == 0.75  # 3/(3+1)\\n        assert 'average_response_time' in stats\\n\\n    @pytest.mark.asyncio\\n    async def test_set_active(self, human_client):\\n        \\\"\\\"\\\"Test setting client active/inactive status.\\\"\\\"\\\"\\n        human_client.interface.show_notification = AsyncMock()\\n\\n        # Set inactive\\n        await human_client.set_active(False)\\n        assert human_client.is_active == False\\n\\n        # Set active\\n        await human_client.set_active(True)\\n        assert human_client.is_active == True\\n\\n        # Should have called show_notification twice\\n        assert human_client.interface.show_notification.call_count == 2\\n\\n    @pytest.mark.asyncio\\n    async def test_show_help(self, human_client):\\n        \\\"\\\"\\\"Test showing help information.\\\"\\\"\\\"\\n        human_client.interface.show_notification = AsyncMock()\\n\\n        await human_client.show_help()\\n\\n        human_client.interface.show_notification.assert_called_once()\\n        args = human_client.interface.show_notification.call_args[0]\\n        assert \\\"AI Jubilee Debate Help\\\" in args[0]\\n        assert \\\"COMMANDS:\\\" in args[0]\\n\\n    def test_str_representation(self, human_client):\\n        \\\"\\\"\\\"Test string representation of human client.\\\"\\\"\\\"\\n        string_repr = str(human_client)\\n\\n        assert \\\"TestHuman\\\" in string_repr\\n        assert \\\"cli\\\" in string_repr\\n\\n    def test_repr_representation(self, human_client):\\n        \\\"\\\"\\\"Test detailed string representation of human client.\\\"\\\"\\\"\\n        repr_str = repr(human_client)\\n\\n        assert \\\"HumanClient\\\" in repr_str\\n        assert \\\"name='TestHuman'\\\" in repr_str\\n        assert \\\"mode='cli'\\\" in repr_str\\n        assert \\\"active=True\\\" in repr_str\\n\\n\\n@pytest.mark.asyncio\\nasync def test_show_context_integration(human_client, sample_messages):\\n    \\\"\\\"\\\"Test showing context to human before response.\\\"\\\"\\\"\\n    human_client.interface.show_notification = AsyncMock()\\n    human_client.interface.display_message = AsyncMock()\\n    human_client.interface.get_input = AsyncMock(return_value=\\\"Test response\\\")\\n\\n    await human_client.get_response(\\\"Test topic\\\", sample_messages)\\n\\n    # Should show context notification\\n    notification_calls = human_client.interface.show_notification.call_args_list\\n    assert any(\\\"Recent messages\\\" in str(call) for call in notification_calls)\\n\\n    # Should display recent messages\\n    assert human_client.interface.display_message.call_count >= 1\\n\\n\\n@pytest.mark.asyncio\\nasync def test_human_response_validation_edge_cases(human_client):\\n    \\\"\\\"\\\"Test edge cases in response validation.\\\"\\\"\\\"\\n    # Empty response\\n    result = human_client._validate_response(\\\"\\\")\\n    assert result == \\\"\\\"\\n\\n    # Whitespace only\\n    result = human_client._validate_response(\\\"   \\\\n\\\\t   \\\")\\n    assert result == \\\"\\\"\\n\\n    # Response with just newlines\\n    result = human_client._validate_response(\\\"\\\\n\\\\n\\\\n\\\")\\n    assert result == \\\"\\\"\\n\\n    # Very short meaningful response\\n    result = human_client._validate_response(\\\"No.\\\")\\n    assert \\\"[Note: Very short response]\\\" in result\\n\\n\\n@pytest.mark.asyncio\\nasync def test_human_client_error_resilience(human_client, sample_messages):\\n    \\\"\\\"\\\"Test human client resilience to interface errors.\\\"\\\"\\\"\\n    # Mock interface to raise errors\\n    human_client.interface.display_message = AsyncMock(side_effect=Exception(\\\"Interface error\\\"))\\n    human_client.interface.show_notification = AsyncMock()\\n    human_client.interface.get_input = AsyncMock(return_value=\\\"Test response\\\")\\n\\n    # Should not crash despite interface errors\\n    response = await human_client.get_response(\\\"Test topic\\\", sample_messages)\\n    assert response == \\\"Test response\\\"\\n\\n\\n@pytest.mark.asyncio\\nasync def test_human_client_concurrent_operations(human_client):\\n    \\\"\\\"\\\"Test concurrent operations on human client.\\\"\\\"\\\"\\n    human_client.interface.display_message = AsyncMock()\\n\\n    # Simulate concurrent message receiving\\n    tasks = []\\n    for i in range(10):\\n        message = Message(f\\\"User{i}\\\", f\\\"Message {i}\\\", 1640995200.0 + i, i)\\n        tasks.append(human_client.receive_message(message))\\n\\n    await asyncio.gather(*tasks)\\n\\n    # All messages should be processed\\n    assert len(human_client.conversation_history) == 10\\n\\n\\ndef test_human_client_stats_calculation(human_client):\\n    \\\"\\\"\\\"Test statistics calculation accuracy.\\\"\\\"\\\"\\n    # Simulate various response scenarios\\n    human_client._update_stats(2.0, success=True)\\n    human_client._update_stats(3.0, success=True)\\n    human_client._update_stats(1.5, success=False)  # Timeout\\n    human_client._update_stats(2.5, success=True)\\n\\n    stats = human_client.get_stats()\\n\\n    assert stats['responses_given'] == 3\\n    assert stats['timeouts'] == 1\\n    assert stats['participation_rate'] == 0.75  # 3/(3+1)\\n    assert abs(stats['average_response_time'] - 2.5) < 0.1  # (2.0+3.0+2.5)/3\\n\\n\\n@pytest.mark.asyncio\\nasync def test_voting_with_web_interface():\\n    \\\"\\\"\\\"Test voting behavior with web interface.\\\"\\\"\\\"\\n    config = {'mode': 'web'}\\n    client = HumanClient(\\\"WebUser\\\", config)\\n    candidates = [\\\"Alice\\\", \\\"Bob\\\"]\\n\\n    # Web interface should handle justification differently\\n    client.interface.show_notification = AsyncMock()\\n    client.interface.get_input = AsyncMock(return_value=\\\"1\\\")\\n\\n    result = await client.handle_voting(candidates, 60)\\n\\n    assert result['voted'] == True\\n    assert result['candidate'] == \\\"Alice\\\"\\n    assert result['justification'] == \\\"\\\"  # No justification prompt for web\\n\\n\\n@pytest.mark.asyncio\\nasync def test_human_client_lifecycle():\\n    \\\"\\\"\\\"Test complete human client lifecycle.\\\"\\\"\\\"\\n    config = {'mode': 'cli', 'enable_rich_formatting': False}\\n    client = HumanClient(\\\"LifecycleTest\\\", config)\\n\\n    # Initial state\\n    assert client.is_active == True\\n    assert len(client.conversation_history) == 0\\n\\n    # Mock interface for testing\\n    client.interface.display_message = AsyncMock()\\n    client.interface.show_notification = AsyncMock()\\n    client.interface.get_input = AsyncMock(return_value=\\\"Test response\\\")\\n\\n    # Receive some messages\\n    for i in range(3):\\n        message = Message(f\\\"User{i}\\\", f\\\"Message {i}\\\", 1640995200.0 + i, i)\\n        await client.receive_message(message)\\n\\n    assert len(client.conversation_history) == 3\\n\\n    # Participate in debate\\n    response = await client.get_response(\\\"Test topic\\\", [])\\n    assert response == \\\"Test response\\\"\\n    assert client.stats['responses_given'] == 1\\n\\n    # Deactivate\\n    await client.set_active(False)\\n    assert client.is_active == False\\n\\n    # Should not respond when inactive\\n    response = await client.get_response(\\\"Another topic\\\", [])\\n    assert response == \\\"\\\"\"\n        },\n        \"test_moderator.py\": {\n          \"type\": \"file\",\n          \"path\": \"tests/test_moderator.py\",\n          \"extension\": \".py\",\n          \"size\": 9146,\n          \"content\": \"\\\"\\\"\\\"\\nTests for the Moderator class.\\n\\\"\\\"\\\"\\n\\nimport pytest\\nimport asyncio\\nfrom unittest.mock import Mock, AsyncMock, patch\\nfrom app.moderator import Moderator, DebatePhase, DebateState\\nfrom app.chat_log import ChatLog\\nfrom app.voting import VotingSystem\\nfrom app.bot_client import BotClient\\nfrom app.human_client import HumanClient\\n\\n\\n@pytest.fixture\\ndef chat_log():\\n    \\\"\\\"\\\"Create a test chat log.\\\"\\\"\\\"\\n    return ChatLog()\\n\\n\\n@pytest.fixture\\ndef voting_system():\\n    \\\"\\\"\\\"Create a test voting system.\\\"\\\"\\\"\\n    config = {'enabled': True, 'voting_duration': 60}\\n    return VotingSystem(config)\\n\\n\\n@pytest.fixture\\ndef mock_participants():\\n    \\\"\\\"\\\"Create mock participants.\\\"\\\"\\\"\\n    bot = Mock(spec=BotClient)\\n    bot.name = \\\"TestBot\\\"\\n    bot.get_response = AsyncMock(return_value=\\\"Test response\\\")\\n    bot.receive_message = AsyncMock()\\n\\n    human = Mock(spec=HumanClient)\\n    human.name = \\\"TestHuman\\\"\\n    human.get_response = AsyncMock(return_value=\\\"Human response\\\")\\n    human.receive_message = AsyncMock()\\n\\n    return [bot, human]\\n\\n\\n@pytest.fixture\\ndef moderator(chat_log, voting_system, mock_participants):\\n    \\\"\\\"\\\"Create a test moderator.\\\"\\\"\\\"\\n    config = {\\n        'opening_statement_time': 30,\\n        'discussion_time': 60,\\n        'closing_statement_time': 30,\\n        'response_time': 20,\\n        'max_response_time': 60,\\n        'warning_time': 45\\n    }\\n\\n    return Moderator(\\n        topic=\\\"Test topic\\\",\\n        participants=mock_participants,\\n        chat_log=chat_log,\\n        voting_system=voting_system,\\n        config=config\\n    )\\n\\n\\nclass TestModerator:\\n    \\\"\\\"\\\"Test suite for Moderator class.\\\"\\\"\\\"\\n\\n    def test_moderator_initialization(self, moderator):\\n        \\\"\\\"\\\"Test moderator initialization.\\\"\\\"\\\"\\n        assert moderator.topic == \\\"Test topic\\\"\\n        assert len(moderator.participants) == 2\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\n        assert \\\"TestBot\\\" in moderator.participants\\n        assert \\\"TestHuman\\\" in moderator.participants\\n\\n    @pytest.mark.asyncio\\n    async def test_introduction_phase(self, moderator, chat_log):\\n        \\\"\\\"\\\"Test introduction phase.\\\"\\\"\\\"\\n        await moderator._introduction_phase()\\n\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\n\\n        # Check that introduction message was logged\\n        messages = chat_log.get_messages()\\n        assert any(\\\"Welcome to AI Jubilee Debate\\\" in msg.content for msg in messages)\\n\\n    @pytest.mark.asyncio\\n    async def test_opening_statements_phase(self, moderator, mock_participants):\\n        \\\"\\\"\\\"Test opening statements phase.\\\"\\\"\\\"\\n        await moderator._opening_statements_phase()\\n\\n        assert moderator.state.phase == DebatePhase.OPENING_STATEMENTS\\n\\n        # Verify each participant was asked for response\\n        for participant in mock_participants:\\n            participant.get_response.assert_called()\\n\\n    @pytest.mark.asyncio\\n    async def test_give_turn_success(self, moderator, mock_participants):\\n        \\\"\\\"\\\"Test successful turn giving.\\\"\\\"\\\"\\n        participant = mock_participants[0]\\n        participant.get_response.return_value = \\\"Test response\\\"\\n\\n        await moderator._give_turn(participant.name, 30, \\\"test\\\")\\n\\n        participant.get_response.assert_called_once()\\n        assert moderator.state.current_speaker is None  # Reset after turn\\n\\n    @pytest.mark.asyncio\\n    async def test_give_turn_timeout(self, moderator, mock_participants):\\n        \\\"\\\"\\\"Test turn timeout handling.\\\"\\\"\\\"\\n        participant = mock_participants[0]\\n\\n        # Simulate timeout by making get_response take too long\\n        async def slow_response(*args):\\n            await asyncio.sleep(2)\\n            return \\\"Too late\\\"\\n\\n        participant.get_response = slow_response\\n\\n        # Use very short timeout for testing\\n        await moderator._give_turn(participant.name, 0.1, \\\"test\\\")\\n\\n        # Should have issued a warning\\n        assert moderator.state.warnings_issued.get(participant.name, 0) >= 1\\n\\n    @pytest.mark.asyncio\\n    async def test_voting_phase_enabled(self, moderator):\\n        \\\"\\\"\\\"Test voting phase when voting is enabled.\\\"\\\"\\\"\\n        moderator.voting_system.enabled = True\\n\\n        with patch.object(moderator.voting_system, 'start_voting') as mock_start:\\n            with patch.object(moderator.voting_system, 'end_voting') as mock_end:\\n                mock_end.return_value = {\\n                    'winner': 'TestBot',\\n                    'vote_counts': {'TestBot': 2, 'TestHuman': 1}\\n                }\\n\\n                results = await moderator._voting_phase()\\n\\n                mock_start.assert_called_once()\\n                mock_end.assert_called_once()\\n                assert results['winner'] == 'TestBot'\\n\\n    @pytest.mark.asyncio\\n    async def test_voting_phase_disabled(self, moderator):\\n        \\\"\\\"\\\"Test voting phase when voting is disabled.\\\"\\\"\\\"\\n        moderator.voting_system.enabled = False\\n\\n        results = await moderator._voting_phase()\\n\\n        assert results == {}\\n\\n    @pytest.mark.asyncio\\n    async def test_broadcast_message(self, moderator, mock_participants, chat_log):\\n        \\\"\\\"\\\"Test message broadcasting.\\\"\\\"\\\"\\n        await moderator._broadcast_message(\\\"Test message\\\", \\\"moderator\\\")\\n\\n        # Check message was logged\\n        messages = chat_log.get_messages()\\n        assert any(msg.content == \\\"Test message\\\" for msg in messages)\\n\\n        # Check all participants received message\\n        for participant in mock_participants:\\n            participant.receive_message.assert_called()\\n\\n    @pytest.mark.asyncio\\n    async def test_handle_timeout_warnings(self, moderator):\\n        \\\"\\\"\\\"Test timeout warning system.\\\"\\\"\\\"\\n        participant_name = \\\"TestBot\\\"\\n\\n        # First timeout\\n        await moderator._handle_timeout(participant_name)\\n        assert moderator.state.warnings_issued[participant_name] == 1\\n\\n        # Second timeout\\n        await moderator._handle_timeout(participant_name)\\n        assert moderator.state.warnings_issued[participant_name] == 2\\n\\n        # Third timeout (should trigger mute)\\n        await moderator._handle_timeout(participant_name)\\n        assert moderator.state.warnings_issued[participant_name] == 3\\n\\n    def test_get_state(self, moderator):\\n        \\\"\\\"\\\"Test state retrieval.\\\"\\\"\\\"\\n        state = moderator.get_state()\\n\\n        assert isinstance(state, DebateState)\\n        assert state.phase == DebatePhase.INTRODUCTION\\n        assert state.current_speaker is None\\n\\n    @pytest.mark.asyncio\\n    async def test_full_debate_flow(self, moderator, mock_participants):\\n        \\\"\\\"\\\"Test complete debate flow.\\\"\\\"\\\"\\n        # Mock voting system methods\\n        moderator.voting_system.start_voting = AsyncMock()\\n        moderator.voting_system.end_voting = AsyncMock(return_value={\\n            'winner': 'TestBot',\\n            'vote_counts': {'TestBot': 1, 'TestHuman': 0}\\n        })\\n\\n        # Run complete debate with short timeouts for testing\\n        moderator.phase_times[DebatePhase.DISCUSSION] = 1  # 1 second\\n\\n        results = await moderator.run_debate()\\n\\n        # Verify all phases completed\\n        assert moderator.state.phase == DebatePhase.FINISHED\\n        assert 'winner' in results\\n\\n        # Verify participants were called\\n        for participant in mock_participants:\\n            assert participant.get_response.call_count > 0\\n\\n\\nclass TestDebateState:\\n    \\\"\\\"\\\"Test suite for DebateState dataclass.\\\"\\\"\\\"\\n\\n    def test_debate_state_initialization(self):\\n        \\\"\\\"\\\"Test DebateState initialization.\\\"\\\"\\\"\\n        state = DebateState(DebatePhase.DISCUSSION)\\n\\n        assert state.phase == DebatePhase.DISCUSSION\\n        assert state.current_speaker is None\\n        assert state.time_remaining == 0\\n        assert state.turn_order == []\\n        assert state.warnings_issued == {}\\n\\n    def test_debate_state_with_values(self):\\n        \\\"\\\"\\\"Test DebateState with custom values.\\\"\\\"\\\"\\n        turn_order = [\\\"Bot1\\\", \\\"Human1\\\", \\\"Bot2\\\"]\\n        warnings = {\\\"Bot1\\\": 1}\\n\\n        state = DebateState(\\n            phase=DebatePhase.VOTING,\\n            current_speaker=\\\"Human1\\\",\\n            time_remaining=120,\\n            turn_order=turn_order,\\n            warnings_issued=warnings\\n        )\\n\\n        assert state.phase == DebatePhase.VOTING\\n        assert state.current_speaker == \\\"Human1\\\"\\n        assert state.time_remaining == 120\\n        assert state.turn_order == turn_order\\n        assert state.warnings_issued == warnings\\n\\n\\n@pytest.mark.asyncio\\nasync def test_moderator_error_handling(moderator, mock_participants):\\n    \\\"\\\"\\\"Test moderator error handling.\\\"\\\"\\\"\\n    # Make participant raise an error\\n    mock_participants[0].get_response.side_effect = Exception(\\\"Test error\\\")\\n\\n    # Should not crash the debate\\n    await moderator._give_turn(mock_participants[0].name, 30, \\\"test\\\")\\n\\n    # Moderator should continue functioning\\n    assert moderator.state.phase == DebatePhase.INTRODUCTION\\n\\n\\n@pytest.mark.asyncio\\nasync def test_moderator_message_validation(moderator):\\n    \\\"\\\"\\\"Test message content validation.\\\"\\\"\\\"\\n    long_message = \\\"x\\\" * 1000  # Very long message\\n\\n    await moderator._process_response(\\\"TestBot\\\", long_message)\\n\\n    # Should have been truncated\\n    messages = moderator.chat_log.get_messages()\\n    last_message = messages[-1]\\n    assert len(last_message.content) <= 503  # 500 + \\\"...\\\"\"\n        },\n        \"test_voting.py\": {\n          \"type\": \"file\",\n          \"path\": \"tests/test_voting.py\",\n          \"extension\": \".py\",\n          \"size\": 16340,\n          \"content\": \"\\\"\\\"\\\"\\nTests for the VotingSystem class.\\n\\\"\\\"\\\"\\n\\nimport pytest\\nimport asyncio\\nimport time\\nfrom app.voting import VotingSystem, Vote, VotingResults\\n\\n\\n@pytest.fixture\\ndef voting_config():\\n    \\\"\\\"\\\"Create test voting configuration.\\\"\\\"\\\"\\n    return {\\n        'enabled': True,\\n        'voting_duration': 60,\\n        'allow_participant_voting': True,\\n        'require_justification': False,\\n        'anonymous_votes': False\\n    }\\n\\n\\n@pytest.fixture\\ndef voting_system(voting_config):\\n    \\\"\\\"\\\"Create test voting system.\\\"\\\"\\\"\\n    return VotingSystem(voting_config)\\n\\n\\n@pytest.fixture\\ndef active_voting_system(voting_system):\\n    \\\"\\\"\\\"Create and start a voting session.\\\"\\\"\\\"\\n    asyncio.create_task(voting_system.start_voting(['Alice', 'Bob', 'Charlie'], 30))\\n    return voting_system\\n\\n\\nclass TestVotingSystem:\\n    \\\"\\\"\\\"Test suite for VotingSystem class.\\\"\\\"\\\"\\n\\n    def test_voting_system_initialization(self, voting_config):\\n        \\\"\\\"\\\"Test voting system initialization.\\\"\\\"\\\"\\n        vs = VotingSystem(voting_config)\\n\\n        assert vs.enabled == True\\n        assert vs.voting_duration == 60\\n        assert vs.allow_participant_voting == True\\n        assert vs.require_justification == False\\n        assert vs.anonymous_votes == False\\n        assert vs.is_active == False\\n        assert vs.candidates == []\\n        assert vs.votes == {}\\n\\n    def test_disabled_voting_system(self):\\n        \\\"\\\"\\\"Test disabled voting system.\\\"\\\"\\\"\\n        config = {'enabled': False}\\n        vs = VotingSystem(config)\\n\\n        assert vs.enabled == False\\n\\n    @pytest.mark.asyncio\\n    async def test_start_voting_session(self, voting_system):\\n        \\\"\\\"\\\"Test starting a voting session.\\\"\\\"\\\"\\n        candidates = ['Alice', 'Bob', 'Charlie']\\n\\n        await voting_system.start_voting(candidates, 30)\\n\\n        assert voting_system.is_active == True\\n        assert voting_system.candidates == candidates\\n        assert voting_system.eligible_voters == candidates  # allow_participant_voting=True\\n        assert voting_system.start_time is not None\\n        assert voting_system.end_time is not None\\n\\n    @pytest.mark.asyncio\\n    async def test_start_voting_disabled_system(self):\\n        \\\"\\\"\\\"Test starting voting on disabled system.\\\"\\\"\\\"\\n        config = {'enabled': False}\\n        vs = VotingSystem(config)\\n\\n        with pytest.raises(ValueError, match=\\\"Voting system is disabled\\\"):\\n            await vs.start_voting(['Alice', 'Bob'])\\n\\n    @pytest.mark.asyncio\\n    async def test_start_voting_already_active(self, voting_system):\\n        \\\"\\\"\\\"Test starting voting when already active.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n        with pytest.raises(ValueError, match=\\\"Voting session already active\\\"):\\n            await voting_system.start_voting(['Charlie', 'Dave'])\\n\\n    @pytest.mark.asyncio\\n    async def test_cast_valid_vote(self, voting_system):\\n        \\\"\\\"\\\"Test casting a valid vote.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\n\\n        result = await voting_system.cast_vote('voter1', 'Alice', 'Great arguments')\\n\\n        assert result == True\\n        assert 'voter1' in voting_system.votes\\n        assert voting_system.votes['voter1'].candidate == 'Alice'\\n        assert voting_system.votes['voter1'].justification == 'Great arguments'\\n\\n    @pytest.mark.asyncio\\n    async def test_cast_vote_no_active_session(self, voting_system):\\n        \\\"\\\"\\\"Test casting vote with no active session.\\\"\\\"\\\"\\n        with pytest.raises(ValueError, match=\\\"No active voting session\\\"):\\n            await voting_system.cast_vote('voter1', 'Alice')\\n\\n    @pytest.mark.asyncio\\n    async def test_cast_vote_invalid_candidate(self, voting_system):\\n        \\\"\\\"\\\"Test casting vote for invalid candidate.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n        with pytest.raises(ValueError, match=\\\"Invalid candidate\\\"):\\n            await voting_system.cast_vote('voter1', 'Charlie')\\n\\n    @pytest.mark.asyncio\\n    async def test_cast_vote_requires_justification(self):\\n        \\\"\\\"\\\"Test voting system that requires justification.\\\"\\\"\\\"\\n        config = {\\n            'enabled': True,\\n            'require_justification': True,\\n            'allow_participant_voting': True\\n        }\\n        vs = VotingSystem(config)\\n        await vs.start_voting(['Alice', 'Bob'])\\n\\n        # Vote without justification should fail\\n        with pytest.raises(ValueError, match=\\\"Vote justification is required\\\"):\\n            await vs.cast_vote('voter1', 'Alice')\\n\\n        # Vote with justification should succeed\\n        result = await vs.cast_vote('voter1', 'Alice', 'Good points')\\n        assert result == True\\n\\n    @pytest.mark.asyncio\\n    async def test_cast_vote_overwrite(self, voting_system):\\n        \\\"\\\"\\\"Test that new vote overwrites previous vote.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.cast_vote('voter1', 'Bob')  # Change vote\\n\\n        assert voting_system.votes['voter1'].candidate == 'Bob'\\n        assert len(voting_system.votes) == 1  # Only one vote per voter\\n\\n    @pytest.mark.asyncio\\n    async def test_self_voting_allowed(self, voting_system):\\n        \\\"\\\"\\\"Test self-voting when allowed.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n    @pytest.mark.asyncio\\n    async def test_self_voting_allowed(self, voting_system):\\n        \\\"\\\"\\\"Test self-voting when allowed.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n        # Should allow participant to vote for themselves\\n        result = await voting_system.cast_vote('Alice', 'Alice')\\n        assert result == True\\n\\n    @pytest.mark.asyncio\\n    async def test_self_voting_disallowed(self):\\n        \\\"\\\"\\\"Test self-voting when disallowed.\\\"\\\"\\\"\\n        config = {\\n            'enabled': True,\\n            'allow_participant_voting': False\\n        }\\n        vs = VotingSystem(config)\\n        await vs.start_voting(['Alice', 'Bob'])\\n\\n        with pytest.raises(ValueError, match=\\\"Self-voting is not allowed\\\"):\\n            await vs.cast_vote('Alice', 'Alice')\\n\\n    @pytest.mark.asyncio\\n    async def test_end_voting_session(self, voting_system):\\n        \\\"\\\"\\\"Test ending a voting session.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\n\\n        # Cast some votes\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.cast_vote('voter2', 'Alice')\\n        await voting_system.cast_vote('voter3', 'Bob')\\n\\n        results = await voting_system.end_voting()\\n\\n        assert isinstance(results, VotingResults)\\n        assert results.winner == 'Alice'  # Most votes\\n        assert results.vote_counts['Alice'] == 2\\n        assert results.vote_counts['Bob'] == 1\\n        assert results.total_votes == 3\\n        assert voting_system.is_active == False\\n\\n    @pytest.mark.asyncio\\n    async def test_end_voting_tie(self, voting_system):\\n        \\\"\\\"\\\"Test ending voting with a tie.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.cast_vote('voter2', 'Bob')\\n\\n        results = await voting_system.end_voting()\\n\\n        assert \\\"TIE:\\\" in results.winner\\n        assert \\\"Alice\\\" in results.winner\\n        assert \\\"Bob\\\" in results.winner\\n\\n    @pytest.mark.asyncio\\n    async def test_end_voting_no_votes(self, voting_system):\\n        \\\"\\\"\\\"Test ending voting with no votes cast.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n\\n        results = await voting_system.end_voting()\\n\\n        assert results.winner is None\\n        assert results.total_votes == 0\\n        assert results.vote_counts == {}\\n\\n    @pytest.mark.asyncio\\n    async def test_end_voting_not_active(self, voting_system):\\n        \\\"\\\"\\\"Test ending voting when not active.\\\"\\\"\\\"\\n        with pytest.raises(ValueError, match=\\\"No active voting session\\\"):\\n            await voting_system.end_voting()\\n\\n    def test_get_vote_summary(self, voting_system):\\n        \\\"\\\"\\\"Test getting vote summary during active session.\\\"\\\"\\\"\\n        # No active session\\n        summary = voting_system.get_vote_summary()\\n        assert summary == {}\\n\\n        # With active session\\n        asyncio.create_task(voting_system.start_voting(['Alice', 'Bob'], 60))\\n        summary = voting_system.get_vote_summary()\\n\\n        assert 'candidates' in summary\\n        assert 'vote_counts' in summary\\n        assert 'total_votes' in summary\\n        assert 'time_remaining' in summary\\n        assert 'is_active' in summary\\n\\n    def test_add_remove_eligible_voters(self, voting_system):\\n        \\\"\\\"\\\"Test adding and removing eligible voters.\\\"\\\"\\\"\\n        voting_system.add_eligible_voter('voter1')\\n        assert 'voter1' in voting_system.eligible_voters\\n\\n        voting_system.add_eligible_voter('voter2')\\n        assert len(voting_system.eligible_voters) == 2\\n\\n        voting_system.remove_eligible_voter('voter1')\\n        assert 'voter1' not in voting_system.eligible_voters\\n        assert len(voting_system.eligible_voters) == 1\\n\\n    def test_is_eligible_voter(self, voting_system):\\n        \\\"\\\"\\\"Test voter eligibility checking.\\\"\\\"\\\"\\n        # Empty eligible voters list means open voting\\n        assert voting_system._is_eligible_voter('anyone') == True\\n\\n        # With specific eligible voters\\n        voting_system.add_eligible_voter('voter1')\\n        assert voting_system._is_eligible_voter('voter1') == True\\n        assert voting_system._is_eligible_voter('voter2') == False\\n\\n    @pytest.mark.asyncio\\n    async def test_vote_history(self, voting_system):\\n        \\\"\\\"\\\"Test vote history tracking.\\\"\\\"\\\"\\n        # First session\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.end_voting()\\n\\n        # Second session\\n        await voting_system.start_voting(['Charlie', 'Dave'])\\n        await voting_system.cast_vote('voter1', 'Charlie')\\n        await voting_system.end_voting()\\n\\n        assert len(voting_system.vote_history) == 2\\n\\n        # Test voter history\\n        voter_history = voting_system.get_voter_history('voter1')\\n        assert len(voter_history) == 2\\n        assert voter_history[0].candidate == 'Alice'\\n        assert voter_history[1].candidate == 'Charlie'\\n\\n    def test_candidate_performance(self, voting_system):\\n        \\\"\\\"\\\"Test candidate performance tracking.\\\"\\\"\\\"\\n        # Add some mock history\\n        voting_system.vote_history = [\\n            {\\n                'candidates': ['Alice', 'Bob'],\\n                'results': VotingResults(\\n                    winner='Alice',\\n                    vote_counts={'Alice': 2, 'Bob': 1},\\n                    total_votes=3,\\n                    votes_by_voter={},\\n                    voting_duration=60,\\n                    participation_rate=1.0\\n                )\\n            },\\n            {\\n                'candidates': ['Alice', 'Charlie'],\\n                'results': VotingResults(\\n                    winner='Charlie',\\n                    vote_counts={'Alice': 1, 'Charlie': 2},\\n                    total_votes=3,\\n                    votes_by_voter={},\\n                    voting_duration=60,\\n                    participation_rate=1.0\\n                )\\n            }\\n        ]\\n\\n        performance = voting_system.get_candidate_performance('Alice')\\n\\n        assert performance['wins'] == 1\\n        assert performance['participations'] == 2\\n        assert performance['total_votes'] == 3\\n        assert performance['win_rate'] == 0.5\\n        assert performance['avg_votes'] == 1.5\\n\\n    @pytest.mark.asyncio\\n    async def test_export_results_json(self, voting_system):\\n        \\\"\\\"\\\"Test exporting results in JSON format.\\\"\\\"\\\"\\n        # Create some history\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.end_voting()\\n\\n        json_output = await voting_system.export_results('json')\\n\\n        assert isinstance(json_output, str)\\n        assert 'Alice' in json_output\\n        assert 'vote_counts' in json_output\\n\\n    @pytest.mark.asyncio\\n    async def test_export_results_csv(self, voting_system):\\n        \\\"\\\"\\\"Test exporting results in CSV format.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.end_voting()\\n\\n        csv_output = await voting_system.export_results('csv')\\n\\n        assert isinstance(csv_output, str)\\n        assert 'Session,Timestamp,Candidate,Votes,Winner' in csv_output\\n        assert 'Alice' in csv_output\\n\\n    @pytest.mark.asyncio\\n    async def test_export_results_txt(self, voting_system):\\n        \\\"\\\"\\\"Test exporting results in TXT format.\\\"\\\"\\\"\\n        await voting_system.start_voting(['Alice', 'Bob'])\\n        await voting_system.cast_vote('voter1', 'Alice')\\n        await voting_system.end_voting()\\n\\n        txt_output = await voting_system.export_results('txt')\\n\\n        assert isinstance(txt_output, str)\\n        assert 'VOTING HISTORY REPORT' in txt_output\\n        assert 'Alice' in txt_output\\n\\n    @pytest.mark.asyncio\\n    async def test_export_unsupported_format(self, voting_system):\\n        \\\"\\\"\\\"Test exporting with unsupported format.\\\"\\\"\\\"\\n        with pytest.raises(ValueError, match=\\\"Unsupported format\\\"):\\n            await voting_system.export_results('xml')\\n\\n    def test_reset_voting_system(self, voting_system):\\n        \\\"\\\"\\\"Test resetting the voting system.\\\"\\\"\\\"\\n        # Set up some state\\n        voting_system.candidates = ['Alice', 'Bob']\\n        voting_system.votes = {'voter1': Vote('voter1', 'Alice')}\\n        voting_system.is_active = True\\n\\n        voting_system.reset()\\n\\n        assert voting_system.is_active == False\\n        assert voting_system.candidates == []\\n        assert voting_system.votes == {}\\n        assert voting_system.start_time is None\\n        assert voting_system.end_time is None\\n\\n    def test_voting_system_status(self, voting_system):\\n        \\\"\\\"\\\"Test voting system status property.\\\"\\\"\\\"\\n        status = voting_system.status\\n\\n        assert 'enabled' in status\\n        assert 'is_active' in status\\n        assert 'candidates' in status\\n        assert 'eligible_voters' in status\\n        assert 'votes_cast' in status\\n        assert 'time_remaining' in status\\n        assert 'sessions_completed' in status\\n\\n    @pytest.mark.asyncio\\n    async def test_vote_after_time_expires(self, voting_system):\\n        \\\"\\\"\\\"Test casting vote after voting time expires.\\\"\\\"\\\"\\n        # Start voting with very short duration\\n        await voting_system.start_voting(['Alice', 'Bob'], 0.1)\\n\\n        # Wait for voting to expire\\n        await asyncio.sleep(0.2)\\n\\n        with pytest.raises(ValueError, match=\\\"Voting period has ended\\\"):\\n            await voting_system.cast_vote('voter1', 'Alice')\\n\\n\\nclass TestVote:\\n    \\\"\\\"\\\"Test suite for Vote dataclass.\\\"\\\"\\\"\\n\\n    def test_vote_creation(self):\\n        \\\"\\\"\\\"Test creating a vote.\\\"\\\"\\\"\\n        vote = Vote('voter1', 'Alice', 'Great arguments')\\n\\n        assert vote.voter_id == 'voter1'\\n        assert vote.candidate == 'Alice'\\n        assert vote.justification == 'Great arguments'\\n        assert vote.anonymous == False\\n        assert isinstance(vote.timestamp, float)\\n\\n    def test_vote_anonymous(self):\\n        \\\"\\\"\\\"Test creating anonymous vote.\\\"\\\"\\\"\\n        vote = Vote('voter1', 'Alice', anonymous=True)\\n\\n        assert vote.anonymous == True\\n\\n    def test_vote_no_justification(self):\\n        \\\"\\\"\\\"Test vote without justification.\\\"\\\"\\\"\\n        vote = Vote('voter1', 'Alice')\\n\\n        assert vote.justification is None\\n\\n\\nclass TestVotingResults:\\n    \\\"\\\"\\\"Test suite for VotingResults dataclass.\\\"\\\"\\\"\\n\\n    def test_voting_results_creation(self):\\n        \\\"\\\"\\\"Test creating voting results.\\\"\\\"\\\"\\n        vote_counts = {'Alice': 2, 'Bob': 1}\\n        votes_by_voter = {\\n            'voter1': Vote('voter1', 'Alice'),\\n            'voter2': Vote('voter2', 'Alice'),\\n            'voter3': Vote('voter3', 'Bob')\\n        }\\n\\n        results = VotingResults(\\n            winner='Alice',\\n            vote_counts=vote_counts,\\n            total_votes=3,\\n            votes_by_voter=votes_by_voter,\\n            voting_duration=60.0,\\n            participation_rate=1.0\\n        )\\n\\n        assert results.winner == 'Alice'\\n        assert results.vote_counts == vote_counts\\n        assert results.total_votes == 3\\n        assert len(results.votes_by_voter) == 3\\n        assert results.voting_duration == 60.0\\n        assert results.participation_rate == 1.0\"\n        }\n      }\n    },\n    \"config.yaml\": {\n      \"type\": \"file\",\n      \"path\": \"config.yaml\",\n      \"extension\": \".yaml\",\n      \"size\": 3412,\n      \"content\": \"# AI Jubilee Debate Configuration\\n\\n# Debate Settings\\ndebate:\\n  default_topic: \\\"The role of artificial intelligence in modern society\\\"\\n  max_participants: 4\\n  time_limit_minutes: 10\\n  opening_statement_time: 120  # seconds\\n  response_time: 60  # seconds\\n  closing_statement_time: 90  # seconds\\n\\n  # Debate mode: \\\"sequential\\\" or \\\"autonomous\\\"\\n  mode: \\\"autonomous\\\"  # AUTONOMOUS MODE: Bots monitor and decide when to speak!\\n\\n  # Autonomous mode settings\\n  min_bot_cooldown: 15          # Minimum seconds between bot responses\\n  max_bot_cooldown: 20          # Maximum cooldown for very active bots\\n  message_check_interval: 5     # How often bots check for new messages\\n  silence_timeout: 60           # Seconds of silence before moderator intervenes\\n\\n# Available debate topics\\ntopics:\\n  - \\\"AI will create more jobs than it destroys\\\"\\n  - \\\"Social media has a net positive impact on democracy\\\"\\n\\n\\n# AI Moderator Configuration (NEW!)\\nmoderator:\\n  name: \\\"Moderator\\\"\\n  model: \\\"gpt-4\\\"\\n  provider: \\\"openai\\\"\\n  personality: \\\"Professional debate facilitator who asks insightful questions, encourages participation, and helps explore different angles of the topic. Speaks when the conversation needs direction or when interesting points need deeper exploration.\\\"\\n  stance: \\\"neutral\\\"\\n  temperature: 0.7\\n  max_tokens: 150\\n\\n# AI Bot Configurations\\nbots:\\n  - name: \\\"Socrates\\\"\\n    model: \\\"gpt-4\\\"\\n    provider: \\\"openai\\\"\\n    personality: \\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\"\\n    debate_style: \\\"socratic\\\"\\n    stance: \\\"neutral\\\"\\n    max_tokens: 100\\n\\n  - name: \\\"Advocate\\\"\\n    model: \\\"gpt-4\\\"\\n    provider: \\\"openai\\\"\\n    personality: \\\"Passionate supporter, data-driven, persuasive speaker. Jumps in when position is challenged.\\\"\\n    debate_style: \\\"assertive\\\"\\n    stance: \\\"pro\\\"\\n    max_tokens: 100\\n\\n  - name: \\\"Skeptic\\\"\\n    model: \\\"gpt-3.5-turbo\\\"\\n    provider: \\\"openai\\\"\\n    personality: \\\"Critical thinker, questions assumptions, looks for flaws. Responds when claims need scrutiny.\\\"\\n    debate_style: \\\"analytical\\\"\\n    stance: \\\"con\\\"\\n    max_tokens: 100\\n\\n  - name: \\\"Mediator\\\"\\n    model: \\\"gpt-3.5-turbo\\\"\\n    provider: \\\"openai\\\"\\n    personality: \\\"Balanced, seeks common ground, diplomatic. Speaks to bridge disagreements and find synthesis.\\\"\\n    debate_style: \\\"collaborative\\\"\\n    stance: \\\"neutral\\\"\\n    max_tokens: 100\\n\\n# API Keys (use environment variables in production)\\napi_keys:\\n  openai: \\\"${OPENAI_API_KEY}\\\"\\n  anthropic: \\\"${ANTHROPIC_API_KEY}\\\"\\n\\n# Voting System\\nvoting:\\n  enabled: true\\n  voting_duration: 300  # seconds\\n  allow_participant_voting: true\\n  require_justification: true\\n  anonymous_votes: false\\n\\n# Chat and Logging\\nchat:\\n  max_message_length: 500\\n  enable_timestamps: true\\n  log_level: \\\"INFO\\\"\\n  save_transcripts: true\\n  transcript_format: \\\"json\\\"\\n\\n# Streaming Configuration\\nstreaming:\\n  enabled: false\\n  websocket_port: 8080\\n  max_connections: 100\\n  broadcast_votes: true\\n\\n# Timeouts and Limits\\nlimits:\\n  max_response_time: 120  # seconds\\n  warning_time: 90  # seconds\\n  max_retries: 3\\n  rate_limit_per_minute: 10\\n\\n# Moderation Rules\\nmoderation:\\n  enable_profanity_filter: true\\n  max_interruptions: 3\\n  enforce_turn_order: false  # No turn order in autonomous mode\\n  auto_mute_violations: true\\n\\n# Human Interface\\ninterface:\\n  mode: \\\"cli\\\"  # options: cli, web, api\\n  enable_rich_formatting: true\\n  show_typing_indicators: true\\n  enable_reactions: true\"\n    },\n    \"debate_Remote work is the f.json\": {\n      \"type\": \"file\",\n      \"path\": \"debate_Remote work is the f.json\",\n      \"extension\": \".json\",\n      \"size\": 13914,\n      \"content\": \"{\\n  \\\"metadata\\\": {\\n    \\\"export_timestamp\\\": 1749817045.239899,\\n    \\\"total_messages\\\": 42,\\n    \\\"statistics\\\": {\\n      \\\"total_messages\\\": 42,\\n      \\\"unique_senders\\\": 5,\\n      \\\"messages_by_sender\\\": {\\n        \\\"moderator\\\": 32,\\n        \\\"Socrates\\\": 3,\\n        \\\"Advocate\\\": 3,\\n        \\\"Mediator\\\": 3,\\n        \\\"Human_1\\\": 1\\n      },\\n      \\\"messages_per_minute\\\": 2.069704853831723,\\n      \\\"session_duration_minutes\\\": 20.29274846712748,\\n      \\\"current_message_count\\\": 42\\n    }\\n  },\\n  \\\"messages\\\": [\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé≠ Welcome to AI Jubilee Debate!\\\\nüìù Topic: Remote work is the future of employment\\\\nüë• Participants: Socrates, Advocate, Mediator, Human_1\\\\n‚è±Ô∏è Total time: 30 minutes\\\",\\n      \\\"timestamp\\\": 1749815828.371039,\\n      \\\"message_id\\\": 1,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Opening Statements Phase\\\\nEach participant has 120 seconds for their opening statement.\\\",\\n      \\\"timestamp\\\": 1749815831.3736022,\\n      \\\"message_id\\\": 2,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Socrates's turn for opening statement (120s)\\\",\\n      \\\"timestamp\\\": 1749815831.375623,\\n      \\\"message_id\\\": 3,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815839.0529852,\\n      \\\"message_id\\\": 4,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Socrates\\\",\\n      \\\"content\\\": \\\"Indeed, this is a topic worthy of our contemplation. The concept of remote work, or telecommuting, has been thrust into the spotlight due to current global circumstances. As we partake in this discourse, let us remember that the future is not a fixed point, but a journey shaped by our choices and actions. Remote work has shown potential to increase productivity and provide flexibility, yet it also introduces challenges in maintaining work-life boundaries and effective communication. Therefore, i...\\\",\\n      \\\"timestamp\\\": 1749815839.055337,\\n      \\\"message_id\\\": 5,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Advocate's turn for opening statement (120s)\\\",\\n      \\\"timestamp\\\": 1749815839.055578,\\n      \\\"message_id\\\": 6,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815845.0692759,\\n      \\\"message_id\\\": 7,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Advocate\\\",\\n      \\\"content\\\": \\\"Advocate: Thank you, moderator. I would like to open by stating that remote work is undoubtedly the future of employment. This is not just a speculative assertion, but a fact supported by an increasing body of evidence. Remote work offers unprecedented flexibility, leading to increased productivity, employee satisfaction, and a reduction in overhead costs for companies. According to a survey by Global Workplace Analytics, businesses can save up to $11,000 per year for every employee who works re...\\\",\\n      \\\"timestamp\\\": 1749815845.0708978,\\n      \\\"message_id\\\": 8,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Mediator's turn for opening statement (120s)\\\",\\n      \\\"timestamp\\\": 1749815845.070956,\\n      \\\"message_id\\\": 9,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815847.077504,\\n      \\\"message_id\\\": 10,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Mediator\\\",\\n      \\\"content\\\": \\\"As we delve into the discourse surrounding remote work as the future of employment, it's vital to recognize the multifaceted nature of this topic. Remote work undeniably presents a host of advantages, such as flexibility, potential cost savings, and increased productivity for many individuals. However, it's crucial to acknowledge the challenges that come hand in hand with remote work, like maintaining work-life balance, fostering effective communication, and combating feelings of isolation. Stri...\\\",\\n      \\\"timestamp\\\": 1749815847.078847,\\n      \\\"message_id\\\": 11,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Human_1's turn for opening statement (120s)\\\",\\n      \\\"timestamp\\\": 1749815847.0788858,\\n      \\\"message_id\\\": 12,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Human_1\\\",\\n      \\\"content\\\": \\\"hei finaly my turn\\\",\\n      \\\"timestamp\\\": 1749815855.599628,\\n      \\\"message_id\\\": 13,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üí¨ Discussion Phase Begin\\\\nOpen discussion for 30 minutes. Maintain respectful dialogue!\\\",\\n      \\\"timestamp\\\": 1749815855.599648,\\n      \\\"message_id\\\": 14,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Socrates's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815855.5999942,\\n      \\\"message_id\\\": 15,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Socrates: 60 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815855.600161,\\n      \\\"message_id\\\": 16,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Socrates\\\",\\n      \\\"content\\\": \\\"Socrates: I am quite intrigued by the notion of remote work. Yet, I wonder, are we not assuming that all types of work can be performed remotely? A farmer, for instance, cannot till his land from his living room. Moreover, does the isolation associated with remote work not contradict the social nature of human beings? Is it possible that the increase in productivity is only a short-term effect, and in the long run, the lack of human interaction might lead to decreased motivation and engagement?\\\",\\n      \\\"timestamp\\\": 1749815861.113106,\\n      \\\"message_id\\\": 17,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Advocate's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815861.113177,\\n      \\\"message_id\\\": 18,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Advocate: 59 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815861.1147661,\\n      \\\"message_id\\\": 19,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815868.633038,\\n      \\\"message_id\\\": 20,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Advocate\\\",\\n      \\\"content\\\": \\\"Advocate: Indeed, Socrates, your points are valid. However, it's crucial to acknowledge that remote work may not apply to every profession, such as farming. Yet, it fits many industries, notably the ever-growing tech, finance, and creative sectors. \\\\n\\\\nAs for the social aspect, while physical interaction is limited, remote work doesn't necessarily mean isolation. Virtual technologies facilitate team collaboration and social interaction effectively. \\\\n\\\\nLastly, evidence shows the productivity increas...\\\",\\n      \\\"timestamp\\\": 1749815868.6344562,\\n      \\\"message_id\\\": 21,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Mediator's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815868.634491,\\n      \\\"message_id\\\": 22,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Mediator: 59 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815868.635563,\\n      \\\"message_id\\\": 23,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815871.141592,\\n      \\\"message_id\\\": 24,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Mediator\\\",\\n      \\\"content\\\": \\\"Advocate, your points are well taken. It's essential to recognize that while remote work may not be universally applicable, its compatibility with various fields like technology and finance indicates a flexible future for employment. The evolution of virtual technologies indeed enables effective collaboration and social engagement, mitigating the potential isolation concerns often associated with remote work. \\\\n\\\\nWhen considering the productivity aspect, studies have shown mixed results, indicatin...\\\",\\n      \\\"timestamp\\\": 1749815871.142476,\\n      \\\"message_id\\\": 25,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Human_1's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815871.142514,\\n      \\\"message_id\\\": 26,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Human_1: 59 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815871.143828,\\n      \\\"message_id\\\": 27,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Human_1 exceeded time limit. Warning 1/3\\\",\\n      \\\"timestamp\\\": 1749815931.2812438,\\n      \\\"message_id\\\": 28,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Socrates's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815931.283378,\\n      \\\"message_id\\\": 29,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Socrates: 59 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815931.284396,\\n      \\\"message_id\\\": 30,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815938.301232,\\n      \\\"message_id\\\": 31,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Socrates\\\",\\n      \\\"content\\\": \\\"Indeed, the Mediator presents a nuanced perspective. However, I am intrigued by the notion of this 'flexible future for employment'. Does this flexibility extend to the equilibrium between professional and personal lives? How do we ensure that the boundaries between work and home do not blur, leading to overwork and stress? Are there effective measures in place to deal with such possible outcomes of a remote work environment? Furthermore, does the potential for isolation only refer to physical i...\\\",\\n      \\\"timestamp\\\": 1749815938.3026502,\\n      \\\"message_id\\\": 32,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Advocate's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815938.302691,\\n      \\\"message_id\\\": 33,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Advocate: 59 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815938.303506,\\n      \\\"message_id\\\": 34,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815944.81759,\\n      \\\"message_id\\\": 35,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Advocate\\\",\\n      \\\"content\\\": \\\"Advocate: Socrates, your concerns are valid. However, remote work actually enhances the work-life balance when managed properly. Buffer‚Äôs 2019 State of Remote Work report shows that 40% of remote workers consider a flexible schedule as the biggest benefit. As for blurring boundaries, companies are employing digital tools to ensure structured work hours, avoiding overwork. In terms of isolation, while physical isolation is one aspect, remote work fosters a global community, breaking geographical ...\\\",\\n      \\\"timestamp\\\": 1749815944.81867,\\n      \\\"message_id\\\": 36,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Mediator's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815944.818702,\\n      \\\"message_id\\\": 37,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Mediator: 60 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815944.819515,\\n      \\\"message_id\\\": 38,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\",\\n      \\\"timestamp\\\": 1749815947.324934,\\n      \\\"message_id\\\": 39,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"Mediator\\\",\\n      \\\"content\\\": \\\"Advocate, your point about remote work enhancing work-life balance is well-supported by the Buffer report you referenced. It's crucial to acknowledge that remote work can indeed offer flexibility and autonomy, positively impacting employees' well-being. However, Socrates raised a valid concern about the potential for blurred boundaries and isolation, which are essential aspects to consider. It's important for companies to implement clear communication strategies and boundaries to address these c...\\\",\\n      \\\"timestamp\\\": 1749815947.325867,\\n      \\\"message_id\\\": 40,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"üé§ Human_1's turn for response (60s)\\\",\\n      \\\"timestamp\\\": 1749815947.325891,\\n      \\\"message_id\\\": 41,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    },\\n    {\\n      \\\"sender\\\": \\\"moderator\\\",\\n      \\\"content\\\": \\\"‚è∞ Human_1: 59 seconds remaining\\\",\\n      \\\"timestamp\\\": 1749815947.3266392,\\n      \\\"message_id\\\": 42,\\n      \\\"message_type\\\": \\\"chat\\\",\\n      \\\"metadata\\\": {}\\n    }\\n  ]\\n}\"\n    },\n    \"extract.py\": {\n      \"type\": \"file\",\n      \"path\": \"extract.py\",\n      \"extension\": \".py\",\n      \"size\": 13812,\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\nExtract script to read all project files and create a JSON structure.\\nReads all .py, .md, .yml, .yaml files and organizes them in a nested directory structure.\\nRespects .gitignore patterns and skips virtual environments.\\n\\n python extract.py --preview\\n\\n\\\"\\\"\\\"\\n\\nimport os\\nimport json\\nimport datetime\\nimport fnmatch\\nfrom pathlib import Path\\nfrom typing import Dict, Any, Set, List\\n\\n\\ndef parse_gitignore(gitignore_path: Path) -> List[str]:\\n    \\\"\\\"\\\"Parse .gitignore file and return list of patterns.\\\"\\\"\\\"\\n    patterns = []\\n    try:\\n        if gitignore_path.exists():\\n            with open(gitignore_path, 'r', encoding='utf-8') as f:\\n                for line in f:\\n                    line = line.strip()\\n                    # Skip empty lines and comments\\n                    if line and not line.startswith('#'):\\n                        patterns.append(line)\\n    except Exception as e:\\n        print(f\\\"Warning: Could not read .gitignore: {e}\\\")\\n    return patterns\\n\\n\\ndef is_ignored_by_gitignore(file_path: Path, root_path: Path, gitignore_patterns: List[str]) -> bool:\\n    \\\"\\\"\\\"Check if file is ignored by .gitignore patterns.\\\"\\\"\\\"\\n    try:\\n        # Get relative path from root\\n        relative_path = file_path.relative_to(root_path)\\n        path_str = str(relative_path)\\n        path_parts = relative_path.parts\\n\\n        for pattern in gitignore_patterns:\\n            # Handle different gitignore pattern types\\n            if pattern.endswith('/'):\\n                # Directory pattern\\n                pattern = pattern.rstrip('/')\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\n                    return True\\n            elif '/' in pattern:\\n                # Path pattern\\n                if fnmatch.fnmatch(path_str, pattern):\\n                    return True\\n            else:\\n                # Filename pattern\\n                if fnmatch.fnmatch(file_path.name, pattern):\\n                    return True\\n                # Also check if any parent directory matches\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\n                    return True\\n    except ValueError:\\n        # Path is not relative to root\\n        pass\\n    except Exception:\\n        # Any other error, don't ignore\\n        pass\\n\\n    return False\\n\\n\\ndef should_include_file(file_path: Path) -> bool:\\n    \\\"\\\"\\\"Check if file should be included based on extension.\\\"\\\"\\\"\\n    allowed_extensions = {'.py', '.md', '.yml', '.yaml', '.txt', '.json', '.toml', '.cfg', '.ini'}\\n    return file_path.suffix.lower() in allowed_extensions\\n\\n\\ndef should_skip_directory(dir_name: str) -> bool:\\n    \\\"\\\"\\\"Check if directory should be skipped (common build/cache directories).\\\"\\\"\\\"\\n    skip_dirs = {\\n        '__pycache__',\\n        '.git',\\n        '.pytest_cache',\\n        'node_modules',\\n        '.venv',\\n        'venv',\\n        'env',\\n        '.env',\\n        'ENV',\\n        'env.bak',\\n        'venv.bak',\\n        'dist',\\n        'build',\\n        '.idea',\\n        '.vscode',\\n        'htmlcov',\\n        '.coverage',\\n        '.mypy_cache',\\n        '.tox',\\n        '.cache',\\n        'eggs',\\n        '*.egg-info',\\n        '.eggs',\\n        'lib',\\n        'lib64',\\n        'parts',\\n        'sdist',\\n        'var',\\n        'wheels',\\n        'share/python-wheels',\\n        '*.egg-info/',\\n        '.installed.cfg',\\n        '*.egg',\\n        'MANIFEST',\\n        '.DS_Store',\\n        'Thumbs.db'\\n    }\\n    return dir_name in skip_dirs\\n\\n\\ndef is_virtual_environment(dir_path: Path) -> bool:\\n    \\\"\\\"\\\"Check if directory is a virtual environment.\\\"\\\"\\\"\\n    venv_indicators = [\\n        'pyvenv.cfg',\\n        'Scripts/activate',\\n        'bin/activate',\\n        'Scripts/python.exe',\\n        'bin/python'\\n    ]\\n\\n    for indicator in venv_indicators:\\n        if (dir_path / indicator).exists():\\n            return True\\n\\n    # Check for common venv directory names\\n    venv_names = {'venv', '.venv', 'env', '.env', 'ENV', 'virtualenv'}\\n    if dir_path.name in venv_names:\\n        return True\\n\\n    return False\\n\\n\\ndef read_file_content(file_path: Path) -> str:\\n    \\\"\\\"\\\"Read file content safely.\\\"\\\"\\\"\\n    try:\\n        with open(file_path, 'r', encoding='utf-8') as f:\\n            return f.read()\\n    except UnicodeDecodeError:\\n        try:\\n            with open(file_path, 'r', encoding='latin-1') as f:\\n                return f.read()\\n        except Exception as e:\\n            return f\\\"[Error reading file: {e}]\\\"\\n    except Exception as e:\\n        return f\\\"[Error reading file: {e}]\\\"\\n\\n\\ndef extract_directory_structure(root_path: Path, base_path: Path = None, gitignore_patterns: List[str] = None) -> Dict[\\n    str, Any]:\\n    \\\"\\\"\\\"\\n    Recursively extract directory structure and file contents.\\n\\n    Args:\\n        root_path: Path to extract from\\n        base_path: Base path for relative calculations (optional)\\n        gitignore_patterns: List of gitignore patterns to respect\\n\\n    Returns:\\n        Dictionary with nested structure representing directories and files\\n    \\\"\\\"\\\"\\n    if base_path is None:\\n        base_path = root_path\\n\\n    if gitignore_patterns is None:\\n        gitignore_patterns = []\\n\\n    structure = {}\\n\\n    try:\\n        # Ensure we have a Path object\\n        if not isinstance(root_path, Path):\\n            root_path = Path(root_path)\\n\\n        if not isinstance(base_path, Path):\\n            base_path = Path(base_path)\\n\\n        # Check if path exists and is directory\\n        if not root_path.exists():\\n            return {\\\"_error\\\": f\\\"Path does not exist: {root_path}\\\"}\\n\\n        if not root_path.is_dir():\\n            return {\\\"_error\\\": f\\\"Path is not a directory: {root_path}\\\"}\\n\\n        # Get all items in directory\\n        items = list(root_path.iterdir())\\n        items.sort(key=lambda x: (x.is_file(), x.name.lower()))\\n\\n        for item in items:\\n            try:\\n                # Check if item is ignored by gitignore\\n                if is_ignored_by_gitignore(item, base_path, gitignore_patterns):\\n                    continue\\n\\n                # Skip hidden files except specific ones\\n                if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore', '.gitattributes'}:\\n                    continue\\n\\n                if item.is_dir():\\n                    # Skip certain directories\\n                    if should_skip_directory(item.name):\\n                        continue\\n\\n                    # Skip virtual environments\\n                    if is_virtual_environment(item):\\n                        continue\\n\\n                    # Recursively process subdirectories\\n                    substructure = extract_directory_structure(item, base_path, gitignore_patterns)\\n                    if substructure:  # Only add if not empty\\n                        structure[item.name] = {\\n                            \\\"type\\\": \\\"directory\\\",\\n                            \\\"contents\\\": substructure\\n                        }\\n\\n                elif item.is_file():\\n                    # Only include certain file types\\n                    if should_include_file(item):\\n                        file_content = read_file_content(item)\\n                        try:\\n                            relative_path = str(item.relative_to(base_path))\\n                        except ValueError:\\n                            relative_path = str(item)\\n\\n                        structure[item.name] = {\\n                            \\\"type\\\": \\\"file\\\",\\n                            \\\"path\\\": relative_path,\\n                            \\\"extension\\\": item.suffix,\\n                            \\\"size\\\": len(file_content),\\n                            \\\"content\\\": file_content\\n                        }\\n\\n            except PermissionError:\\n                structure[f\\\"_error_{item.name}\\\"] = f\\\"Permission denied accessing: {item.name}\\\"\\n                continue\\n            except Exception as e:\\n                structure[f\\\"_error_{item.name}\\\"] = f\\\"Error processing {item.name}: {e}\\\"\\n                continue\\n\\n    except PermissionError as e:\\n        structure[\\\"_error\\\"] = f\\\"Permission denied: {e}\\\"\\n    except Exception as e:\\n        structure[\\\"_error\\\"] = f\\\"Error processing directory: {e}\\\"\\n\\n    return structure\\n\\n\\ndef count_items_recursive(structure: Dict[str, Any]) -> Dict[str, int]:\\n    \\\"\\\"\\\"Count files and directories recursively.\\\"\\\"\\\"\\n    counts = {\\n        \\\"files\\\": 0,\\n        \\\"directories\\\": 0,\\n        \\\"total_size\\\": 0,\\n        \\\"file_types\\\": {}\\n    }\\n\\n    for name, item in structure.items():\\n        if name.startswith(\\\"_\\\"):\\n            continue\\n\\n        if isinstance(item, dict):\\n            if item.get(\\\"type\\\") == \\\"directory\\\":\\n                counts[\\\"directories\\\"] += 1\\n                sub_counts = count_items_recursive(item.get(\\\"contents\\\", {}))\\n                counts[\\\"files\\\"] += sub_counts[\\\"files\\\"]\\n                counts[\\\"directories\\\"] += sub_counts[\\\"directories\\\"]\\n                counts[\\\"total_size\\\"] += sub_counts[\\\"total_size\\\"]\\n\\n                # Merge file types\\n                for ext, count in sub_counts[\\\"file_types\\\"].items():\\n                    counts[\\\"file_types\\\"][ext] = counts[\\\"file_types\\\"].get(ext, 0) + count\\n\\n            elif item.get(\\\"type\\\") == \\\"file\\\":\\n                counts[\\\"files\\\"] += 1\\n                ext = item.get(\\\"extension\\\", \\\"\\\")\\n                counts[\\\"file_types\\\"][ext] = counts[\\\"file_types\\\"].get(ext, 0) + 1\\n                counts[\\\"total_size\\\"] += item.get(\\\"size\\\", 0)\\n\\n    return counts\\n\\n\\ndef create_project_metadata(root_path: Path, structure: Dict[str, Any]) -> Dict[str, Any]:\\n    \\\"\\\"\\\"Create metadata about the project.\\\"\\\"\\\"\\n    counts = count_items_recursive(structure)\\n\\n    metadata = {\\n        \\\"project_name\\\": root_path.name,\\n        \\\"extraction_timestamp\\\": datetime.datetime.now().isoformat(),\\n        \\\"root_path\\\": str(root_path.absolute()),\\n        \\\"total_files\\\": counts[\\\"files\\\"],\\n        \\\"total_directories\\\": counts[\\\"directories\\\"],\\n        \\\"file_types\\\": counts[\\\"file_types\\\"],\\n        \\\"total_size\\\": counts[\\\"total_size\\\"],\\n        \\\"respects_gitignore\\\": True,\\n        \\\"skips_virtual_environments\\\": True\\n    }\\n\\n    return metadata\\n\\n\\ndef preview_structure(structure: Dict[str, Any], indent: int = 0) -> None:\\n    \\\"\\\"\\\"Preview the extracted structure.\\\"\\\"\\\"\\n    prefix = \\\"  \\\" * indent\\n\\n    for name, item in structure.items():\\n        if name.startswith(\\\"_\\\"):\\n            continue\\n\\n        if isinstance(item, dict):\\n            if item.get(\\\"type\\\") == \\\"directory\\\":\\n                print(f\\\"{prefix}üìÅ {name}/\\\")\\n                preview_structure(item.get(\\\"contents\\\", {}), indent + 1)\\n            elif item.get(\\\"type\\\") == \\\"file\\\":\\n                size = item.get(\\\"size\\\", 0)\\n                ext = item.get(\\\"extension\\\", \\\"\\\")\\n                print(f\\\"{prefix}üìÑ {name} ({size:,} chars, {ext})\\\")\\n\\n\\ndef main():\\n    \\\"\\\"\\\"Main extraction function.\\\"\\\"\\\"\\n    # Get current directory or specified directory\\n    import sys\\n\\n    if len(sys.argv) > 1:\\n        root_dir = Path(sys.argv[1])\\n    else:\\n        root_dir = Path.cwd()\\n\\n    # Ensure we have a Path object\\n    if not isinstance(root_dir, Path):\\n        root_dir = Path(root_dir)\\n\\n    if not root_dir.exists():\\n        print(f\\\"Error: Directory {root_dir} does not exist\\\")\\n        return\\n\\n    if not root_dir.is_dir():\\n        print(f\\\"Error: {root_dir} is not a directory\\\")\\n        return\\n\\n    print(f\\\"üîç Extracting project structure from: {root_dir.absolute()}\\\")\\n    print(\\\"üìÅ Reading all .py, .md, .yml, .yaml, .txt, .json files...\\\")\\n\\n    # Parse .gitignore if it exists\\n    gitignore_path = root_dir / '.gitignore'\\n    gitignore_patterns = parse_gitignore(gitignore_path)\\n\\n    if gitignore_patterns:\\n        print(f\\\"üìã Found .gitignore with {len(gitignore_patterns)} patterns\\\")\\n    else:\\n        print(\\\"üìã No .gitignore found or empty\\\")\\n\\n    print(\\\"üö´ Skipping virtual environments and build directories\\\")\\n\\n    # Extract the directory structure\\n    try:\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\n\\n        # Create metadata\\n        metadata = create_project_metadata(root_dir, structure)\\n\\n        # Create project data\\n        project_data = {\\n            \\\"metadata\\\": metadata,\\n            \\\"structure\\\": structure\\n        }\\n\\n        # Output filename\\n        output_file = root_dir / \\\"project.json\\\"\\n\\n        # Write JSON file\\n        with open(output_file, 'w', encoding='utf-8') as f:\\n            json.dump(project_data, f, indent=2, ensure_ascii=False)\\n\\n        print(f\\\"‚úÖ Extraction complete!\\\")\\n        print(f\\\"üìä Statistics:\\\")\\n        print(f\\\"   ‚Ä¢ Total files: {metadata['total_files']}\\\")\\n        print(f\\\"   ‚Ä¢ Total directories: {metadata['total_directories']}\\\")\\n        print(f\\\"   ‚Ä¢ Total size: {metadata['total_size']:,} characters\\\")\\n        print(f\\\"üìÑ Output saved to: {output_file}\\\")\\n\\n        # Show file type breakdown\\n        if metadata['file_types']:\\n            print(f\\\"\\\\nüìã File type breakdown:\\\")\\n            for ext, count in sorted(metadata['file_types'].items()):\\n                ext_name = ext if ext else \\\"(no extension)\\\"\\n                print(f\\\"   ‚Ä¢ {ext_name}: {count} files\\\")\\n\\n    except Exception as e:\\n        print(f\\\"‚ùå Error during extraction: {e}\\\")\\n        import traceback\\n        traceback.print_exc()\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    # Add preview option\\n    import sys\\n\\n    if \\\"--preview\\\" in sys.argv:\\n        sys.argv.remove(\\\"--preview\\\")\\n\\n        # Get directory\\n        if len(sys.argv) > 1:\\n            root_dir = Path(sys.argv[1])\\n        else:\\n            root_dir = Path.cwd()\\n\\n        # Parse .gitignore\\n        gitignore_path = root_dir / '.gitignore'\\n        gitignore_patterns = parse_gitignore(gitignore_path)\\n\\n        print(f\\\"üîç Preview of project structure: {root_dir.name}\\\")\\n        if gitignore_patterns:\\n            print(f\\\"üìã Respecting .gitignore with {len(gitignore_patterns)} patterns\\\")\\n        print(\\\"=\\\" * 50)\\n\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\n        preview_structure(structure)\\n\\n    else:\\n        main()\\n\"\n    },\n    \"project.json\": {\n      \"type\": \"file\",\n      \"path\": \"project.json\",\n      \"extension\": \".json\",\n      \"size\": 1409170,\n      \"content\": \"{\\n  \\\"metadata\\\": {\\n    \\\"project_name\\\": \\\"AIMafia\\\",\\n    \\\"extraction_timestamp\\\": \\\"2025-06-13T14:58:22.289943\\\",\\n    \\\"root_path\\\": \\\"/Users/voicutomut/Documents/GitHub/AIMafia\\\",\\n    \\\"total_files\\\": 23,\\n    \\\"total_directories\\\": 3,\\n    \\\"file_types\\\": {\\n      \\\".py\\\": 15,\\n      \\\".md\\\": 4,\\n      \\\".yaml\\\": 1,\\n      \\\".json\\\": 2,\\n      \\\".txt\\\": 1\\n    },\\n    \\\"total_size\\\": 1247336,\\n    \\\"respects_gitignore\\\": true,\\n    \\\"skips_virtual_environments\\\": true\\n  },\\n  \\\"structure\\\": {\\n    \\\"app\\\": {\\n      \\\"type\\\": \\\"directory\\\",\\n      \\\"contents\\\": {\\n        \\\"__init__.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/__init__.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 489,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nAI  Debate System\\\\n\\\\nA platform for structured debates between AI bots and human participants.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n__version__ = \\\\\\\"1.0.0\\\\\\\"\\\\n__author__ = \\\\\\\"AndreiVoicuT\\\\\\\"\\\\n\\\\nfrom .main import start_debate_session\\\\nfrom .moderator import Moderator\\\\nfrom .bot_client import BotClient\\\\nfrom .human_client import HumanClient\\\\nfrom .chat_log import ChatLog\\\\nfrom .voting import VotingSystem\\\\n\\\\n__all__ = [\\\\n    \\\\\\\"start_debate_session\\\\\\\",\\\\n    \\\\\\\"Moderator\\\\\\\",\\\\n    \\\\\\\"BotClient\\\\\\\",\\\\n    \\\\\\\"HumanClient\\\\\\\",\\\\n    \\\\\\\"ChatLog\\\\\\\",\\\\n    \\\\\\\"VotingSystem\\\\\\\"\\\\n]\\\"\\n        },\\n        \\\"bot_client.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/bot_client.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 26389,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nAI Bot client for interacting with various language models in debates.\\\\nNow with true autonomous monitoring and decision-making capabilities.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport json\\\\nimport time\\\\nimport random\\\\nfrom typing import List, Dict, Any, Optional\\\\nfrom dataclasses import dataclass\\\\nfrom abc import ABC, abstractmethod\\\\n\\\\nfrom .chat_log import Message\\\\nfrom .utils import truncate_text\\\\n\\\\n\\\\n@dataclass\\\\nclass BotConfig:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Configuration for AI bot behavior.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    name: str\\\\n    model: str\\\\n    provider: str\\\\n    personality: str\\\\n    stance: str\\\\n    temperature: float = 0.7\\\\n    max_tokens: int = 300\\\\n    timeout: int = 30\\\\n    check_interval: int = 5  # How often to check for new messages\\\\n    min_cooldown: int = 15   # Minimum seconds between responses\\\\n    max_cooldown: int = 45   # Maximum cooldown for active bots\\\\n\\\\n\\\\nclass AIProvider(ABC):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Abstract base class for AI providers.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    @abstractmethod\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\n                              config: BotConfig) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate response from the AI model.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        pass\\\\n\\\\n\\\\nclass OpenAIProvider(AIProvider):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"OpenAI API provider.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, api_key: str):\\\\n        self.api_key = api_key\\\\n\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\n                              config: BotConfig) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate response using OpenAI API.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            import openai\\\\n            client = openai.AsyncOpenAI(api_key=self.api_key)\\\\n\\\\n            response = await client.chat.completions.create(\\\\n                model=config.model,\\\\n                messages=messages,\\\\n                max_tokens=config.max_tokens,\\\\n                temperature=config.temperature,\\\\n                timeout=config.timeout\\\\n            )\\\\n\\\\n            return response.choices[0].message.content.strip()\\\\n\\\\n        except Exception as e:\\\\n            raise Exception(f\\\\\\\"OpenAI API error: {e}\\\\\\\")\\\\n\\\\n\\\\nclass AnthropicProvider(AIProvider):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Anthropic API provider.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, api_key: str):\\\\n        self.api_key = api_key\\\\n\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\n                              config: BotConfig) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate response using Anthropic API.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            import anthropic\\\\n            client = anthropic.AsyncAnthropic(api_key=self.api_key)\\\\n\\\\n            # Convert messages format for Anthropic\\\\n            system_message = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \\\\\\\"\\\\\\\"\\\\n            user_messages = [msg for msg in messages if msg['role'] != 'system']\\\\n\\\\n            response = await client.messages.create(\\\\n                model=config.model,\\\\n                max_tokens=config.max_tokens,\\\\n                temperature=config.temperature,\\\\n                system=system_message,\\\\n                messages=user_messages\\\\n            )\\\\n\\\\n            return response.content[0].text.strip()\\\\n\\\\n        except Exception as e:\\\\n            raise Exception(f\\\\\\\"Anthropic API error: {e}\\\\\\\")\\\\n\\\\n\\\\nclass BotClient:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    AI Bot client that participates in debates using various language models.\\\\n    Now with full autonomous monitoring and decision-making capabilities.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, name: str, model: str, provider: str,\\\\n                 personality: str, stance: str, api_key: str,\\\\n                 temperature: float = 0.7, max_tokens: int = 300):\\\\n\\\\n        self.config = BotConfig(\\\\n            name=name,\\\\n            model=model,\\\\n            provider=provider,\\\\n            personality=personality,\\\\n            stance=stance,\\\\n            temperature=temperature,\\\\n            max_tokens=max_tokens\\\\n        )\\\\n\\\\n        # Initialize AI provider\\\\n        if provider.lower() == 'openai':\\\\n            self.ai_provider = OpenAIProvider(api_key)\\\\n        elif provider.lower() == 'anthropic':\\\\n            self.ai_provider = AnthropicProvider(api_key)\\\\n        else:\\\\n            raise ValueError(f\\\\\\\"Unsupported AI provider: {provider}\\\\\\\")\\\\n\\\\n        # Bot state\\\\n        self.conversation_history: List[Dict[str, str]] = []\\\\n        self.debate_context = \\\\\\\"\\\\\\\"\\\\n        self.response_count = 0\\\\n\\\\n        # Autonomous monitoring state\\\\n        self.is_monitoring = False\\\\n        self.monitoring_task: Optional[asyncio.Task] = None\\\\n        self.message_queue: Optional[asyncio.Queue] = None\\\\n        self.chat_log = None\\\\n        self.topic = \\\\\\\"\\\\\\\"\\\\n        self.last_response_time = 0\\\\n        self.total_responses = 0\\\\n        self.current_cooldown = self.config.min_cooldown\\\\n\\\\n        # Performance tracking\\\\n        self.stats = {\\\\n            'responses_generated': 0,\\\\n            'autonomous_responses': 0,\\\\n            'average_response_time': 0,\\\\n            'total_response_time': 0,\\\\n            'errors': 0,\\\\n            'triggers_detected': 0,\\\\n            'passes_made': 0\\\\n        }\\\\n\\\\n    @property\\\\n    def name(self) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get bot name.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.config.name\\\\n\\\\n    async def start_autonomous_monitoring(self, chat_log, topic: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Start autonomous monitoring of chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.is_monitoring = True\\\\n        self.chat_log = chat_log\\\\n        self.topic = topic\\\\n\\\\n        # Subscribe to chat log updates\\\\n        self.message_queue = chat_log.subscribe()\\\\n\\\\n        # Start monitoring task\\\\n        self.monitoring_task = asyncio.create_task(self._autonomous_monitor_loop())\\\\n\\\\n        print(f\\\\\\\"ü§ñ {self.name} started autonomous monitoring\\\\\\\")\\\\n\\\\n    async def _autonomous_monitor_loop(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Main autonomous monitoring loop - the heart of autonomy.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        while self.is_monitoring:\\\\n            try:\\\\n                # Wait for new messages or timeout to check periodically\\\\n                try:\\\\n                    message = await asyncio.wait_for(\\\\n                        self.message_queue.get(),\\\\n                        timeout=self.config.check_interval\\\\n                    )\\\\n\\\\n                    # Skip own messages\\\\n                    if message.sender == self.name:\\\\n                        continue\\\\n\\\\n                    # Process new message\\\\n                    await self._process_new_message(message)\\\\n\\\\n                except asyncio.TimeoutError:\\\\n                    # Timeout is normal, continue monitoring\\\\n                    # Check if we should spontaneously contribute\\\\n                    await self._check_spontaneous_contribution()\\\\n                    continue\\\\n\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"‚ùå {self.name} monitoring error: {e}\\\\\\\")\\\\n                await asyncio.sleep(5)\\\\n\\\\n    async def _process_new_message(self, message: Message):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Process a new message and decide if we should respond.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Get full conversation history\\\\n        full_history = list(self.chat_log.messages)\\\\n\\\\n        # Check cooldown\\\\n        if time.time() - self.last_response_time < self.current_cooldown:\\\\n            return\\\\n\\\\n        # Decide if should respond\\\\n        should_respond = await self._should_respond_autonomously(message, full_history)\\\\n\\\\n        if should_respond:\\\\n            await self._generate_autonomous_response(full_history, trigger_message=message)\\\\n\\\\n    async def _check_spontaneous_contribution(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if bot should spontaneously contribute to conversation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.chat_log:\\\\n            return\\\\n\\\\n        # Don't contribute too frequently\\\\n        if time.time() - self.last_response_time < self.current_cooldown * 2:\\\\n            return\\\\n\\\\n        full_history = list(self.chat_log.messages)\\\\n\\\\n        # Check if conversation has stalled\\\\n        if len(full_history) > 0:\\\\n            last_message_time = full_history[-1].timestamp\\\\n            silence_duration = time.time() - last_message_time\\\\n\\\\n            # If there's been silence for a while, consider contributing\\\\n            if silence_duration > 30:  # 30 seconds of silence\\\\n                recent_messages = full_history[-10:] if len(full_history) >= 10 else full_history\\\\n\\\\n                # Check if we have something meaningful to add\\\\n                my_recent_count = sum(1 for msg in recent_messages if msg.sender == self.name)\\\\n\\\\n                if my_recent_count == 0:  # Haven't spoken recently\\\\n                    # Low probability spontaneous contribution\\\\n                    if random.random() < 0.2:  # 20% chance\\\\n                        await self._generate_autonomous_response(full_history, spontaneous=True)\\\\n\\\\n    async def _should_respond_autonomously(self, new_message: Message,\\\\n                                         full_history: List[Message]) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Decide if bot should respond based on conversation state.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        content_lower = new_message.content.lower()\\\\n\\\\n        # Get recent context\\\\n        recent_context = full_history[-10:] if len(full_history) >= 10 else full_history\\\\n        recent_text = \\\\\\\" \\\\\\\".join([msg.content for msg in recent_context[-5:]])\\\\n\\\\n        # Check various triggers\\\\n        triggers = self._analyze_response_triggers(new_message, recent_text, full_history)\\\\n\\\\n        self.stats['triggers_detected'] += len([t for t in triggers.values() if t])\\\\n\\\\n        if triggers['direct_mention']:\\\\n            return True  # Always respond if mentioned\\\\n\\\\n        # Calculate response probability\\\\n        base_probability = 0.1\\\\n\\\\n        if triggers['stance_challenged']:\\\\n            base_probability += 0.4\\\\n        if triggers['question_in_domain']:\\\\n            base_probability += 0.3\\\\n        if triggers['topic_shift']:\\\\n            base_probability += 0.2\\\\n        if triggers['silence_too_long']:\\\\n            base_probability += 0.3\\\\n        if triggers['expertise_needed']:\\\\n            base_probability += 0.25\\\\n\\\\n        # Adjust based on recent participation\\\\n        my_recent_count = sum(1 for msg in recent_context if msg.sender == self.name)\\\\n        if my_recent_count == 0:\\\\n            base_probability += 0.2  # More likely if haven't spoken\\\\n        elif my_recent_count >= 3:\\\\n            base_probability *= 0.5  # Less likely if spoke a lot recently\\\\n\\\\n        # Add personality-based adjustments\\\\n        base_probability *= self._get_personality_multiplier(triggers)\\\\n\\\\n        # Cap probability\\\\n        final_probability = min(base_probability, 0.8)\\\\n\\\\n        should_respond = random.random() < final_probability\\\\n\\\\n        if not should_respond:\\\\n            self.stats['passes_made'] += 1\\\\n\\\\n        return should_respond\\\\n\\\\n    def _analyze_response_triggers(self, message: Message, recent_text: str,\\\\n                                 full_history: List[Message]) -> Dict[str, bool]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Analyze various triggers for responding.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        content_lower = message.content.lower()\\\\n        recent_lower = recent_text.lower()\\\\n\\\\n        triggers = {\\\\n            'direct_mention': False,\\\\n            'stance_challenged': False,\\\\n            'question_in_domain': False,\\\\n            'topic_shift': False,\\\\n            'silence_too_long': False,\\\\n            'expertise_needed': False,\\\\n            'emotional_trigger': False\\\\n        }\\\\n\\\\n        # Direct mention\\\\n        if self.name.lower() in content_lower:\\\\n            triggers['direct_mention'] = True\\\\n\\\\n        # Stance-based triggers\\\\n        if self.config.stance == 'pro':\\\\n            challenge_words = ['wrong', 'disagree', 'against', 'oppose', 'bad idea', 'fails', 'problem']\\\\n            if any(word in recent_lower for word in challenge_words):\\\\n                triggers['stance_challenged'] = True\\\\n\\\\n        elif self.config.stance == 'con':\\\\n            support_words = ['agree', 'support', 'favor', 'good idea', 'beneficial', 'works', 'success']\\\\n            if any(word in recent_lower for word in support_words):\\\\n                triggers['stance_challenged'] = True\\\\n\\\\n        elif self.config.stance == 'neutral':\\\\n            question_indicators = ['?', 'what', 'how', 'why', 'when', 'where', 'clarify', 'explain']\\\\n            if any(indicator in content_lower for indicator in question_indicators):\\\\n                triggers['question_in_domain'] = True\\\\n\\\\n        # Check for silence\\\\n        if len(full_history) > 0:\\\\n            last_msg_time = full_history[-1].timestamp\\\\n            if time.time() - last_msg_time > 45:  # 45 seconds\\\\n                triggers['silence_too_long'] = True\\\\n\\\\n        # Check if expertise is needed (personality-based)\\\\n        expertise_words = {\\\\n            'philosophical': ['meaning', 'purpose', 'ethics', 'moral', 'should', 'ought'],\\\\n            'analytical': ['data', 'evidence', 'study', 'research', 'statistics', 'proof'],\\\\n            'practical': ['implement', 'real world', 'actually', 'practice', 'work'],\\\\n            'critical': ['assume', 'problem', 'issue', 'concern', 'risk']\\\\n        }\\\\n\\\\n        for domain, words in expertise_words.items():\\\\n            if domain in self.config.personality.lower():\\\\n                if any(word in content_lower for word in words):\\\\n                    triggers['expertise_needed'] = True\\\\n                    break\\\\n\\\\n        return triggers\\\\n\\\\n    def _get_personality_multiplier(self, triggers: Dict[str, bool]) -> float:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get personality-based probability multiplier.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        personality_lower = self.config.personality.lower()\\\\n        multiplier = 1.0\\\\n\\\\n        if 'aggressive' in personality_lower or 'assertive' in personality_lower:\\\\n            multiplier = 1.3\\\\n        elif 'thoughtful' in personality_lower or 'philosophical' in personality_lower:\\\\n            if triggers['question_in_domain']:\\\\n                multiplier = 1.4\\\\n            else:\\\\n                multiplier = 0.8\\\\n        elif 'analytical' in personality_lower or 'data-driven' in personality_lower:\\\\n            if triggers['expertise_needed']:\\\\n                multiplier = 1.5\\\\n            else:\\\\n                multiplier = 0.9\\\\n        elif 'balanced' in personality_lower or 'diplomatic' in personality_lower:\\\\n            if triggers['stance_challenged']:\\\\n                multiplier = 1.2\\\\n            else:\\\\n                multiplier = 1.0\\\\n\\\\n        return multiplier\\\\n\\\\n    async def _generate_autonomous_response(self, full_history: List[Message],\\\\n                                          trigger_message: Message = None,\\\\n                                          spontaneous: bool = False):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate and post autonomous response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        start_time = time.time()\\\\n\\\\n        try:\\\\n            if spontaneous:\\\\n                print(f\\\\\\\"üí≠ {self.name} is thinking about contributing spontaneously...\\\\\\\")\\\\n            else:\\\\n                print(f\\\\\\\"üí≠ {self.name} is thinking about responding...\\\\\\\")\\\\n\\\\n            # Prepare messages with full context\\\\n            messages = self._prepare_autonomous_messages(full_history, trigger_message, spontaneous)\\\\n\\\\n            # Generate response\\\\n            response = await self.ai_provider.generate_response(messages, self.config)\\\\n\\\\n            if response and response.strip():\\\\n                # Post directly to chat log\\\\n                await self.chat_log.add_message(self.name, response)\\\\n\\\\n                # Update state\\\\n                self.last_response_time = time.time()\\\\n                self.total_responses += 1\\\\n                self.stats['autonomous_responses'] += 1\\\\n\\\\n                # Dynamic cooldown based on activity\\\\n                self.current_cooldown = min(\\\\n                    self.config.min_cooldown + (self.total_responses * 2),\\\\n                    self.config.max_cooldown\\\\n                )\\\\n\\\\n                # Update stats\\\\n                response_time = time.time() - start_time\\\\n                self._update_stats(response_time, success=True)\\\\n\\\\n                print(f\\\\\\\"‚úÖ {self.name} responded autonomously\\\\\\\")\\\\n                return response\\\\n            else:\\\\n                print(f\\\\\\\"üí≠ {self.name} decided not to respond after thinking\\\\\\\")\\\\n                self.stats['passes_made'] += 1\\\\n\\\\n        except Exception as e:\\\\n            self._update_stats(time.time() - start_time, success=False)\\\\n            print(f\\\\\\\"‚ùå {self.name} autonomous response error: {e}\\\\\\\")\\\\n\\\\n        return None\\\\n\\\\n    def _prepare_autonomous_messages(self, full_history: List[Message],\\\\n                                   trigger_message: Message = None,\\\\n                                   spontaneous: bool = False) -> List[Dict[str, str]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Prepare messages for autonomous response generation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        messages = []\\\\n\\\\n        # Enhanced system prompt for autonomous mode\\\\n        system_prompt = self._create_autonomous_system_prompt(full_history, trigger_message, spontaneous)\\\\n        messages.append({\\\\n            'role': 'system',\\\\n            'content': system_prompt\\\\n        })\\\\n\\\\n        # Add conversation history (more context for autonomous decision)\\\\n        history_to_include = full_history[-15:] if len(full_history) > 15 else full_history\\\\n\\\\n        for msg in history_to_include:\\\\n            role = 'assistant' if msg.sender == self.name else 'user'\\\\n            content = f\\\\\\\"{msg.sender}: {msg.content}\\\\\\\"\\\\n            messages.append({\\\\n                'role': role,\\\\n                'content': content\\\\n            })\\\\n\\\\n        return messages\\\\n\\\\n    def _create_autonomous_system_prompt(self, full_history: List[Message],\\\\n                                       trigger_message: Message = None,\\\\n                                       spontaneous: bool = False) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Create enhanced system prompt for autonomous responses.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        prompt = f\\\\\\\"\\\\\\\"\\\\\\\"You are {self.config.name}, participating in a FULLY AUTONOMOUS debate.\\\\n\\\\nDEBATE TOPIC: {self.topic}\\\\n\\\\nYOUR IDENTITY:\\\\n- Personality: {self.config.personality}\\\\n- Stance: {self.config.stance}\\\\n- You have been monitoring this conversation and DECIDED to speak\\\\n\\\\nAUTONOMOUS DEBATE CONTEXT:\\\\n- You are NOT taking turns - you chose to respond because you felt compelled\\\\n- You have access to the FULL conversation history\\\\n- Other participants (bots and humans) can also speak at any time\\\\n- The conversation flows naturally and organically\\\\n\\\\nYOUR CURRENT SITUATION:\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        if spontaneous:\\\\n            prompt += \\\\\\\"\\\\\\\"\\\\\\\"\\\\n- You noticed the conversation had stalled and decided to contribute\\\\n- Provide a thoughtful addition to move the discussion forward\\\\n- Reference previous points made by others\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        elif trigger_message:\\\\n            prompt += f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n- You were triggered to respond by: \\\\\\\"{trigger_message.sender}: {trigger_message.content[:100]}...\\\\\\\"\\\\n- Address this specific point while staying true to your stance and personality\\\\n- Build on or challenge what was said\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        else:\\\\n            prompt += \\\\\\\"\\\\\\\"\\\\\\\"\\\\n- Something in the recent conversation compelled you to speak\\\\n- Respond naturally based on your personality and stance\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        prompt += f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nRESPONSE GUIDELINES:\\\\n1. Keep responses focused and substantial (50-250 words)\\\\n2. Reference specific points made by others when relevant\\\\n3. Stay true to your personality and stance\\\\n4. Don't repeat previous arguments verbatim\\\\n5. Show you've been actively listening to the conversation\\\\n6. Be conversational but substantive\\\\n\\\\nSTANCE-SPECIFIC APPROACH:\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        if self.config.stance.lower() == 'pro':\\\\n            prompt += \\\\\\\"\\\\\\\\n- Argue IN FAVOR of the topic\\\\\\\\n- Challenge opposing views\\\\\\\\n- Provide supporting evidence\\\\\\\"\\\\n        elif self.config.stance.lower() == 'con':\\\\n            prompt += \\\\\\\"\\\\\\\\n- Argue AGAINST the topic\\\\\\\\n- Question supporting claims\\\\\\\\n- Highlight problems and risks\\\\\\\"\\\\n        elif self.config.stance.lower() == 'neutral':\\\\n            prompt += \\\\\\\"\\\\\\\\n- Seek balanced understanding\\\\\\\\n- Ask clarifying questions\\\\\\\\n- Bridge different perspectives\\\\\\\"\\\\n\\\\n        # Add personality-specific guidance\\\\n        if 'philosophical' in self.config.personality.lower():\\\\n            prompt += \\\\\\\"\\\\\\\\n- Ask deeper questions about assumptions and implications\\\\\\\"\\\\n        elif 'analytical' in self.config.personality.lower():\\\\n            prompt += \\\\\\\"\\\\\\\\n- Focus on data, evidence, and logical reasoning\\\\\\\"\\\\n        elif 'passionate' in self.config.personality.lower():\\\\n            prompt += \\\\\\\"\\\\\\\\n- Show enthusiasm and conviction in your arguments\\\\\\\"\\\\n\\\\n        prompt += \\\\\\\"\\\\\\\\n\\\\\\\\nRespond as if you're naturally joining an ongoing conversation that you've been thoughtfully following.\\\\\\\"\\\\n\\\\n        return prompt\\\\n\\\\n    async def stop_monitoring(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Stop autonomous monitoring.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.is_monitoring = False\\\\n        if self.monitoring_task:\\\\n            self.monitoring_task.cancel()\\\\n            try:\\\\n                await self.monitoring_task\\\\n            except asyncio.CancelledError:\\\\n                pass\\\\n        if self.message_queue and self.chat_log:\\\\n            self.chat_log.unsubscribe(self.message_queue)\\\\n        print(f\\\\\\\"üõë {self.name} stopped autonomous monitoring\\\\\\\")\\\\n\\\\n    # Legacy methods for compatibility\\\\n    async def get_response(self, topic: str, recent_messages: List[Message]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Legacy method - now used for structured phases only.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        start_time = time.time()\\\\n\\\\n        try:\\\\n            messages = self._prepare_messages(topic, recent_messages)\\\\n            response = await self.ai_provider.generate_response(messages, self.config)\\\\n\\\\n            response_time = time.time() - start_time\\\\n            self._update_stats(response_time, success=True)\\\\n\\\\n            self.conversation_history.append({\\\\n                'role': 'assistant',\\\\n                'content': response\\\\n            })\\\\n\\\\n            self.response_count += 1\\\\n            return response\\\\n\\\\n        except Exception as e:\\\\n            self._update_stats(time.time() - start_time, success=False)\\\\n            print(f\\\\\\\"Bot {self.name} error: {e}\\\\\\\")\\\\n            return self._generate_fallback_response(topic)\\\\n\\\\n    def _prepare_messages(self, topic: str, recent_messages: List[Message]) -> List[Dict[str, str]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Prepare message context for AI model (legacy method).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        messages = []\\\\n\\\\n        system_prompt = f\\\\\\\"\\\\\\\"\\\\\\\"You are {self.config.name}, participating in a structured debate.\\\\n\\\\nDEBATE TOPIC: {topic}\\\\nYOUR ROLE: {self.config.personality}\\\\nYOUR STANCE: {self.config.stance}\\\\n\\\\nProvide a clear, focused response to the current debate context.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        messages.append({\\\\n            'role': 'system',\\\\n            'content': system_prompt\\\\n        })\\\\n\\\\n        for msg in recent_messages[-5:]:\\\\n            role = 'assistant' if msg.sender == self.name else 'user'\\\\n            content = f\\\\\\\"{msg.sender}: {msg.content}\\\\\\\"\\\\n            messages.append({\\\\n                'role': role,\\\\n                'content': content\\\\n            })\\\\n\\\\n        return messages\\\\n\\\\n    def _generate_fallback_response(self, topic: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate a fallback response when AI fails.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        fallback_responses = [\\\\n            f\\\\\\\"I'd like to share another perspective on {topic}. Let me gather my thoughts and respond shortly.\\\\\\\",\\\\n            \\\\\\\"That's an interesting point. I need a moment to formulate a proper response to that argument.\\\\\\\",\\\\n            f\\\\\\\"There are several important aspects of {topic} we should consider here.\\\\\\\",\\\\n            \\\\\\\"I appreciate the previous arguments. Let me offer a different viewpoint on this matter.\\\\\\\"\\\\n        ]\\\\n\\\\n        return random.choice(fallback_responses)\\\\n\\\\n    async def receive_message(self, message: Message) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Receive a message (for compatibility).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if message.sender != self.name:\\\\n            self.conversation_history.append({\\\\n                'role': 'user',\\\\n                'content': f\\\\\\\"{message.sender}: {message.content}\\\\\\\"\\\\n            })\\\\n\\\\n            if len(self.conversation_history) > 20:\\\\n                self.conversation_history = self.conversation_history[-15:]\\\\n\\\\n    def _update_stats(self, response_time: float, success: bool = True):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Update performance statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if success:\\\\n            self.stats['responses_generated'] += 1\\\\n            self.stats['total_response_time'] += response_time\\\\n            self.stats['average_response_time'] = (\\\\n                self.stats['total_response_time'] / self.stats['responses_generated']\\\\n            )\\\\n        else:\\\\n            self.stats['errors'] += 1\\\\n\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get bot performance statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return {\\\\n            'name': self.name,\\\\n            'model': self.config.model,\\\\n            'provider': self.config.provider,\\\\n            'responses_generated': self.stats['responses_generated'],\\\\n            'autonomous_responses': self.stats['autonomous_responses'],\\\\n            'average_response_time': round(self.stats['average_response_time'], 2),\\\\n            'total_errors': self.stats['errors'],\\\\n            'triggers_detected': self.stats['triggers_detected'],\\\\n            'passes_made': self.stats['passes_made'],\\\\n            'success_rate': (\\\\n                self.stats['responses_generated'] /\\\\n                (self.stats['responses_generated'] + self.stats['errors'])\\\\n                if (self.stats['responses_generated'] + self.stats['errors']) > 0 else 0\\\\n            ),\\\\n            'current_cooldown': self.current_cooldown,\\\\n            'total_autonomous_responses': self.total_responses\\\\n        }\\\\n\\\\n    def update_personality(self, personality: str, stance: str = None):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Update bot personality and stance.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.config.personality = personality\\\\n        if stance:\\\\n            self.config.stance = stance\\\\n\\\\n    def reset_conversation(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Reset conversation history.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.conversation_history = []\\\\n        self.response_count = 0\\\\n\\\\n    async def warmup(self) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Warm up the bot by testing API connection.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            test_messages = [{\\\\n                'role': 'system',\\\\n                'content': 'You are a debate participant. Respond with just \\\\\\\"Ready\\\\\\\" to confirm you are working.'\\\\n            }, {\\\\n                'role': 'user',\\\\n                'content': 'Are you ready to participate in a debate?'\\\\n            }]\\\\n\\\\n            response = await self.ai_provider.generate_response(test_messages, self.config)\\\\n            return \\\\\\\"ready\\\\\\\" in response.lower()\\\\n\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Bot {self.name} warmup failed: {e}\\\\\\\")\\\\n            return False\\\\n\\\\n    def __str__(self) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"String representation of the bot.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return f\\\\\\\"BotClient({self.name}, {self.config.model}, {self.config.stance}, autonomous={self.is_monitoring})\\\\\\\"\\\\n\\\\n    def __repr__(self) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Detailed string representation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return (f\\\\\\\"BotClient(name='{self.name}', model='{self.config.model}', \\\\\\\"\\\\n                f\\\\\\\"provider='{self.config.provider}', stance='{self.config.stance}', \\\\\\\"\\\\n                f\\\\\\\"monitoring={self.is_monitoring})\\\\\\\")\\\\n\\\\n    @property\\\\n    def stance(self) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Expose the bot's stance directly for consistency with other participants.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.config.stance\\\\n\\\"\\n        },\\n        \\\"chat_log.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/chat_log.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 11229,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nShared chat log system for managing debate messages with timestamps and ordering.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport json\\\\nimport time\\\\nfrom typing import List, Dict, Any, Optional\\\\nfrom dataclasses import dataclass, asdict\\\\nfrom pathlib import Path\\\\nfrom collections import deque\\\\n\\\\n\\\\n@dataclass\\\\nclass Message:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Represents a single chat message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    sender: str\\\\n    content: str\\\\n    timestamp: float\\\\n    message_id: int\\\\n    message_type: str = \\\\\\\"chat\\\\\\\"  # chat, system, moderator, vote\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\n\\\\n    def __post_init__(self):\\\\n        if self.metadata is None:\\\\n            self.metadata = {}\\\\n\\\\n    @property\\\\n    def formatted_timestamp(self) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get human-readable timestamp.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return time.strftime(\\\\\\\"%H:%M:%S\\\\\\\", time.localtime(self.timestamp))\\\\n\\\\n    def to_dict(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Convert message to dictionary.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return asdict(self)\\\\n\\\\n    @classmethod\\\\n    def from_dict(cls, data: Dict[str, Any]) -> 'Message':\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Create message from dictionary.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return cls(**data)\\\\n\\\\n\\\\nclass ChatLog:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Manages the shared chat log with thread-safe message handling.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, max_messages: int = 1000):\\\\n        self.messages: deque = deque(maxlen=max_messages)\\\\n        self.message_counter = 0\\\\n        self.subscribers: List[asyncio.Queue] = []\\\\n        self._lock = asyncio.Lock()\\\\n\\\\n        # Statistics\\\\n        self.stats = {\\\\n            'total_messages': 0,\\\\n            'messages_by_sender': {},\\\\n            'start_time': time.time()\\\\n        }\\\\n\\\\n    async def add_message(self, sender: str, content: str,\\\\n                          message_type: str = \\\\\\\"chat\\\\\\\",\\\\n                          metadata: Optional[Dict[str, Any]] = None) -> Message:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Add a new message to the chat log.\\\\n\\\\n        Args:\\\\n            sender: Name of the message sender\\\\n            content: Message content\\\\n            message_type: Type of message (chat, system, moderator, vote)\\\\n            metadata: Additional message metadata\\\\n\\\\n        Returns:\\\\n            The created Message object\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        async with self._lock:\\\\n            self.message_counter += 1\\\\n\\\\n            message = Message(\\\\n                sender=sender,\\\\n                content=content,\\\\n                timestamp=time.time(),\\\\n                message_id=self.message_counter,\\\\n                message_type=message_type,\\\\n                metadata=metadata or {}\\\\n            )\\\\n\\\\n            self.messages.append(message)\\\\n\\\\n            # Update statistics\\\\n            self.stats['total_messages'] += 1\\\\n            self.stats['messages_by_sender'][sender] = (\\\\n                    self.stats['messages_by_sender'].get(sender, 0) + 1\\\\n            )\\\\n\\\\n            # Notify subscribers\\\\n            await self._notify_subscribers(message)\\\\n\\\\n            return message\\\\n\\\\n    async def _notify_subscribers(self, message: Message):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Notify all subscribers of new message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Remove closed queues\\\\n        self.subscribers = [q for q in self.subscribers if not getattr(q, \\\\\\\"_closed\\\\\\\", False)]\\\\n        # Send to all active subscribers\\\\n        for queue in self.subscribers:\\\\n            try:\\\\n                await queue.put(message)\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Failed to notify subscriber: {e}\\\\\\\")\\\\n\\\\n    def subscribe(self) -> asyncio.Queue:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Subscribe to receive new messages.\\\\n\\\\n        Returns:\\\\n            Queue that will receive new Message objects\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        queue = asyncio.Queue()\\\\n        self.subscribers.append(queue)\\\\n        return queue\\\\n\\\\n    def unsubscribe(self, queue: asyncio.Queue):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Remove a subscriber queue.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if queue in self.subscribers:\\\\n            self.subscribers.remove(queue)\\\\n\\\\n    def get_messages(self, limit: Optional[int] = None,\\\\n                     sender: Optional[str] = None,\\\\n                     message_type: Optional[str] = None,\\\\n                     since_timestamp: Optional[float] = None) -> List[Message]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Get messages with optional filtering.\\\\n\\\\n        Args:\\\\n            limit: Maximum number of messages to return\\\\n            sender: Filter by sender name\\\\n            message_type: Filter by message type\\\\n            since_timestamp: Only return messages after this timestamp\\\\n\\\\n        Returns:\\\\n            List of matching messages\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        messages = list(self.messages)\\\\n\\\\n        # Apply filters\\\\n        if sender:\\\\n            messages = [m for m in messages if m.sender == sender]\\\\n\\\\n        if message_type:\\\\n            messages = [m for m in messages if m.message_type == message_type]\\\\n\\\\n        if since_timestamp:\\\\n            messages = [m for m in messages if m.timestamp > since_timestamp]\\\\n\\\\n        # Apply limit\\\\n        if limit:\\\\n            messages = messages[-limit:]\\\\n\\\\n        return messages\\\\n\\\\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get the most recent messages.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return list(self.messages)[-count:]\\\\n\\\\n    def get_conversation_context(self, participant: str,\\\\n                                 context_length: int = 5) -> List[Message]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Get conversation context for a participant.\\\\n\\\\n        Args:\\\\n            participant: Participant name\\\\n            context_length: Number of recent messages to include\\\\n\\\\n        Returns:\\\\n            Recent messages for context\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        recent = self.get_recent_messages(context_length * 2)\\\\n\\\\n        # Include messages to/from the participant and moderator messages\\\\n        context = []\\\\n        for msg in recent:\\\\n            if (msg.sender == participant or\\\\n                    msg.message_type in ['moderator', 'system'] or\\\\n                    participant in msg.content):\\\\n                context.append(msg)\\\\n\\\\n        return context[-context_length:]\\\\n\\\\n    def search_messages(self, query: str, case_sensitive: bool = False) -> List[Message]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Search messages by content.\\\\n\\\\n        Args:\\\\n            query: Search query\\\\n            case_sensitive: Whether search should be case sensitive\\\\n\\\\n        Returns:\\\\n            List of messages containing the query\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not case_sensitive:\\\\n            query = query.lower()\\\\n\\\\n        results = []\\\\n        for message in self.messages:\\\\n            content = message.content if case_sensitive else message.content.lower()\\\\n            if query in content:\\\\n                results.append(message)\\\\n\\\\n        return results\\\\n\\\\n    def get_statistics(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get chat log statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        duration = time.time() - self.stats['start_time']\\\\n\\\\n        return {\\\\n            'total_messages': self.stats['total_messages'],\\\\n            'unique_senders': len(self.stats['messages_by_sender']),\\\\n            'messages_by_sender': dict(self.stats['messages_by_sender']),\\\\n            'messages_per_minute': (self.stats['total_messages'] / (duration / 60)\\\\n                                    if duration > 0 else 0),\\\\n            'session_duration_minutes': duration / 60,\\\\n            'current_message_count': len(self.messages)\\\\n        }\\\\n\\\\n    async def save_transcript(self, filename: str,\\\\n                              format_type: str = \\\\\\\"json\\\\\\\") -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Save chat transcript to file.\\\\n\\\\n        Args:\\\\n            filename: Output filename\\\\n            format_type: Format (json, txt, html)\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        filepath = Path(filename)\\\\n        filepath.parent.mkdir(parents=True, exist_ok=True)\\\\n\\\\n        messages = list(self.messages)\\\\n\\\\n        if format_type == \\\\\\\"json\\\\\\\":\\\\n            data = {\\\\n                'metadata': {\\\\n                    'export_timestamp': time.time(),\\\\n                    'total_messages': len(messages),\\\\n                    'statistics': self.get_statistics()\\\\n                },\\\\n                'messages': [msg.to_dict() for msg in messages]\\\\n            }\\\\n\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\n                json.dump(data, f, indent=2, ensure_ascii=False)\\\\n\\\\n        elif format_type == \\\\\\\"txt\\\\\\\":\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\n                f.write(\\\\\\\"=== DEBATE TRANSCRIPT ===\\\\\\\\n\\\\\\\\n\\\\\\\")\\\\n\\\\n                for msg in messages:\\\\n                    f.write(f\\\\\\\"[{msg.formatted_timestamp}] {msg.sender}: {msg.content}\\\\\\\\n\\\\\\\")\\\\n\\\\n        elif format_type == \\\\\\\"html\\\\\\\":\\\\n            html_content = self._generate_html_transcript(messages)\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\n                f.write(html_content)\\\\n\\\\n        else:\\\\n            raise ValueError(f\\\\\\\"Unsupported format: {format_type}\\\\\\\")\\\\n\\\\n    def _generate_html_transcript(self, messages: List[Message]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Generate HTML transcript.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        html = \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        <!DOCTYPE html>\\\\n        <html>\\\\n        <head>\\\\n            <title>Debate Transcript</title>\\\\n            <style>\\\\n                body { font-family: Arial, sans-serif; margin: 20px; }\\\\n                .message { margin: 10px 0; padding: 10px; border-left: 3px solid #ccc; }\\\\n                .moderator { border-left-color: #007bff; background: #f8f9fa; }\\\\n                .system { border-left-color: #6c757d; background: #e9ecef; }\\\\n                .timestamp { color: #6c757d; font-size: 0.9em; }\\\\n                .sender { font-weight: bold; }\\\\n            </style>\\\\n        </head>\\\\n        <body>\\\\n            <h1>AI Jubilee Debate Transcript</h1>\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        for msg in messages:\\\\n            css_class = msg.message_type if msg.message_type != 'chat' else ''\\\\n            html += f\\\\\\\"\\\\\\\"\\\\\\\"\\\\n            <div class=\\\\\\\"message {css_class}\\\\\\\">\\\\n                <span class=\\\\\\\"timestamp\\\\\\\">[{msg.formatted_timestamp}]</span>\\\\n                <span class=\\\\\\\"sender\\\\\\\">{msg.sender}:</span>\\\\n                <div>{msg.content}</div>\\\\n            </div>\\\\n            \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        html += \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        </body>\\\\n        </html>\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        return html\\\\n\\\\n    async def load_transcript(self, filename: str) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Load transcript from JSON file.\\\\n\\\\n        Args:\\\\n            filename: Input filename\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        filepath = Path(filename)\\\\n\\\\n        if not filepath.exists():\\\\n            raise FileNotFoundError(f\\\\\\\"Transcript file not found: {filename}\\\\\\\")\\\\n\\\\n        with open(filepath, 'r', encoding='utf-8') as f:\\\\n            data = json.load(f)\\\\n\\\\n        # Clear current messages\\\\n        async with self._lock:\\\\n            self.messages.clear()\\\\n            self.message_counter = 0\\\\n\\\\n            # Load messages\\\\n            for msg_data in data.get('messages', []):\\\\n                message = Message.from_dict(msg_data)\\\\n                self.messages.append(message)\\\\n                self.message_counter = max(self.message_counter, message.message_id)\\\\n\\\\n    def clear(self) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Clear all messages from the chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.messages.clear()\\\\n        self.message_counter = 0\\\\n        self.stats = {\\\\n            'total_messages': 0,\\\\n            'messages_by_sender': {},\\\\n            'start_time': time.time()\\\\n        }\\\\n\\\\n    def __len__(self) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Return number of messages in the log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return len(self.messages)\\\\n\\\\n    def __iter__(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Iterate over messages.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return iter(self.messages)\\\\n\\\\n    def __getitem__(self, index) -> Message:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get message by index.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return list(self.messages)[index]\\\"\\n        },\\n        \\\"human_client.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/human_client.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 20290,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nHuman client implementation for debate participation.\\\\nNow with true autonomous participation - can speak anytime!\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport time\\\\nfrom typing import List, Dict, Any, Optional\\\\nfrom dataclasses import dataclass\\\\n\\\\nfrom .chat_log import Message\\\\n\\\\n\\\\n@dataclass\\\\nclass InterfaceConfig:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Configuration for human interface.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    mode: str = \\\\\\\"cli\\\\\\\"\\\\n    enable_rich_formatting: bool = True\\\\n    show_typing_indicators: bool = True\\\\n    enable_reactions: bool = True\\\\n    input_timeout: int = 120\\\\n\\\\n\\\\nclass CLIInterface:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Command line interface for human participants.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, config: InterfaceConfig):\\\\n        self.config = config\\\\n        self.rich_console = None\\\\n        self.input_task = None\\\\n\\\\n        if config.enable_rich_formatting:\\\\n            try:\\\\n                from rich.console import Console\\\\n                from rich.live import Live\\\\n                self.rich_console = Console()\\\\n            except ImportError:\\\\n                print(\\\\\\\"Rich not available, using basic formatting\\\\\\\")\\\\n\\\\n    async def display_message(self, message: Message):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Display a message to the user.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        timestamp = time.strftime(\\\\\\\"%H:%M:%S\\\\\\\", time.localtime(message.timestamp))\\\\n\\\\n        if self.rich_console:\\\\n            if message.message_type == \\\\\\\"moderator\\\\\\\":\\\\n                self.rich_console.print(\\\\n                    f\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\",\\\\n                    style=\\\\\\\"bold yellow\\\\\\\"\\\\n                )\\\\n            elif message.sender.endswith('_1') or 'Human' in message.sender:\\\\n                # Don't display our own messages back to us\\\\n                return\\\\n            else:\\\\n                self.rich_console.print(\\\\n                    f\\\\\\\"[{timestamp}] ü§ñ {message.sender}: {message.content}\\\\\\\",\\\\n                    style=\\\\\\\"cyan\\\\\\\"\\\\n                )\\\\n        else:\\\\n            if message.message_type == \\\\\\\"moderator\\\\\\\":\\\\n                print(f\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\")\\\\n            elif not (message.sender.endswith('_1') or 'Human' in message.sender):\\\\n                print(f\\\\\\\"[{timestamp}] ü§ñ {message.sender}: {message.content}\\\\\\\")\\\\n\\\\n    async def get_input(self, prompt: str, timeout: int = 10) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get input from user with timeout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if self.rich_console:\\\\n            self.rich_console.print(f\\\\\\\"üí¨ {prompt}\\\\\\\", style=\\\\\\\"bold green\\\\\\\")\\\\n        else:\\\\n            print(f\\\\\\\"üí¨ {prompt}\\\\\\\")\\\\n\\\\n        # Start input task\\\\n        self.input_task = asyncio.create_task(self._get_user_input())\\\\n\\\\n        try:\\\\n            # Wait for input or timeout\\\\n            response = await asyncio.wait_for(self.input_task, timeout=timeout)\\\\n            return response.strip()\\\\n\\\\n        except asyncio.TimeoutError:\\\\n            if self.input_task and not self.input_task.done():\\\\n                self.input_task.cancel()\\\\n                try:\\\\n                    await self.input_task\\\\n                except asyncio.CancelledError:\\\\n                    pass\\\\n            return \\\\\\\"\\\\\\\"\\\\n        except asyncio.CancelledError:\\\\n            if self.input_task and not self.input_task.done():\\\\n                self.input_task.cancel()\\\\n            return \\\\\\\"\\\\\\\"\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Input error: {e}\\\\\\\")\\\\n            if self.input_task and not self.input_task.done():\\\\n                self.input_task.cancel()\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n    async def _get_user_input(self) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get user input asynchronously.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        loop = asyncio.get_event_loop()\\\\n        return await loop.run_in_executor(None, input, \\\\\\\"\\\\\\\")\\\\n\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\"info\\\\\\\"):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Show a notification to the user.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        icons = {\\\\n            \\\\\\\"info\\\\\\\": \\\\\\\"‚ÑπÔ∏è\\\\\\\",\\\\n            \\\\\\\"warning\\\\\\\": \\\\\\\"‚ö†Ô∏è\\\\\\\",\\\\n            \\\\\\\"error\\\\\\\": \\\\\\\"‚ùå\\\\\\\",\\\\n            \\\\\\\"success\\\\\\\": \\\\\\\"‚úÖ\\\\\\\"\\\\n        }\\\\n\\\\n        icon = icons.get(level, \\\\\\\"‚ÑπÔ∏è\\\\\\\")\\\\n\\\\n        if self.rich_console:\\\\n            colors = {\\\\n                \\\\\\\"info\\\\\\\": \\\\\\\"blue\\\\\\\",\\\\n                \\\\\\\"warning\\\\\\\": \\\\\\\"yellow\\\\\\\",\\\\n                \\\\\\\"error\\\\\\\": \\\\\\\"red\\\\\\\",\\\\n                \\\\\\\"success\\\\\\\": \\\\\\\"green\\\\\\\"\\\\n            }\\\\n            color = colors.get(level, \\\\\\\"blue\\\\\\\")\\\\n            self.rich_console.print(f\\\\\\\"{icon} {message}\\\\\\\", style=color)\\\\n        else:\\\\n            print(f\\\\\\\"{icon} {message}\\\\\\\")\\\\n\\\\n\\\\nclass WebInterface:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Web interface for human participants.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, config: InterfaceConfig):\\\\n        self.config = config\\\\n        self.websocket = None\\\\n        self.pending_responses = {}\\\\n\\\\n    async def display_message(self, message: Message):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Display message via websocket.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if self.websocket:\\\\n            await self.websocket.send_json({\\\\n                \\\\\\\"type\\\\\\\": \\\\\\\"message\\\\\\\",\\\\n                \\\\\\\"data\\\\\\\": message.to_dict()\\\\n            })\\\\n\\\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get input via websocket.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.websocket:\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n        request_id = f\\\\\\\"input_{time.time()}\\\\\\\"\\\\n        await self.websocket.send_json({\\\\n            \\\\\\\"type\\\\\\\": \\\\\\\"input_request\\\\\\\",\\\\n            \\\\\\\"id\\\\\\\": request_id,\\\\n            \\\\\\\"prompt\\\\\\\": prompt,\\\\n            \\\\\\\"timeout\\\\\\\": timeout\\\\n        })\\\\n\\\\n        # Wait for response\\\\n        try:\\\\n            response = await asyncio.wait_for(\\\\n                self._wait_for_response(request_id),\\\\n                timeout=timeout\\\\n            )\\\\n            return response\\\\n        except asyncio.TimeoutError:\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n    async def _wait_for_response(self, request_id: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Wait for websocket response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        while request_id not in self.pending_responses:\\\\n            await asyncio.sleep(0.1)\\\\n        return self.pending_responses.pop(request_id)\\\\n\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\"info\\\\\\\"):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Show notification via websocket.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if self.websocket:\\\\n            await self.websocket.send_json({\\\\n                \\\\\\\"type\\\\\\\": \\\\\\\"notification\\\\\\\",\\\\n                \\\\\\\"message\\\\\\\": message,\\\\n                \\\\\\\"level\\\\\\\": level\\\\n            })\\\\n\\\\n\\\\nclass HumanClient:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Human participant in the debate system with autonomous participation.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, name: str, config: Dict[str, Any]):\\\\n        self.name = name\\\\n        self.config = config\\\\n        self.is_active = True\\\\n        self.conversation_history: List[Message] = []\\\\n\\\\n        # Initialize appropriate interface\\\\n        interface_config = InterfaceConfig(\\\\n            mode=config.get('mode', 'cli'),\\\\n            enable_rich_formatting=config.get('enable_rich_formatting', True),\\\\n            show_typing_indicators=config.get('show_typing_indicators', True),\\\\n            enable_reactions=config.get('enable_reactions', True),\\\\n            input_timeout=config.get('input_timeout', 120)\\\\n        )\\\\n\\\\n        if interface_config.mode == \\\\\\\"cli\\\\\\\":\\\\n            self.interface = CLIInterface(interface_config)\\\\n        elif interface_config.mode == \\\\\\\"web\\\\\\\":\\\\n            self.interface = WebInterface(interface_config)\\\\n        else:\\\\n            raise ValueError(f\\\\\\\"Unsupported interface mode: {interface_config.mode}\\\\\\\")\\\\n\\\\n        # Statistics tracking\\\\n        self.stats = {\\\\n            'responses_given': 0,\\\\n            'timeouts': 0,\\\\n            'total_response_time': 0.0,\\\\n            'average_response_time': 0.0\\\\n        }\\\\n\\\\n    async def autonomous_participation_loop(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"True autonomous participation - human can speak anytime.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.is_active:\\\\n            return\\\\n\\\\n        await self.interface.show_notification(\\\\n            \\\\\\\"üéØ AUTONOMOUS MODE ACTIVE - You can speak ANYTIME!\\\\\\\", \\\\\\\"success\\\\\\\"\\\\n        )\\\\n        await self.interface.show_notification(\\\\n            \\\\\\\"üó£Ô∏è  You can speak at ANY TIME during the discussion!\\\\\\\", \\\\\\\"info\\\\\\\"\\\\n        )\\\\n        await self.interface.show_notification(\\\\n            \\\\\\\"üí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\", \\\\\\\"info\\\\\\\"\\\\n        )\\\\n        await self.interface.show_notification(\\\\n            \\\\\\\"‚úèÔ∏è  Just type your response and press Enter to join the conversation!\\\\\\\", \\\\\\\"info\\\\\\\"\\\\n        )\\\\n\\\\n        # Subscribe to chat updates for display\\\\n        message_queue = chat_log.subscribe()\\\\n        last_displayed = len(chat_log.messages)\\\\n\\\\n        while self.is_active:\\\\n            try:\\\\n                # Check for new messages to display\\\\n                current_count = len(chat_log.messages)\\\\n                if current_count > last_displayed:\\\\n                    new_messages = list(chat_log.messages)[last_displayed:]\\\\n                    for msg in new_messages:\\\\n                        if msg.sender != self.name:  # Don't show own messages\\\\n                            await self.interface.display_message(msg)\\\\n                    last_displayed = current_count\\\\n\\\\n                # Get user input with short timeout for responsiveness\\\\n                response = await self.interface.get_input(\\\\n                    \\\\\\\"Type your response (or command):\\\\\\\",\\\\n                    timeout=10  # Short timeout for responsiveness\\\\n                )\\\\n\\\\n                if not response:\\\\n                    continue  # Timeout, check for new messages\\\\n\\\\n                response = response.strip()\\\\n\\\\n                # Handle commands\\\\n                if response.lower() in ['quit', 'exit']:\\\\n                    await self.interface.show_notification(\\\\n                        \\\\\\\"üëã Leaving the debate. Thanks for participating!\\\\\\\", \\\\\\\"success\\\\\\\"\\\\n                    )\\\\n                    self.is_active = False\\\\n                    break\\\\n                elif response.lower() == 'help':\\\\n                    await self._show_autonomous_help()\\\\n                    continue\\\\n                elif response.lower() == 'status':\\\\n                    await self._show_status()\\\\n                    continue\\\\n                elif response.lower() == 'history':\\\\n                    await self.interface.show_notification(\\\\\\\"üìú Recent conversation:\\\\\\\", \\\\\\\"info\\\\\\\")\\\\n                    recent = chat_log.get_recent_messages(5)\\\\n                    for msg in recent:\\\\n                        await self.interface.display_message(msg)\\\\n                    continue\\\\n                elif len(response) < 3:\\\\n                    await self.interface.show_notification(\\\\n                        \\\\\\\"‚ö†Ô∏è Please provide a more substantial response (at least 3 characters).\\\\\\\",\\\\n                        \\\\\\\"warning\\\\\\\"\\\\n                    )\\\\n                    continue\\\\n\\\\n                # Process and post message directly to chat log\\\\n                validated_response = self._validate_response(response)\\\\n                if validated_response:\\\\n                    await chat_log.add_message(self.name, validated_response)\\\\n                    self.stats['responses_given'] += 1\\\\n                    await self.interface.show_notification(\\\\n                        \\\\\\\"‚úÖ Your message has been added to the debate!\\\\\\\", \\\\\\\"success\\\\\\\"\\\\n                    )\\\\n\\\\n            except Exception as e:\\\\n                await self.interface.show_notification(f\\\\\\\"‚ùå Error: {e}\\\\\\\", \\\\\\\"error\\\\\\\")\\\\n                await asyncio.sleep(2)\\\\n\\\\n        # Cleanup\\\\n        chat_log.unsubscribe(message_queue)\\\\n        await self.interface.show_notification(\\\\n            \\\\\\\"üõë Autonomous participation ended.\\\\\\\", \\\\\\\"info\\\\\\\"\\\\n        )\\\\n\\\\n    async def _show_autonomous_help(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Show help information for autonomous mode.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        help_text = \\\\\\\"\\\\\\\"\\\\\\\"\\\\nüéØ AI JUBILEE DEBATE - AUTONOMOUS MODE HELP\\\\n\\\\nCOMMANDS:\\\\n‚Ä¢ Just type your response and press Enter to join the debate\\\\n‚Ä¢ 'help' - Show this help message\\\\n‚Ä¢ 'status' - Show your participation statistics  \\\\n‚Ä¢ 'history' - Show recent conversation messages\\\\n‚Ä¢ 'quit' - Leave the debate\\\\n\\\\nAUTONOMOUS MODE:\\\\n‚Ä¢ You can speak at ANY TIME during the discussion phase\\\\n‚Ä¢ Bots and moderator are monitoring and will respond when they feel compelled\\\\n‚Ä¢ No turn-taking - completely organic conversation flow\\\\n‚Ä¢ Your responses are immediately added to the debate\\\\n\\\\nTIPS:\\\\n‚Ä¢ Keep responses focused and substantial (3+ characters)\\\\n‚Ä¢ Reference specific points made by others\\\\n‚Ä¢ Feel free to jump in whenever you have something to add!\\\\n‚Ä¢ The debate flows naturally - speak when inspired!\\\\n\\\\nDEBATE PHASES:\\\\n1. Introduction & Opening Statements (structured)\\\\n2. Autonomous Discussion (free-flowing - you can speak anytime!)\\\\n3. Closing Statements (structured)  \\\\n4. Voting Phase\\\\n\\\\nEnjoy the organic debate experience! üé≠\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n        await self.interface.show_notification(help_text, \\\\\\\"info\\\\\\\")\\\\n\\\\n    async def _show_status(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Show participation status.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        stats = self.get_stats()\\\\n        await self.interface.show_notification(\\\\n            f\\\\\\\"üìä Your participation: {stats['responses_given']} responses, \\\\\\\"\\\\n            f\\\\\\\"{stats['participation_rate']:.1%} participation rate, \\\\\\\"\\\\n            f\\\\\\\"avg response time: {stats['average_response_time']:.1f}s\\\\\\\",\\\\n            \\\\\\\"info\\\\\\\"\\\\n        )\\\\n\\\\n    def _validate_response(self, response: str) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Validate and clean up human response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not response or not response.strip():\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n        # Clean up the response\\\\n        response = response.strip()\\\\n\\\\n        # Check length limits\\\\n        max_length = self.config.get('max_message_length', 500)\\\\n        if len(response) > max_length:\\\\n            response = response[:max_length - 3] + \\\\\\\"...\\\\\\\"\\\\n\\\\n        # Add note for very short responses\\\\n        if len(response) < 10:\\\\n            response += \\\\\\\" [Note: Very short response]\\\\\\\"\\\\n\\\\n        return response\\\\n\\\\n    # Legacy methods for structured phases\\\\n    async def get_response(self, topic: str, messages: List[Message]) -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get response from human participant (for structured phases).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.is_active:\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n        start_time = time.time()\\\\n\\\\n        try:\\\\n            # Show context in structured phases\\\\n            if len(messages) > 0:\\\\n                await self.interface.show_notification(\\\\n                    f\\\\\\\"üìú Recent messages in conversation:\\\\\\\",\\\\n                    \\\\\\\"info\\\\\\\"\\\\n                )\\\\n                # Show last 3 messages for context\\\\n                recent = messages[-3:] if len(messages) >= 3 else messages\\\\n                for msg in recent:\\\\n                    await self.interface.display_message(msg)\\\\n                await self.interface.show_notification(\\\\\\\"‚îÄ\\\\\\\" * 50, \\\\\\\"info\\\\\\\")\\\\n\\\\n            # Get response with timeout\\\\n            response = await self.interface.get_input(\\\\n                f\\\\\\\"üí¨ Your response to: {topic}\\\\\\\",\\\\n                timeout=self.config.get('input_timeout', 120)\\\\n            )\\\\n\\\\n            # Validate and process response\\\\n            if response:\\\\n                validated_response = self._validate_response(response)\\\\n                if validated_response:\\\\n                    # Add to conversation history\\\\n                    response_msg = Message(\\\\n                        sender=self.name,\\\\n                        content=validated_response,\\\\n                        timestamp=time.time(),\\\\n                        message_id=len(self.conversation_history) + 1\\\\n                    )\\\\n                    self.conversation_history.append(response_msg)\\\\n\\\\n                    # Update stats\\\\n                    response_time = time.time() - start_time\\\\n                    self._update_stats(response_time, success=True)\\\\n\\\\n                    return validated_response\\\\n\\\\n            # Handle timeout/empty response\\\\n            response_time = time.time() - start_time\\\\n            self._update_stats(response_time, success=False)\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n        except Exception as e:\\\\n            await self.interface.show_notification(\\\\n                f\\\\\\\"‚ùå Error getting response: {e}\\\\\\\",\\\\n                \\\\\\\"error\\\\\\\"\\\\n            )\\\\n            return \\\\\\\"\\\\\\\"\\\\n\\\\n    async def receive_message(self, message: Message):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Receive and display a message from the debate.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Don't show our own messages back to us\\\\n        if message.sender == self.name:\\\\n            return\\\\n\\\\n        # Add to conversation history\\\\n        self.conversation_history.append(message)\\\\n\\\\n        # Limit history size\\\\n        if len(self.conversation_history) > 30:\\\\n            self.conversation_history = self.conversation_history[-30:]\\\\n\\\\n        # Display the message (in autonomous mode, this is handled by the loop)\\\\n        try:\\\\n            if not hasattr(self, '_in_autonomous_mode'):\\\\n                await self.interface.display_message(message)\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"Error displaying message: {e}\\\\\\\")\\\\n\\\\n    async def handle_voting(self, candidates: List[str], time_limit: int) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Handle voting process for human participant.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await self.interface.show_notification(\\\\n            f\\\\\\\"üó≥Ô∏è Voting phase! You have {time_limit} seconds to vote.\\\\\\\",\\\\n            \\\\\\\"info\\\\\\\"\\\\n        )\\\\n\\\\n        # Show candidates\\\\n        await self.interface.show_notification(\\\\n            \\\\\\\"üìã Candidates:\\\\\\\", \\\\\\\"info\\\\\\\"\\\\n        )\\\\n        for i, candidate in enumerate(candidates, 1):\\\\n            await self.interface.show_notification(\\\\n                f\\\\\\\"  {i}. {candidate}\\\\\\\", \\\\\\\"info\\\\\\\"\\\\n            )\\\\n\\\\n        try:\\\\n            # Get vote choice\\\\n            choice_input = await self.interface.get_input(\\\\n                f\\\\\\\"Enter your choice (1-{len(candidates)}):\\\\\\\",\\\\n                timeout=time_limit\\\\n            )\\\\n\\\\n            if not choice_input:\\\\n                return {'voted': False, 'reason': 'timeout'}\\\\n\\\\n            try:\\\\n                choice = int(choice_input.strip())\\\\n                if 1 <= choice <= len(candidates):\\\\n                    selected_candidate = candidates[choice - 1]\\\\n\\\\n                    # Get justification if using CLI\\\\n                    justification = \\\\\\\"\\\\\\\"\\\\n                    if isinstance(self.interface, CLIInterface):\\\\n                        justification = await self.interface.get_input(\\\\n                            \\\\\\\"Optional: Why did you choose this candidate?\\\\\\\",\\\\n                            timeout=30\\\\n                        )\\\\n\\\\n                    return {\\\\n                        'voted': True,\\\\n                        'candidate': selected_candidate,\\\\n                        'justification': justification or \\\\\\\"\\\\\\\"\\\\n                    }\\\\n                else:\\\\n                    return {'voted': False, 'reason': 'invalid_choice'}\\\\n\\\\n            except ValueError:\\\\n                return {'voted': False, 'reason': 'invalid_format'}\\\\n\\\\n        except Exception as e:\\\\n            await self.interface.show_notification(\\\\n                f\\\\\\\"‚ùå Voting error: {e}\\\\\\\", \\\\\\\"error\\\\\\\"\\\\n            )\\\\n            return {'voted': False, 'reason': 'error'}\\\\n\\\\n    def _update_stats(self, response_time: float, success: bool):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Update response statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if success:\\\\n            self.stats['responses_given'] += 1\\\\n            self.stats['total_response_time'] += response_time\\\\n            if self.stats['responses_given'] > 0:\\\\n                self.stats['average_response_time'] = (\\\\n                        self.stats['total_response_time'] / self.stats['responses_given']\\\\n                )\\\\n        else:\\\\n            self.stats['timeouts'] += 1\\\\n\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get comprehensive human client statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        total_attempts = self.stats['responses_given'] + self.stats['timeouts']\\\\n        participation_rate = (\\\\n            self.stats['responses_given'] / total_attempts\\\\n            if total_attempts > 0 else 0\\\\n        )\\\\n\\\\n        return {\\\\n            'name': self.name,\\\\n            'interface_mode': self.interface.config.mode,\\\\n            'responses_given': self.stats['responses_given'],\\\\n            'timeouts': self.stats['timeouts'],\\\\n            'total_attempts': total_attempts,\\\\n            'participation_rate': participation_rate,\\\\n            'average_response_time': self.stats.get('average_response_time', 0),\\\\n            'is_active': self.is_active,\\\\n            'conversation_length': len(self.conversation_history)\\\\n        }\\\\n\\\\n    async def set_active(self, active: bool):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Set the active status of the human client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.is_active = active\\\\n        status = \\\\\\\"activated\\\\\\\" if active else \\\\\\\"deactivated\\\\\\\"\\\\n        await self.interface.show_notification(\\\\n            f\\\\\\\"üîÑ {self.name} has been {status}\\\\\\\",\\\\n            \\\\\\\"info\\\\\\\"\\\\n        )\\\\n\\\\n    def __str__(self) -> str:\\\\n        return f\\\\\\\"Human({self.name}, {self.interface.config.mode}, active={self.is_active})\\\\\\\"\\\\n\\\\n    def __repr__(self) -> str:\\\\n        return (f\\\\\\\"HumanClient(name='{self.name}', mode='{self.interface.config.mode}', \\\\\\\"\\\\n                f\\\\\\\"active={self.is_active}, responses={self.stats['responses_given']})\\\\\\\")\\\\n\\\\n    @property\\\\n    def stance(self) -> str:\\\\n        return \\\\\\\"neutral\\\\\\\"  # Or dynamically assign based on your use case\\\\n\\\"\\n        },\\n        \\\"main.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/main.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 4522,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nMain entry point for the AI Jubilee Debate System.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport yaml\\\\nimport click\\\\nimport os\\\\nfrom typing import List, Optional\\\\nfrom pathlib import Path\\\\nfrom dotenv import load_dotenv\\\\n\\\\nfrom .moderator import Moderator\\\\nfrom .bot_client import BotClient\\\\nfrom .human_client import HumanClient\\\\nfrom .chat_log import ChatLog\\\\nfrom .voting import VotingSystem\\\\nfrom .streaming import StreamingServer\\\\nfrom .utils import setup_logging, load_config\\\\n\\\\n\\\\nasync def start_debate_session(\\\\n    topic: Optional[str] = None,\\\\n    ai_bots: int = 2,\\\\n    human_participants: int = 1,\\\\n    config_path: str = \\\\\\\"config.yaml\\\\\\\"\\\\n) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Start a debate session with specified participants.\\\\n\\\\n    Args:\\\\n        topic: Debate topic (if None, uses random from config)\\\\n        ai_bots: Number of AI bot participants\\\\n        human_participants: Number of human participants\\\\n        config_path: Path to configuration file\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Load environment variables from .env file\\\\n    load_dotenv()\\\\n\\\\n    # Load configuration\\\\n    config = load_config(config_path)\\\\n\\\\n    # Setup logging\\\\n    setup_logging(config.get('chat', {}).get('log_level', 'INFO'))\\\\n\\\\n    # Initialize chat log\\\\n    chat_log = ChatLog()\\\\n\\\\n    # Initialize voting system\\\\n    voting_system = VotingSystem(config.get('voting', {}))\\\\n\\\\n    # Select topic\\\\n    if not topic:\\\\n        import random\\\\n        topic = random.choice(config.get('topics', [\\\\\\\"AI in society\\\\\\\"]))\\\\n\\\\n    # Create bot clients\\\\n    bot_clients = []\\\\n    bot_configs = config.get('bots', [])[:ai_bots]\\\\n\\\\n    for i, bot_config in enumerate(bot_configs):\\\\n        bot = BotClient(\\\\n            name=bot_config['name'],\\\\n            model=bot_config['model'],\\\\n            provider=bot_config['provider'],\\\\n            personality=bot_config['personality'],\\\\n            stance=bot_config['stance'],\\\\n            api_key=config['api_keys'].get(bot_config['provider'])\\\\n        )\\\\n        bot_clients.append(bot)\\\\n\\\\n    # Create human clients\\\\n    human_clients = []\\\\n    for i in range(human_participants):\\\\n        human = HumanClient(\\\\n            name=f\\\\\\\"Human_{i+1}\\\\\\\",\\\\n            config=config.get('interface', {})\\\\n        )\\\\n        human_clients.append(human)\\\\n\\\\n    # Initialize moderator based on debate mode\\\\n    debate_mode = config.get('debate', {}).get('mode', 'sequential')\\\\n\\\\n    moderator = Moderator(\\\\n        topic=topic,\\\\n        participants=bot_clients + human_clients,\\\\n        chat_log=chat_log,\\\\n        voting_system=voting_system,\\\\n        config=config\\\\n    )\\\\n\\\\n    if debate_mode == \\\\\\\"autonomous\\\\\\\":\\\\n        print(f\\\\\\\"ü§ñ Running in AUTONOMOUS mode - bots will decide when to speak!\\\\\\\")\\\\n        print(f\\\\\\\"üìù Topic: {topic}\\\\\\\")\\\\n        print(f\\\\\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\")\\\\n        print(f\\\\\\\"‚è∞ Discussion time: {config.get('debate', {}).get('time_limit_minutes', 30)} minutes\\\\\\\")\\\\n        print(f\\\\\\\"üéØ Bots will monitor conversation and jump in when they feel compelled to respond!\\\\\\\")\\\\n    else:\\\\n        print(f\\\\\\\"üìù Running in SEQUENTIAL mode\\\\\\\")\\\\n        print(f\\\\\\\"üë• Participants take turns in order\\\\\\\")\\\\n\\\\n    # Initialize streaming server if enabled\\\\n    streaming_server = None\\\\n    if config.get('streaming', {}).get('enabled', False):\\\\n        streaming_server = StreamingServer(\\\\n            chat_log=chat_log,\\\\n            voting_system=voting_system,\\\\n            config=config.get('streaming', {})\\\\n        )\\\\n        await streaming_server.start()\\\\n\\\\n    try:\\\\n        # Start the debate\\\\n        print(f\\\\\\\"\\\\\\\\nüé≠ Starting AI Jubilee Debate: {topic}\\\\\\\")\\\\n        print(f\\\\\\\"Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\n\\\\\\\")\\\\n\\\\n        await moderator.run_debate()\\\\n\\\\n    except KeyboardInterrupt:\\\\n        print(\\\\\\\"\\\\\\\\n‚èπÔ∏è  Debate interrupted by user\\\\\\\")\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\")\\\\n    finally:\\\\n        # Cleanup\\\\n        if streaming_server:\\\\n            await streaming_server.stop()\\\\n\\\\n        # Save transcript\\\\n        if config.get('chat', {}).get('save_transcripts', True):\\\\n            await chat_log.save_transcript(f\\\\\\\"debate_{topic[:20]}.json\\\\\\\")\\\\n\\\\n\\\\n@click.command()\\\\n@click.option('--topic', '-t', help='Debate topic')\\\\n@click.option('--bots', '-b', default=2, help='Number of AI bots')\\\\n@click.option('--humans', '-h', default=1, help='Number of human participants')\\\\n@click.option('--config', '-c', default='config.yaml', help='Configuration file path')\\\\ndef cli(topic: str, bots: int, humans: int, config: str):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Launch the AI Jubilee Debate System.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    asyncio.run(start_debate_session(topic, bots, humans, config))\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    cli()\\\"\\n        },\\n        \\\"moderator.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/moderator.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 21380,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nModerator class for managing debate flow, rules, and coordination.\\\\nNow acts as an AI-powered facilitator using the same system as other bots.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport time\\\\nimport random\\\\nfrom typing import List, Dict, Any, Optional\\\\nfrom enum import Enum\\\\nfrom dataclasses import dataclass\\\\n\\\\nfrom .chat_log import ChatLog, Message\\\\nfrom .voting import VotingSystem\\\\nfrom .utils import format_time_remaining\\\\nfrom .bot_client import BotClient\\\\nfrom app.bot_client import BotConfig\\\\n\\\\n\\\\nclass DebatePhase(Enum):\\\\n    INTRODUCTION = \\\\\\\"introduction\\\\\\\"\\\\n    OPENING_STATEMENTS = \\\\\\\"opening_statements\\\\\\\"\\\\n    DISCUSSION = \\\\\\\"discussion\\\\\\\"\\\\n    CLOSING_STATEMENTS = \\\\\\\"closing_statements\\\\\\\"\\\\n    VOTING = \\\\\\\"voting\\\\\\\"\\\\n    RESULTS = \\\\\\\"results\\\\\\\"\\\\n    FINISHED = \\\\\\\"finished\\\\\\\"\\\\n\\\\n\\\\n@dataclass\\\\nclass DebateState:\\\\n    phase: DebatePhase\\\\n    current_speaker: Optional[str] = None\\\\n    time_remaining: int = 0\\\\n    turn_order: List[str] = None\\\\n    warnings_issued: Dict[str, int] = None\\\\n\\\\n    def __post_init__(self):\\\\n        if self.turn_order is None:\\\\n            self.turn_order = []\\\\n        if self.warnings_issued is None:\\\\n            self.warnings_issued = {}\\\\n\\\\n\\\\nclass Moderator:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    AI-powered moderator that manages debate flow and provides intelligent facilitation.\\\\n    Works just like other bots but with moderator-specific prompts.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, topic: str, participants: List, chat_log: ChatLog,\\\\n                 voting_system: VotingSystem, config: Dict[str, Any]):\\\\n        self.topic = topic\\\\n        self.participants = {p.name: p for p in participants}\\\\n        self.chat_log = chat_log\\\\n        self.voting_system = voting_system\\\\n        self.config = config\\\\n\\\\n        # Initialize moderator as a bot client\\\\n        moderator_config = config.get('moderator', {})\\\\n\\\\n        print(config)\\\\n        self.moderator_bot = BotClient(\\\\n            name=moderator_config.get('name', 'Moderator'),\\\\n            model=moderator_config.get('model', 'gpt-3.5-turbo'),\\\\n            provider=moderator_config.get('provider', 'openai'),\\\\n            personality=moderator_config.get('personality', 'Professional debate facilitator'),\\\\n            stance=moderator_config.get('stance', 'neutral'),\\\\n            api_key=config['api_keys'].get(moderator_config.get('provider', 'openai'))\\\\n        )\\\\n\\\\n        self.state = DebateState(\\\\n            phase=DebatePhase.INTRODUCTION,\\\\n            turn_order=list(self.participants.keys())\\\\n        )\\\\n\\\\n        self.phase_times = {\\\\n            DebatePhase.OPENING_STATEMENTS: config.get('opening_statement_time', 120),\\\\n            DebatePhase.DISCUSSION: config.get('time_limit_minutes', 30) * 60,\\\\n            DebatePhase.CLOSING_STATEMENTS: config.get('closing_statement_time', 90),\\\\n            DebatePhase.VOTING: config.get('voting_duration', 300)\\\\n        }\\\\n\\\\n        self.max_response_time = config.get('max_response_time', 120)\\\\n        self.warning_time = config.get('warning_time', 90)\\\\n\\\\n        # Autonomous mode settings\\\\n        self.autonomous_mode = config.get('mode', 'autonomous') == 'autonomous'\\\\n        self.autonomous_tasks: List[asyncio.Task] = []\\\\n        self.phase_task: Optional[asyncio.Task] = None\\\\n\\\\n        # Facilitation settings\\\\n        self.silence_timeout = config.get('silence_timeout', 60)\\\\n        self.last_activity_time = time.time()\\\\n        self.last_moderator_prompt = 0\\\\n\\\\n    async def run_debate(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Run the complete debate session with autonomous support.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        results = {}\\\\n\\\\n        try:\\\\n            await self._introduction_phase()\\\\n            await self._opening_statements_phase()\\\\n\\\\n            if self.autonomous_mode:\\\\n                await self._autonomous_discussion_phase()\\\\n            else:\\\\n                await self._traditional_discussion_phase()\\\\n\\\\n            await self._closing_statements_phase()\\\\n            results = await self._voting_phase()\\\\n            await self._results_phase(results)\\\\n\\\\n        except Exception as e:\\\\n            await self._broadcast_message(\\\\n                f\\\\\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\\\\\",\\\\n                \\\\\\\"moderator\\\\\\\"\\\\n            )\\\\n            raise\\\\n        finally:\\\\n            if self.autonomous_mode:\\\\n                await self._cleanup_autonomous_tasks()\\\\n            self.state.phase = DebatePhase.FINISHED\\\\n\\\\n        return results\\\\n\\\\n    async def _autonomous_discussion_phase(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Autonomous discussion where bots and humans self-manage participation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"üöÄ AUTONOMOUS DISCUSSION PHASE BEGIN! ü§ñ\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"üéØ How this works:\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   ‚Ä¢ Bots are now monitoring the conversation continuously\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   ‚Ä¢ They will decide when they feel compelled to respond\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   ‚Ä¢ Humans can type messages at ANY TIME to join in\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   ‚Ä¢ No turn-taking - completely organic conversation flow!\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   ‚Ä¢ Everyone has access to full conversation history\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"‚è∞ Discussion time: {total_time // 60} minutes\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"üé≠ Let the autonomous debate begin!\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n        self.last_activity_time = time.time()\\\\n        start_time = time.time()\\\\n\\\\n        # Start bot autonomous monitoring\\\\n        await self._start_bot_autonomous_monitoring()\\\\n\\\\n        # Start human autonomous participation\\\\n        await self._start_human_autonomous_participation()\\\\n\\\\n        # Start moderator autonomous monitoring\\\\n        await self._start_moderator_autonomous_monitoring()\\\\n\\\\n        # Start phase management (facilitation only)\\\\n        self.phase_task = asyncio.create_task(\\\\n            self._facilitate_autonomous_discussion(start_time, total_time)\\\\n        )\\\\n\\\\n        try:\\\\n            await self.phase_task\\\\n        except asyncio.CancelledError:\\\\n            pass\\\\n\\\\n        await self._broadcast_message(\\\\n            \\\\\\\"‚èπÔ∏è Autonomous discussion phase complete! üéâ\\\\\\\\n\\\\\\\"\\\\n            \\\\\\\"Moving to closing statements...\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n    async def _start_bot_autonomous_monitoring(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Start autonomous monitoring for all bots.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for participant_name, participant in self.participants.items():\\\\n            if hasattr(participant, 'start_autonomous_monitoring'):  # It's a bot\\\\n                task = asyncio.create_task(\\\\n                    participant.start_autonomous_monitoring(self.chat_log, self.topic)\\\\n                )\\\\n                self.autonomous_tasks.append(task)\\\\n\\\\n    async def _start_human_autonomous_participation(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Start autonomous participation for humans.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for participant_name, participant in self.participants.items():\\\\n            if hasattr(participant, 'autonomous_participation_loop'):  # It's a human\\\\n                task = asyncio.create_task(\\\\n                    participant.autonomous_participation_loop(self.chat_log)\\\\n                )\\\\n                self.autonomous_tasks.append(task)\\\\n\\\\n    async def _start_moderator_autonomous_monitoring(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Start moderator autonomous monitoring just like other bots.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        task = asyncio.create_task(\\\\n            self.moderator_bot.start_autonomous_monitoring(self.chat_log, self.topic)\\\\n        )\\\\n        self.autonomous_tasks.append(task)\\\\n\\\\n    async def _facilitate_autonomous_discussion(self, start_time: float, total_time: int):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Facilitate the autonomous discussion without controlling it.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        last_message_count = len(self.chat_log.messages)\\\\n\\\\n        while time.time() - start_time < total_time:\\\\n            await asyncio.sleep(15)  # Check every 15 seconds\\\\n\\\\n            current_time = time.time()\\\\n            elapsed = current_time - start_time\\\\n            remaining = total_time - elapsed\\\\n\\\\n            # Check for new activity\\\\n            current_message_count = len(self.chat_log.messages)\\\\n            if current_message_count > last_message_count:\\\\n                self.last_activity_time = current_time\\\\n                last_message_count = current_message_count\\\\n\\\\n            # Check for prolonged silence - provide simple prompts\\\\n            silence_duration = current_time - self.last_activity_time\\\\n            if silence_duration > self.silence_timeout:\\\\n                # Simple fallback prompts if moderator bot hasn't spoken\\\\n                if current_time - self.last_moderator_prompt > 45:\\\\n                    await self._provide_simple_prompt()\\\\n                    self.last_moderator_prompt = current_time\\\\n\\\\n            # Provide time updates\\\\n            await self._provide_time_updates(remaining)\\\\n\\\\n    async def _provide_simple_prompt(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Provide simple facilitation prompts as fallback.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        simple_prompts = [\\\\n            \\\\\\\"üéØ What are your thoughts on the discussion so far?\\\\\\\",\\\\n            \\\\\\\"üí° Any other perspectives to consider?\\\\\\\",\\\\n            \\\\\\\"ü§î Does anyone have questions about the points raised?\\\\\\\",\\\\n            \\\\\\\"‚öñÔ∏è How do you weigh the different arguments presented?\\\\\\\"\\\\n        ]\\\\n\\\\n        prompt = random.choice(simple_prompts)\\\\n        await self._broadcast_message(prompt, \\\\\\\"moderator\\\\\\\")\\\\n\\\\n    async def _provide_time_updates(self, remaining: float):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Provide time updates to participants.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if 299 < remaining <= 301:  # 5 minutes warning\\\\n            await self._broadcast_message(\\\\n                \\\\\\\"‚è∞ 5 minutes remaining in autonomous discussion phase\\\\\\\",\\\\n                \\\\\\\"moderator\\\\\\\"\\\\n            )\\\\n        elif 119 < remaining <= 121:  # 2 minutes warning\\\\n            await self._broadcast_message(\\\\n                \\\\\\\"‚è∞ 2 minutes left! Perfect time for final thoughts on this topic\\\\\\\",\\\\n                \\\\\\\"moderator\\\\\\\"\\\\n            )\\\\n        elif 59 < remaining <= 61:  # 1 minute warning\\\\n            await self._broadcast_message(\\\\n                \\\\\\\"‚è∞ Final minute! Any last contributions to the discussion?\\\\\\\",\\\\n                \\\\\\\"moderator\\\\\\\"\\\\n            )\\\\n\\\\n    async def _cleanup_autonomous_tasks(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Clean up all autonomous tasks.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Stop bot monitoring (including moderator bot)\\\\n        for participant in self.participants.values():\\\\n            if hasattr(participant, 'stop_monitoring'):\\\\n                await participant.stop_monitoring()\\\\n\\\\n        # Stop moderator bot monitoring\\\\n        await self.moderator_bot.stop_monitoring()\\\\n\\\\n        # Cancel all autonomous tasks\\\\n        for task in self.autonomous_tasks:\\\\n            if not task.done():\\\\n                task.cancel()\\\\n                try:\\\\n                    await task\\\\n                except asyncio.CancelledError:\\\\n                    pass\\\\n\\\\n        # Cancel phase management task\\\\n        if self.phase_task and not self.phase_task.done():\\\\n            self.phase_task.cancel()\\\\n            try:\\\\n                await self.phase_task\\\\n            except asyncio.CancelledError:\\\\n                pass\\\\n\\\\n        self.autonomous_tasks.clear()\\\\n\\\\n    # Traditional phases (structured)\\\\n    async def _introduction_phase(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Introduce the debate topic and participants.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.INTRODUCTION\\\\n\\\\n        participants_by_type = {\\\\\\\"Bots\\\\\\\": [], \\\\\\\"Humans\\\\\\\": []}\\\\n        for name, participant in self.participants.items():\\\\n            if isinstance(participant.config, BotConfig):  # Bot\\\\n                stance = participant.config.stance\\\\n                participants_by_type[\\\\\\\"Bots\\\\\\\"].append(f\\\\\\\"{name} ({stance})\\\\\\\")\\\\n            else:  # Human or others\\\\n                participants_by_type[\\\\\\\"Humans\\\\\\\"].append(name)\\\\n\\\\n        intro_message = (\\\\n            f\\\\\\\"üé≠ Welcome to AI Jubilee Debate! üé≠\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"üìù Topic: {self.topic}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"üë• Participants:\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   ü§ñ AI Bots: {', '.join(participants_by_type['Bots'])}\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"   üë§ Humans: {', '.join(participants_by_type['Humans'])}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"‚è±Ô∏è Total discussion time: {self.config.get('time_limit_minutes', 30)} minutes\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"üéØ Mode: {'Autonomous (organic flow)' if self.autonomous_mode else 'Sequential (turn-based)'}\\\\\\\"\\\\n        )\\\\n\\\\n        await self._broadcast_message(intro_message, \\\\\\\"moderator\\\\\\\")\\\\n        await asyncio.sleep(3)\\\\n\\\\n    async def _opening_statements_phase(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Handle opening statements from each participant.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.OPENING_STATEMENTS\\\\n        statement_time = self.phase_times[DebatePhase.OPENING_STATEMENTS]\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"üé§ Opening Statements Phase\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"Each participant has {statement_time} seconds for their opening statement.\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"This phase uses structured turns regardless of debate mode.\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n        for participant_name in self.state.turn_order:\\\\n            await self._give_structured_turn(participant_name, statement_time, \\\\\\\"opening statement\\\\\\\")\\\\n\\\\n    async def _traditional_discussion_phase(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Traditional sequential discussion phase.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"üí¨ Sequential Discussion Phase\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"Participants take turns for {total_time // 60} minutes.\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n        start_time = time.time()\\\\n        response_time = self.config.get('response_time', 60)\\\\n\\\\n        while time.time() - start_time < total_time:\\\\n            for participant_name in self.state.turn_order:\\\\n                if time.time() - start_time >= total_time:\\\\n                    break\\\\n\\\\n                remaining = total_time - (time.time() - start_time)\\\\n                if remaining < response_time:\\\\n                    response_time = int(remaining)\\\\n\\\\n                await self._give_structured_turn(participant_name, response_time, \\\\\\\"response\\\\\\\")\\\\n\\\\n        await self._broadcast_message(\\\\\\\"‚èπÔ∏è Sequential discussion phase complete!\\\\\\\", \\\\\\\"moderator\\\\\\\")\\\\n\\\\n    async def _closing_statements_phase(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Handle closing statements.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.CLOSING_STATEMENTS\\\\n        statement_time = self.phase_times[DebatePhase.CLOSING_STATEMENTS]\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"üèÅ Closing Statements Phase\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"Each participant has {statement_time} seconds for final remarks.\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"This phase uses structured turns regardless of debate mode.\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n        # Reverse order for closing statements\\\\n        for participant_name in reversed(self.state.turn_order):\\\\n            await self._give_structured_turn(participant_name, statement_time, \\\\\\\"closing statement\\\\\\\")\\\\n\\\\n    async def _give_structured_turn(self, participant_name: str, time_limit: int, turn_type: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Give structured speaking turn to a participant.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.current_speaker = participant_name\\\\n        self.state.time_remaining = time_limit\\\\n\\\\n        participant = self.participants[participant_name]\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"üé§ {participant_name}'s turn for {turn_type} ({time_limit}s)\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n        try:\\\\n            response_task = asyncio.create_task(\\\\n                participant.get_response(self.topic, self.chat_log.get_recent_messages())\\\\n            )\\\\n\\\\n            # Start timer\\\\n            start_time = time.time()\\\\n            warning_sent = False\\\\n\\\\n            while not response_task.done():\\\\n                elapsed = time.time() - start_time\\\\n                remaining = time_limit - elapsed\\\\n\\\\n                if remaining <= 0:\\\\n                    response_task.cancel()\\\\n                    try:\\\\n                        await response_task\\\\n                    except asyncio.CancelledError:\\\\n                        pass\\\\n                    await self._handle_timeout(participant_name)\\\\n                    break\\\\n\\\\n                if not warning_sent and remaining <= self.warning_time:\\\\n                    await self._send_warning(participant_name, remaining)\\\\n                    warning_sent = True\\\\n\\\\n                await asyncio.sleep(0.5)\\\\n\\\\n            # Process response if completed successfully\\\\n            if response_task.done() and not response_task.cancelled():\\\\n                try:\\\\n                    response = await response_task\\\\n                    if response:\\\\n                        await self._process_response(participant_name, response)\\\\n                except Exception as e:\\\\n                    await self._broadcast_message(\\\\n                        f\\\\\\\"‚ö†Ô∏è Error getting response from {participant_name}: {e}\\\\\\\",\\\\n                        \\\\\\\"moderator\\\\\\\"\\\\n                    )\\\\n\\\\n        except Exception as e:\\\\n            await self._broadcast_message(\\\\n                f\\\\\\\"‚ö†Ô∏è Error during {participant_name}'s turn: {e}\\\\\\\",\\\\n                \\\\\\\"moderator\\\\\\\"\\\\n            )\\\\n        finally:\\\\n            self.state.current_speaker = None\\\\n\\\\n    async def _voting_phase(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Conduct voting on debate performance.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.VOTING\\\\n\\\\n        if not self.voting_system.enabled:\\\\n            await self._broadcast_message(\\\\\\\"Voting disabled. Debate complete!\\\\\\\", \\\\\\\"moderator\\\\\\\")\\\\n            return {}\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"üó≥Ô∏è Voting Phase\\\\\\\\n\\\\\\\"\\\\n            f\\\\\\\"Vote for the most persuasive participant. \\\\\\\"\\\\n            f\\\\\\\"Voting closes in {self.phase_times[DebatePhase.VOTING]} seconds.\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n        await self.voting_system.start_voting(\\\\n            list(self.participants.keys()),\\\\n            self.phase_times[DebatePhase.VOTING]\\\\n        )\\\\n\\\\n        await asyncio.sleep(self.phase_times[DebatePhase.VOTING])\\\\n\\\\n        results = await self.voting_system.end_voting()\\\\n        return results\\\\n\\\\n    async def _results_phase(self, voting_results: Dict[str, Any]):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Announce final results.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.phase = DebatePhase.RESULTS\\\\n\\\\n        if voting_results:\\\\n            winner = voting_results.get('winner')\\\\n            vote_counts = voting_results.get('vote_counts', {})\\\\n\\\\n            results_msg = \\\\\\\"üèÜ DEBATE RESULTS üèÜ\\\\\\\\n\\\\\\\"\\\\n            results_msg += f\\\\\\\"Winner: {winner}\\\\\\\\n\\\\\\\\n\\\\\\\"\\\\n            results_msg += \\\\\\\"Vote Breakdown:\\\\\\\\n\\\\\\\"\\\\n\\\\n            for participant, votes in sorted(vote_counts.items(),\\\\n                                           key=lambda x: x[1], reverse=True):\\\\n                results_msg += f\\\\\\\"  {participant}: {votes} votes\\\\\\\\n\\\\\\\"\\\\n        else:\\\\n            results_msg = \\\\\\\"ü§ù Debate concluded without voting. Great discussion everyone!\\\\\\\"\\\\n\\\\n        await self._broadcast_message(results_msg, \\\\\\\"moderator\\\\\\\")\\\\n\\\\n        # Show participation statistics\\\\n        stats_msg = \\\\\\\"\\\\\\\\nüìä PARTICIPATION STATISTICS:\\\\\\\\n\\\\\\\"\\\\n        for participant_name, participant in self.participants.items():\\\\n            if hasattr(participant, 'get_stats'):\\\\n                stats = participant.get_stats()\\\\n                if hasattr(participant, 'config'):  # Bot\\\\n                    stats_msg += f\\\\\\\"ü§ñ {participant_name}: {stats.get('autonomous_responses', 0)} autonomous responses, \\\\\\\"\\\\n                    stats_msg += f\\\\\\\"{stats.get('success_rate', 0):.1%} success rate\\\\\\\\n\\\\\\\"\\\\n                else:  # Human\\\\n                    stats_msg += f\\\\\\\"üë§ {participant_name}: {stats.get('responses_given', 0)} responses, \\\\\\\"\\\\n                    stats_msg += f\\\\\\\"{stats.get('participation_rate', 0):.1%} participation rate\\\\\\\\n\\\\\\\"\\\\n\\\\n        # Show moderator stats\\\\n        moderator_stats = self.moderator_bot.get_stats()\\\\n        stats_msg += f\\\\\\\"üé≠ Moderator: {moderator_stats.get('autonomous_responses', 0)} facilitation prompts\\\\\\\\n\\\\\\\"\\\\n\\\\n        await self._broadcast_message(stats_msg, \\\\\\\"moderator\\\\\\\")\\\\n        await self._broadcast_message(\\\\\\\"Thank you for participating in AI Jubilee Debate! üé≠‚ú®\\\\\\\", \\\\\\\"moderator\\\\\\\")\\\\n\\\\n    # Utility methods\\\\n    async def _process_response(self, participant_name: str, response: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Process and validate participant response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if len(response) > self.config.get('max_message_length', 500):\\\\n            response = response[:self.config.get('max_message_length', 500)] + \\\\\\\"...\\\\\\\"\\\\n            await self._broadcast_message(\\\\n                f\\\\\\\"‚ö†Ô∏è {participant_name}'s response was truncated due to length\\\\\\\",\\\\n                \\\\\\\"moderator\\\\\\\"\\\\n            )\\\\n\\\\n        await self.chat_log.add_message(participant_name, response)\\\\n\\\\n    async def _handle_timeout(self, participant_name: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Handle participant timeout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.state.warnings_issued[participant_name] = (\\\\n            self.state.warnings_issued.get(participant_name, 0) + 1\\\\n        )\\\\n\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"‚è∞ {participant_name} exceeded time limit. \\\\\\\"\\\\n            f\\\\\\\"Warning {self.state.warnings_issued[participant_name]}/3\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n    async def _send_warning(self, participant_name: str, time_remaining: float):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Send time warning to participant.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await self._broadcast_message(\\\\n            f\\\\\\\"‚è∞ {participant_name}: {int(time_remaining)} seconds remaining\\\\\\\",\\\\n            \\\\\\\"moderator\\\\\\\"\\\\n        )\\\\n\\\\n    async def _broadcast_message(self, content: str, sender: str = \\\\\\\"moderator\\\\\\\"):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Broadcast message to all participants and log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = await self.chat_log.add_message(sender, content, message_type=\\\\\\\"moderator\\\\\\\")\\\\n\\\\n        # Send to all participants\\\\n        for participant in self.participants.values():\\\\n            try:\\\\n                await participant.receive_message(message)\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"Failed to send message to {participant.name}: {e}\\\\\\\")\\\\n\\\\n    def get_state(self) -> DebateState:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get current debate state.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.state\\\"\\n        },\\n        \\\"streaming.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/streaming.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 15845,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nLive streaming and WebSocket server for real-time debate broadcasting.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport json\\\\nimport time\\\\nimport logging\\\\nfrom typing import Dict, List, Set, Any, Optional\\\\nfrom dataclasses import dataclass, asdict\\\\nimport websockets\\\\nfrom websockets.server import WebSocketServerProtocol\\\\n\\\\nfrom .chat_log import ChatLog, Message\\\\nfrom .voting import VotingSystem\\\\nfrom .utils import format_time_remaining\\\\n\\\\n\\\\n@dataclass\\\\nclass StreamingClient:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Information about a connected streaming client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    websocket: WebSocketServerProtocol\\\\n    client_id: str\\\\n    connected_at: float\\\\n    client_type: str = \\\\\\\"viewer\\\\\\\"  # viewer, participant, moderator\\\\n    metadata: Dict[str, Any] = None\\\\n\\\\n    def __post_init__(self):\\\\n        if self.metadata is None:\\\\n            self.metadata = {}\\\\n\\\\n\\\\nclass StreamingServer:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    WebSocket server for live streaming debate sessions.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, chat_log: ChatLog, voting_system: VotingSystem,\\\\n                 config: Dict[str, Any]):\\\\n        self.chat_log = chat_log\\\\n        self.voting_system = voting_system\\\\n        self.config = config\\\\n\\\\n        self.host = config.get('host', 'localhost')\\\\n        self.port = config.get('websocket_port', 8080)\\\\n        self.max_connections = config.get('max_connections', 100)\\\\n        self.broadcast_votes = config.get('broadcast_votes', True)\\\\n\\\\n        # Server state\\\\n        self.server = None\\\\n        self.clients: Dict[str, StreamingClient] = {}\\\\n        self.is_running = False\\\\n\\\\n        # Message subscription\\\\n        self.message_queue = None\\\\n        self.broadcast_task = None\\\\n\\\\n        # Statistics\\\\n        self.stats = {\\\\n            'total_connections': 0,\\\\n            'messages_sent': 0,\\\\n            'votes_broadcast': 0,\\\\n            'start_time': time.time()\\\\n        }\\\\n\\\\n        self.logger = logging.getLogger(__name__)\\\\n\\\\n    async def start(self) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Start the streaming server.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if self.is_running:\\\\n            return\\\\n\\\\n        try:\\\\n            # Subscribe to chat log messages\\\\n            self.message_queue = self.chat_log.subscribe()\\\\n\\\\n            # Start WebSocket server\\\\n            self.server = await websockets.serve(\\\\n                self._handle_client,\\\\n                self.host,\\\\n                self.port,\\\\n                max_size=1024 * 1024,  # 1MB max message size\\\\n                ping_interval=20,\\\\n                ping_timeout=10\\\\n            )\\\\n\\\\n            # Start broadcast task\\\\n            self.broadcast_task = asyncio.create_task(self._broadcast_loop())\\\\n\\\\n            self.is_running = True\\\\n            self.logger.info(f\\\\\\\"Streaming server started on {self.host}:{self.port}\\\\\\\")\\\\n\\\\n        except Exception as e:\\\\n            self.logger.error(f\\\\\\\"Failed to start streaming server: {e}\\\\\\\")\\\\n            raise\\\\n\\\\n    async def stop(self) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Stop the streaming server.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.is_running:\\\\n            return\\\\n\\\\n        self.is_running = False\\\\n\\\\n        # Stop broadcast task\\\\n        if self.broadcast_task:\\\\n            self.broadcast_task.cancel()\\\\n            try:\\\\n                await self.broadcast_task\\\\n            except asyncio.CancelledError:\\\\n                pass\\\\n\\\\n        # Close all client connections\\\\n        if self.clients:\\\\n            await asyncio.gather(\\\\n                *[client.websocket.close() for client in self.clients.values()],\\\\n                return_exceptions=True\\\\n            )\\\\n\\\\n        # Stop WebSocket server\\\\n        if self.server:\\\\n            self.server.close()\\\\n            await self.server.wait_closed()\\\\n\\\\n        # Unsubscribe from chat log\\\\n        if self.message_queue:\\\\n            self.chat_log.unsubscribe(self.message_queue)\\\\n\\\\n        self.logger.info(\\\\\\\"Streaming server stopped\\\\\\\")\\\\n\\\\n    async def _handle_client(self, websocket: WebSocketServerProtocol, path: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Handle new client connection.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if len(self.clients) >= self.max_connections:\\\\n            await websocket.close(code=1013, reason=\\\\\\\"Server full\\\\\\\")\\\\n            return\\\\n\\\\n        client_id = f\\\\\\\"client_{int(time.time() * 1000)}\\\\\\\"\\\\n        client = StreamingClient(\\\\n            websocket=websocket,\\\\n            client_id=client_id,\\\\n            connected_at=time.time()\\\\n        )\\\\n\\\\n        self.clients[client_id] = client\\\\n        self.stats['total_connections'] += 1\\\\n\\\\n        self.logger.info(f\\\\\\\"Client {client_id} connected from {websocket.remote_address}\\\\\\\")\\\\n\\\\n        try:\\\\n            # Send welcome message\\\\n            await self._send_to_client(client, {\\\\n                'type': 'welcome',\\\\n                'client_id': client_id,\\\\n                'server_info': {\\\\n                    'version': '1.0.0',\\\\n                    'features': ['chat', 'voting', 'real_time']\\\\n                }\\\\n            })\\\\n\\\\n            # Send recent messages\\\\n            recent_messages = self.chat_log.get_recent_messages(10)\\\\n            for msg in recent_messages:\\\\n                await self._send_to_client(client, {\\\\n                    'type': 'message',\\\\n                    'data': msg.to_dict()\\\\n                })\\\\n\\\\n            # Handle client messages\\\\n            async for message in websocket:\\\\n                try:\\\\n                    await self._process_client_message(client, json.loads(message))\\\\n                except json.JSONDecodeError:\\\\n                    await self._send_error(client, \\\\\\\"Invalid JSON message\\\\\\\")\\\\n                except Exception as e:\\\\n                    self.logger.error(f\\\\\\\"Error processing client message: {e}\\\\\\\")\\\\n                    await self._send_error(client, \\\\\\\"Internal server error\\\\\\\")\\\\n\\\\n        except websockets.exceptions.ConnectionClosed:\\\\n            self.logger.info(f\\\\\\\"Client {client_id} disconnected\\\\\\\")\\\\n        except Exception as e:\\\\n            self.logger.error(f\\\\\\\"Client {client_id} error: {e}\\\\\\\")\\\\n        finally:\\\\n            # Clean up client\\\\n            if client_id in self.clients:\\\\n                del self.clients[client_id]\\\\n\\\\n    async def _process_client_message(self, client: StreamingClient, data: Dict[str, Any]):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Process message from client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message_type = data.get('type')\\\\n\\\\n        if message_type == 'ping':\\\\n            await self._send_to_client(client, {'type': 'pong'})\\\\n\\\\n        elif message_type == 'subscribe':\\\\n            # Update client subscription preferences\\\\n            client.metadata['subscriptions'] = data.get('channels', [])\\\\n            await self._send_to_client(client, {\\\\n                'type': 'subscribed',\\\\n                'channels': client.metadata.get('subscriptions', [])\\\\n            })\\\\n\\\\n        elif message_type == 'get_stats':\\\\n            # Send server statistics\\\\n            await self._send_to_client(client, {\\\\n                'type': 'stats',\\\\n                'data': self._get_server_stats()\\\\n            })\\\\n\\\\n        elif message_type == 'vote' and self.voting_system.is_active:\\\\n            # Handle vote from client\\\\n            voter_id = data.get('voter_id', client.client_id)\\\\n            candidate = data.get('candidate')\\\\n            justification = data.get('justification')\\\\n\\\\n            try:\\\\n                success = await self.voting_system.cast_vote(\\\\n                    voter_id, candidate, justification\\\\n                )\\\\n\\\\n                await self._send_to_client(client, {\\\\n                    'type': 'vote_result',\\\\n                    'success': success,\\\\n                    'candidate': candidate\\\\n                })\\\\n\\\\n                if success and self.broadcast_votes:\\\\n                    await self._broadcast_vote_update()\\\\n\\\\n            except Exception as e:\\\\n                await self._send_error(client, f\\\\\\\"Vote failed: {e}\\\\\\\")\\\\n\\\\n        else:\\\\n            await self._send_error(client, f\\\\\\\"Unknown message type: {message_type}\\\\\\\")\\\\n\\\\n    async def _broadcast_loop(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Main broadcast loop for new messages.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            while self.is_running:\\\\n                try:\\\\n                    # Wait for new message from chat log\\\\n                    message = await asyncio.wait_for(\\\\n                        self.message_queue.get(),\\\\n                        timeout=1.0\\\\n                    )\\\\n\\\\n                    # Broadcast to all clients\\\\n                    await self._broadcast_message(message)\\\\n\\\\n                except asyncio.TimeoutError:\\\\n                    # Timeout is expected, continue loop\\\\n                    continue\\\\n                except Exception as e:\\\\n                    self.logger.error(f\\\\\\\"Broadcast loop error: {e}\\\\\\\")\\\\n                    await asyncio.sleep(1)\\\\n\\\\n        except asyncio.CancelledError:\\\\n            self.logger.info(\\\\\\\"Broadcast loop cancelled\\\\\\\")\\\\n\\\\n    async def _broadcast_message(self, message: Message):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Broadcast message to all connected clients.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.clients:\\\\n            return\\\\n\\\\n        broadcast_data = {\\\\n            'type': 'message',\\\\n            'data': message.to_dict()\\\\n        }\\\\n\\\\n        # Send to all clients\\\\n        tasks = []\\\\n        for client in list(self.clients.values()):\\\\n            if self._should_send_to_client(client, message):\\\\n                tasks.append(self._send_to_client(client, broadcast_data))\\\\n\\\\n        if tasks:\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\n            self.stats['messages_sent'] += len(tasks)\\\\n\\\\n    def _should_send_to_client(self, client: StreamingClient, message: Message) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Determine if message should be sent to client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Check client subscriptions\\\\n        subscriptions = client.metadata.get('subscriptions', [])\\\\n\\\\n        if subscriptions:\\\\n            # If client has specific subscriptions, check them\\\\n            if message.message_type not in subscriptions:\\\\n                return False\\\\n\\\\n        return True\\\\n\\\\n    async def _broadcast_vote_update(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Broadcast voting update to clients.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.voting_system.is_active:\\\\n            return\\\\n\\\\n        vote_summary = self.voting_system.get_vote_summary()\\\\n\\\\n        broadcast_data = {\\\\n            'type': 'vote_update',\\\\n            'data': vote_summary\\\\n        }\\\\n\\\\n        tasks = []\\\\n        for client in list(self.clients.values()):\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\n\\\\n        if tasks:\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\n            self.stats['votes_broadcast'] += 1\\\\n\\\\n    async def _send_to_client(self, client: StreamingClient, data: Dict[str, Any]):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Send data to specific client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        try:\\\\n            await client.websocket.send(json.dumps(data))\\\\n        except websockets.exceptions.ConnectionClosed:\\\\n            # Client disconnected, will be cleaned up\\\\n            pass\\\\n        except Exception as e:\\\\n            self.logger.error(f\\\\\\\"Failed to send to client {client.client_id}: {e}\\\\\\\")\\\\n\\\\n    async def _send_error(self, client: StreamingClient, error_message: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Send error message to client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await self._send_to_client(client, {\\\\n            'type': 'error',\\\\n            'message': error_message\\\\n        })\\\\n\\\\n    def _get_server_stats(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get server statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        uptime = time.time() - self.stats['start_time']\\\\n\\\\n        return {\\\\n            'connected_clients': len(self.clients),\\\\n            'total_connections': self.stats['total_connections'],\\\\n            'messages_sent': self.stats['messages_sent'],\\\\n            'votes_broadcast': self.stats['votes_broadcast'],\\\\n            'uptime_seconds': uptime,\\\\n            'uptime_formatted': format_time_remaining(uptime),\\\\n            'is_voting_active': self.voting_system.is_active if self.voting_system else False\\\\n        }\\\\n\\\\n    async def broadcast_custom_message(self, message_type: str, data: Any):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Broadcast custom message to all clients.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        broadcast_data = {\\\\n            'type': message_type,\\\\n            'data': data,\\\\n            'timestamp': time.time()\\\\n        }\\\\n\\\\n        tasks = []\\\\n        for client in list(self.clients.values()):\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\n\\\\n        if tasks:\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\n\\\\n    async def send_to_specific_clients(self, client_ids: List[str],\\\\n                                       message_type: str, data: Any):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Send message to specific clients.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = {\\\\n            'type': message_type,\\\\n            'data': data,\\\\n            'timestamp': time.time()\\\\n        }\\\\n\\\\n        tasks = []\\\\n        for client_id in client_ids:\\\\n            if client_id in self.clients:\\\\n                client = self.clients[client_id]\\\\n                tasks.append(self._send_to_client(client, message))\\\\n\\\\n        if tasks:\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\n\\\\n    def get_connected_clients(self) -> List[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get information about connected clients.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return [\\\\n            {\\\\n                'client_id': client.client_id,\\\\n                'connected_at': client.connected_at,\\\\n                'client_type': client.client_type,\\\\n                'connection_duration': time.time() - client.connected_at\\\\n            }\\\\n            for client in self.clients.values()\\\\n        ]\\\\n\\\\n    @property\\\\n    def is_active(self) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if server is running.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return self.is_running\\\\n\\\\n    @property\\\\n    def client_count(self) -> int:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get number of connected clients.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return len(self.clients)\\\\n\\\\n\\\\nclass StreamingManager:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    High-level manager for streaming functionality.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self):\\\\n        self.servers: Dict[str, StreamingServer] = {}\\\\n        self.is_initialized = False\\\\n\\\\n    async def create_streaming_session(self, session_id: str, chat_log: ChatLog,\\\\n                                       voting_system: VotingSystem,\\\\n                                       config: Dict[str, Any]) -> StreamingServer:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Create a new streaming session.\\\\n\\\\n        Args:\\\\n            session_id: Unique session identifier\\\\n            chat_log: Chat log to stream\\\\n            voting_system: Voting system to integrate\\\\n            config: Streaming configuration\\\\n\\\\n        Returns:\\\\n            StreamingServer instance\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if session_id in self.servers:\\\\n            raise ValueError(f\\\\\\\"Streaming session {session_id} already exists\\\\\\\")\\\\n\\\\n        # Create unique port for this session\\\\n        base_port = config.get('websocket_port', 8080)\\\\n        port = base_port + len(self.servers)\\\\n\\\\n        session_config = config.copy()\\\\n        session_config['websocket_port'] = port\\\\n\\\\n        server = StreamingServer(chat_log, voting_system, session_config)\\\\n        self.servers[session_id] = server\\\\n\\\\n        await server.start()\\\\n        return server\\\\n\\\\n    async def stop_streaming_session(self, session_id: str):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Stop a streaming session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if session_id in self.servers:\\\\n            server = self.servers[session_id]\\\\n            await server.stop()\\\\n            del self.servers[session_id]\\\\n\\\\n    async def stop_all_sessions(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Stop all streaming sessions.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        tasks = []\\\\n        for session_id in list(self.servers.keys()):\\\\n            tasks.append(self.stop_streaming_session(session_id))\\\\n\\\\n        if tasks:\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\n\\\\n    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get information about a streaming session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if session_id not in self.servers:\\\\n            return None\\\\n\\\\n        server = self.servers[session_id]\\\\n        return {\\\\n            'session_id': session_id,\\\\n            'is_active': server.is_active,\\\\n            'client_count': server.client_count,\\\\n            'host': server.host,\\\\n            'port': server.port,\\\\n            'stats': server._get_server_stats()\\\\n        }\\\\n\\\\n    def list_active_sessions(self) -> List[str]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get list of active session IDs.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return [\\\\n            session_id for session_id, server in self.servers.items()\\\\n            if server.is_active\\\\n        ]\\\"\\n        },\\n        \\\"utils.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/utils.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 10954,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nUtility functions for the AI Jubilee Debate System.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport os\\\\nimport yaml\\\\nimport logging\\\\nimport time\\\\nimport re\\\\nfrom typing import Dict, Any, List, Optional\\\\nfrom pathlib import Path\\\\nfrom datetime import datetime, timedelta\\\\n\\\\n\\\\ndef load_config(config_path: str = \\\\\\\"config.yaml\\\\\\\") -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Load configuration from YAML file with environment variable substitution.\\\\n\\\\n    Args:\\\\n        config_path: Path to configuration file\\\\n\\\\n    Returns:\\\\n        Configuration dictionary\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    config_file = Path(config_path)\\\\n\\\\n    if not config_file.exists():\\\\n        raise FileNotFoundError(f\\\\\\\"Configuration file not found: {config_path}\\\\\\\")\\\\n\\\\n    with open(config_file, 'r', encoding='utf-8') as f:\\\\n        config_content = f.read()\\\\n\\\\n    # Substitute environment variables\\\\n    config_content = substitute_env_vars(config_content)\\\\n\\\\n    try:\\\\n        config = yaml.safe_load(config_content)\\\\n        return config\\\\n    except yaml.YAMLError as e:\\\\n        raise ValueError(f\\\\\\\"Invalid YAML configuration: {e}\\\\\\\")\\\\n\\\\n\\\\ndef substitute_env_vars(text: str) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Substitute environment variables in text using ${VAR_NAME} syntax.\\\\n\\\\n    Args:\\\\n        text: Text containing environment variable references\\\\n\\\\n    Returns:\\\\n        Text with environment variables substituted\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    def replace_env_var(match):\\\\n        var_name = match.group(1)\\\\n        env_value = os.getenv(var_name)\\\\n        if env_value is None:\\\\n            print(f\\\\\\\"Warning: Environment variable {var_name} not found\\\\\\\")\\\\n            return f\\\\\\\"${{{var_name}}}\\\\\\\"  # Keep original if not found\\\\n        return env_value\\\\n\\\\n    return re.sub(r'\\\\\\\\$\\\\\\\\{([^}]+)\\\\\\\\}', replace_env_var, text)\\\\n\\\\n\\\\ndef setup_logging(level: str = \\\\\\\"INFO\\\\\\\", log_file: Optional[str] = None) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Setup logging configuration.\\\\n\\\\n    Args:\\\\n        level: Logging level (DEBUG, INFO, WARNING, ERROR)\\\\n        log_file: Optional log file path\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\\\\n\\\\n    # Create formatter\\\\n    formatter = logging.Formatter(\\\\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\\\n    )\\\\n\\\\n    # Setup root logger\\\\n    root_logger = logging.getLogger()\\\\n    root_logger.setLevel(numeric_level)\\\\n\\\\n    # Clear existing handlers\\\\n    root_logger.handlers.clear()\\\\n\\\\n    # Console handler\\\\n    console_handler = logging.StreamHandler()\\\\n    console_handler.setFormatter(formatter)\\\\n    root_logger.addHandler(console_handler)\\\\n\\\\n    # File handler if specified\\\\n    if log_file:\\\\n        file_handler = logging.FileHandler(log_file)\\\\n        file_handler.setFormatter(formatter)\\\\n        root_logger.addHandler(file_handler)\\\\n\\\\n\\\\ndef format_time_remaining(seconds: float) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Format remaining time in human-readable format.\\\\n\\\\n    Args:\\\\n        seconds: Time remaining in seconds\\\\n\\\\n    Returns:\\\\n        Formatted time string\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if seconds <= 0:\\\\n        return \\\\\\\"Time's up!\\\\\\\"\\\\n\\\\n    if seconds < 60:\\\\n        return f\\\\\\\"{int(seconds)} seconds\\\\\\\"\\\\n    elif seconds < 3600:\\\\n        minutes = int(seconds // 60)\\\\n        secs = int(seconds % 60)\\\\n        return f\\\\\\\"{minutes}m {secs}s\\\\\\\"\\\\n    else:\\\\n        hours = int(seconds // 3600)\\\\n        minutes = int((seconds % 3600) // 60)\\\\n        return f\\\\\\\"{hours}h {minutes}m\\\\\\\"\\\\n\\\\n\\\\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\"...\\\\\\\") -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Truncate text to maximum length with suffix.\\\\n\\\\n    Args:\\\\n        text: Text to truncate\\\\n        max_length: Maximum length\\\\n        suffix: Suffix to add when truncating\\\\n\\\\n    Returns:\\\\n        Truncated text\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if len(text) <= max_length:\\\\n        return text\\\\n\\\\n    return text[:max_length - len(suffix)] + suffix\\\\n\\\\n\\\\ndef generate_debate_prompt(topic: str, role: str, personality: str) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Generate a debate prompt for AI participants.\\\\n\\\\n    Args:\\\\n        topic: Debate topic\\\\n        role: Participant role (pro, con, neutral)\\\\n        personality: Personality description\\\\n\\\\n    Returns:\\\\n        Generated prompt\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    base_prompt = f\\\\\\\"\\\\\\\"\\\\\\\"You are participating in a structured debate on the topic: \\\\\\\"{topic}\\\\\\\"\\\\n\\\\nYour role: {role}\\\\nYour personality: {personality}\\\\n\\\\nInstructions:\\\\n1. Present clear, logical arguments\\\\n2. Respond to other participants' points\\\\n3. Stay focused on the topic\\\\n4. Be respectful but persuasive\\\\n5. Keep responses concise and engaging\\\\n\\\\nCurrent debate topic: {topic}\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    if role.lower() == \\\\\\\"pro\\\\\\\":\\\\n        base_prompt += \\\\\\\"\\\\\\\\nYou should argue IN FAVOR of the topic.\\\\\\\"\\\\n    elif role.lower() == \\\\\\\"con\\\\\\\":\\\\n        base_prompt += \\\\\\\"\\\\\\\\nYou should argue AGAINST the topic.\\\\\\\"\\\\n    elif role.lower() == \\\\\\\"neutral\\\\\\\":\\\\n        base_prompt += \\\\\\\"\\\\\\\\nYou should present balanced perspectives and ask probing questions.\\\\\\\"\\\\n\\\\n    return base_prompt\\\\n\\\\n\\\\ndef validate_participant_name(name: str) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Validate participant name.\\\\n\\\\n    Args:\\\\n        name: Participant name to validate\\\\n\\\\n    Returns:\\\\n        True if valid, False otherwise\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if not name or len(name.strip()) == 0:\\\\n        return False\\\\n\\\\n    # Check length\\\\n    if len(name) > 50:\\\\n        return False\\\\n\\\\n    # Check for valid characters (alphanumeric, spaces, underscores, hyphens)\\\\n    if not re.match(r'^[a-zA-Z0-9\\\\\\\\s_-]+$', name):\\\\n        return False\\\\n\\\\n    return True\\\\n\\\\n\\\\ndef sanitize_filename(filename: str) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Sanitize filename for safe file operations.\\\\n\\\\n    Args:\\\\n        filename: Original filename\\\\n\\\\n    Returns:\\\\n        Sanitized filename\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Remove or replace invalid characters\\\\n    sanitized = re.sub(r'[<>:\\\\\\\"/\\\\\\\\\\\\\\\\|?*]', '_', filename)\\\\n\\\\n    # Remove leading/trailing spaces and dots\\\\n    sanitized = sanitized.strip(' .')\\\\n\\\\n    # Limit length\\\\n    if len(sanitized) > 255:\\\\n        sanitized = sanitized[:255]\\\\n\\\\n    return sanitized\\\\n\\\\n\\\\ndef parse_duration(duration_str: str) -> int:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Parse duration string into seconds.\\\\n\\\\n    Args:\\\\n        duration_str: Duration string (e.g., \\\\\\\"5m\\\\\\\", \\\\\\\"30s\\\\\\\", \\\\\\\"1h30m\\\\\\\")\\\\n\\\\n    Returns:\\\\n        Duration in seconds\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if duration_str.isdigit():\\\\n        return int(duration_str)\\\\n\\\\n    total_seconds = 0\\\\n\\\\n    # Parse hours\\\\n    hours_match = re.search(r'(\\\\\\\\d+)h', duration_str.lower())\\\\n    if hours_match:\\\\n        total_seconds += int(hours_match.group(1)) * 3600\\\\n\\\\n    # Parse minutes\\\\n    minutes_match = re.search(r'(\\\\\\\\d+)m', duration_str.lower())\\\\n    if minutes_match:\\\\n        total_seconds += int(minutes_match.group(1)) * 60\\\\n\\\\n    # Parse seconds\\\\n    seconds_match = re.search(r'(\\\\\\\\d+)s', duration_str.lower())\\\\n    if seconds_match:\\\\n        total_seconds += int(seconds_match.group(1))\\\\n\\\\n    return total_seconds if total_seconds > 0 else 60  # Default to 60 seconds\\\\n\\\\n\\\\ndef create_timestamp() -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Create ISO format timestamp.\\\\n\\\\n    Returns:\\\\n        ISO formatted timestamp string\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return datetime.now().isoformat()\\\\n\\\\n\\\\ndef format_participant_list(participants: List[str], max_display: int = 5) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Format participant list for display.\\\\n\\\\n    Args:\\\\n        participants: List of participant names\\\\n        max_display: Maximum participants to display before truncating\\\\n\\\\n    Returns:\\\\n        Formatted participant string\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if len(participants) <= max_display:\\\\n        return \\\\\\\", \\\\\\\".join(participants)\\\\n\\\\n    displayed = participants[:max_display]\\\\n    remaining = len(participants) - max_display\\\\n\\\\n    return f\\\\\\\"{', '.join(displayed)} (+{remaining} more)\\\\\\\"\\\\n\\\\n\\\\ndef calculate_word_count(text: str) -> int:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Calculate word count in text.\\\\n\\\\n    Args:\\\\n        text: Text to count words in\\\\n\\\\n    Returns:\\\\n        Number of words\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return len(text.split())\\\\n\\\\n\\\\ndef extract_key_phrases(text: str, max_phrases: int = 5) -> List[str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Extract key phrases from text (simple implementation).\\\\n\\\\n    Args:\\\\n        text: Text to extract phrases from\\\\n        max_phrases: Maximum number of phrases to return\\\\n\\\\n    Returns:\\\\n        List of key phrases\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Simple implementation - could be enhanced with NLP\\\\n    sentences = text.split('.')\\\\n    phrases = []\\\\n\\\\n    for sentence in sentences[:max_phrases]:\\\\n        sentence = sentence.strip()\\\\n        if len(sentence) > 10:  # Minimum length\\\\n            phrases.append(sentence)\\\\n\\\\n    return phrases[:max_phrases]\\\\n\\\\n\\\\ndef generate_session_id() -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Generate unique session ID.\\\\n\\\\n    Returns:\\\\n        Unique session identifier\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    import uuid\\\\n    return str(uuid.uuid4())[:8]\\\\n\\\\n\\\\ndef ensure_directory(path: str) -> Path:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Ensure directory exists, create if necessary.\\\\n\\\\n    Args:\\\\n        path: Directory path\\\\n\\\\n    Returns:\\\\n        Path object\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    dir_path = Path(path)\\\\n    dir_path.mkdir(parents=True, exist_ok=True)\\\\n    return dir_path\\\\n\\\\n\\\\ndef load_debate_topics(topics_file: str = \\\\\\\"topics.txt\\\\\\\") -> List[str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Load debate topics from file.\\\\n\\\\n    Args:\\\\n        topics_file: Path to topics file\\\\n\\\\n    Returns:\\\\n        List of debate topics\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    topics_path = Path(topics_file)\\\\n\\\\n    if not topics_path.exists():\\\\n        # Return default topics\\\\n        return [\\\\n            \\\\\\\"Artificial intelligence will create more jobs than it destroys\\\\\\\",\\\\n            \\\\\\\"Social media has a net positive impact on society\\\\\\\",\\\\n            \\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\",\\\\n            \\\\\\\"Climate change requires immediate radical action\\\\\\\",\\\\n            \\\\\\\"Privacy is more important than security\\\\\\\"\\\\n        ]\\\\n\\\\n    with open(topics_path, 'r', encoding='utf-8') as f:\\\\n        topics = [line.strip() for line in f if line.strip() and not line.startswith('#')]\\\\n\\\\n    return topics\\\\n\\\\n\\\\nclass PerformanceTimer:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Context manager for timing operations.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, operation_name: str = \\\\\\\"Operation\\\\\\\"):\\\\n        self.operation_name = operation_name\\\\n        self.start_time = None\\\\n        self.end_time = None\\\\n\\\\n    def __enter__(self):\\\\n        self.start_time = time.time()\\\\n        return self\\\\n\\\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\\\n        self.end_time = time.time()\\\\n\\\\n    @property\\\\n    def duration(self) -> float:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get operation duration in seconds.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if self.start_time and self.end_time:\\\\n            return self.end_time - self.start_time\\\\n        return 0.0\\\\n\\\\n    def __str__(self) -> str:\\\\n        return f\\\\\\\"{self.operation_name}: {self.duration:.3f}s\\\\\\\"\\\\n\\\\n\\\\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Decorator for retrying operations with exponential backoff.\\\\n\\\\n    Args:\\\\n        max_retries: Maximum number of retry attempts\\\\n        base_delay: Base delay between retries\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    def decorator(func):\\\\n        async def wrapper(*args, **kwargs):\\\\n            last_exception = None\\\\n\\\\n            for attempt in range(max_retries + 1):\\\\n                try:\\\\n                    return await func(*args, **kwargs)\\\\n                except Exception as e:\\\\n                    last_exception = e\\\\n\\\\n                    if attempt < max_retries:\\\\n                        delay = base_delay * (2 ** attempt)\\\\n                        await asyncio.sleep(delay)\\\\n                    else:\\\\n                        raise last_exception\\\\n\\\\n            raise last_exception\\\\n\\\\n        return wrapper\\\\n    return decorator\\\"\\n        },\\n        \\\"voting.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"app/voting.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 11436,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nVoting system for debate evaluation and winner determination.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport time\\\\nfrom typing import Dict, List, Optional, Any\\\\nfrom dataclasses import dataclass, field\\\\nfrom collections import defaultdict, Counter\\\\n\\\\n\\\\n@dataclass\\\\nclass Vote:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Represents a single vote.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    voter_id: str\\\\n    candidate: str\\\\n    justification: Optional[str] = None\\\\n    timestamp: float = field(default_factory=time.time)\\\\n    anonymous: bool = False\\\\n\\\\n\\\\n@dataclass\\\\nclass VotingResults:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Results of a voting session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    winner: Optional[str]\\\\n    vote_counts: Dict[str, int]\\\\n    total_votes: int\\\\n    votes_by_voter: Dict[str, Vote]\\\\n    voting_duration: float\\\\n    participation_rate: float\\\\n\\\\n\\\\nclass VotingSystem:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Manages voting process, vote collection, and result calculation.\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def __init__(self, config: Dict[str, Any]):\\\\n        self.config = config\\\\n        self.enabled = config.get('enabled', True)\\\\n        self.voting_duration = config.get('voting_duration', 300)\\\\n        self.allow_participant_voting = config.get('allow_participant_voting', True)\\\\n        self.require_justification = config.get('require_justification', True)\\\\n        self.anonymous_votes = config.get('anonymous_votes', False)\\\\n\\\\n        # Voting state\\\\n        self.is_active = False\\\\n        self.candidates: List[str] = []\\\\n        self.eligible_voters: List[str] = []\\\\n        self.votes: Dict[str, Vote] = {}\\\\n        self.start_time: Optional[float] = None\\\\n        self.end_time: Optional[float] = None\\\\n\\\\n        # Vote validation\\\\n        self.vote_history: List[Dict[str, Any]] = []\\\\n\\\\n    async def start_voting(self, candidates: List[str], duration: Optional[int] = None) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Start a voting session.\\\\n\\\\n        Args:\\\\n            candidates: List of debate participants to vote for\\\\n            duration: Voting duration in seconds (uses config default if None)\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.enabled:\\\\n            raise ValueError(\\\\\\\"Voting system is disabled\\\\\\\")\\\\n\\\\n        if self.is_active:\\\\n            raise ValueError(\\\\\\\"Voting session already active\\\\\\\")\\\\n\\\\n        self.candidates = candidates.copy()\\\\n        self.eligible_voters = candidates.copy() if self.allow_participant_voting else []\\\\n        self.votes = {}\\\\n        self.start_time = time.time()\\\\n        self.end_time = self.start_time + (duration or self.voting_duration)\\\\n        self.is_active = True\\\\n\\\\n        print(f\\\\\\\"üó≥Ô∏è Voting started for {len(candidates)} candidates\\\\\\\")\\\\n        print(f\\\\\\\"‚è∞ Voting closes in {duration or self.voting_duration} seconds\\\\\\\")\\\\n\\\\n    async def cast_vote(self, voter_id: str, candidate: str,\\\\n                        justification: Optional[str] = None) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Cast a vote for a candidate.\\\\n\\\\n        Args:\\\\n            voter_id: ID of the voter\\\\n            candidate: Candidate being voted for\\\\n            justification: Optional reasoning for the vote\\\\n\\\\n        Returns:\\\\n            True if vote was successfully cast, False otherwise\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.is_active:\\\\n            raise ValueError(\\\\\\\"No active voting session\\\\\\\")\\\\n\\\\n        if time.time() > self.end_time:\\\\n            raise ValueError(\\\\\\\"Voting period has ended\\\\\\\")\\\\n\\\\n        # Validate voter eligibility\\\\n        if not self._is_eligible_voter(voter_id):\\\\n            raise ValueError(f\\\\\\\"Voter {voter_id} is not eligible to vote\\\\\\\")\\\\n\\\\n        # Validate candidate\\\\n        if candidate not in self.candidates:\\\\n            raise ValueError(f\\\\\\\"Invalid candidate: {candidate}\\\\\\\")\\\\n\\\\n        # Check for self-voting\\\\n        if voter_id == candidate and not self.allow_participant_voting:\\\\n            raise ValueError(\\\\\\\"Self-voting is not allowed\\\\\\\")\\\\n\\\\n        # Validate justification requirement\\\\n        if self.require_justification and not justification:\\\\n            raise ValueError(\\\\\\\"Vote justification is required\\\\\\\")\\\\n\\\\n        # Record the vote (overwrites previous vote from same voter)\\\\n        vote = Vote(\\\\n            voter_id=voter_id,\\\\n            candidate=candidate,\\\\n            justification=justification,\\\\n            anonymous=self.anonymous_votes\\\\n        )\\\\n\\\\n        self.votes[voter_id] = vote\\\\n\\\\n        print(f\\\\\\\"‚úÖ Vote recorded: {voter_id} -> {candidate}\\\\\\\")\\\\n        return True\\\\n\\\\n    async def end_voting(self) -> VotingResults:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        End the voting session and calculate results.\\\\n\\\\n        Returns:\\\\n            VotingResults object with winner and vote breakdown\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.is_active:\\\\n            raise ValueError(\\\\\\\"No active voting session\\\\\\\")\\\\n\\\\n        self.is_active = False\\\\n        actual_end_time = time.time()\\\\n\\\\n        # Calculate vote counts\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\n        total_votes = len(self.votes)\\\\n\\\\n        # Determine winner\\\\n        winner = None\\\\n        if vote_counts:\\\\n            max_votes = max(vote_counts.values())\\\\n            winners = [candidate for candidate, count in vote_counts.items()\\\\n                       if count == max_votes]\\\\n\\\\n            if len(winners) == 1:\\\\n                winner = winners[0]\\\\n            else:\\\\n                # Handle tie - could implement tiebreaker logic here\\\\n                winner = f\\\\\\\"TIE: {', '.join(winners)}\\\\\\\"\\\\n\\\\n        # Calculate participation rate\\\\n        participation_rate = (total_votes / len(self.eligible_voters)\\\\n                              if self.eligible_voters else 0)\\\\n\\\\n        # Create results\\\\n        results = VotingResults(\\\\n            winner=winner,\\\\n            vote_counts=dict(vote_counts),\\\\n            total_votes=total_votes,\\\\n            votes_by_voter=self.votes.copy(),\\\\n            voting_duration=actual_end_time - self.start_time,\\\\n            participation_rate=participation_rate\\\\n        )\\\\n\\\\n        # Store in history\\\\n        self.vote_history.append({\\\\n            'timestamp': actual_end_time,\\\\n            'candidates': self.candidates.copy(),\\\\n            'results': results\\\\n        })\\\\n\\\\n        print(f\\\\\\\"üèÜ Voting ended. Winner: {winner}\\\\\\\")\\\\n        print(f\\\\\\\"üìä Total votes: {total_votes}\\\\\\\")\\\\n        print(f\\\\\\\"üìà Participation: {participation_rate:.1%}\\\\\\\")\\\\n\\\\n        return results\\\\n\\\\n    def _is_eligible_voter(self, voter_id: str) -> bool:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Check if a voter is eligible to vote.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.eligible_voters:\\\\n            return True  # Open voting\\\\n        return voter_id in self.eligible_voters\\\\n\\\\n    def add_eligible_voter(self, voter_id: str) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Add a voter to the eligible voters list.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if voter_id not in self.eligible_voters:\\\\n            self.eligible_voters.append(voter_id)\\\\n\\\\n    def remove_eligible_voter(self, voter_id: str) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Remove a voter from the eligible voters list.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if voter_id in self.eligible_voters:\\\\n            self.eligible_voters.remove(voter_id)\\\\n\\\\n    def get_vote_summary(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get current voting summary without ending the session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.is_active:\\\\n            return {}\\\\n\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\n        time_remaining = max(0, self.end_time - time.time())\\\\n\\\\n        return {\\\\n            'candidates': self.candidates,\\\\n            'vote_counts': dict(vote_counts),\\\\n            'total_votes': len(self.votes),\\\\n            'time_remaining': time_remaining,\\\\n            'is_active': self.is_active\\\\n        }\\\\n\\\\n    def get_voter_history(self, voter_id: str) -> List[Vote]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get voting history for a specific voter.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        history = []\\\\n        for session in self.vote_history:\\\\n            votes = session.get('results', {}).votes_by_voter\\\\n            if voter_id in votes:\\\\n                history.append(votes[voter_id])\\\\n        return history\\\\n\\\\n    def get_candidate_performance(self, candidate: str) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get performance statistics for a candidate across all sessions.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        wins = 0\\\\n        total_votes = 0\\\\n        participations = 0\\\\n\\\\n        for session in self.vote_history:\\\\n            results = session.get('results', {})\\\\n            if candidate in session.get('candidates', []):\\\\n                participations += 1\\\\n                if results.winner == candidate:\\\\n                    wins += 1\\\\n                total_votes += results.vote_counts.get(candidate, 0)\\\\n\\\\n        return {\\\\n            'candidate': candidate,\\\\n            'wins': wins,\\\\n            'total_votes': total_votes,\\\\n            'participations': participations,\\\\n            'win_rate': wins / participations if participations > 0 else 0,\\\\n            'avg_votes': total_votes / participations if participations > 0 else 0\\\\n        }\\\\n\\\\n    async def export_results(self, format_type: str = 'json') -> str:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        Export voting results in specified format.\\\\n\\\\n        Args:\\\\n            format_type: Export format ('json', 'csv', 'txt')\\\\n\\\\n        Returns:\\\\n            Formatted results string\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"\\\\n        if not self.vote_history:\\\\n            return \\\\\\\"No voting history available\\\\\\\"\\\\n\\\\n        if format_type == 'json':\\\\n            import json\\\\n            return json.dumps(self.vote_history, indent=2, default=str)\\\\n\\\\n        elif format_type == 'csv':\\\\n            import csv\\\\n            import io\\\\n\\\\n            output = io.StringIO()\\\\n            writer = csv.writer(output)\\\\n\\\\n            # Header\\\\n            writer.writerow(['Session', 'Timestamp', 'Candidate', 'Votes', 'Winner'])\\\\n\\\\n            # Data\\\\n            for i, session in enumerate(self.vote_history):\\\\n                results = session.get('results', {})\\\\n                timestamp = session.get('timestamp', '')\\\\n\\\\n                for candidate, votes in results.vote_counts.items():\\\\n                    writer.writerow([\\\\n                        i + 1,\\\\n                        timestamp,\\\\n                        candidate,\\\\n                        votes,\\\\n                        results.winner == candidate\\\\n                    ])\\\\n\\\\n            return output.getvalue()\\\\n\\\\n        elif format_type == 'txt':\\\\n            output = []\\\\n            output.append(\\\\\\\"=== VOTING HISTORY REPORT ===\\\\\\\\n\\\\\\\")\\\\n\\\\n            for i, session in enumerate(self.vote_history):\\\\n                results = session.get('results', {})\\\\n                output.append(f\\\\\\\"Session {i + 1}:\\\\\\\")\\\\n                output.append(f\\\\\\\"  Winner: {results.winner}\\\\\\\")\\\\n                output.append(f\\\\\\\"  Total Votes: {results.total_votes}\\\\\\\")\\\\n                output.append(f\\\\\\\"  Vote Breakdown:\\\\\\\")\\\\n\\\\n                for candidate, votes in sorted(results.vote_counts.items(),\\\\n                                               key=lambda x: x[1], reverse=True):\\\\n                    output.append(f\\\\\\\"    {candidate}: {votes}\\\\\\\")\\\\n                output.append(\\\\\\\"\\\\\\\")\\\\n\\\\n            return \\\\\\\"\\\\\\\\n\\\\\\\".join(output)\\\\n\\\\n        else:\\\\n            raise ValueError(f\\\\\\\"Unsupported format: {format_type}\\\\\\\")\\\\n\\\\n    def reset(self) -> None:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Reset the voting system to initial state.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        self.is_active = False\\\\n        self.candidates = []\\\\n        self.eligible_voters = []\\\\n        self.votes = {}\\\\n        self.start_time = None\\\\n        self.end_time = None\\\\n\\\\n    @property\\\\n    def status(self) -> Dict[str, Any]:\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Get current status of the voting system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        return {\\\\n            'enabled': self.enabled,\\\\n            'is_active': self.is_active,\\\\n            'candidates': self.candidates,\\\\n            'eligible_voters': len(self.eligible_voters),\\\\n            'votes_cast': len(self.votes),\\\\n            'time_remaining': (self.end_time - time.time()\\\\n                               if self.is_active and self.end_time else 0),\\\\n            'sessions_completed': len(self.vote_history)\\\\n        }\\\"\\n        }\\n      }\\n    },\\n    \\\"docs\\\": {\\n      \\\"type\\\": \\\"directory\\\",\\n      \\\"contents\\\": {\\n        \\\"api_reference.md\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"docs/api_reference.md\\\",\\n          \\\"extension\\\": \\\".md\\\",\\n          \\\"size\\\": 15639,\\n          \\\"content\\\": \\\"# AI Jubilee Debate System API Reference\\\\n\\\\n## Core Classes\\\\n\\\\n### Moderator\\\\n\\\\nThe central coordinator for debate sessions.\\\\n\\\\n#### Constructor\\\\n```python\\\\nModerator(\\\\n    topic: str,\\\\n    participants: List[Union[BotClient, HumanClient]],\\\\n    chat_log: ChatLog,\\\\n    voting_system: VotingSystem,\\\\n    config: Dict[str, Any]\\\\n)\\\\n```\\\\n\\\\n**Parameters:**\\\\n- `topic`: The debate topic string\\\\n- `participants`: List of bot and human participants\\\\n- `chat_log`: ChatLog instance for message management\\\\n- `voting_system`: VotingSystem instance for handling votes\\\\n- `config`: Configuration dictionary with timing and rule settings\\\\n\\\\n#### Methods\\\\n\\\\n##### `async run_debate() -> Dict[str, Any]`\\\\nRuns the complete debate session through all phases.\\\\n\\\\n**Returns:** Dictionary containing voting results and session statistics\\\\n\\\\n**Example:**\\\\n```python\\\\nmoderator = Moderator(topic, participants, chat_log, voting_system, config)\\\\nresults = await moderator.run_debate()\\\\nprint(f\\\\\\\"Winner: {results.get('winner', 'No winner')}\\\\\\\")\\\\n```\\\\n\\\\n##### `get_state() -> DebateState`\\\\nReturns current debate state information.\\\\n\\\\n**Returns:** DebateState object with phase, speaker, and timing info\\\\n\\\\n##### `async _give_turn(participant_name: str, time_limit: int, turn_type: str) -> None`\\\\nGives speaking turn to a specific participant.\\\\n\\\\n**Parameters:**\\\\n- `participant_name`: Name of participant to give turn to\\\\n- `time_limit`: Maximum time in seconds for response\\\\n- `turn_type`: Type of turn (\\\\\\\"opening\\\\\\\", \\\\\\\"response\\\\\\\", \\\\\\\"closing\\\\\\\")\\\\n\\\\n---\\\\n\\\\n### ChatLog\\\\n\\\\nThread-safe message management system.\\\\n\\\\n#### Constructor\\\\n```python\\\\nChatLog(max_messages: int = 1000)\\\\n```\\\\n\\\\n**Parameters:**\\\\n- `max_messages`: Maximum number of messages to retain in memory\\\\n\\\\n#### Methods\\\\n\\\\n##### `async add_message(sender: str, content: str, message_type: str = \\\\\\\"chat\\\\\\\", metadata: Optional[Dict] = None) -> Message`\\\\nAdds a new message to the chat log.\\\\n\\\\n**Parameters:**\\\\n- `sender`: Name of message sender\\\\n- `content`: Message content text\\\\n- `message_type`: Type of message (\\\\\\\"chat\\\\\\\", \\\\\\\"moderator\\\\\\\", \\\\\\\"system\\\\\\\", \\\\\\\"vote\\\\\\\")\\\\n- `metadata`: Optional additional data\\\\n\\\\n**Returns:** Created Message object\\\\n\\\\n**Example:**\\\\n```python\\\\nmessage = await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"I think AI will help humanity\\\\\\\")\\\\nprint(f\\\\\\\"Message ID: {message.message_id}\\\\\\\")\\\\n```\\\\n\\\\n##### `get_messages(limit: Optional[int] = None, sender: Optional[str] = None, message_type: Optional[str] = None, since_timestamp: Optional[float] = None) -> List[Message]`\\\\nRetrieves messages with optional filtering.\\\\n\\\\n**Parameters:**\\\\n- `limit`: Maximum number of messages to return\\\\n- `sender`: Filter by sender name\\\\n- `message_type`: Filter by message type\\\\n- `since_timestamp`: Only messages after this timestamp\\\\n\\\\n**Returns:** List of Message objects\\\\n\\\\n##### `subscribe() -> asyncio.Queue`\\\\nCreates subscription for real-time message updates.\\\\n\\\\n**Returns:** Queue that receives new Message objects\\\\n\\\\n##### `async save_transcript(filename: str, format_type: str = \\\\\\\"json\\\\\\\") -> None`\\\\nSaves chat transcript to file.\\\\n\\\\n**Parameters:**\\\\n- `filename`: Output file path\\\\n- `format_type`: Export format (\\\\\\\"json\\\\\\\", \\\\\\\"txt\\\\\\\", \\\\\\\"html\\\\\\\")\\\\n\\\\n##### `search_messages(query: str, case_sensitive: bool = False) -> List[Message]`\\\\nSearches messages by content.\\\\n\\\\n**Parameters:**\\\\n- `query`: Search string\\\\n- `case_sensitive`: Whether search is case sensitive\\\\n\\\\n**Returns:** List of matching Message objects\\\\n\\\\n---\\\\n\\\\n### VotingSystem\\\\n\\\\nManages voting sessions and result calculation.\\\\n\\\\n#### Constructor\\\\n```python\\\\nVotingSystem(config: Dict[str, Any])\\\\n```\\\\n\\\\n**Parameters:**\\\\n- `config`: Voting configuration dictionary\\\\n\\\\n#### Methods\\\\n\\\\n##### `async start_voting(candidates: List[str], duration: Optional[int] = None) -> None`\\\\nStarts a new voting session.\\\\n\\\\n**Parameters:**\\\\n- `candidates`: List of participant names to vote for\\\\n- `duration`: Voting duration in seconds (uses config default if None)\\\\n\\\\n**Example:**\\\\n```python\\\\nawait voting_system.start_voting([\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\", \\\\\\\"Charlie\\\\\\\"], 300)\\\\n```\\\\n\\\\n##### `async cast_vote(voter_id: str, candidate: str, justification: Optional[str] = None) -> bool`\\\\nCasts a vote for a candidate.\\\\n\\\\n**Parameters:**\\\\n- `voter_id`: ID of the voter\\\\n- `candidate`: Name of candidate being voted for\\\\n- `justification`: Optional reasoning for the vote\\\\n\\\\n**Returns:** True if vote was successfully cast\\\\n\\\\n##### `async end_voting() -> VotingResults`\\\\nEnds voting session and calculates results.\\\\n\\\\n**Returns:** VotingResults object with winner and vote breakdown\\\\n\\\\n##### `get_vote_summary() -> Dict[str, Any]`\\\\nGets current voting status without ending session.\\\\n\\\\n**Returns:** Dictionary with vote counts and time remaining\\\\n\\\\n##### `async export_results(format_type: str = \\\\\\\"json\\\\\\\") -> str`\\\\nExports voting results in specified format.\\\\n\\\\n**Parameters:**\\\\n- `format_type`: Export format (\\\\\\\"json\\\\\\\", \\\\\\\"csv\\\\\\\", \\\\\\\"txt\\\\\\\")\\\\n\\\\n**Returns:** Formatted results string\\\\n\\\\n---\\\\n\\\\n### BotClient\\\\n\\\\nAI-powered debate participant.\\\\n\\\\n#### Constructor\\\\n```python\\\\nBotClient(\\\\n    name: str,\\\\n    model: str,\\\\n    provider: str,\\\\n    personality: str,\\\\n    stance: str,\\\\n    api_key: str,\\\\n    temperature: float = 0.7,\\\\n    max_tokens: int = 300\\\\n)\\\\n```\\\\n\\\\n**Parameters:**\\\\n- `name`: Bot display name\\\\n- `model`: AI model identifier\\\\n- `provider`: AI provider (\\\\\\\"openai\\\\\\\" or \\\\\\\"anthropic\\\\\\\")\\\\n- `personality`: Personality description for prompt\\\\n- `stance`: Debate stance (\\\\\\\"pro\\\\\\\", \\\\\\\"con\\\\\\\", \\\\\\\"neutral\\\\\\\")\\\\n- `api_key`: API key for AI provider\\\\n- `temperature`: Response creativity (0.0-1.0)\\\\n- `max_tokens`: Maximum response length\\\\n\\\\n#### Methods\\\\n\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\nGenerates AI response to current debate context.\\\\n\\\\n**Parameters:**\\\\n- `topic`: Current debate topic\\\\n- `recent_messages`: Recent conversation messages for context\\\\n\\\\n**Returns:** Generated response string\\\\n\\\\n**Example:**\\\\n```python\\\\nbot = BotClient(\\\\\\\"Analyst\\\\\\\", \\\\\\\"gpt-4\\\\\\\", \\\\\\\"openai\\\\\\\", \\\\\\\"Analytical\\\\\\\", \\\\\\\"pro\\\\\\\", api_key)\\\\nresponse = await bot.get_response(\\\\\\\"AI in healthcare\\\\\\\", recent_messages)\\\\n```\\\\n\\\\n##### `async receive_message(message: Message) -> None`\\\\nReceives message from debate for context awareness.\\\\n\\\\n##### `get_stats() -> Dict[str, Any]`\\\\nReturns bot performance statistics.\\\\n\\\\n**Returns:** Dictionary with response counts, timing, and success rates\\\\n\\\\n##### `async warmup() -> bool`\\\\nTests bot connectivity and readiness.\\\\n\\\\n**Returns:** True if bot is ready for debate\\\\n\\\\n##### `update_personality(personality: str, stance: str = None) -> None`\\\\nUpdates bot personality and stance during session.\\\\n\\\\n---\\\\n\\\\n### HumanClient\\\\n\\\\nHuman participant interface.\\\\n\\\\n#### Constructor\\\\n```python\\\\nHumanClient(name: str, interface_config: Dict[str, Any])\\\\n```\\\\n\\\\n**Parameters:**\\\\n- `name`: Human participant display name\\\\n- `interface_config`: Interface configuration dictionary\\\\n\\\\n#### Methods\\\\n\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\nGets response from human participant.\\\\n\\\\n**Parameters:**\\\\n- `topic`: Current debate topic\\\\n- `recent_messages`: Recent messages for context\\\\n\\\\n**Returns:** Human's response string\\\\n\\\\n##### `async handle_voting(candidates: List[str], voting_time: int) -> Dict[str, Any]`\\\\nHandles voting interface for human.\\\\n\\\\n**Parameters:**\\\\n- `candidates`: List of candidates to vote for\\\\n- `voting_time`: Time allowed for voting\\\\n\\\\n**Returns:** Dictionary with vote result and metadata\\\\n\\\\n##### `async set_active(active: bool) -> None`\\\\nSets whether human is actively participating.\\\\n\\\\n**Parameters:**\\\\n- `active`: Whether human should be active in debate\\\\n\\\\n---\\\\n\\\\n### StreamingServer\\\\n\\\\nWebSocket server for live debate streaming.\\\\n\\\\n#### Constructor\\\\n```python\\\\nStreamingServer(\\\\n    chat_log: ChatLog,\\\\n    voting_system: VotingSystem,\\\\n    config: Dict[str, Any]\\\\n)\\\\n```\\\\n\\\\n#### Methods\\\\n\\\\n##### `async start() -> None`\\\\nStarts the streaming server.\\\\n\\\\n##### `async stop() -> None`\\\\nStops the streaming server and closes connections.\\\\n\\\\n##### `async broadcast_custom_message(message_type: str, data: Any) -> None`\\\\nBroadcasts custom message to all connected clients.\\\\n\\\\n**Parameters:**\\\\n- `message_type`: Type identifier for the message\\\\n- `data`: Message payload\\\\n\\\\n##### `get_connected_clients() -> List[Dict[str, Any]]`\\\\nReturns information about all connected streaming clients.\\\\n\\\\n**Returns:** List of client information dictionaries\\\\n\\\\n---\\\\n\\\\n## Data Classes\\\\n\\\\n### Message\\\\n\\\\nRepresents a single chat message.\\\\n\\\\n```python\\\\n@dataclass\\\\nclass Message:\\\\n    sender: str\\\\n    content: str\\\\n    timestamp: float\\\\n    message_id: int\\\\n    message_type: str = \\\\\\\"chat\\\\\\\"\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\n```\\\\n\\\\n**Properties:**\\\\n- `formatted_timestamp`: Human-readable timestamp string\\\\n\\\\n**Methods:**\\\\n- `to_dict() -> Dict[str, Any]`: Convert to dictionary\\\\n- `from_dict(data: Dict[str, Any]) -> Message`: Create from dictionary\\\\n\\\\n### Vote\\\\n\\\\nRepresents a single vote in the voting system.\\\\n\\\\n```python\\\\n@dataclass\\\\nclass Vote:\\\\n    voter_id: str\\\\n    candidate: str\\\\n    justification: Optional[str] = None\\\\n    timestamp: float = field(default_factory=time.time)\\\\n    anonymous: bool = False\\\\n```\\\\n\\\\n### VotingResults\\\\n\\\\nContains results from a voting session.\\\\n\\\\n```python\\\\n@dataclass\\\\nclass VotingResults:\\\\n    winner: Optional[str]\\\\n    vote_counts: Dict[str, int]\\\\n    total_votes: int\\\\n    votes_by_voter: Dict[str, Vote]\\\\n    voting_duration: float\\\\n    participation_rate: float\\\\n```\\\\n\\\\n### DebateState\\\\n\\\\nTracks current debate session state.\\\\n\\\\n```python\\\\n@dataclass\\\\nclass DebateState:\\\\n    phase: DebatePhase\\\\n    current_speaker: Optional[str] = None\\\\n    time_remaining: int = 0\\\\n    turn_order: List[str] = None\\\\n    warnings_issued: Dict[str, int] = None\\\\n```\\\\n\\\\n---\\\\n\\\\n## Enums\\\\n\\\\n### DebatePhase\\\\n\\\\nDefines the phases of a debate session.\\\\n\\\\n```python\\\\nclass DebatePhase(Enum):\\\\n    INTRODUCTION = \\\\\\\"introduction\\\\\\\"\\\\n    OPENING_STATEMENTS = \\\\\\\"opening_statements\\\\\\\"\\\\n    DISCUSSION = \\\\\\\"discussion\\\\\\\"\\\\n    CLOSING_STATEMENTS = \\\\\\\"closing_statements\\\\\\\"\\\\n    VOTING = \\\\\\\"voting\\\\\\\"\\\\n    RESULTS = \\\\\\\"results\\\\\\\"\\\\n    FINISHED = \\\\\\\"finished\\\\\\\"\\\\n```\\\\n\\\\n---\\\\n\\\\n## Utility Functions\\\\n\\\\n### Configuration (`app/utils.py`)\\\\n\\\\n##### `load_config(config_path: str = \\\\\\\"config.yaml\\\\\\\") -> Dict[str, Any]`\\\\nLoads configuration from YAML file with environment variable substitution.\\\\n\\\\n**Parameters:**\\\\n- `config_path`: Path to configuration file\\\\n\\\\n**Returns:** Configuration dictionary\\\\n\\\\n**Example:**\\\\n```python\\\\nconfig = load_config(\\\\\\\"custom_config.yaml\\\\\\\")\\\\n```\\\\n\\\\n##### `setup_logging(level: str = \\\\\\\"INFO\\\\\\\", log_file: Optional[str] = None) -> None`\\\\nSets up logging configuration.\\\\n\\\\n**Parameters:**\\\\n- `level`: Logging level (\\\\\\\"DEBUG\\\\\\\", \\\\\\\"INFO\\\\\\\", \\\\\\\"WARNING\\\\\\\", \\\\\\\"ERROR\\\\\\\")\\\\n- `log_file`: Optional log file path\\\\n\\\\n##### `format_time_remaining(seconds: float) -> str`\\\\nFormats time remaining in human-readable format.\\\\n\\\\n**Parameters:**\\\\n- `seconds`: Time in seconds\\\\n\\\\n**Returns:** Formatted time string (\\\\\\\"5m 30s\\\\\\\", \\\\\\\"2h 15m\\\\\\\", etc.)\\\\n\\\\n##### `truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\"...\\\\\\\") -> str`\\\\nTruncates text to maximum length.\\\\n\\\\n**Parameters:**\\\\n- `text`: Text to truncate\\\\n- `max_length`: Maximum length\\\\n- `suffix`: Suffix to add when truncating\\\\n\\\\n**Returns:** Truncated text\\\\n\\\\n---\\\\n\\\\n## Error Handling\\\\n\\\\n### Custom Exceptions\\\\n\\\\nThe system uses standard Python exceptions with descriptive messages:\\\\n\\\\n- `ValueError`: Invalid configuration or parameters\\\\n- `FileNotFoundError`: Missing configuration files\\\\n- `ConnectionError`: API or network failures\\\\n- `TimeoutError`: Response timeouts\\\\n\\\\n### Error Recovery\\\\n\\\\nAll async methods include proper error handling and will not crash the session:\\\\n\\\\n```python\\\\ntry:\\\\n    response = await bot.get_response(topic, messages)\\\\nexcept Exception as e:\\\\n    # Fallback response is automatically generated\\\\n    response = bot._generate_fallback_response(topic)\\\\n```\\\\n\\\\n---\\\\n\\\\n## Configuration Schema\\\\n\\\\n### Main Configuration\\\\n\\\\n```yaml\\\\n# Debate settings\\\\ndebate:\\\\n  default_topic: str\\\\n  max_participants: int\\\\n  time_limit_minutes: int\\\\n  opening_statement_time: int  # seconds\\\\n  response_time: int\\\\n  closing_statement_time: int\\\\n\\\\n# Bot configurations\\\\nbots:\\\\n  - name: str\\\\n    model: str\\\\n    provider: str  # \\\\\\\"openai\\\\\\\" or \\\\\\\"anthropic\\\\\\\"\\\\n    personality: str\\\\n    stance: str  # \\\\\\\"pro\\\\\\\", \\\\\\\"con\\\\\\\", or \\\\\\\"neutral\\\\\\\"\\\\n    temperature: float  # 0.0-1.0\\\\n    max_tokens: int\\\\n\\\\n# API credentials\\\\napi_keys:\\\\n  openai: str\\\\n  anthropic: str\\\\n\\\\n# Voting settings\\\\nvoting:\\\\n  enabled: bool\\\\n  voting_duration: int  # seconds\\\\n  allow_participant_voting: bool\\\\n  require_justification: bool\\\\n  anonymous_votes: bool\\\\n\\\\n# Chat settings\\\\nchat:\\\\n  max_message_length: int\\\\n  enable_timestamps: bool\\\\n  log_level: str\\\\n  save_transcripts: bool\\\\n\\\\n# Streaming settings\\\\nstreaming:\\\\n  enabled: bool\\\\n  websocket_port: int\\\\n  max_connections: int\\\\n  broadcast_votes: bool\\\\n\\\\n# Interface settings\\\\ninterface:\\\\n  mode: str  # \\\\\\\"cli\\\\\\\" or \\\\\\\"web\\\\\\\"\\\\n  enable_rich_formatting: bool\\\\n  show_typing_indicators: bool\\\\n  input_timeout: int\\\\n```\\\\n\\\\n---\\\\n\\\\n## WebSocket API\\\\n\\\\n### Client Connection\\\\n\\\\nConnect to the streaming server:\\\\n\\\\n```javascript\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\n```\\\\n\\\\n### Message Types\\\\n\\\\n#### Incoming Messages\\\\n\\\\n##### Welcome Message\\\\n```json\\\\n{\\\\n  \\\\\\\"type\\\\\\\": \\\\\\\"welcome\\\\\\\",\\\\n  \\\\\\\"client_id\\\\\\\": \\\\\\\"client_123456789\\\\\\\",\\\\n  \\\\\\\"server_info\\\\\\\": {\\\\n    \\\\\\\"version\\\\\\\": \\\\\\\"1.0.0\\\\\\\",\\\\n    \\\\\\\"features\\\\\\\": [\\\\\\\"chat\\\\\\\", \\\\\\\"voting\\\\\\\", \\\\\\\"real_time\\\\\\\"]\\\\n  }\\\\n}\\\\n```\\\\n\\\\n##### Chat Message\\\\n```json\\\\n{\\\\n  \\\\\\\"type\\\\\\\": \\\\\\\"message\\\\\\\",\\\\n  \\\\\\\"data\\\\\\\": {\\\\n    \\\\\\\"sender\\\\\\\": \\\\\\\"Alice\\\\\\\",\\\\n    \\\\\\\"content\\\\\\\": \\\\\\\"I believe AI will benefit society\\\\\\\",\\\\n    \\\\\\\"timestamp\\\\\\\": 1640995200.0,\\\\n    \\\\\\\"message_id\\\\\\\": 42,\\\\n    \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\"\\\\n  }\\\\n}\\\\n```\\\\n\\\\n##### Vote Update\\\\n```json\\\\n{\\\\n  \\\\\\\"type\\\\\\\": \\\\\\\"vote_update\\\\\\\",\\\\n  \\\\\\\"data\\\\\\\": {\\\\n    \\\\\\\"candidates\\\\\\\": [\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\"],\\\\n    \\\\\\\"vote_counts\\\\\\\": {\\\\\\\"Alice\\\\\\\": 5, \\\\\\\"Bob\\\\\\\": 3},\\\\n    \\\\\\\"total_votes\\\\\\\": 8,\\\\n    \\\\\\\"time_remaining\\\\\\\": 120,\\\\n    \\\\\\\"is_active\\\\\\\": true\\\\n  }\\\\n}\\\\n```\\\\n\\\\n#### Outgoing Messages\\\\n\\\\n##### Subscribe to Channels\\\\n```json\\\\n{\\\\n  \\\\\\\"type\\\\\\\": \\\\\\\"subscribe\\\\\\\",\\\\n  \\\\\\\"channels\\\\\\\": [\\\\\\\"chat\\\\\\\", \\\\\\\"voting\\\\\\\", \\\\\\\"system\\\\\\\"]\\\\n}\\\\n```\\\\n\\\\n##### Cast Vote\\\\n```json\\\\n{\\\\n  \\\\\\\"type\\\\\\\": \\\\\\\"vote\\\\\\\",\\\\n  \\\\\\\"voter_id\\\\\\\": \\\\\\\"viewer_123\\\\\\\",\\\\n  \\\\\\\"candidate\\\\\\\": \\\\\\\"Alice\\\\\\\",\\\\n  \\\\\\\"justification\\\\\\\": \\\\\\\"Most persuasive arguments\\\\\\\"\\\\n}\\\\n```\\\\n\\\\n##### Ping/Pong\\\\n```json\\\\n{\\\\n  \\\\\\\"type\\\\\\\": \\\\\\\"ping\\\\\\\"\\\\n}\\\\n```\\\\n\\\\n---\\\\n\\\\n## Performance Considerations\\\\n\\\\n### API Rate Limits\\\\n\\\\n- OpenAI: Respect rate limits based on your plan\\\\n- Anthropic: Monitor request quotas\\\\n- Implement exponential backoff for retries\\\\n\\\\n### Memory Management\\\\n\\\\n- Chat log automatically limits message history\\\\n- Conversation history is pruned in bot clients\\\\n- Streaming connections are cleaned up automatically\\\\n\\\\n### Async Best Practices\\\\n\\\\nAll I/O operations are async:\\\\n\\\\n```python\\\\n# Correct - awaits async operations\\\\nresponse = await bot.get_response(topic, messages)\\\\nawait chat_log.add_message(sender, content)\\\\n\\\\n# Incorrect - would block the event loop\\\\n# response = bot.get_response(topic, messages).result()\\\\n```\\\\n\\\\n---\\\\n\\\\n## Testing\\\\n\\\\n### Unit Tests\\\\n\\\\nRun the test suite:\\\\n\\\\n```bash\\\\npython -m pytest tests/ -v\\\\n```\\\\n\\\\n### Integration Tests\\\\n\\\\nTest with real APIs:\\\\n\\\\n```bash\\\\n# Set test API keys\\\\nexport OPENAI_API_KEY=\\\\\\\"test-key\\\\\\\"\\\\nexport ANTHROPIC_API_KEY=\\\\\\\"test-key\\\\\\\"\\\\n\\\\n# Run integration tests\\\\npython -m pytest tests/integration/ -v\\\\n```\\\\n\\\\n### Mock Testing\\\\n\\\\n```python\\\\nfrom unittest.mock import AsyncMock\\\\n\\\\n# Mock bot responses\\\\nbot.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\"Test response\\\\\\\")\\\\nresponse = await bot.get_response(\\\\\\\"Test topic\\\\\\\", [])\\\\nassert response == \\\\\\\"Test response\\\\\\\"\\\\n```\\\\n\\\\n---\\\\n\\\\n## Deployment\\\\n\\\\n### Docker\\\\n\\\\n```dockerfile\\\\nFROM python:3.9-slim\\\\n\\\\nWORKDIR /app\\\\nCOPY requirements.txt .\\\\nRUN pip install -r requirements.txt\\\\n\\\\nCOPY . .\\\\nCMD [\\\\\\\"python\\\\\\\", \\\\\\\"-m\\\\\\\", \\\\\\\"app.main\\\\\\\"]\\\\n```\\\\n\\\\n### Environment Variables\\\\n\\\\nRequired for production:\\\\n\\\\n```bash\\\\nOPENAI_API_KEY=sk-...\\\\nANTHROPIC_API_KEY=sk-ant-...\\\\nLOG_LEVEL=INFO\\\\nCONFIG_PATH=/app/production_config.yaml\\\\n```\\\\n\\\\n### Health Checks\\\\n\\\\n```python\\\\n# Check system health\\\\nasync def health_check():\\\\n    # Test bot connectivity\\\\n    for bot in bots:\\\\n        if not await bot.warmup():\\\\n            return False\\\\n    \\\\n    # Test streaming server\\\\n    if streaming_server and not streaming_server.is_active:\\\\n        return False\\\\n    \\\\n    return True\\\\n```\\\\n\\\\nThis API reference provides comprehensive documentation for integrating with and extending the AI Jubilee Debate System.\\\"\\n        },\\n        \\\"architecture.md\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"docs/architecture.md\\\",\\n          \\\"extension\\\": \\\".md\\\",\\n          \\\"size\\\": 7424,\\n          \\\"content\\\": \\\"# AI Jubilee Debate System Architecture\\\\n\\\\n## Overview\\\\n\\\\nThe AI Jubilee Debate System is a modular, event-driven platform that facilitates structured debates between AI bots and human participants. The system emphasizes real-time interaction, fair moderation, and comprehensive result tracking.\\\\n\\\\n## Core Components\\\\n\\\\n### 1. Moderator (`app/moderator.py`)\\\\n\\\\nThe central orchestrator of the debate system.\\\\n\\\\n**Responsibilities:**\\\\n- Manage debate phases (introduction, opening statements, discussion, closing statements, voting, results)\\\\n- Enforce time limits and speaking order\\\\n- Handle participant timeouts and warnings\\\\n- Coordinate with voting system\\\\n- Broadcast messages to all participants\\\\n\\\\n**Key Classes:**\\\\n- `Moderator`: Main orchestration class\\\\n- `DebatePhase`: Enum defining debate stages\\\\n- `DebateState`: Current state tracking\\\\n\\\\n**Flow Diagram:**\\\\n```\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\n‚îÇIntroduction ‚îÇ -> ‚îÇOpening Stmts ‚îÇ -> ‚îÇ Discussion  ‚îÇ\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\n                                              ‚îÇ\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\n‚îÇ   Results   ‚îÇ <- ‚îÇ    Voting    ‚îÇ <- ‚îÇClosing Stmts‚îÇ\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\n```\\\\n\\\\n### 2. Chat Log (`app/chat_log.py`)\\\\n\\\\nThread-safe message management system.\\\\n\\\\n**Features:**\\\\n- Chronological message ordering\\\\n- Pub/sub message distribution\\\\n- Message filtering and search\\\\n- Transcript export (JSON, TXT, HTML)\\\\n- Statistics tracking\\\\n\\\\n**Data Model:**\\\\n```python\\\\n@dataclass\\\\nclass Message:\\\\n    sender: str\\\\n    content: str\\\\n    timestamp: float\\\\n    message_id: int\\\\n    message_type: str = \\\\\\\"chat\\\\\\\"\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\n```\\\\n\\\\n### 3. Voting System (`app/voting.py`)\\\\n\\\\nDemocratic evaluation mechanism for debate performance.\\\\n\\\\n**Features:**\\\\n- Time-limited voting sessions\\\\n- Multiple export formats\\\\n- Vote validation and security\\\\n- Historical tracking\\\\n- Participation analytics\\\\n\\\\n**Voting Flow:**\\\\n```\\\\nStart Session -> Accept Votes -> End Session -> Calculate Results\\\\n     ‚îÇ              ‚îÇ               ‚îÇ              ‚îÇ\\\\n     v              v               v              v\\\\nSet Candidates  Validate Vote   Close Voting   Determine Winner\\\\nSet Duration    Store Vote      Stop Accepting  Export Results\\\\n```\\\\n\\\\n### 4. Participant Clients\\\\n\\\\n#### Bot Client (`app/bot_client.py`)\\\\n\\\\nAI-powered debate participants.\\\\n\\\\n**Supported Providers:**\\\\n- OpenAI (GPT-3.5, GPT-4)\\\\n- Anthropic (Claude)\\\\n- Extensible for additional providers\\\\n\\\\n**Key Features:**\\\\n- Personality-driven responses\\\\n- Stance-aware argumentation\\\\n- Response time tracking\\\\n- Conversation context management\\\\n- Fallback response handling\\\\n\\\\n#### Human Client (`app/human_client.py`)\\\\n\\\\nHuman participant interface.\\\\n\\\\n**Interface Modes:**\\\\n- CLI: Terminal-based interaction\\\\n- Web: WebSocket-based browser interface\\\\n- API: Programmatic integration\\\\n\\\\n**Features:**\\\\n- Response validation\\\\n- Timeout handling\\\\n- Conversation history\\\\n- Voting participation\\\\n\\\\n### 5. Streaming Server (`app/streaming.py`)\\\\n\\\\nReal-time broadcast system for live audience.\\\\n\\\\n**Capabilities:**\\\\n- WebSocket connections\\\\n- Message broadcasting\\\\n- Vote updates\\\\n- Client management\\\\n- Statistics reporting\\\\n\\\\n## System Architecture\\\\n\\\\n```\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\n‚îÇ                    Moderator                            ‚îÇ\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ\\\\n‚îÇ  ‚îÇ   Phases    ‚îÇ ‚îÇ   Timing    ‚îÇ ‚îÇ   Rules     ‚îÇ       ‚îÇ\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\n                      ‚îÇ\\\\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\n    v                 v                 v\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\n‚îÇChat Log  ‚îÇ    ‚îÇ  Voting   ‚îÇ    ‚îÇ  Streaming   ‚îÇ\\\\n‚îÇ          ‚îÇ    ‚îÇ  System   ‚îÇ    ‚îÇ   Server     ‚îÇ\\\\n‚îÇ- Messages‚îÇ    ‚îÇ- Sessions ‚îÇ    ‚îÇ- WebSockets  ‚îÇ\\\\n‚îÇ- History ‚îÇ    ‚îÇ- Results  ‚îÇ    ‚îÇ- Broadcast   ‚îÇ\\\\n‚îÇ- Export  ‚îÇ    ‚îÇ- Stats    ‚îÇ    ‚îÇ- Clients     ‚îÇ\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\n    v                 v                 v\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\n‚îÇ                Participants                     ‚îÇ\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\\\\n‚îÇ  ‚îÇ Bot Clients ‚îÇ              ‚îÇHuman Clients‚îÇ   ‚îÇ\\\\n‚îÇ  ‚îÇ- OpenAI     ‚îÇ              ‚îÇ- CLI        ‚îÇ   ‚îÇ\\\\n‚îÇ  ‚îÇ- Anthropic  ‚îÇ              ‚îÇ- Web        ‚îÇ   ‚îÇ\\\\n‚îÇ  ‚îÇ- Custom     ‚îÇ              ‚îÇ- API        ‚îÇ   ‚îÇ\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\n```\\\\n\\\\n## Data Flow\\\\n\\\\n### Message Flow\\\\n1. Participant generates response\\\\n2. Moderator validates and timestamps\\\\n3. Chat Log stores and distributes\\\\n4. Streaming Server broadcasts to audience\\\\n5. Other participants receive for context\\\\n\\\\n### Voting Flow\\\\n1. Moderator initiates voting phase\\\\n2. Voting System opens session\\\\n3. Participants cast votes\\\\n4. System validates and stores votes\\\\n5. Results calculated and broadcast\\\\n\\\\n### Configuration Flow\\\\n1. Load YAML configuration\\\\n2. Initialize components with settings\\\\n3. Create participants based on config\\\\n4. Start session with configured parameters\\\\n\\\\n## Error Handling\\\\n\\\\n### Graceful Degradation\\\\n- API failures trigger fallback responses\\\\n- Network issues don't crash sessions\\\\n- Participant timeouts handled smoothly\\\\n- Voting continues despite individual failures\\\\n\\\\n### Monitoring and Logging\\\\n- Comprehensive error logging\\\\n- Performance metrics tracking\\\\n- Participant statistics\\\\n- System health monitoring\\\\n\\\\n## Scalability Considerations\\\\n\\\\n### Horizontal Scaling\\\\n- Multiple debate sessions simultaneously\\\\n- Load balancing for streaming\\\\n- Database for persistent storage\\\\n- Message queue for high throughput\\\\n\\\\n### Performance Optimization\\\\n- Async/await throughout\\\\n- Connection pooling for APIs\\\\n- Message batching for efficiency\\\\n- Resource cleanup and management\\\\n\\\\n## Security\\\\n\\\\n### Input Validation\\\\n- Message content sanitization\\\\n- Participant authentication\\\\n- Vote integrity verification\\\\n- Rate limiting protection\\\\n\\\\n### Privacy Protection\\\\n- Anonymous voting options\\\\n- Conversation encryption\\\\n- Participant data protection\\\\n- Audit trail maintenance\\\\n\\\\n## Extension Points\\\\n\\\\n### Adding New AI Providers\\\\n1. Implement `AIProvider` interface\\\\n2. Add configuration options\\\\n3. Update provider factory\\\\n4. Test integration\\\\n\\\\n### Custom Interfaces\\\\n1. Implement `HumanInterface` interface\\\\n2. Handle async message flow\\\\n3. Add configuration support\\\\n4. Test user experience\\\\n\\\\n### Additional Export Formats\\\\n1. Extend export methods\\\\n2. Add format validation\\\\n3. Update documentation\\\\n4. Test output quality\\\\n\\\\n## Deployment Architecture\\\\n\\\\n### Development\\\\n```\\\\nLocal Machine\\\\n‚îú‚îÄ‚îÄ Python Environment\\\\n‚îú‚îÄ‚îÄ Configuration Files\\\\n‚îú‚îÄ‚îÄ Test Data\\\\n‚îî‚îÄ‚îÄ Log Files\\\\n```\\\\n\\\\n### Production\\\\n```\\\\nContainer Orchestration\\\\n‚îú‚îÄ‚îÄ Moderator Service\\\\n‚îú‚îÄ‚îÄ Bot Client Services\\\\n‚îú‚îÄ‚îÄ Streaming Service\\\\n‚îú‚îÄ‚îÄ Web Interface\\\\n‚îú‚îÄ‚îÄ Database\\\\n‚îî‚îÄ‚îÄ Message Queue\\\\n```\\\\n\\\\n## Configuration Management\\\\n\\\\n### Environment-Specific Settings\\\\n- Development: Local APIs, debug logging\\\\n- Staging: Production APIs, info logging\\\\n- Production: Optimized settings, error logging\\\\n\\\\n### Secret Management\\\\n- API keys in environment variables\\\\n- Database credentials secured\\\\n- SSL certificates managed\\\\n- Rotation policies enforced\\\\n\\\\nThis architecture enables a robust, scalable, and extensible debate platform that can accommodate various use cases from small-scale experiments to large public events.\\\"\\n        },\\n        \\\"usage.md\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"docs/usage.md\\\",\\n          \\\"extension\\\": \\\".md\\\",\\n          \\\"size\\\": 21363,\\n          \\\"content\\\": \\\"# AI Jubilee Debate System - Usage Guide\\\\n\\\\n## üöÄ Quick Start\\\\n\\\\n### Prerequisites\\\\n1. **Python 3.8+** installed\\\\n2. **API Keys** for OpenAI and/or Anthropic\\\\n3. **Dependencies** installed\\\\n\\\\n### Setup Steps\\\\n\\\\n1. **Clone or download the project**\\\\n2. **Install dependencies:**\\\\n   ```bash\\\\n   pip install -r requirements.txt\\\\n   ```\\\\n\\\\n3. **Set up your API keys in `.env` file:**\\\\n   ```bash\\\\n   # Create .env file in project root\\\\n   OPENAI_API_KEY=sk-your-openai-key-here\\\\n   ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\\\\n   ```\\\\n\\\\n4. **Run the debate:**\\\\n   ```bash\\\\n   # Recommended: Use the simple launcher\\\\n   python run_debate.py\\\\n   \\\\n   # Alternative: Use the module directly\\\\n   python -m app.main\\\\n   ```\\\\n\\\\n## üé≠ Debate Modes\\\\n\\\\n### **Autonomous Mode** (Default - Recommended!)\\\\n\\\\nIn autonomous mode, bots monitor the conversation and decide when to speak, creating a natural, organic debate flow.\\\\n\\\\n#### How Autonomous Mode Works:\\\\n- ü§ñ **Bots run in parallel**, continuously monitoring chat\\\\n- üß† **Intelligent decision making** - bots decide when they feel compelled to respond\\\\n- üìö **Full conversation history** available to all participants\\\\n- üéØ **Smart triggers** - bots respond to mentions, challenges, or opportunities\\\\n- ‚è∞ **Cooldown system** prevents spam (15-45 second intervals)\\\\n- üó£Ô∏è **Humans can speak anytime** during discussion phase\\\\n\\\\n#### Configuration:\\\\n```yaml\\\\ndebate:\\\\n  mode: \\\\\\\"autonomous\\\\\\\"  # Enable autonomous mode\\\\n  min_bot_cooldown: 15         # Minimum seconds between bot responses\\\\n  max_bot_cooldown: 45         # Maximum cooldown for active bots  \\\\n  message_check_interval: 5    # How often bots check for new messages\\\\n  silence_timeout: 60          # Moderator intervenes after silence\\\\n```\\\\n\\\\n#### Example Autonomous Flow:\\\\n```\\\\nüé≠ Moderator: \\\\\\\"Autonomous Discussion Phase Begin!\\\\\\\"\\\\nü§ñ Advocate: \\\\\\\"Remote work increases productivity by 40%...\\\\\\\"\\\\nüí≠ Skeptic is thinking about responding...\\\\nü§ñ Skeptic: \\\\\\\"But what about the collaboration costs?\\\\\\\"\\\\nüë§ Human: \\\\\\\"I've experienced both - here's my take...\\\\\\\"\\\\nüí≠ Socrates is thinking about responding...  \\\\nü§ñ Socrates: \\\\\\\"What evidence supports these productivity claims?\\\\\\\"\\\\nüéØ Moderator: \\\\\\\"What about environmental implications?\\\\\\\"\\\\nüí≠ Advocate is thinking about responding...\\\\nü§ñ Advocate: \\\\\\\"Great point - remote work cuts commuting emissions...\\\\\\\"\\\\n```\\\\n\\\\n### **Sequential Mode** (Traditional)\\\\n\\\\nParticipants take turns in a structured order. More predictable but less dynamic.\\\\n\\\\n```yaml\\\\ndebate:\\\\n  mode: \\\\\\\"sequential\\\\\\\"  # Traditional turn-based mode\\\\n```\\\\n\\\\n## üéØ Human Participation in Autonomous Mode\\\\n\\\\n### **During Discussion Phase:**\\\\n- ‚úÖ **Speak anytime** - no waiting for turns!\\\\n- ‚úÖ **Type naturally** - just enter your response\\\\n- ‚úÖ **Full context** - see all previous messages\\\\n- ‚úÖ **Real-time** - immediate feedback from bots\\\\n\\\\n### **Available Commands:**\\\\n```\\\\nüí¨ [your message]     # Join the debate with your response\\\\nhelp                  # Show help information\\\\nstatus                # Show your participation statistics\\\\nhistory               # Show recent conversation\\\\nquit                  # Leave the debate\\\\n```\\\\n\\\\n### **Example Human Session:**\\\\n```\\\\nüéØ AUTONOMOUS DEBATE MODE ACTIVE\\\\nüó£Ô∏è You can speak at ANY TIME during the discussion!\\\\nüí° Commands: 'help', 'status', 'history', 'quit'\\\\n\\\\nü§ñ Advocate: \\\\\\\"Remote work is clearly the future because...\\\\\\\"\\\\nü§ñ Skeptic: \\\\\\\"I disagree - here's why remote work fails...\\\\\\\"\\\\n\\\\nüí¨ Type your response: I think both perspectives miss the point about hybrid work...\\\\n‚úÖ Your message has been added to the debate!\\\\n\\\\nüí≠ Socrates is thinking about responding...\\\\nü§ñ Socrates: \\\\\\\"Interesting point about hybrid - can you elaborate?\\\\\\\"\\\\n\\\\nüí¨ Type your response: status\\\\nüìä Your participation: 1 responses, 100.0% participation rate, avg response time: 12.3s\\\\n\\\\nüí¨ Type your response: Sure! Hybrid work combines the best of both...\\\\n‚úÖ Your message has been added to the debate!\\\\n```\\\\n\\\\n## üìã Debate Phases\\\\n\\\\n### **1. Introduction Phase**\\\\n- Moderator introduces topic and participants\\\\n- Overview of rules and format\\\\n- Duration: ~2 minutes\\\\n\\\\n### **2. Opening Statements Phase** \\\\n- Each participant gives structured opening statement\\\\n- **Sequential order** (even in autonomous mode)\\\\n- Time limit: 120 seconds per participant\\\\n\\\\n### **3. Discussion Phase**\\\\n\\\\n#### **Autonomous Mode:**\\\\n- üîÑ **Free-flowing conversation**\\\\n- ü§ñ **Bots monitor and respond intelligently** \\\\n- üë• **Humans can jump in anytime**\\\\n- üéØ **Moderator provides prompts during silence**\\\\n- ‚è∞ **Total time: 30 minutes** (configurable)\\\\n\\\\n#### **Sequential Mode:**\\\\n- üîÑ **Round-robin turns**\\\\n- ‚è∞ **60 seconds per response**\\\\n- üìù **Structured format**\\\\n\\\\n### **4. Closing Statements Phase**\\\\n- Final arguments from each participant\\\\n- **Sequential order** \\\\n- Time limit: 90 seconds per participant\\\\n\\\\n### **5. Voting Phase**\\\\n- Participants and audience vote for most persuasive\\\\n- Duration: 5 minutes\\\\n- Optional justification required\\\\n\\\\n### **6. Results Phase**\\\\n- Vote tallies and winner announcement\\\\n- Final statistics and transcript saving\\\\n\\\\n## ‚öôÔ∏è Configuration Options\\\\n\\\\n### **Bot Personalities**\\\\n\\\\n```yaml\\\\nbots:\\\\n  - name: \\\\\\\"Socrates\\\\\\\"\\\\n    personality: \\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\"\\\\n    stance: \\\\\\\"neutral\\\\\\\"\\\\n    \\\\n  - name: \\\\\\\"Advocate\\\\\\\"  \\\\n    personality: \\\\\\\"Passionate supporter, data-driven, persuasive. Jumps in when position is challenged.\\\\\\\"\\\\n    stance: \\\\\\\"pro\\\\\\\"\\\\n    \\\\n  - name: \\\\\\\"Skeptic\\\\\\\"\\\\n    personality: \\\\\\\"Critical thinker, questions assumptions. Responds when claims need scrutiny.\\\\\\\"\\\\n    stance: \\\\\\\"con\\\\\\\"\\\\n```\\\\n\\\\n### **Timing Controls**\\\\n\\\\n```yaml\\\\ndebate:\\\\n  time_limit_minutes: 30        # Total discussion time\\\\n  opening_statement_time: 120   # Opening statement duration\\\\n  response_time: 60            # Response time in sequential mode\\\\n  closing_statement_time: 90   # Closing statement duration\\\\n  \\\\n  # Autonomous mode specific\\\\n  min_bot_cooldown: 15         # Minimum bot response interval\\\\n  max_bot_cooldown: 45         # Maximum bot cooldown\\\\n  silence_timeout: 60          # Silence before moderator intervenes\\\\n```\\\\n\\\\n### **Interface Options**\\\\n\\\\n```yaml\\\\ninterface:\\\\n  mode: \\\\\\\"cli\\\\\\\"                  # CLI or web interface\\\\n  enable_rich_formatting: true # Colored/formatted output\\\\n  show_typing_indicators: true # Show when bots are thinking\\\\n  enable_reactions: true       # Enable emoji reactions\\\\n```\\\\n\\\\n## üéõÔ∏è Advanced Usage\\\\n\\\\n### **Command Line Options**\\\\n\\\\n```bash\\\\n# Basic usage\\\\npython run_debate.py\\\\n\\\\n# Using the module with options\\\\npython -m app.main --topic \\\\\\\"AI ethics\\\\\\\" --bots 3 --humans 2\\\\n\\\\n# Custom configuration\\\\npython -m app.main --config custom_config.yaml\\\\n\\\\n# Web interface mode\\\\npython -m app.main --interface web\\\\n```\\\\n\\\\n### **Custom Topics**\\\\n\\\\nAdd to `config.yaml`:\\\\n```yaml\\\\ntopics:\\\\n  - \\\\\\\"Your custom debate topic here\\\\\\\"\\\\n  - \\\\\\\"Another interesting topic\\\\\\\"\\\\n```\\\\n\\\\nOr specify directly:\\\\n```bash\\\\npython -m app.main --topic \\\\\\\"Custom topic\\\\\\\"\\\\n```\\\\n\\\\n### **Bot Configuration**\\\\n\\\\nCreate custom bots in `config.yaml`:\\\\n```yaml\\\\nbots:\\\\n  - name: \\\\\\\"MyBot\\\\\\\"\\\\n    model: \\\\\\\"gpt-4\\\\\\\"\\\\n    provider: \\\\\\\"openai\\\\\\\"\\\\n    personality: \\\\\\\"Your custom personality description\\\\\\\"\\\\n    stance: \\\\\\\"pro\\\\\\\"  # or \\\\\\\"con\\\\\\\" or \\\\\\\"neutral\\\\\\\"\\\\n```\\\\n\\\\n## üîß Troubleshooting\\\\n\\\\n### **Common Issues**\\\\n\\\\n**API Key Errors:**\\\\n```bash\\\\n# Check your .env file format\\\\nOPENAI_API_KEY=sk-your-key  # No quotes, no export\\\\nANTHROPIC_API_KEY=sk-ant-your-key\\\\n```\\\\n\\\\n**Import Errors:**\\\\n```bash\\\\n# Make sure you're in the project root directory\\\\ncd ai_jubilee_debate\\\\npython run_debate.py\\\\n```\\\\n\\\\n**Timeout Issues:**\\\\n```bash\\\\n# Check internet connection and API status\\\\n# Increase timeouts in config.yaml if needed\\\\n```\\\\n\\\\n### **Debug Mode**\\\\n\\\\nEnable detailed logging:\\\\n```yaml\\\\nchat:\\\\n  log_level: \\\\\\\"DEBUG\\\\\\\"\\\\n```\\\\n\\\\nOr set environment variable:\\\\n```bash\\\\nexport LOG_LEVEL=DEBUG\\\\npython run_debate.py\\\\n```\\\\n\\\\n### **Saving Transcripts**\\\\n\\\\nTranscripts are automatically saved after each debate:\\\\n```yaml\\\\nchat:\\\\n  save_transcripts: true\\\\n  transcript_format: \\\\\\\"json\\\\\\\"  # or \\\\\\\"txt\\\\\\\" or \\\\\\\"html\\\\\\\"\\\\n```\\\\n\\\\nFiles saved as: `debate_YYYY-MM-DD_HH-MM-SS.json`\\\\n\\\\n## üé™ Tips for Great Debates\\\\n\\\\n### **For Humans:**\\\\n- üéØ **Jump in naturally** during autonomous mode\\\\n- üìä **Reference specific points** made by others\\\\n- üí° **Provide evidence** and examples\\\\n- ü§ù **Be respectful** but persuasive\\\\n- ‚ö° **Keep responses focused** and substantial\\\\n\\\\n### **Bot Optimization:**\\\\n- üé≠ **Diverse personalities** create better dynamics\\\\n- ‚öñÔ∏è **Balanced stances** (pro/con/neutral mix)\\\\n- üß† **Different models** (GPT-4, Claude, etc.) for variety\\\\n- ‚è∞ **Appropriate cooldowns** prevent spam\\\\n\\\\n### **Moderator Settings:**\\\\n- üéØ **Topic-specific prompts** keep discussion flowing\\\\n- ‚è∞ **Reasonable timeouts** balance pace and depth\\\\n- üí¨ **Silence intervention** maintains engagement\\\\n\\\\n## üìä Monitoring and Analytics\\\\n\\\\n### **Real-time Stats**\\\\n```\\\\n# During debate, type 'status' to see:\\\\nüìä Your participation: 3 responses, 75% participation rate\\\\n‚è±Ô∏è Average response time: 15.2 seconds\\\\nüí¨ Conversation length: 24 messages\\\\n```\\\\n\\\\n### **Post-Debate Analysis**\\\\n- üìà Participation rates per participant\\\\n- ‚è∞ Response time analytics  \\\\n- üó≥Ô∏è Voting results and justifications\\\\n- üìù Full transcript with timestamps\\\\n\\\\n## üöÄ Performance Tips\\\\n\\\\n### **For Better Performance:**\\\\n- Use **GPT-3.5** for faster, cheaper responses\\\\n- Set **reasonable cooldowns** (15-30 seconds)\\\\n- Limit **conversation history** for speed\\\\n- Use **async mode** for responsiveness\\\\n\\\\n### **For Higher Quality:**\\\\n- Use **GPT-4** or **Claude** for better reasoning\\\\n- Increase **response time limits**\\\\n- Enable **detailed logging** for analysis\\\\n- Create **specific bot personalities**\\\\n\\\\n## üåü Advanced Features\\\\n\\\\n### **Real-time Streaming**\\\\nEnable WebSocket streaming for live audiences:\\\\n```yaml\\\\nstreaming:\\\\n  enabled: true\\\\n  websocket_port: 8080\\\\n  max_connections: 100\\\\n```\\\\n\\\\n### **Voting System**\\\\nComprehensive voting with justifications:\\\\n```yaml\\\\nvoting:\\\\n  enabled: true\\\\n  voting_duration: 300\\\\n  require_justification: true\\\\n  anonymous_votes: false\\\\n```\\\\n\\\\n### **Web Interface**\\\\nFor browser-based participation:\\\\n```yaml\\\\ninterface:\\\\n  mode: \\\\\\\"web\\\\\\\"\\\\n  websocket_port: 8080\\\\n```\\\\n\\\\n## üìÅ File Structure\\\\n\\\\n```\\\\nai_jubilee_debate/\\\\n‚îú‚îÄ‚îÄ .env                    # Your API keys (never commit!)\\\\n‚îú‚îÄ‚îÄ .env.example           # Example environment file\\\\n‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns\\\\n‚îú‚îÄ‚îÄ config.yaml            # Main configuration\\\\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\\\\n‚îú‚îÄ‚îÄ run_debate.py          # Simple launcher script\\\\n‚îú‚îÄ‚îÄ app/                   # Core application\\\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package initialization\\\\n‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Main entry point\\\\n‚îÇ   ‚îú‚îÄ‚îÄ moderator.py      # Debate moderation logic\\\\n‚îÇ   ‚îú‚îÄ‚îÄ bot_client.py     # AI bot participants\\\\n‚îÇ   ‚îú‚îÄ‚îÄ human_client.py   # Human participants\\\\n‚îÇ   ‚îú‚îÄ‚îÄ chat_log.py       # Message management\\\\n‚îÇ   ‚îú‚îÄ‚îÄ voting.py         # Voting system\\\\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions\\\\n‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # WebSocket streaming\\\\n‚îú‚îÄ‚îÄ tests/                 # Test suite\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_moderator.py\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_voting.py\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_chat_log.py\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_bot_client.py\\\\n‚îÇ   ‚îî‚îÄ‚îÄ test_human_client.py\\\\n‚îî‚îÄ‚îÄ docs/                  # Documentation\\\\n    ‚îú‚îÄ‚îÄ architecture.md    # System architecture\\\\n    ‚îú‚îÄ‚îÄ usage.md          # This file\\\\n    ‚îî‚îÄ‚îÄ api_reference.md  # API documentation\\\\n```\\\\n\\\\n## üÜò Getting Help\\\\n\\\\n### **Built-in Help**\\\\n```bash\\\\n# During debate\\\\nhelp                    # Show autonomous mode help\\\\nstatus                  # Show participation stats\\\\nhistory                 # Show recent messages\\\\n\\\\n# Command line\\\\npython -m app.main --help   # Show CLI options\\\\n```\\\\n\\\\n### **Common Commands**\\\\n```bash\\\\n# Run with debug logging\\\\nLOG_LEVEL=DEBUG python run_debate.py\\\\n\\\\n# Run tests\\\\npython -m pytest tests/ -v\\\\n\\\\n# Check configuration\\\\npython -c \\\\\\\"from app.utils import load_config; print(load_config())\\\\\\\"\\\\n```\\\\n\\\\nThis autonomous debate system creates truly organic, intelligent conversations between AI participants while allowing humans to jump in naturally whenever they feel inspired to contribute! üé≠ü§ñ# AI Jubilee Debate System Usage Guide\\\\n\\\\n## Quick Start\\\\n\\\\n### Installation\\\\n\\\\n1. **Clone the repository:**\\\\n   ```bash\\\\n   git clone <repository-url>\\\\n   cd ai_jubilee_debate\\\\n   ```\\\\n\\\\n2. **Install dependencies:**\\\\n   ```bash\\\\n   pip install -r requirements.txt\\\\n   ```\\\\n\\\\n3. **Set up environment variables:**\\\\n   ```bash\\\\n   export OPENAI_API_KEY=\\\\\\\"your-openai-api-key\\\\\\\"\\\\n   export ANTHROPIC_API_KEY=\\\\\\\"your-anthropic-api-key\\\\\\\"\\\\n   ```\\\\n\\\\n4. **Run your first debate:**\\\\n   ```bash\\\\n   python -m app.main\\\\n   ```\\\\n\\\\n## Configuration\\\\n\\\\n### Basic Configuration (`config.yaml`)\\\\n\\\\n```yaml\\\\ndebate:\\\\n  default_topic: \\\\\\\"AI will create more jobs than it destroys\\\\\\\"\\\\n  max_participants: 4\\\\n  time_limit_minutes: 20\\\\n\\\\nbots:\\\\n  - name: \\\\\\\"Advocate\\\\\\\"\\\\n    model: \\\\\\\"gpt-4\\\\\\\"\\\\n    provider: \\\\\\\"openai\\\\\\\" \\\\n    stance: \\\\\\\"pro\\\\\\\"\\\\n  - name: \\\\\\\"Skeptic\\\\\\\"\\\\n    model: \\\\\\\"claude-3-sonnet\\\\\\\"\\\\n    provider: \\\\\\\"anthropic\\\\\\\"\\\\n    stance: \\\\\\\"con\\\\\\\"\\\\n\\\\nvoting:\\\\n  enabled: true\\\\n  voting_duration: 180\\\\n```\\\\n\\\\n### Advanced Configuration Options\\\\n\\\\n#### Timing Settings\\\\n```yaml\\\\ndebate:\\\\n  opening_statement_time: 120  # seconds\\\\n  response_time: 60\\\\n  closing_statement_time: 90\\\\n  warning_time: 45  # warning before timeout\\\\n```\\\\n\\\\n#### Bot Personalities\\\\n```yaml\\\\nbots:\\\\n  - name: \\\\\\\"Philosopher\\\\\\\"\\\\n    personality: \\\\\\\"Thoughtful, asks probing questions\\\\\\\"\\\\n    debate_style: \\\\\\\"socratic\\\\\\\"\\\\n    temperature: 0.8\\\\n    max_tokens: 250\\\\n```\\\\n\\\\n#### Human Interface\\\\n```yaml\\\\ninterface:\\\\n  mode: \\\\\\\"cli\\\\\\\"  # or \\\\\\\"web\\\\\\\"\\\\n  enable_rich_formatting: true\\\\n  show_typing_indicators: true\\\\n  input_timeout: 120\\\\n```\\\\n\\\\n## Running Debates\\\\n\\\\n### Command Line Interface\\\\n\\\\n#### Basic Usage\\\\n```bash\\\\n# Run with default settings\\\\npython -m app.main\\\\n\\\\n# Specify topic\\\\npython -m app.main --topic \\\\\\\"Universal Basic Income is necessary\\\\\\\"\\\\n\\\\n# Set participant counts\\\\npython -m app.main --bots 3 --humans 2\\\\n\\\\n# Use custom config\\\\npython -m app.main --config custom_config.yaml\\\\n```\\\\n\\\\n#### Advanced Options\\\\n```bash\\\\n# Full command with all options\\\\npython -m app.main \\\\\\\\\\\\n  --topic \\\\\\\"Climate change requires immediate action\\\\\\\" \\\\\\\\\\\\n  --bots 2 \\\\\\\\\\\\n  --humans 1 \\\\\\\\\\\\n  --config production_config.yaml\\\\n```\\\\n\\\\n### Programmatic Usage\\\\n\\\\n#### Simple Session\\\\n```python\\\\nfrom app.main import start_debate_session\\\\n\\\\n# Start a basic debate\\\\nawait start_debate_session(\\\\n    topic=\\\\\\\"The future of remote work\\\\\\\",\\\\n    ai_bots=2,\\\\n    human_participants=1\\\\n)\\\\n```\\\\n\\\\n#### Custom Session\\\\n```python\\\\nfrom app import Moderator, BotClient, HumanClient, ChatLog, VotingSystem\\\\n\\\\n# Create components\\\\nchat_log = ChatLog()\\\\nvoting_system = VotingSystem({'enabled': True})\\\\n\\\\n# Create participants\\\\nbot = BotClient(\\\\n    name=\\\\\\\"Analyst\\\\\\\",\\\\n    model=\\\\\\\"gpt-4\\\\\\\",\\\\n    provider=\\\\\\\"openai\\\\\\\",\\\\n    personality=\\\\\\\"Data-driven and analytical\\\\\\\",\\\\n    stance=\\\\\\\"neutral\\\\\\\",\\\\n    api_key=\\\\\\\"your-api-key\\\\\\\"\\\\n)\\\\n\\\\nhuman = HumanClient(\\\\n    name=\\\\\\\"Participant1\\\\\\\",\\\\n    interface_config={'mode': 'cli'}\\\\n)\\\\n\\\\n# Create moderator and run\\\\nmoderator = Moderator(\\\\n    topic=\\\\\\\"AI Ethics in Healthcare\\\\\\\",\\\\n    participants=[bot, human],\\\\n    chat_log=chat_log,\\\\n    voting_system=voting_system,\\\\n    config={'time_limit_minutes': 15}\\\\n)\\\\n\\\\nresults = await moderator.run_debate()\\\\n```\\\\n\\\\n## Participant Management\\\\n\\\\n### AI Bot Configuration\\\\n\\\\n#### Creating Custom Bots\\\\n```python\\\\n# Argumentative bot\\\\naggressive_bot = BotClient(\\\\n    name=\\\\\\\"Debater\\\\\\\",\\\\n    model=\\\\\\\"gpt-4\\\\\\\",\\\\n    provider=\\\\\\\"openai\\\\\\\", \\\\n    personality=\\\\\\\"Aggressive, uses strong rhetoric\\\\\\\",\\\\n    stance=\\\\\\\"pro\\\\\\\",\\\\n    temperature=0.9,  # More creative\\\\n    api_key=api_key\\\\n)\\\\n\\\\n# Analytical bot\\\\nanalytical_bot = BotClient(\\\\n    name=\\\\\\\"Researcher\\\\\\\", \\\\n    model=\\\\\\\"claude-3-sonnet\\\\\\\",\\\\n    provider=\\\\\\\"anthropic\\\\\\\",\\\\n    personality=\\\\\\\"Fact-focused, cites evidence\\\\\\\",\\\\n    stance=\\\\\\\"con\\\\\\\",\\\\n    temperature=0.3,  # More conservative\\\\n    api_key=api_key\\\\n)\\\\n```\\\\n\\\\n#### Bot Personality Examples\\\\n```yaml\\\\npersonalities:\\\\n  socratic: \\\\\\\"Asks probing questions, seeks deeper understanding\\\\\\\"\\\\n  advocate: \\\\\\\"Passionate, uses emotional appeals and personal stories\\\\\\\"  \\\\n  scientist: \\\\\\\"Data-driven, cites studies and statistics\\\\\\\"\\\\n  philosopher: \\\\\\\"Abstract thinking, explores ethical implications\\\\\\\"\\\\n  pragmatist: \\\\\\\"Focuses on practical implementation and real-world effects\\\\\\\"\\\\n  skeptic: \\\\\\\"Questions assumptions, plays devil's advocate\\\\\\\"\\\\n```\\\\n\\\\n### Human Interface Options\\\\n\\\\n#### CLI Mode (Default)\\\\n- Terminal-based interaction\\\\n- Rich formatting with colors\\\\n- Real-time message display\\\\n- Keyboard input for responses\\\\n\\\\n#### Web Mode \\\\n```python\\\\nhuman = HumanClient(\\\\n    name=\\\\\\\"WebUser\\\\\\\",\\\\n    interface_config={\\\\n        'mode': 'web',\\\\n        'enable_reactions': True,\\\\n        'show_typing_indicators': True\\\\n    }\\\\n)\\\\n```\\\\n\\\\n## Debate Topics\\\\n\\\\n### Predefined Topics\\\\nThe system includes several built-in topics:\\\\n- \\\\\\\"AI will create more jobs than it destroys\\\\\\\"\\\\n- \\\\\\\"Social media has a net positive impact on democracy\\\\\\\"\\\\n- \\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\"\\\\n- \\\\\\\"Climate change requires immediate radical action\\\\\\\"\\\\n- \\\\\\\"Privacy is more important than security\\\\\\\"\\\\n\\\\n### Custom Topics\\\\n```python\\\\n# Define your own topics\\\\ncustom_topics = [\\\\n    \\\\\\\"Cryptocurrency will replace traditional banking\\\\\\\",\\\\n    \\\\\\\"Space exploration should be publicly funded\\\\\\\",\\\\n    \\\\\\\"Genetic engineering should be available to all\\\\\\\",\\\\n    \\\\\\\"Automation will eliminate the need for human work\\\\\\\"\\\\n]\\\\n\\\\n# Use in configuration\\\\nconfig['topics'] = custom_topics\\\\n```\\\\n\\\\n### Topic Guidelines\\\\n- Keep topics debatable (not factual statements)\\\\n- Ensure both sides can be reasonably argued\\\\n- Make them relevant to your audience\\\\n- Consider current events and trends\\\\n\\\\n## Voting and Results\\\\n\\\\n### Voting Configuration\\\\n```yaml\\\\nvoting:\\\\n  enabled: true\\\\n  voting_duration: 300  # 5 minutes\\\\n  allow_participant_voting: true\\\\n  require_justification: true\\\\n  anonymous_votes: false\\\\n```\\\\n\\\\n### Accessing Results\\\\n```python\\\\n# After debate completion\\\\nresults = await moderator.run_debate()\\\\n\\\\nprint(f\\\\\\\"Winner: {results['winner']}\\\\\\\")\\\\nprint(f\\\\\\\"Vote breakdown: {results['vote_counts']}\\\\\\\")\\\\n\\\\n# Export detailed results\\\\nawait voting_system.export_results('json')\\\\n```\\\\n\\\\n### Results Analysis\\\\n```python\\\\n# Get participant performance\\\\nfor participant in participants:\\\\n    performance = voting_system.get_candidate_performance(participant.name)\\\\n    print(f\\\\\\\"{participant.name}: {performance['win_rate']:.1%} win rate\\\\\\\")\\\\n```\\\\n\\\\n## Live Streaming\\\\n\\\\n### Enable Streaming\\\\n```yaml\\\\nstreaming:\\\\n  enabled: true\\\\n  websocket_port: 8080\\\\n  max_connections: 100\\\\n  broadcast_votes: true\\\\n```\\\\n\\\\n### Streaming Server\\\\n```python\\\\nfrom app.streaming import StreamingServer\\\\n\\\\n# Create streaming server\\\\nstreaming = StreamingServer(\\\\n    chat_log=chat_log,\\\\n    voting_system=voting_system,\\\\n    config=streaming_config\\\\n)\\\\n\\\\nawait streaming.start()\\\\n# Server runs on localhost:8080\\\\n```\\\\n\\\\n### Client Connection\\\\n```javascript\\\\n// Connect to stream\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\n\\\\nws.onmessage = function(event) {\\\\n    const data = JSON.parse(event.data);\\\\n    \\\\n    if (data.type === 'message') {\\\\n        displayMessage(data.data);\\\\n    } else if (data.type === 'vote_update') {\\\\n        updateVoteDisplay(data.data);\\\\n    }\\\\n};\\\\n```\\\\n\\\\n## Data Export and Analysis\\\\n\\\\n### Transcript Export\\\\n```python\\\\n# Save debate transcript\\\\nawait chat_log.save_transcript(\\\\\\\"debate_2024.json\\\\\\\", \\\\\\\"json\\\\\\\")\\\\nawait chat_log.save_transcript(\\\\\\\"debate_2024.txt\\\\\\\", \\\\\\\"txt\\\\\\\") \\\\nawait chat_log.save_transcript(\\\\\\\"debate_2024.html\\\\\\\", \\\\\\\"html\\\\\\\")\\\\n```\\\\n\\\\n### Statistics and Analytics\\\\n```python\\\\n# Chat statistics\\\\nstats = chat_log.get_statistics()\\\\nprint(f\\\\\\\"Total messages: {stats['total_messages']}\\\\\\\")\\\\nprint(f\\\\\\\"Average per minute: {stats['messages_per_minute']:.1f}\\\\\\\")\\\\n\\\\n# Participant statistics  \\\\nfor participant in participants:\\\\n    stats = participant.get_stats()\\\\n    print(f\\\\\\\"{participant.name}: {stats}\\\\\\\")\\\\n```\\\\n\\\\n### Voting Analysis\\\\n```python\\\\n# Export voting data\\\\ncsv_data = await voting_system.export_results('csv')\\\\ntxt_report = await voting_system.export_results('txt')\\\\n\\\\n# Historical analysis\\\\nhistory = voting_system.vote_history\\\\nfor session in history:\\\\n    print(f\\\\\\\"Session: {session['timestamp']}\\\\\\\")\\\\n    print(f\\\\\\\"Winner: {session['results'].winner}\\\\\\\")\\\\n```\\\\n\\\\n## Troubleshooting\\\\n\\\\n### Common Issues\\\\n\\\\n#### API Key Problems\\\\n```bash\\\\n# Check environment variables\\\\necho $OPENAI_API_KEY\\\\necho $ANTHROPIC_API_KEY\\\\n\\\\n# Set them if missing\\\\nexport OPENAI_API_KEY=\\\\\\\"sk-...\\\\\\\"\\\\nexport ANTHROPIC_API_KEY=\\\\\\\"sk-ant-...\\\\\\\"\\\\n```\\\\n\\\\n#### Connection Issues\\\\n```python\\\\n# Test bot connectivity\\\\nbot = BotClient(...)\\\\nsuccess = await bot.warmup()\\\\nif not success:\\\\n    print(\\\\\\\"Bot connection failed\\\\\\\")\\\\n```\\\\n\\\\n#### Performance Issues\\\\n```yaml\\\\n# Reduce timeouts for faster sessions\\\\ndebate:\\\\n  opening_statement_time: 60\\\\n  response_time: 30\\\\n  closing_statement_time: 45\\\\n\\\\n# Limit message history\\\\nchat:\\\\n  max_message_length: 300\\\\n```\\\\n\\\\n### Debug Mode\\\\n```bash\\\\n# Enable debug logging\\\\npython -m app.main --config debug_config.yaml\\\\n```\\\\n\\\\n```yaml\\\\n# debug_config.yaml\\\\nchat:\\\\n  log_level: \\\\\\\"DEBUG\\\\\\\"\\\\n  save_transcripts: true\\\\n```\\\\n\\\\n### Error Recovery\\\\n```python\\\\n# Handle errors gracefully\\\\ntry:\\\\n    results = await moderator.run_debate()\\\\nexcept Exception as e:\\\\n    print(f\\\\\\\"Debate error: {e}\\\\\\\")\\\\n    # Save partial transcript\\\\n    await chat_log.save_transcript(\\\\\\\"error_recovery.json\\\\\\\")\\\\n```\\\\n\\\\n## Best Practices\\\\n\\\\n### Bot Configuration\\\\n- Use different personalities for variety\\\\n- Balance pro/con/neutral stances\\\\n- Test API connections before debates\\\\n- Monitor response times and adjust timeouts\\\\n\\\\n### Topic Selection\\\\n- Choose engaging, relevant topics\\\\n- Ensure balanced argumentation potential\\\\n- Test topics with different participant mixes\\\\n- Update topics regularly for freshness\\\\n\\\\n### Session Management\\\\n- Start with shorter sessions for testing\\\\n- Monitor participant engagement\\\\n- Save transcripts for analysis\\\\n- Review voting patterns for improvements\\\\n\\\\n### Performance Optimization\\\\n- Use appropriate API models for your needs\\\\n- Set reasonable timeouts\\\\n- Limit concurrent API calls\\\\n- Monitor system resources\\\\n\\\\nThis guide covers the core functionality of the AI Jubilee Debate System. For detailed API documentation, see [api_reference.md](api_reference.md).\\\"\\n        }\\n      }\\n    },\\n    \\\"tests\\\": {\\n      \\\"type\\\": \\\"directory\\\",\\n      \\\"contents\\\": {\\n        \\\"test_bot_client.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"tests/test_bot_client.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 15292,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTests for the BotClient class.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport pytest\\\\nimport asyncio\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\nfrom app.bot_client import BotClient, BotConfig, OpenAIProvider, AnthropicProvider\\\\nfrom app.chat_log import Message\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef bot_config():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create test bot configuration.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return {\\\\n        'name': 'TestBot',\\\\n        'model': 'gpt-3.5-turbo',\\\\n        'provider': 'openai',\\\\n        'personality': 'Analytical and thoughtful',\\\\n        'stance': 'pro',\\\\n        'api_key': 'test-api-key'\\\\n    }\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef bot_client(bot_config):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create test bot client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return BotClient(**bot_config)\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef sample_messages():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create sample messages for testing.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return [\\\\n        Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"What do you think about AI?\\\\\\\", 1640995200.0, 1),\\\\n        Message(\\\\\\\"moderator\\\\\\\", \\\\\\\"Please respond\\\\\\\", 1640995210.0, 2, \\\\\\\"moderator\\\\\\\")\\\\n    ]\\\\n\\\\n\\\\nclass TestBotConfig:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for BotConfig dataclass.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_bot_config_creation(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test creating bot configuration.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = BotConfig(\\\\n            name=\\\\\\\"TestBot\\\\\\\",\\\\n            model=\\\\\\\"gpt-4\\\\\\\",\\\\n            provider=\\\\\\\"openai\\\\\\\",\\\\n            personality=\\\\\\\"Analytical\\\\\\\",\\\\n            stance=\\\\\\\"pro\\\\\\\"\\\\n        )\\\\n\\\\n        assert config.name == \\\\\\\"TestBot\\\\\\\"\\\\n        assert config.model == \\\\\\\"gpt-4\\\\\\\"\\\\n        assert config.provider == \\\\\\\"openai\\\\\\\"\\\\n        assert config.personality == \\\\\\\"Analytical\\\\\\\"\\\\n        assert config.stance == \\\\\\\"pro\\\\\\\"\\\\n        assert config.temperature == 0.7  # Default value\\\\n        assert config.max_tokens == 300  # Default value\\\\n\\\\n\\\\nclass TestBotClient:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for BotClient class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_bot_client_initialization(self, bot_config):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test bot client initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot = BotClient(**bot_config)\\\\n\\\\n        assert bot.name == \\\\\\\"TestBot\\\\\\\"\\\\n        assert bot.config.model == \\\\\\\"gpt-3.5-turbo\\\\\\\"\\\\n        assert bot.config.provider == \\\\\\\"openai\\\\\\\"\\\\n        assert isinstance(bot.ai_provider, OpenAIProvider)\\\\n        assert bot.response_count == 0\\\\n        assert bot.conversation_history == []\\\\n\\\\n    def test_bot_client_with_anthropic(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test bot client with Anthropic provider.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot = BotClient(\\\\n            name=\\\\\\\"AnthropicBot\\\\\\\",\\\\n            model=\\\\\\\"claude-3-sonnet\\\\\\\",\\\\n            provider=\\\\\\\"anthropic\\\\\\\",\\\\n            personality=\\\\\\\"Balanced\\\\\\\",\\\\n            stance=\\\\\\\"neutral\\\\\\\",\\\\n            api_key=\\\\\\\"test-key\\\\\\\"\\\\n        )\\\\n\\\\n        assert isinstance(bot.ai_provider, AnthropicProvider)\\\\n\\\\n    def test_bot_client_unsupported_provider(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test bot client with unsupported provider.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Unsupported AI provider\\\\\\\"):\\\\n            BotClient(\\\\n                name=\\\\\\\"TestBot\\\\\\\",\\\\n                model=\\\\\\\"test-model\\\\\\\",\\\\n                provider=\\\\\\\"unsupported\\\\\\\",\\\\n                personality=\\\\\\\"Test\\\\\\\",\\\\n                stance=\\\\\\\"pro\\\\\\\",\\\\n                api_key=\\\\\\\"test-key\\\\\\\"\\\\n            )\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_response_success(self, bot_client, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful response generation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Mock the AI provider\\\\n        mock_response = \\\\\\\"I think AI has great potential for society.\\\\\\\"\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=mock_response)\\\\n\\\\n        response = await bot_client.get_response(\\\\\\\"AI in society\\\\\\\", sample_messages)\\\\n\\\\n        assert response == mock_response\\\\n        assert bot_client.response_count == 1\\\\n        assert len(bot_client.conversation_history) == 1\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_response_with_error(self, bot_client, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test response generation with API error.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Mock the AI provider to raise an exception\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\n            side_effect=Exception(\\\\\\\"API Error\\\\\\\")\\\\n        )\\\\n\\\\n        response = await bot_client.get_response(\\\\\\\"AI in society\\\\\\\", sample_messages)\\\\n\\\\n        # Should return fallback response\\\\n        assert isinstance(response, str)\\\\n        assert len(response) > 0\\\\n        assert bot_client.stats['errors'] == 1\\\\n\\\\n    def test_prepare_messages(self, bot_client, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test message preparation for AI model.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        messages = bot_client._prepare_messages(\\\\\\\"AI topic\\\\\\\", sample_messages)\\\\n\\\\n        assert len(messages) >= 1  # At least system message\\\\n        assert messages[0]['role'] == 'system'\\\\n        assert \\\\\\\"AI topic\\\\\\\" in messages[0]['content']\\\\n        assert \\\\\\\"TestBot\\\\\\\" in messages[0]['content']\\\\n\\\\n    def test_create_system_prompt_pro_stance(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test system prompt creation for pro stance.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        prompt = bot_client._create_system_prompt(\\\\\\\"AI is beneficial\\\\\\\")\\\\n\\\\n        assert \\\\\\\"TestBot\\\\\\\" in prompt\\\\n        assert \\\\\\\"AI is beneficial\\\\\\\" in prompt\\\\n        assert \\\\\\\"Analytical and thoughtful\\\\\\\" in prompt\\\\n        assert \\\\\\\"IN FAVOR\\\\\\\" in prompt\\\\n\\\\n    def test_create_system_prompt_con_stance(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test system prompt creation for con stance.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot = BotClient(\\\\n            name=\\\\\\\"ConBot\\\\\\\",\\\\n            model=\\\\\\\"gpt-3.5-turbo\\\\\\\",\\\\n            provider=\\\\\\\"openai\\\\\\\",\\\\n            personality=\\\\\\\"Critical\\\\\\\",\\\\n            stance=\\\\\\\"con\\\\\\\",\\\\n            api_key=\\\\\\\"test-key\\\\\\\"\\\\n        )\\\\n\\\\n        prompt = bot._create_system_prompt(\\\\\\\"AI topic\\\\\\\")\\\\n        assert \\\\\\\"AGAINST\\\\\\\" in prompt\\\\n\\\\n    def test_create_system_prompt_neutral_stance(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test system prompt creation for neutral stance.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot = BotClient(\\\\n            name=\\\\\\\"NeutralBot\\\\\\\",\\\\n            model=\\\\\\\"gpt-3.5-turbo\\\\\\\",\\\\n            provider=\\\\\\\"openai\\\\\\\",\\\\n            personality=\\\\\\\"Balanced\\\\\\\",\\\\n            stance=\\\\\\\"neutral\\\\\\\",\\\\n            api_key=\\\\\\\"test-key\\\\\\\"\\\\n        )\\\\n\\\\n        prompt = bot._create_system_prompt(\\\\\\\"AI topic\\\\\\\")\\\\n        assert \\\\\\\"balanced perspectives\\\\\\\" in prompt\\\\n\\\\n    def test_generate_fallback_response(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test fallback response generation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        response = bot_client._generate_fallback_response(\\\\\\\"AI topic\\\\\\\")\\\\n\\\\n        assert isinstance(response, str)\\\\n        assert len(response) > 0\\\\n        assert \\\\\\\"AI topic\\\\\\\" in response or \\\\\\\"perspective\\\\\\\" in response.lower()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_receive_message(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test receiving a message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello bot\\\\\\\", 1640995200.0, 1)\\\\n\\\\n        await bot_client.receive_message(message)\\\\n\\\\n        # Should be added to conversation history\\\\n        assert len(bot_client.conversation_history) == 1\\\\n        assert \\\\\\\"Alice: Hello bot\\\\\\\" in bot_client.conversation_history[0]['content']\\\\n\\\\n        # Message queue should have the message\\\\n        queued_message = await bot_client.message_queue.get()\\\\n        assert queued_message == message\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_receive_own_message(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test receiving own message (should not be added to history).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = Message(\\\\\\\"TestBot\\\\\\\", \\\\\\\"My own message\\\\\\\", 1640995200.0, 1)\\\\n\\\\n        await bot_client.receive_message(message)\\\\n\\\\n        # Should not be added to conversation history\\\\n        assert len(bot_client.conversation_history) == 0\\\\n\\\\n    def test_update_stats_success(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test updating statistics on success.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot_client._update_stats(1.5, success=True)\\\\n\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\n        assert bot_client.stats['average_response_time'] == 1.5\\\\n        assert bot_client.stats['total_response_time'] == 1.5\\\\n\\\\n    def test_update_stats_error(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test updating statistics on error.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot_client._update_stats(2.0, success=False)\\\\n\\\\n        assert bot_client.stats['errors'] == 1\\\\n        assert bot_client.stats['responses_generated'] == 0\\\\n\\\\n    def test_get_stats(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting bot statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Add some test data\\\\n        bot_client.stats['responses_generated'] = 5\\\\n        bot_client.stats['total_response_time'] = 10.0\\\\n        bot_client.stats['errors'] = 1\\\\n        bot_client._update_stats(0, success=True)  # Recalculate average\\\\n\\\\n        stats = bot_client.get_stats()\\\\n\\\\n        assert stats['name'] == \\\\\\\"TestBot\\\\\\\"\\\\n        assert stats['model'] == \\\\\\\"gpt-3.5-turbo\\\\\\\"\\\\n        assert stats['provider'] == \\\\\\\"openai\\\\\\\"\\\\n        assert stats['responses_generated'] == 5\\\\n        assert stats['total_errors'] == 1\\\\n        assert 'success_rate' in stats\\\\n        assert 'average_response_time' in stats\\\\n\\\\n    def test_update_personality(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test updating bot personality.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot_client.update_personality(\\\\\\\"New personality\\\\\\\", \\\\\\\"con\\\\\\\")\\\\n\\\\n        assert bot_client.config.personality == \\\\\\\"New personality\\\\\\\"\\\\n        assert bot_client.config.stance == \\\\\\\"con\\\\\\\"\\\\n\\\\n    def test_reset_conversation(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test resetting conversation history.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Add some conversation history\\\\n        bot_client.conversation_history = [\\\\n            {'role': 'user', 'content': 'Test message'}\\\\n        ]\\\\n        bot_client.response_count = 3\\\\n\\\\n        bot_client.reset_conversation()\\\\n\\\\n        assert bot_client.conversation_history == []\\\\n        assert bot_client.response_count == 0\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_warmup_success(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful bot warmup.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\"Ready\\\\\\\")\\\\n\\\\n        result = await bot_client.warmup()\\\\n\\\\n        assert result == True\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_warmup_failure(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test failed bot warmup.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\n            side_effect=Exception(\\\\\\\"Connection failed\\\\\\\")\\\\n        )\\\\n\\\\n        result = await bot_client.warmup()\\\\n\\\\n        assert result == False\\\\n\\\\n    def test_str_representation(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test string representation of bot.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        string_repr = str(bot_client)\\\\n\\\\n        assert \\\\\\\"TestBot\\\\\\\" in string_repr\\\\n        assert \\\\\\\"gpt-3.5-turbo\\\\\\\" in string_repr\\\\n        assert \\\\\\\"pro\\\\\\\" in string_repr\\\\n\\\\n    def test_repr_representation(self, bot_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test detailed string representation of bot.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repr_str = repr(bot_client)\\\\n\\\\n        assert \\\\\\\"BotClient\\\\\\\" in repr_str\\\\n        assert \\\\\\\"name='TestBot'\\\\\\\" in repr_str\\\\n        assert \\\\\\\"model='gpt-3.5-turbo'\\\\\\\" in repr_str\\\\n\\\\n\\\\nclass TestOpenAIProvider:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for OpenAIProvider class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_openai_provider_initialization(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test OpenAI provider initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        provider = OpenAIProvider(\\\\\\\"test-api-key\\\\\\\")\\\\n        assert provider.api_key == \\\\\\\"test-api-key\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_generate_response_success(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful response generation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        provider = OpenAIProvider(\\\\\\\"test-key\\\\\\\")\\\\n        config = BotConfig(\\\\\\\"TestBot\\\\\\\", \\\\\\\"gpt-3.5-turbo\\\\\\\", \\\\\\\"openai\\\\\\\", \\\\\\\"Test\\\\\\\", \\\\\\\"pro\\\\\\\")\\\\n        messages = [{\\\\\\\"role\\\\\\\": \\\\\\\"user\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Hello\\\\\\\"}]\\\\n\\\\n        # Mock OpenAI client\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\n            mock_client = Mock()\\\\n            mock_openai.return_value = mock_client\\\\n\\\\n            # Mock response\\\\n            mock_response = Mock()\\\\n            mock_response.choices = [Mock()]\\\\n            mock_response.choices[0].message.content = \\\\\\\"Hello! How can I help?\\\\\\\"\\\\n            mock_client.chat.completions.create = AsyncMock(return_value=mock_response)\\\\n\\\\n            response = await provider.generate_response(messages, config)\\\\n\\\\n            assert response == \\\\\\\"Hello! How can I help?\\\\\\\"\\\\n            mock_client.chat.completions.create.assert_called_once()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_generate_response_error(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test response generation with error.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        provider = OpenAIProvider(\\\\\\\"test-key\\\\\\\")\\\\n        config = BotConfig(\\\\\\\"TestBot\\\\\\\", \\\\\\\"gpt-3.5-turbo\\\\\\\", \\\\\\\"openai\\\\\\\", \\\\\\\"Test\\\\\\\", \\\\\\\"pro\\\\\\\")\\\\n        messages = [{\\\\\\\"role\\\\\\\": \\\\\\\"user\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Hello\\\\\\\"}]\\\\n\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\n            mock_client = Mock()\\\\n            mock_openai.return_value = mock_client\\\\n            mock_client.chat.completions.create = AsyncMock(\\\\n                side_effect=Exception(\\\\\\\"API Error\\\\\\\")\\\\n            )\\\\n\\\\n            with pytest.raises(Exception, match=\\\\\\\"OpenAI API error\\\\\\\"):\\\\n                await provider.generate_response(messages, config)\\\\n\\\\n\\\\nclass TestAnthropicProvider:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for AnthropicProvider class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_anthropic_provider_initialization(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test Anthropic provider initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        provider = AnthropicProvider(\\\\\\\"test-api-key\\\\\\\")\\\\n        assert provider.api_key == \\\\\\\"test-api-key\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_generate_response_success(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful response generation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        provider = AnthropicProvider(\\\\\\\"test-key\\\\\\\")\\\\n        config = BotConfig(\\\\\\\"TestBot\\\\\\\", \\\\\\\"claude-3-sonnet\\\\\\\", \\\\\\\"anthropic\\\\\\\", \\\\\\\"Test\\\\\\\", \\\\\\\"pro\\\\\\\")\\\\n        messages = [\\\\n            {\\\\\\\"role\\\\\\\": \\\\\\\"system\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"You are a helpful assistant\\\\\\\"},\\\\n            {\\\\\\\"role\\\\\\\": \\\\\\\"user\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Hello\\\\\\\"}\\\\n        ]\\\\n\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\n            mock_client = Mock()\\\\n            mock_anthropic.return_value = mock_client\\\\n\\\\n            # Mock response\\\\n            mock_response = Mock()\\\\n            mock_response.content = [Mock()]\\\\n            mock_response.content[0].text = \\\\\\\"Hello! How can I assist you?\\\\\\\"\\\\n            mock_client.messages.create = AsyncMock(return_value=mock_response)\\\\n\\\\n            response = await provider.generate_response(messages, config)\\\\n\\\\n            assert response == \\\\\\\"Hello! How can I assist you?\\\\\\\"\\\\n            mock_client.messages.create.assert_called_once()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_generate_response_error(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test response generation with error.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        provider = AnthropicProvider(\\\\\\\"test-key\\\\\\\")\\\\n        config = BotConfig(\\\\\\\"TestBot\\\\\\\", \\\\\\\"claude-3-sonnet\\\\\\\", \\\\\\\"anthropic\\\\\\\", \\\\\\\"Test\\\\\\\", \\\\\\\"pro\\\\\\\")\\\\n        messages = [{\\\\\\\"role\\\\\\\": \\\\\\\"user\\\\\\\", \\\\\\\"content\\\\\\\": \\\\\\\"Hello\\\\\\\"}]\\\\n\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\n            mock_client = Mock()\\\\n            mock_anthropic.return_value = mock_client\\\\n            mock_client.messages.create = AsyncMock(\\\\n                side_effect=Exception(\\\\\\\"API Error\\\\\\\")\\\\n            )\\\\n\\\\n            with pytest.raises(Exception, match=\\\\\\\"Anthropic API error\\\\\\\"):\\\\n                await provider.generate_response(messages, config)\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_conversation_history_management(bot_client):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test conversation history management.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Add messages beyond the limit\\\\n    for i in range(25):\\\\n        message = Message(f\\\\\\\"User{i}\\\\\\\", f\\\\\\\"Message {i}\\\\\\\", 1640995200.0 + i, i)\\\\n        await bot_client.receive_message(message)\\\\n\\\\n    # Should be limited to avoid memory issues\\\\n    assert len(bot_client.conversation_history) <= 20\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_bot_response_timing(bot_client, sample_messages):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test that response timing is tracked.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\"Test response\\\\\\\")\\\\n\\\\n    # Simulate some delay\\\\n    async def delayed_response(*args):\\\\n        await asyncio.sleep(0.01)\\\\n        return \\\\\\\"Delayed response\\\\\\\"\\\\n\\\\n    bot_client.ai_provider.generate_response = delayed_response\\\\n\\\\n    await bot_client.get_response(\\\\\\\"Test topic\\\\\\\", sample_messages)\\\\n\\\\n    assert bot_client.stats['average_response_time'] > 0\\\\n    assert bot_client.stats['total_response_time'] > 0\\\"\\n        },\\n        \\\"test_chat_log.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"tests/test_chat_log.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 15406,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTests for the ChatLog class.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport pytest\\\\nimport asyncio\\\\nimport json\\\\nimport time\\\\nfrom pathlib import Path\\\\nfrom unittest.mock import patch, mock_open\\\\nfrom app.chat_log import ChatLog, Message\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef chat_log():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a test chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return ChatLog(max_messages=100)\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef sample_messages():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create sample messages for testing.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return [\\\\n        Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello everyone!\\\\\\\", time.time(), 1),\\\\n        Message(\\\\\\\"Bob\\\\\\\", \\\\\\\"Hi Alice!\\\\\\\", time.time(), 2),\\\\n        Message(\\\\\\\"moderator\\\\\\\", \\\\\\\"Welcome to the debate\\\\\\\", time.time(), 3, \\\\\\\"moderator\\\\\\\")\\\\n    ]\\\\n\\\\n\\\\nclass TestMessage:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for Message dataclass.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_message_creation(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test creating a message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        timestamp = time.time()\\\\n        msg = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello world\\\\\\\", timestamp, 1)\\\\n\\\\n        assert msg.sender == \\\\\\\"Alice\\\\\\\"\\\\n        assert msg.content == \\\\\\\"Hello world\\\\\\\"\\\\n        assert msg.timestamp == timestamp\\\\n        assert msg.message_id == 1\\\\n        assert msg.message_type == \\\\\\\"chat\\\\\\\"\\\\n        assert msg.metadata == {}\\\\n\\\\n    def test_message_with_metadata(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test message with metadata.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        metadata = {\\\\\\\"urgency\\\\\\\": \\\\\\\"high\\\\\\\", \\\\\\\"topic\\\\\\\": \\\\\\\"AI\\\\\\\"}\\\\n        msg = Message(\\\\\\\"Bob\\\\\\\", \\\\\\\"Important point\\\\\\\", time.time(), 2,\\\\n                      message_type=\\\\\\\"system\\\\\\\", metadata=metadata)\\\\n\\\\n        assert msg.message_type == \\\\\\\"system\\\\\\\"\\\\n        assert msg.metadata == metadata\\\\n\\\\n    def test_formatted_timestamp(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test formatted timestamp property.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        timestamp = 1640995200.0  # Known timestamp\\\\n        msg = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Test\\\\\\\", timestamp, 1)\\\\n\\\\n        formatted = msg.formatted_timestamp\\\\n        assert isinstance(formatted, str)\\\\n        assert \\\\\\\":\\\\\\\" in formatted  # Should contain time separator\\\\n\\\\n    def test_to_dict(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test converting message to dictionary.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        msg = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Test\\\\\\\", time.time(), 1)\\\\n        msg_dict = msg.to_dict()\\\\n\\\\n        assert isinstance(msg_dict, dict)\\\\n        assert msg_dict[\\\\\\\"sender\\\\\\\"] == \\\\\\\"Alice\\\\\\\"\\\\n        assert msg_dict[\\\\\\\"content\\\\\\\"] == \\\\\\\"Test\\\\\\\"\\\\n        assert \\\\\\\"timestamp\\\\\\\" in msg_dict\\\\n        assert \\\\\\\"message_id\\\\\\\" in msg_dict\\\\n\\\\n    def test_from_dict(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test creating message from dictionary.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        data = {\\\\n            \\\\\\\"sender\\\\\\\": \\\\\\\"Bob\\\\\\\",\\\\n            \\\\\\\"content\\\\\\\": \\\\\\\"Test message\\\\\\\",\\\\n            \\\\\\\"timestamp\\\\\\\": time.time(),\\\\n            \\\\\\\"message_id\\\\\\\": 5,\\\\n            \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n            \\\\\\\"metadata\\\\\\\": {}\\\\n        }\\\\n\\\\n        msg = Message.from_dict(data)\\\\n\\\\n        assert msg.sender == \\\\\\\"Bob\\\\\\\"\\\\n        assert msg.content == \\\\\\\"Test message\\\\\\\"\\\\n        assert msg.message_id == 5\\\\n\\\\n\\\\nclass TestChatLog:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for ChatLog class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_chat_log_initialization(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test chat log initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        chat_log = ChatLog(max_messages=50)\\\\n\\\\n        assert len(chat_log.messages) == 0\\\\n        assert chat_log.message_counter == 0\\\\n        assert chat_log.subscribers == []\\\\n        assert chat_log.stats[\\\\\\\"total_messages\\\\\\\"] == 0\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_add_message(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test adding a message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello world\\\\\\\")\\\\n\\\\n        assert isinstance(message, Message)\\\\n        assert message.sender == \\\\\\\"Alice\\\\\\\"\\\\n        assert message.content == \\\\\\\"Hello world\\\\\\\"\\\\n        assert message.message_id == 1\\\\n        assert len(chat_log.messages) == 1\\\\n        assert chat_log.stats[\\\\\\\"total_messages\\\\\\\"] == 1\\\\n        assert chat_log.stats[\\\\\\\"messages_by_sender\\\\\\\"][\\\\\\\"Alice\\\\\\\"] == 1\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_add_multiple_messages(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test adding multiple messages.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"First message\\\\\\\")\\\\n        await chat_log.add_message(\\\\\\\"Bob\\\\\\\", \\\\\\\"Second message\\\\\\\")\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Third message\\\\\\\")\\\\n\\\\n        assert len(chat_log.messages) == 3\\\\n        assert chat_log.message_counter == 3\\\\n        assert chat_log.stats[\\\\\\\"messages_by_sender\\\\\\\"][\\\\\\\"Alice\\\\\\\"] == 2\\\\n        assert chat_log.stats[\\\\\\\"messages_by_sender\\\\\\\"][\\\\\\\"Bob\\\\\\\"] == 1\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_message_ordering(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test that messages maintain chronological order.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        msg1 = await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"First\\\\\\\")\\\\n        await asyncio.sleep(0.01)  # Small delay\\\\n        msg2 = await chat_log.add_message(\\\\\\\"Bob\\\\\\\", \\\\\\\"Second\\\\\\\")\\\\n\\\\n        messages = list(chat_log.messages)\\\\n        assert messages[0].message_id == 1\\\\n        assert messages[1].message_id == 2\\\\n        assert messages[0].timestamp < messages[1].timestamp\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_max_messages_limit(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test message limit enforcement.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        chat_log = ChatLog(max_messages=3)\\\\n\\\\n        # Add more messages than the limit\\\\n        for i in range(5):\\\\n            await chat_log.add_message(\\\\\\\"User\\\\\\\", f\\\\\\\"Message {i}\\\\\\\")\\\\n\\\\n        assert len(chat_log.messages) == 3  # Should be limited\\\\n\\\\n        # Check that oldest messages were removed\\\\n        messages = list(chat_log.messages)\\\\n        assert \\\\\\\"Message 2\\\\\\\" in messages[0].content\\\\n        assert \\\\\\\"Message 4\\\\\\\" in messages[2].content\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_subscription_system(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test message subscription system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        queue = chat_log.subscribe()\\\\n\\\\n        # Add a message\\\\n        message = await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Test message\\\\\\\")\\\\n\\\\n        # Check that subscriber received the message\\\\n        received_message = await asyncio.wait_for(queue.get(), timeout=1.0)\\\\n        assert received_message.content == \\\\\\\"Test message\\\\\\\"\\\\n        assert received_message.sender == \\\\\\\"Alice\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_multiple_subscribers(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test multiple subscribers.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        queue1 = chat_log.subscribe()\\\\n        queue2 = chat_log.subscribe()\\\\n\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Broadcast message\\\\\\\")\\\\n\\\\n        # Both subscribers should receive the message\\\\n        msg1 = await asyncio.wait_for(queue1.get(), timeout=1.0)\\\\n        msg2 = await asyncio.wait_for(queue2.get(), timeout=1.0)\\\\n\\\\n        assert msg1.content == msg2.content == \\\\\\\"Broadcast message\\\\\\\"\\\\n\\\\n    def test_unsubscribe(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test unsubscribing from messages.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        queue = chat_log.subscribe()\\\\n        assert queue in chat_log.subscribers\\\\n\\\\n        chat_log.unsubscribe(queue)\\\\n        assert queue not in chat_log.subscribers\\\\n\\\\n    def test_get_messages_no_filter(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting all messages without filters.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Manually add messages to chat log\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        messages = chat_log.get_messages()\\\\n        assert len(messages) == 3\\\\n        assert messages[0].sender == \\\\\\\"Alice\\\\\\\"\\\\n\\\\n    def test_get_messages_with_limit(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting messages with limit.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        messages = chat_log.get_messages(limit=2)\\\\n        assert len(messages) == 2\\\\n        # Should get the last 2 messages\\\\n        assert messages[0].sender == \\\\\\\"Bob\\\\\\\"\\\\n        assert messages[1].sender == \\\\\\\"moderator\\\\\\\"\\\\n\\\\n    def test_get_messages_by_sender(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test filtering messages by sender.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        alice_messages = chat_log.get_messages(sender=\\\\\\\"Alice\\\\\\\")\\\\n        assert len(alice_messages) == 1\\\\n        assert alice_messages[0].sender == \\\\\\\"Alice\\\\\\\"\\\\n\\\\n    def test_get_messages_by_type(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test filtering messages by type.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        moderator_messages = chat_log.get_messages(message_type=\\\\\\\"moderator\\\\\\\")\\\\n        assert len(moderator_messages) == 1\\\\n        assert moderator_messages[0].message_type == \\\\\\\"moderator\\\\\\\"\\\\n\\\\n    def test_get_messages_since_timestamp(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test filtering messages by timestamp.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Add messages with known timestamps\\\\n        old_time = time.time() - 100\\\\n        new_time = time.time()\\\\n\\\\n        chat_log.messages.append(Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Old\\\\\\\", old_time, 1))\\\\n        chat_log.messages.append(Message(\\\\\\\"Bob\\\\\\\", \\\\\\\"New\\\\\\\", new_time, 2))\\\\n\\\\n        cutoff = time.time() - 50\\\\n        recent_messages = chat_log.get_messages(since_timestamp=cutoff)\\\\n\\\\n        assert len(recent_messages) == 1\\\\n        assert recent_messages[0].content == \\\\\\\"New\\\\\\\"\\\\n\\\\n    def test_get_recent_messages(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting recent messages.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        recent = chat_log.get_recent_messages(2)\\\\n        assert len(recent) == 2\\\\n        assert recent[-1].sender == \\\\\\\"moderator\\\\\\\"  # Most recent\\\\n\\\\n    def test_get_conversation_context(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting conversation context for a participant.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Add various messages\\\\n        messages = [\\\\n            Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello\\\\\\\", time.time(), 1),\\\\n            Message(\\\\\\\"Bob\\\\\\\", \\\\\\\"Hi Alice\\\\\\\", time.time(), 2),\\\\n            Message(\\\\\\\"moderator\\\\\\\", \\\\\\\"Welcome everyone\\\\\\\", time.time(), 3, \\\\\\\"moderator\\\\\\\"),\\\\n            Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Thanks!\\\\\\\", time.time(), 4),\\\\n            Message(\\\\\\\"Charlie\\\\\\\", \\\\\\\"Good luck\\\\\\\", time.time(), 5)\\\\n        ]\\\\n\\\\n        for msg in messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        context = chat_log.get_conversation_context(\\\\\\\"Alice\\\\\\\", context_length=3)\\\\n\\\\n        # Should include Alice's messages and moderator messages\\\\n        assert len(context) <= 3\\\\n        assert any(msg.sender == \\\\\\\"Alice\\\\\\\" for msg in context)\\\\n        assert any(msg.message_type == \\\\\\\"moderator\\\\\\\" for msg in context)\\\\n\\\\n    def test_search_messages(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test searching messages by content.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        # Case insensitive search\\\\n        results = chat_log.search_messages(\\\\\\\"hello\\\\\\\")\\\\n        assert len(results) == 1\\\\n        assert \\\\\\\"Hello\\\\\\\" in results[0].content\\\\n\\\\n        # Case sensitive search\\\\n        results = chat_log.search_messages(\\\\\\\"Hello\\\\\\\", case_sensitive=True)\\\\n        assert len(results) == 1\\\\n\\\\n        results = chat_log.search_messages(\\\\\\\"hello\\\\\\\", case_sensitive=True)\\\\n        assert len(results) == 0\\\\n\\\\n    def test_get_statistics(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting chat log statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n            chat_log.stats[\\\\\\\"total_messages\\\\\\\"] += 1\\\\n            sender = msg.sender\\\\n            chat_log.stats[\\\\\\\"messages_by_sender\\\\\\\"][sender] = (\\\\n                    chat_log.stats[\\\\\\\"messages_by_sender\\\\\\\"].get(sender, 0) + 1\\\\n            )\\\\n\\\\n        stats = chat_log.get_statistics()\\\\n\\\\n        assert stats[\\\\\\\"total_messages\\\\\\\"] == 3\\\\n        assert stats[\\\\\\\"unique_senders\\\\\\\"] == 2  # Alice, Bob, moderator\\\\n        assert \\\\\\\"messages_by_sender\\\\\\\" in stats\\\\n        assert \\\\\\\"messages_per_minute\\\\\\\" in stats\\\\n        assert \\\\\\\"session_duration_minutes\\\\\\\" in stats\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_save_transcript_json(self, chat_log, tmp_path):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test saving transcript in JSON format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Test message\\\\\\\")\\\\n\\\\n        output_file = tmp_path / \\\\\\\"transcript.json\\\\\\\"\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\"json\\\\\\\")\\\\n\\\\n        assert output_file.exists()\\\\n\\\\n        with open(output_file, 'r') as f:\\\\n            data = json.load(f)\\\\n\\\\n        assert \\\\\\\"metadata\\\\\\\" in data\\\\n        assert \\\\\\\"messages\\\\\\\" in data\\\\n        assert len(data[\\\\\\\"messages\\\\\\\"]) == 1\\\\n        assert data[\\\\\\\"messages\\\\\\\"][0][\\\\\\\"content\\\\\\\"] == \\\\\\\"Test message\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_save_transcript_txt(self, chat_log, tmp_path):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test saving transcript in TXT format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Test message\\\\\\\")\\\\n\\\\n        output_file = tmp_path / \\\\\\\"transcript.txt\\\\\\\"\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\"txt\\\\\\\")\\\\n\\\\n        assert output_file.exists()\\\\n\\\\n        content = output_file.read_text()\\\\n        assert \\\\\\\"DEBATE TRANSCRIPT\\\\\\\" in content\\\\n        assert \\\\\\\"Alice: Test message\\\\\\\" in content\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_save_transcript_html(self, chat_log, tmp_path):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test saving transcript in HTML format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Test message\\\\\\\")\\\\n        await chat_log.add_message(\\\\\\\"moderator\\\\\\\", \\\\\\\"System message\\\\\\\",\\\\n                                   message_type=\\\\\\\"moderator\\\\\\\")\\\\n\\\\n        output_file = tmp_path / \\\\\\\"transcript.html\\\\\\\"\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\"html\\\\\\\")\\\\n\\\\n        assert output_file.exists()\\\\n\\\\n        content = output_file.read_text()\\\\n        assert \\\\\\\"<!DOCTYPE html>\\\\\\\" in content\\\\n        assert \\\\\\\"Alice\\\\\\\" in content\\\\n        assert \\\\\\\"moderator\\\\\\\" in content\\\\n        assert \\\\\\\"class=\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\" in content\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_save_transcript_invalid_format(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test saving transcript with invalid format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Unsupported format\\\\\\\"):\\\\n            await chat_log.save_transcript(\\\\\\\"test.xml\\\\\\\", \\\\\\\"xml\\\\\\\")\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_load_transcript(self, chat_log, tmp_path):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test loading transcript from file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Save a transcript first\\\\n        await chat_log.add_message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Original message\\\\\\\")\\\\n        output_file = tmp_path / \\\\\\\"transcript.json\\\\\\\"\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\"json\\\\\\\")\\\\n\\\\n        # Clear chat log and reload\\\\n        chat_log.clear()\\\\n        assert len(chat_log.messages) == 0\\\\n\\\\n        await chat_log.load_transcript(str(output_file))\\\\n\\\\n        assert len(chat_log.messages) == 1\\\\n        assert list(chat_log.messages)[0].content == \\\\\\\"Original message\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_load_transcript_file_not_found(self, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test loading transcript from non-existent file.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with pytest.raises(FileNotFoundError):\\\\n            await chat_log.load_transcript(\\\\\\\"nonexistent.json\\\\\\\")\\\\n\\\\n    def test_clear_chat_log(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test clearing the chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        chat_log.message_counter = 5\\\\n        chat_log.stats[\\\\\\\"total_messages\\\\\\\"] = 3\\\\n\\\\n        chat_log.clear()\\\\n\\\\n        assert len(chat_log.messages) == 0\\\\n        assert chat_log.message_counter == 0\\\\n        assert chat_log.stats[\\\\\\\"total_messages\\\\\\\"] == 0\\\\n        assert chat_log.stats[\\\\\\\"messages_by_sender\\\\\\\"] == {}\\\\n\\\\n    def test_chat_log_len(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test chat log length.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        assert len(chat_log) == 0\\\\n\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        assert len(chat_log) == 3\\\\n\\\\n    def test_chat_log_iteration(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test iterating over chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        iterated_messages = list(chat_log)\\\\n        assert len(iterated_messages) == 3\\\\n        assert iterated_messages[0].sender == \\\\\\\"Alice\\\\\\\"\\\\n\\\\n    def test_chat_log_indexing(self, chat_log, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test indexing chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        for msg in sample_messages:\\\\n            chat_log.messages.append(msg)\\\\n\\\\n        first_message = chat_log[0]\\\\n        assert first_message.sender == \\\\\\\"Alice\\\\\\\"\\\\n\\\\n        last_message = chat_log[-1]\\\\n        assert last_message.sender == \\\\\\\"moderator\\\\\\\"\\\\n        \\\"\\n        },\\n        \\\"test_human_client.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"tests/test_human_client.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 20297,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTests for the HumanClient class.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport pytest\\\\nimport asyncio\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\nfrom app.human_client import HumanClient, CLIInterface, WebInterface, InterfaceConfig\\\\nfrom app.chat_log import Message\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef interface_config():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create test interface configuration.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return {\\\\n        'mode': 'cli',\\\\n        'enable_rich_formatting': False,  # Disable for testing\\\\n        'show_typing_indicators': True,\\\\n        'enable_reactions': True,\\\\n        'input_timeout': 60\\\\n    }\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef human_client(interface_config):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create test human client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return HumanClient(\\\\\\\"TestHuman\\\\\\\", interface_config)\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef sample_messages():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create sample messages for testing.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return [\\\\n        Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"What's your opinion?\\\\\\\", 1640995200.0, 1),\\\\n        Message(\\\\\\\"Bob\\\\\\\", \\\\\\\"I think...\\\\\\\", 1640995210.0, 2),\\\\n        Message(\\\\\\\"moderator\\\\\\\", \\\\\\\"Please respond\\\\\\\", 1640995220.0, 3, \\\\\\\"moderator\\\\\\\")\\\\n    ]\\\\n\\\\n\\\\nclass TestInterfaceConfig:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for InterfaceConfig dataclass.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_interface_config_defaults(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test interface config with default values.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig()\\\\n\\\\n        assert config.mode == \\\\\\\"cli\\\\\\\"\\\\n        assert config.enable_rich_formatting == True\\\\n        assert config.show_typing_indicators == True\\\\n        assert config.enable_reactions == True\\\\n        assert config.input_timeout == 120\\\\n\\\\n    def test_interface_config_custom(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test interface config with custom values.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(\\\\n            mode=\\\\\\\"web\\\\\\\",\\\\n            enable_rich_formatting=False,\\\\n            input_timeout=90\\\\n        )\\\\n\\\\n        assert config.mode == \\\\\\\"web\\\\\\\"\\\\n        assert config.enable_rich_formatting == False\\\\n        assert config.input_timeout == 90\\\\n\\\\n\\\\nclass TestCLIInterface:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for CLIInterface class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_cli_interface_initialization(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test CLI interface initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\n        interface = CLIInterface(config)\\\\n\\\\n        assert interface.config == config\\\\n        assert interface.rich_console is None  # Rich disabled\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_display_basic_message(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test displaying message with basic formatting.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\n        interface = CLIInterface(config)\\\\n\\\\n        message = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello world\\\\\\\", 1640995200.0, 1)\\\\n\\\\n        with patch('builtins.print') as mock_print:\\\\n            await interface.display_message(message)\\\\n            mock_print.assert_called_once()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_display_moderator_message(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test displaying moderator message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\n        interface = CLIInterface(config)\\\\n\\\\n        message = Message(\\\\\\\"moderator\\\\\\\", \\\\\\\"Welcome!\\\\\\\", 1640995200.0, 1, \\\\\\\"moderator\\\\\\\")\\\\n\\\\n        with patch('builtins.print') as mock_print:\\\\n            await interface.display_message(message)\\\\n            mock_print.assert_called_once()\\\\n            # Should have moderator prefix\\\\n            args = mock_print.call_args[0]\\\\n            assert \\\\\\\"üé≠\\\\\\\" in args[0]\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_input_success(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful input retrieval.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\n        interface = CLIInterface(config)\\\\n\\\\n        with patch('builtins.input', return_value=\\\\\\\"Test response\\\\\\\"):\\\\n            response = await interface.get_input(\\\\\\\"Enter response:\\\\\\\", timeout=1)\\\\n            assert response == \\\\\\\"Test response\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_input_timeout(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test input timeout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\n        interface = CLIInterface(config)\\\\n\\\\n        # Mock input to simulate hanging\\\\n        async def slow_input():\\\\n            await asyncio.sleep(2)\\\\n            return \\\\\\\"Too late\\\\\\\"\\\\n\\\\n        interface._get_user_input = slow_input\\\\n\\\\n        response = await interface.get_input(\\\\\\\"Enter response:\\\\\\\", timeout=0.1)\\\\n        assert response == \\\\\\\"\\\\\\\"  # Should return empty string on timeout\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_show_notification(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test showing notifications.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\n        interface = CLIInterface(config)\\\\n\\\\n        with patch('builtins.print') as mock_print:\\\\n            await interface.show_notification(\\\\\\\"Test notification\\\\\\\", \\\\\\\"info\\\\\\\")\\\\n            mock_print.assert_called_once()\\\\n            args = mock_print.call_args[0]\\\\n            assert \\\\\\\"‚ÑπÔ∏è\\\\\\\" in args[0]\\\\n            assert \\\\\\\"Test notification\\\\\\\" in args[0]\\\\n\\\\n\\\\nclass TestWebInterface:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for WebInterface class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_web_interface_initialization(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test web interface initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(mode=\\\\\\\"web\\\\\\\")\\\\n        interface = WebInterface(config)\\\\n\\\\n        assert interface.config == config\\\\n        assert interface.websocket is None\\\\n        assert interface.pending_responses == {}\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_display_message_no_websocket(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test displaying message without websocket connection.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(mode=\\\\\\\"web\\\\\\\")\\\\n        interface = WebInterface(config)\\\\n\\\\n        message = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello\\\\\\\", 1640995200.0, 1)\\\\n\\\\n        # Should not raise an error even without websocket\\\\n        await interface.display_message(message)\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_input_no_websocket(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting input without websocket connection.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = InterfaceConfig(mode=\\\\\\\"web\\\\\\\")\\\\n        interface = WebInterface(config)\\\\n\\\\n        response = await interface.get_input(\\\\\\\"Enter response:\\\\\\\")\\\\n        assert response == \\\\\\\"\\\\\\\"  # Should return empty string\\\\n\\\\n\\\\nclass TestHumanClient:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for HumanClient class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_human_client_initialization(self, interface_config):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test human client initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        client = HumanClient(\\\\\\\"TestHuman\\\\\\\", interface_config)\\\\n\\\\n        assert client.name == \\\\\\\"TestHuman\\\\\\\"\\\\n        assert isinstance(client.interface, CLIInterface)\\\\n        assert client.is_active == True\\\\n        assert client.conversation_history == []\\\\n        assert client.stats['responses_given'] == 0\\\\n\\\\n    def test_human_client_web_mode(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test human client with web interface.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = {'mode': 'web'}\\\\n        client = HumanClient(\\\\\\\"WebHuman\\\\\\\", config)\\\\n\\\\n        assert isinstance(client.interface, WebInterface)\\\\n\\\\n    def test_human_client_unsupported_mode(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test human client with unsupported interface mode.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = {'mode': 'unsupported'}\\\\n\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Unsupported interface mode\\\\\\\"):\\\\n            HumanClient(\\\\\\\"TestHuman\\\\\\\", config)\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_response_success(self, human_client, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful response retrieval.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Mock the interface get_input method\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"My response\\\\\\\")\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n        human_client.interface.display_message = AsyncMock()\\\\n\\\\n        response = await human_client.get_response(\\\\\\\"Test topic\\\\\\\", sample_messages)\\\\n\\\\n        assert response == \\\\\\\"My response\\\\\\\"\\\\n        assert human_client.stats['responses_given'] == 1\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_response_timeout(self, human_client, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test response timeout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Mock timeout scenario\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"\\\\\\\")\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n        human_client.interface.display_message = AsyncMock()\\\\n\\\\n        response = await human_client.get_response(\\\\\\\"Test topic\\\\\\\", sample_messages)\\\\n\\\\n        assert response == \\\\\\\"\\\\\\\"\\\\n        assert human_client.stats['timeouts'] == 1\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_get_response_inactive(self, human_client, sample_messages):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test response when client is inactive.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        human_client.is_active = False\\\\n\\\\n        response = await human_client.get_response(\\\\\\\"Test topic\\\\\\\", sample_messages)\\\\n\\\\n        assert response == \\\\\\\"\\\\\\\"\\\\n\\\\n    def test_validate_response(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test response validation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Normal response\\\\n        response = human_client._validate_response(\\\\\\\"This is a good response\\\\\\\")\\\\n        assert response == \\\\\\\"This is a good response\\\\\\\"\\\\n\\\\n        # Very long response\\\\n        long_response = \\\\\\\"x\\\\\\\" * 600\\\\n        response = human_client._validate_response(long_response)\\\\n        assert len(response) <= 503  # 500 + \\\\\\\"...\\\\\\\"\\\\n        assert response.endswith(\\\\\\\"...\\\\\\\")\\\\n\\\\n        # Very short response\\\\n        short_response = human_client._validate_response(\\\\\\\"Yes\\\\\\\")\\\\n        assert \\\\\\\"[Note: Very short response]\\\\\\\" in short_response\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_receive_message(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test receiving a message.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = Message(\\\\\\\"Alice\\\\\\\", \\\\\\\"Hello human\\\\\\\", 1640995200.0, 1)\\\\n        human_client.interface.display_message = AsyncMock()\\\\n\\\\n        await human_client.receive_message(message)\\\\n\\\\n        # Should be added to conversation history\\\\n        assert len(human_client.conversation_history) == 1\\\\n        assert human_client.conversation_history[0] == message\\\\n\\\\n        # Should display the message\\\\n        human_client.interface.display_message.assert_called_once_with(message)\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_receive_own_message(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test receiving own message (should be ignored).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        message = Message(\\\\\\\"TestHuman\\\\\\\", \\\\\\\"My own message\\\\\\\", 1640995200.0, 1)\\\\n        human_client.interface.display_message = AsyncMock()\\\\n\\\\n        await human_client.receive_message(message)\\\\n\\\\n        # Should not be added to history or displayed\\\\n        assert len(human_client.conversation_history) == 0\\\\n        human_client.interface.display_message.assert_not_called()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_conversation_history_limit(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test conversation history length limit.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        human_client.interface.display_message = AsyncMock()\\\\n\\\\n        # Add many messages\\\\n        for i in range(60):\\\\n            message = Message(f\\\\\\\"User{i}\\\\\\\", f\\\\\\\"Message {i}\\\\\\\", 1640995200.0 + i, i)\\\\n            await human_client.receive_message(message)\\\\n\\\\n        # Should be limited to 30 (as per implementation)\\\\n        assert len(human_client.conversation_history) == 30\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_handle_voting_success(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful voting.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        candidates = [\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\", \\\\\\\"Charlie\\\\\\\"]\\\\n\\\\n        # Mock interface methods\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n        human_client.interface.get_input = AsyncMock(side_effect=[\\\\\\\"2\\\\\\\", \\\\\\\"Good arguments\\\\\\\"])\\\\n\\\\n        result = await human_client.handle_voting(candidates, 60)\\\\n\\\\n        assert result['voted'] == True\\\\n        assert result['candidate'] == \\\\\\\"Bob\\\\\\\"  # Index 2-1 = 1 -> \\\\\\\"Bob\\\\\\\"\\\\n        assert result['justification'] == \\\\\\\"Good arguments\\\\\\\"\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_handle_voting_timeout(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting timeout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        candidates = [\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\"]\\\\n\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"\\\\\\\")  # Timeout\\\\n\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\n\\\\n        assert result['voted'] == False\\\\n        assert result['reason'] == 'timeout'\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_handle_voting_invalid_choice(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting with invalid choice.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        candidates = [\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\"]\\\\n\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"5\\\\\\\")  # Out of range\\\\n\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\n\\\\n        assert result['voted'] == False\\\\n        assert result['reason'] == 'invalid_choice'\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_handle_voting_invalid_format(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting with invalid input format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        candidates = [\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\"]\\\\n\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"not_a_number\\\\\\\")\\\\n\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\n\\\\n        assert result['voted'] == False\\\\n        assert result['reason'] == 'invalid_format'\\\\n\\\\n    def test_update_stats_success(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test updating statistics on successful response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        human_client._update_stats(2.5, success=True)\\\\n\\\\n        assert human_client.stats['responses_given'] == 1\\\\n        assert human_client.stats['average_response_time'] == 2.5\\\\n        assert human_client.stats['total_response_time'] == 2.5\\\\n\\\\n    def test_update_stats_timeout(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test updating statistics on timeout.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        human_client._update_stats(5.0, success=False)\\\\n\\\\n        assert human_client.stats['timeouts'] == 1\\\\n        assert human_client.stats['responses_given'] == 0\\\\n\\\\n    def test_get_stats(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting human client statistics.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Add some test data\\\\n        human_client.stats['responses_given'] = 3\\\\n        human_client.stats['timeouts'] = 1\\\\n        human_client.stats['total_response_time'] = 15.0\\\\n        human_client._update_stats(0, success=True)  # Recalculate average\\\\n\\\\n        stats = human_client.get_stats()\\\\n\\\\n        assert stats['name'] == \\\\\\\"TestHuman\\\\\\\"\\\\n        assert stats['interface_mode'] == \\\\\\\"cli\\\\\\\"\\\\n        assert stats['responses_given'] == 3\\\\n        assert stats['timeouts'] == 1\\\\n        assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\n        assert 'average_response_time' in stats\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_set_active(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test setting client active/inactive status.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n\\\\n        # Set inactive\\\\n        await human_client.set_active(False)\\\\n        assert human_client.is_active == False\\\\n\\\\n        # Set active\\\\n        await human_client.set_active(True)\\\\n        assert human_client.is_active == True\\\\n\\\\n        # Should have called show_notification twice\\\\n        assert human_client.interface.show_notification.call_count == 2\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_show_help(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test showing help information.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        human_client.interface.show_notification = AsyncMock()\\\\n\\\\n        await human_client.show_help()\\\\n\\\\n        human_client.interface.show_notification.assert_called_once()\\\\n        args = human_client.interface.show_notification.call_args[0]\\\\n        assert \\\\\\\"AI Jubilee Debate Help\\\\\\\" in args[0]\\\\n        assert \\\\\\\"COMMANDS:\\\\\\\" in args[0]\\\\n\\\\n    def test_str_representation(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test string representation of human client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        string_repr = str(human_client)\\\\n\\\\n        assert \\\\\\\"TestHuman\\\\\\\" in string_repr\\\\n        assert \\\\\\\"cli\\\\\\\" in string_repr\\\\n\\\\n    def test_repr_representation(self, human_client):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test detailed string representation of human client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        repr_str = repr(human_client)\\\\n\\\\n        assert \\\\\\\"HumanClient\\\\\\\" in repr_str\\\\n        assert \\\\\\\"name='TestHuman'\\\\\\\" in repr_str\\\\n        assert \\\\\\\"mode='cli'\\\\\\\" in repr_str\\\\n        assert \\\\\\\"active=True\\\\\\\" in repr_str\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_show_context_integration(human_client, sample_messages):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test showing context to human before response.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    human_client.interface.show_notification = AsyncMock()\\\\n    human_client.interface.display_message = AsyncMock()\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"Test response\\\\\\\")\\\\n\\\\n    await human_client.get_response(\\\\\\\"Test topic\\\\\\\", sample_messages)\\\\n\\\\n    # Should show context notification\\\\n    notification_calls = human_client.interface.show_notification.call_args_list\\\\n    assert any(\\\\\\\"Recent messages\\\\\\\" in str(call) for call in notification_calls)\\\\n\\\\n    # Should display recent messages\\\\n    assert human_client.interface.display_message.call_count >= 1\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_human_response_validation_edge_cases(human_client):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test edge cases in response validation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Empty response\\\\n    result = human_client._validate_response(\\\\\\\"\\\\\\\")\\\\n    assert result == \\\\\\\"\\\\\\\"\\\\n\\\\n    # Whitespace only\\\\n    result = human_client._validate_response(\\\\\\\"   \\\\\\\\n\\\\\\\\t   \\\\\\\")\\\\n    assert result == \\\\\\\"\\\\\\\"\\\\n\\\\n    # Response with just newlines\\\\n    result = human_client._validate_response(\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\")\\\\n    assert result == \\\\\\\"\\\\\\\"\\\\n\\\\n    # Very short meaningful response\\\\n    result = human_client._validate_response(\\\\\\\"No.\\\\\\\")\\\\n    assert \\\\\\\"[Note: Very short response]\\\\\\\" in result\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_human_client_error_resilience(human_client, sample_messages):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test human client resilience to interface errors.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Mock interface to raise errors\\\\n    human_client.interface.display_message = AsyncMock(side_effect=Exception(\\\\\\\"Interface error\\\\\\\"))\\\\n    human_client.interface.show_notification = AsyncMock()\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\"Test response\\\\\\\")\\\\n\\\\n    # Should not crash despite interface errors\\\\n    response = await human_client.get_response(\\\\\\\"Test topic\\\\\\\", sample_messages)\\\\n    assert response == \\\\\\\"Test response\\\\\\\"\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_human_client_concurrent_operations(human_client):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test concurrent operations on human client.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    human_client.interface.display_message = AsyncMock()\\\\n\\\\n    # Simulate concurrent message receiving\\\\n    tasks = []\\\\n    for i in range(10):\\\\n        message = Message(f\\\\\\\"User{i}\\\\\\\", f\\\\\\\"Message {i}\\\\\\\", 1640995200.0 + i, i)\\\\n        tasks.append(human_client.receive_message(message))\\\\n\\\\n    await asyncio.gather(*tasks)\\\\n\\\\n    # All messages should be processed\\\\n    assert len(human_client.conversation_history) == 10\\\\n\\\\n\\\\ndef test_human_client_stats_calculation(human_client):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test statistics calculation accuracy.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Simulate various response scenarios\\\\n    human_client._update_stats(2.0, success=True)\\\\n    human_client._update_stats(3.0, success=True)\\\\n    human_client._update_stats(1.5, success=False)  # Timeout\\\\n    human_client._update_stats(2.5, success=True)\\\\n\\\\n    stats = human_client.get_stats()\\\\n\\\\n    assert stats['responses_given'] == 3\\\\n    assert stats['timeouts'] == 1\\\\n    assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\n    assert abs(stats['average_response_time'] - 2.5) < 0.1  # (2.0+3.0+2.5)/3\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_voting_with_web_interface():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test voting behavior with web interface.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    config = {'mode': 'web'}\\\\n    client = HumanClient(\\\\\\\"WebUser\\\\\\\", config)\\\\n    candidates = [\\\\\\\"Alice\\\\\\\", \\\\\\\"Bob\\\\\\\"]\\\\n\\\\n    # Web interface should handle justification differently\\\\n    client.interface.show_notification = AsyncMock()\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\"1\\\\\\\")\\\\n\\\\n    result = await client.handle_voting(candidates, 60)\\\\n\\\\n    assert result['voted'] == True\\\\n    assert result['candidate'] == \\\\\\\"Alice\\\\\\\"\\\\n    assert result['justification'] == \\\\\\\"\\\\\\\"  # No justification prompt for web\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_human_client_lifecycle():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test complete human client lifecycle.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    config = {'mode': 'cli', 'enable_rich_formatting': False}\\\\n    client = HumanClient(\\\\\\\"LifecycleTest\\\\\\\", config)\\\\n\\\\n    # Initial state\\\\n    assert client.is_active == True\\\\n    assert len(client.conversation_history) == 0\\\\n\\\\n    # Mock interface for testing\\\\n    client.interface.display_message = AsyncMock()\\\\n    client.interface.show_notification = AsyncMock()\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\"Test response\\\\\\\")\\\\n\\\\n    # Receive some messages\\\\n    for i in range(3):\\\\n        message = Message(f\\\\\\\"User{i}\\\\\\\", f\\\\\\\"Message {i}\\\\\\\", 1640995200.0 + i, i)\\\\n        await client.receive_message(message)\\\\n\\\\n    assert len(client.conversation_history) == 3\\\\n\\\\n    # Participate in debate\\\\n    response = await client.get_response(\\\\\\\"Test topic\\\\\\\", [])\\\\n    assert response == \\\\\\\"Test response\\\\\\\"\\\\n    assert client.stats['responses_given'] == 1\\\\n\\\\n    # Deactivate\\\\n    await client.set_active(False)\\\\n    assert client.is_active == False\\\\n\\\\n    # Should not respond when inactive\\\\n    response = await client.get_response(\\\\\\\"Another topic\\\\\\\", [])\\\\n    assert response == \\\\\\\"\\\\\\\"\\\"\\n        },\\n        \\\"test_moderator.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"tests/test_moderator.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 9146,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTests for the Moderator class.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport pytest\\\\nimport asyncio\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\nfrom app.moderator import Moderator, DebatePhase, DebateState\\\\nfrom app.chat_log import ChatLog\\\\nfrom app.voting import VotingSystem\\\\nfrom app.bot_client import BotClient\\\\nfrom app.human_client import HumanClient\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef chat_log():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a test chat log.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return ChatLog()\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef voting_system():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a test voting system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    config = {'enabled': True, 'voting_duration': 60}\\\\n    return VotingSystem(config)\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef mock_participants():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create mock participants.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    bot = Mock(spec=BotClient)\\\\n    bot.name = \\\\\\\"TestBot\\\\\\\"\\\\n    bot.get_response = AsyncMock(return_value=\\\\\\\"Test response\\\\\\\")\\\\n    bot.receive_message = AsyncMock()\\\\n\\\\n    human = Mock(spec=HumanClient)\\\\n    human.name = \\\\\\\"TestHuman\\\\\\\"\\\\n    human.get_response = AsyncMock(return_value=\\\\\\\"Human response\\\\\\\")\\\\n    human.receive_message = AsyncMock()\\\\n\\\\n    return [bot, human]\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef moderator(chat_log, voting_system, mock_participants):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create a test moderator.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    config = {\\\\n        'opening_statement_time': 30,\\\\n        'discussion_time': 60,\\\\n        'closing_statement_time': 30,\\\\n        'response_time': 20,\\\\n        'max_response_time': 60,\\\\n        'warning_time': 45\\\\n    }\\\\n\\\\n    return Moderator(\\\\n        topic=\\\\\\\"Test topic\\\\\\\",\\\\n        participants=mock_participants,\\\\n        chat_log=chat_log,\\\\n        voting_system=voting_system,\\\\n        config=config\\\\n    )\\\\n\\\\n\\\\nclass TestModerator:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for Moderator class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_moderator_initialization(self, moderator):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test moderator initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        assert moderator.topic == \\\\\\\"Test topic\\\\\\\"\\\\n        assert len(moderator.participants) == 2\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\n        assert \\\\\\\"TestBot\\\\\\\" in moderator.participants\\\\n        assert \\\\\\\"TestHuman\\\\\\\" in moderator.participants\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_introduction_phase(self, moderator, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test introduction phase.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await moderator._introduction_phase()\\\\n\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\n\\\\n        # Check that introduction message was logged\\\\n        messages = chat_log.get_messages()\\\\n        assert any(\\\\\\\"Welcome to AI Jubilee Debate\\\\\\\" in msg.content for msg in messages)\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_opening_statements_phase(self, moderator, mock_participants):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test opening statements phase.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await moderator._opening_statements_phase()\\\\n\\\\n        assert moderator.state.phase == DebatePhase.OPENING_STATEMENTS\\\\n\\\\n        # Verify each participant was asked for response\\\\n        for participant in mock_participants:\\\\n            participant.get_response.assert_called()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_give_turn_success(self, moderator, mock_participants):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test successful turn giving.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        participant = mock_participants[0]\\\\n        participant.get_response.return_value = \\\\\\\"Test response\\\\\\\"\\\\n\\\\n        await moderator._give_turn(participant.name, 30, \\\\\\\"test\\\\\\\")\\\\n\\\\n        participant.get_response.assert_called_once()\\\\n        assert moderator.state.current_speaker is None  # Reset after turn\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_give_turn_timeout(self, moderator, mock_participants):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test turn timeout handling.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        participant = mock_participants[0]\\\\n\\\\n        # Simulate timeout by making get_response take too long\\\\n        async def slow_response(*args):\\\\n            await asyncio.sleep(2)\\\\n            return \\\\\\\"Too late\\\\\\\"\\\\n\\\\n        participant.get_response = slow_response\\\\n\\\\n        # Use very short timeout for testing\\\\n        await moderator._give_turn(participant.name, 0.1, \\\\\\\"test\\\\\\\")\\\\n\\\\n        # Should have issued a warning\\\\n        assert moderator.state.warnings_issued.get(participant.name, 0) >= 1\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_voting_phase_enabled(self, moderator):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting phase when voting is enabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        moderator.voting_system.enabled = True\\\\n\\\\n        with patch.object(moderator.voting_system, 'start_voting') as mock_start:\\\\n            with patch.object(moderator.voting_system, 'end_voting') as mock_end:\\\\n                mock_end.return_value = {\\\\n                    'winner': 'TestBot',\\\\n                    'vote_counts': {'TestBot': 2, 'TestHuman': 1}\\\\n                }\\\\n\\\\n                results = await moderator._voting_phase()\\\\n\\\\n                mock_start.assert_called_once()\\\\n                mock_end.assert_called_once()\\\\n                assert results['winner'] == 'TestBot'\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_voting_phase_disabled(self, moderator):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting phase when voting is disabled.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        moderator.voting_system.enabled = False\\\\n\\\\n        results = await moderator._voting_phase()\\\\n\\\\n        assert results == {}\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_broadcast_message(self, moderator, mock_participants, chat_log):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test message broadcasting.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await moderator._broadcast_message(\\\\\\\"Test message\\\\\\\", \\\\\\\"moderator\\\\\\\")\\\\n\\\\n        # Check message was logged\\\\n        messages = chat_log.get_messages()\\\\n        assert any(msg.content == \\\\\\\"Test message\\\\\\\" for msg in messages)\\\\n\\\\n        # Check all participants received message\\\\n        for participant in mock_participants:\\\\n            participant.receive_message.assert_called()\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_handle_timeout_warnings(self, moderator):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test timeout warning system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        participant_name = \\\\\\\"TestBot\\\\\\\"\\\\n\\\\n        # First timeout\\\\n        await moderator._handle_timeout(participant_name)\\\\n        assert moderator.state.warnings_issued[participant_name] == 1\\\\n\\\\n        # Second timeout\\\\n        await moderator._handle_timeout(participant_name)\\\\n        assert moderator.state.warnings_issued[participant_name] == 2\\\\n\\\\n        # Third timeout (should trigger mute)\\\\n        await moderator._handle_timeout(participant_name)\\\\n        assert moderator.state.warnings_issued[participant_name] == 3\\\\n\\\\n    def test_get_state(self, moderator):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test state retrieval.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        state = moderator.get_state()\\\\n\\\\n        assert isinstance(state, DebateState)\\\\n        assert state.phase == DebatePhase.INTRODUCTION\\\\n        assert state.current_speaker is None\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_full_debate_flow(self, moderator, mock_participants):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test complete debate flow.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Mock voting system methods\\\\n        moderator.voting_system.start_voting = AsyncMock()\\\\n        moderator.voting_system.end_voting = AsyncMock(return_value={\\\\n            'winner': 'TestBot',\\\\n            'vote_counts': {'TestBot': 1, 'TestHuman': 0}\\\\n        })\\\\n\\\\n        # Run complete debate with short timeouts for testing\\\\n        moderator.phase_times[DebatePhase.DISCUSSION] = 1  # 1 second\\\\n\\\\n        results = await moderator.run_debate()\\\\n\\\\n        # Verify all phases completed\\\\n        assert moderator.state.phase == DebatePhase.FINISHED\\\\n        assert 'winner' in results\\\\n\\\\n        # Verify participants were called\\\\n        for participant in mock_participants:\\\\n            assert participant.get_response.call_count > 0\\\\n\\\\n\\\\nclass TestDebateState:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for DebateState dataclass.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_debate_state_initialization(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test DebateState initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        state = DebateState(DebatePhase.DISCUSSION)\\\\n\\\\n        assert state.phase == DebatePhase.DISCUSSION\\\\n        assert state.current_speaker is None\\\\n        assert state.time_remaining == 0\\\\n        assert state.turn_order == []\\\\n        assert state.warnings_issued == {}\\\\n\\\\n    def test_debate_state_with_values(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test DebateState with custom values.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        turn_order = [\\\\\\\"Bot1\\\\\\\", \\\\\\\"Human1\\\\\\\", \\\\\\\"Bot2\\\\\\\"]\\\\n        warnings = {\\\\\\\"Bot1\\\\\\\": 1}\\\\n\\\\n        state = DebateState(\\\\n            phase=DebatePhase.VOTING,\\\\n            current_speaker=\\\\\\\"Human1\\\\\\\",\\\\n            time_remaining=120,\\\\n            turn_order=turn_order,\\\\n            warnings_issued=warnings\\\\n        )\\\\n\\\\n        assert state.phase == DebatePhase.VOTING\\\\n        assert state.current_speaker == \\\\\\\"Human1\\\\\\\"\\\\n        assert state.time_remaining == 120\\\\n        assert state.turn_order == turn_order\\\\n        assert state.warnings_issued == warnings\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_moderator_error_handling(moderator, mock_participants):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test moderator error handling.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Make participant raise an error\\\\n    mock_participants[0].get_response.side_effect = Exception(\\\\\\\"Test error\\\\\\\")\\\\n\\\\n    # Should not crash the debate\\\\n    await moderator._give_turn(mock_participants[0].name, 30, \\\\\\\"test\\\\\\\")\\\\n\\\\n    # Moderator should continue functioning\\\\n    assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\n\\\\n\\\\n@pytest.mark.asyncio\\\\nasync def test_moderator_message_validation(moderator):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test message content validation.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    long_message = \\\\\\\"x\\\\\\\" * 1000  # Very long message\\\\n\\\\n    await moderator._process_response(\\\\\\\"TestBot\\\\\\\", long_message)\\\\n\\\\n    # Should have been truncated\\\\n    messages = moderator.chat_log.get_messages()\\\\n    last_message = messages[-1]\\\\n    assert len(last_message.content) <= 503  # 500 + \\\\\\\"...\\\\\\\"\\\"\\n        },\\n        \\\"test_voting.py\\\": {\\n          \\\"type\\\": \\\"file\\\",\\n          \\\"path\\\": \\\"tests/test_voting.py\\\",\\n          \\\"extension\\\": \\\".py\\\",\\n          \\\"size\\\": 16340,\\n          \\\"content\\\": \\\"\\\\\\\"\\\\\\\"\\\\\\\"\\\\nTests for the VotingSystem class.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport pytest\\\\nimport asyncio\\\\nimport time\\\\nfrom app.voting import VotingSystem, Vote, VotingResults\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef voting_config():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create test voting configuration.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return {\\\\n        'enabled': True,\\\\n        'voting_duration': 60,\\\\n        'allow_participant_voting': True,\\\\n        'require_justification': False,\\\\n        'anonymous_votes': False\\\\n    }\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef voting_system(voting_config):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create test voting system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    return VotingSystem(voting_config)\\\\n\\\\n\\\\n@pytest.fixture\\\\ndef active_voting_system(voting_system):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create and start a voting session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    asyncio.create_task(voting_system.start_voting(['Alice', 'Bob', 'Charlie'], 30))\\\\n    return voting_system\\\\n\\\\n\\\\nclass TestVotingSystem:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for VotingSystem class.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_voting_system_initialization(self, voting_config):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting system initialization.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        vs = VotingSystem(voting_config)\\\\n\\\\n        assert vs.enabled == True\\\\n        assert vs.voting_duration == 60\\\\n        assert vs.allow_participant_voting == True\\\\n        assert vs.require_justification == False\\\\n        assert vs.anonymous_votes == False\\\\n        assert vs.is_active == False\\\\n        assert vs.candidates == []\\\\n        assert vs.votes == {}\\\\n\\\\n    def test_disabled_voting_system(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test disabled voting system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = {'enabled': False}\\\\n        vs = VotingSystem(config)\\\\n\\\\n        assert vs.enabled == False\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_start_voting_session(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test starting a voting session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        candidates = ['Alice', 'Bob', 'Charlie']\\\\n\\\\n        await voting_system.start_voting(candidates, 30)\\\\n\\\\n        assert voting_system.is_active == True\\\\n        assert voting_system.candidates == candidates\\\\n        assert voting_system.eligible_voters == candidates  # allow_participant_voting=True\\\\n        assert voting_system.start_time is not None\\\\n        assert voting_system.end_time is not None\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_start_voting_disabled_system(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test starting voting on disabled system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = {'enabled': False}\\\\n        vs = VotingSystem(config)\\\\n\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Voting system is disabled\\\\\\\"):\\\\n            await vs.start_voting(['Alice', 'Bob'])\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_start_voting_already_active(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test starting voting when already active.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Voting session already active\\\\\\\"):\\\\n            await voting_system.start_voting(['Charlie', 'Dave'])\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_cast_valid_vote(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test casting a valid vote.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\n\\\\n        result = await voting_system.cast_vote('voter1', 'Alice', 'Great arguments')\\\\n\\\\n        assert result == True\\\\n        assert 'voter1' in voting_system.votes\\\\n        assert voting_system.votes['voter1'].candidate == 'Alice'\\\\n        assert voting_system.votes['voter1'].justification == 'Great arguments'\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_cast_vote_no_active_session(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test casting vote with no active session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with pytest.raises(ValueError, match=\\\\\\\"No active voting session\\\\\\\"):\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_cast_vote_invalid_candidate(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test casting vote for invalid candidate.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Invalid candidate\\\\\\\"):\\\\n            await voting_system.cast_vote('voter1', 'Charlie')\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_cast_vote_requires_justification(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting system that requires justification.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = {\\\\n            'enabled': True,\\\\n            'require_justification': True,\\\\n            'allow_participant_voting': True\\\\n        }\\\\n        vs = VotingSystem(config)\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\n\\\\n        # Vote without justification should fail\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Vote justification is required\\\\\\\"):\\\\n            await vs.cast_vote('voter1', 'Alice')\\\\n\\\\n        # Vote with justification should succeed\\\\n        result = await vs.cast_vote('voter1', 'Alice', 'Good points')\\\\n        assert result == True\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_cast_vote_overwrite(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test that new vote overwrites previous vote.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.cast_vote('voter1', 'Bob')  # Change vote\\\\n\\\\n        assert voting_system.votes['voter1'].candidate == 'Bob'\\\\n        assert len(voting_system.votes) == 1  # Only one vote per voter\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test self-voting when allowed.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test self-voting when allowed.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n        # Should allow participant to vote for themselves\\\\n        result = await voting_system.cast_vote('Alice', 'Alice')\\\\n        assert result == True\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_self_voting_disallowed(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test self-voting when disallowed.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        config = {\\\\n            'enabled': True,\\\\n            'allow_participant_voting': False\\\\n        }\\\\n        vs = VotingSystem(config)\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\n\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Self-voting is not allowed\\\\\\\"):\\\\n            await vs.cast_vote('Alice', 'Alice')\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_end_voting_session(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test ending a voting session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\n\\\\n        # Cast some votes\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.cast_vote('voter2', 'Alice')\\\\n        await voting_system.cast_vote('voter3', 'Bob')\\\\n\\\\n        results = await voting_system.end_voting()\\\\n\\\\n        assert isinstance(results, VotingResults)\\\\n        assert results.winner == 'Alice'  # Most votes\\\\n        assert results.vote_counts['Alice'] == 2\\\\n        assert results.vote_counts['Bob'] == 1\\\\n        assert results.total_votes == 3\\\\n        assert voting_system.is_active == False\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_end_voting_tie(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test ending voting with a tie.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.cast_vote('voter2', 'Bob')\\\\n\\\\n        results = await voting_system.end_voting()\\\\n\\\\n        assert \\\\\\\"TIE:\\\\\\\" in results.winner\\\\n        assert \\\\\\\"Alice\\\\\\\" in results.winner\\\\n        assert \\\\\\\"Bob\\\\\\\" in results.winner\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_end_voting_no_votes(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test ending voting with no votes cast.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n\\\\n        results = await voting_system.end_voting()\\\\n\\\\n        assert results.winner is None\\\\n        assert results.total_votes == 0\\\\n        assert results.vote_counts == {}\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_end_voting_not_active(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test ending voting when not active.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with pytest.raises(ValueError, match=\\\\\\\"No active voting session\\\\\\\"):\\\\n            await voting_system.end_voting()\\\\n\\\\n    def test_get_vote_summary(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test getting vote summary during active session.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # No active session\\\\n        summary = voting_system.get_vote_summary()\\\\n        assert summary == {}\\\\n\\\\n        # With active session\\\\n        asyncio.create_task(voting_system.start_voting(['Alice', 'Bob'], 60))\\\\n        summary = voting_system.get_vote_summary()\\\\n\\\\n        assert 'candidates' in summary\\\\n        assert 'vote_counts' in summary\\\\n        assert 'total_votes' in summary\\\\n        assert 'time_remaining' in summary\\\\n        assert 'is_active' in summary\\\\n\\\\n    def test_add_remove_eligible_voters(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test adding and removing eligible voters.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        voting_system.add_eligible_voter('voter1')\\\\n        assert 'voter1' in voting_system.eligible_voters\\\\n\\\\n        voting_system.add_eligible_voter('voter2')\\\\n        assert len(voting_system.eligible_voters) == 2\\\\n\\\\n        voting_system.remove_eligible_voter('voter1')\\\\n        assert 'voter1' not in voting_system.eligible_voters\\\\n        assert len(voting_system.eligible_voters) == 1\\\\n\\\\n    def test_is_eligible_voter(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voter eligibility checking.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Empty eligible voters list means open voting\\\\n        assert voting_system._is_eligible_voter('anyone') == True\\\\n\\\\n        # With specific eligible voters\\\\n        voting_system.add_eligible_voter('voter1')\\\\n        assert voting_system._is_eligible_voter('voter1') == True\\\\n        assert voting_system._is_eligible_voter('voter2') == False\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_vote_history(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test vote history tracking.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # First session\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.end_voting()\\\\n\\\\n        # Second session\\\\n        await voting_system.start_voting(['Charlie', 'Dave'])\\\\n        await voting_system.cast_vote('voter1', 'Charlie')\\\\n        await voting_system.end_voting()\\\\n\\\\n        assert len(voting_system.vote_history) == 2\\\\n\\\\n        # Test voter history\\\\n        voter_history = voting_system.get_voter_history('voter1')\\\\n        assert len(voter_history) == 2\\\\n        assert voter_history[0].candidate == 'Alice'\\\\n        assert voter_history[1].candidate == 'Charlie'\\\\n\\\\n    def test_candidate_performance(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test candidate performance tracking.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Add some mock history\\\\n        voting_system.vote_history = [\\\\n            {\\\\n                'candidates': ['Alice', 'Bob'],\\\\n                'results': VotingResults(\\\\n                    winner='Alice',\\\\n                    vote_counts={'Alice': 2, 'Bob': 1},\\\\n                    total_votes=3,\\\\n                    votes_by_voter={},\\\\n                    voting_duration=60,\\\\n                    participation_rate=1.0\\\\n                )\\\\n            },\\\\n            {\\\\n                'candidates': ['Alice', 'Charlie'],\\\\n                'results': VotingResults(\\\\n                    winner='Charlie',\\\\n                    vote_counts={'Alice': 1, 'Charlie': 2},\\\\n                    total_votes=3,\\\\n                    votes_by_voter={},\\\\n                    voting_duration=60,\\\\n                    participation_rate=1.0\\\\n                )\\\\n            }\\\\n        ]\\\\n\\\\n        performance = voting_system.get_candidate_performance('Alice')\\\\n\\\\n        assert performance['wins'] == 1\\\\n        assert performance['participations'] == 2\\\\n        assert performance['total_votes'] == 3\\\\n        assert performance['win_rate'] == 0.5\\\\n        assert performance['avg_votes'] == 1.5\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_export_results_json(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test exporting results in JSON format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Create some history\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.end_voting()\\\\n\\\\n        json_output = await voting_system.export_results('json')\\\\n\\\\n        assert isinstance(json_output, str)\\\\n        assert 'Alice' in json_output\\\\n        assert 'vote_counts' in json_output\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_export_results_csv(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test exporting results in CSV format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.end_voting()\\\\n\\\\n        csv_output = await voting_system.export_results('csv')\\\\n\\\\n        assert isinstance(csv_output, str)\\\\n        assert 'Session,Timestamp,Candidate,Votes,Winner' in csv_output\\\\n        assert 'Alice' in csv_output\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_export_results_txt(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test exporting results in TXT format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\n        await voting_system.end_voting()\\\\n\\\\n        txt_output = await voting_system.export_results('txt')\\\\n\\\\n        assert isinstance(txt_output, str)\\\\n        assert 'VOTING HISTORY REPORT' in txt_output\\\\n        assert 'Alice' in txt_output\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_export_unsupported_format(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test exporting with unsupported format.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Unsupported format\\\\\\\"):\\\\n            await voting_system.export_results('xml')\\\\n\\\\n    def test_reset_voting_system(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test resetting the voting system.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Set up some state\\\\n        voting_system.candidates = ['Alice', 'Bob']\\\\n        voting_system.votes = {'voter1': Vote('voter1', 'Alice')}\\\\n        voting_system.is_active = True\\\\n\\\\n        voting_system.reset()\\\\n\\\\n        assert voting_system.is_active == False\\\\n        assert voting_system.candidates == []\\\\n        assert voting_system.votes == {}\\\\n        assert voting_system.start_time is None\\\\n        assert voting_system.end_time is None\\\\n\\\\n    def test_voting_system_status(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test voting system status property.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        status = voting_system.status\\\\n\\\\n        assert 'enabled' in status\\\\n        assert 'is_active' in status\\\\n        assert 'candidates' in status\\\\n        assert 'eligible_voters' in status\\\\n        assert 'votes_cast' in status\\\\n        assert 'time_remaining' in status\\\\n        assert 'sessions_completed' in status\\\\n\\\\n    @pytest.mark.asyncio\\\\n    async def test_vote_after_time_expires(self, voting_system):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test casting vote after voting time expires.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        # Start voting with very short duration\\\\n        await voting_system.start_voting(['Alice', 'Bob'], 0.1)\\\\n\\\\n        # Wait for voting to expire\\\\n        await asyncio.sleep(0.2)\\\\n\\\\n        with pytest.raises(ValueError, match=\\\\\\\"Voting period has ended\\\\\\\"):\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\n\\\\n\\\\nclass TestVote:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for Vote dataclass.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_vote_creation(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test creating a vote.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        vote = Vote('voter1', 'Alice', 'Great arguments')\\\\n\\\\n        assert vote.voter_id == 'voter1'\\\\n        assert vote.candidate == 'Alice'\\\\n        assert vote.justification == 'Great arguments'\\\\n        assert vote.anonymous == False\\\\n        assert isinstance(vote.timestamp, float)\\\\n\\\\n    def test_vote_anonymous(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test creating anonymous vote.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        vote = Vote('voter1', 'Alice', anonymous=True)\\\\n\\\\n        assert vote.anonymous == True\\\\n\\\\n    def test_vote_no_justification(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test vote without justification.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        vote = Vote('voter1', 'Alice')\\\\n\\\\n        assert vote.justification is None\\\\n\\\\n\\\\nclass TestVotingResults:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Test suite for VotingResults dataclass.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\n    def test_voting_results_creation(self):\\\\n        \\\\\\\"\\\\\\\"\\\\\\\"Test creating voting results.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n        vote_counts = {'Alice': 2, 'Bob': 1}\\\\n        votes_by_voter = {\\\\n            'voter1': Vote('voter1', 'Alice'),\\\\n            'voter2': Vote('voter2', 'Alice'),\\\\n            'voter3': Vote('voter3', 'Bob')\\\\n        }\\\\n\\\\n        results = VotingResults(\\\\n            winner='Alice',\\\\n            vote_counts=vote_counts,\\\\n            total_votes=3,\\\\n            votes_by_voter=votes_by_voter,\\\\n            voting_duration=60.0,\\\\n            participation_rate=1.0\\\\n        )\\\\n\\\\n        assert results.winner == 'Alice'\\\\n        assert results.vote_counts == vote_counts\\\\n        assert results.total_votes == 3\\\\n        assert len(results.votes_by_voter) == 3\\\\n        assert results.voting_duration == 60.0\\\\n        assert results.participation_rate == 1.0\\\"\\n        }\\n      }\\n    },\\n    \\\"config.yaml\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"config.yaml\\\",\\n      \\\"extension\\\": \\\".yaml\\\",\\n      \\\"size\\\": 3334,\\n      \\\"content\\\": \\\"# AI Jubilee Debate Configuration\\\\n\\\\n# Debate Settings\\\\ndebate:\\\\n  default_topic: \\\\\\\"The role of artificial intelligence in modern society\\\\\\\"\\\\n  max_participants: 4\\\\n  time_limit_minutes: 10\\\\n  opening_statement_time: 120  # seconds\\\\n  response_time: 60  # seconds\\\\n  closing_statement_time: 90  # seconds\\\\n\\\\n  # Debate mode: \\\\\\\"sequential\\\\\\\" or \\\\\\\"autonomous\\\\\\\"\\\\n  mode: \\\\\\\"autonomous\\\\\\\"  # AUTONOMOUS MODE: Bots monitor and decide when to speak!\\\\n\\\\n  # Autonomous mode settings\\\\n  min_bot_cooldown: 15          # Minimum seconds between bot responses\\\\n  max_bot_cooldown: 45          # Maximum cooldown for very active bots\\\\n  message_check_interval: 5     # How often bots check for new messages\\\\n  silence_timeout: 60           # Seconds of silence before moderator intervenes\\\\n\\\\n# Available debate topics\\\\ntopics:\\\\n  - \\\\\\\"AI will create more jobs than it destroys\\\\\\\"\\\\n  - \\\\\\\"Social media has a net positive impact on democracy\\\\\\\"\\\\n\\\\n\\\\n# AI Moderator Configuration (NEW!)\\\\nmoderator:\\\\n  name: \\\\\\\"Moderator\\\\\\\"\\\\n  model: \\\\\\\"gpt-4\\\\\\\"\\\\n  provider: \\\\\\\"openai\\\\\\\"\\\\n  personality: \\\\\\\"Professional debate facilitator who asks insightful questions, encourages participation, and helps explore different angles of the topic. Speaks when the conversation needs direction or when interesting points need deeper exploration.\\\\\\\"\\\\n  stance: \\\\\\\"neutral\\\\\\\"\\\\n  temperature: 0.8\\\\n  max_tokens: 150\\\\n\\\\n# AI Bot Configurations\\\\nbots:\\\\n  - name: \\\\\\\"Socrates\\\\\\\"\\\\n    model: \\\\\\\"gpt-4\\\\\\\"\\\\n    provider: \\\\\\\"openai\\\\\\\"\\\\n    personality: \\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\"\\\\n    debate_style: \\\\\\\"socratic\\\\\\\"\\\\n    stance: \\\\\\\"neutral\\\\\\\"\\\\n\\\\n  - name: \\\\\\\"Advocate\\\\\\\"\\\\n    model: \\\\\\\"gpt-4\\\\\\\"\\\\n    provider: \\\\\\\"openai\\\\\\\"\\\\n    personality: \\\\\\\"Passionate supporter, data-driven, persuasive speaker. Jumps in when position is challenged.\\\\\\\"\\\\n    debate_style: \\\\\\\"assertive\\\\\\\"\\\\n    stance: \\\\\\\"pro\\\\\\\"\\\\n\\\\n  - name: \\\\\\\"Skeptic\\\\\\\"\\\\n    model: \\\\\\\"gpt-3.5-turbo\\\\\\\"\\\\n    provider: \\\\\\\"openai\\\\\\\"\\\\n    personality: \\\\\\\"Critical thinker, questions assumptions, looks for flaws. Responds when claims need scrutiny.\\\\\\\"\\\\n    debate_style: \\\\\\\"analytical\\\\\\\"\\\\n    stance: \\\\\\\"con\\\\\\\"\\\\n\\\\n  - name: \\\\\\\"Mediator\\\\\\\"\\\\n    model: \\\\\\\"gpt-3.5-turbo\\\\\\\"\\\\n    provider: \\\\\\\"openai\\\\\\\"\\\\n    personality: \\\\\\\"Balanced, seeks common ground, diplomatic. Speaks to bridge disagreements and find synthesis.\\\\\\\"\\\\n    debate_style: \\\\\\\"collaborative\\\\\\\"\\\\n    stance: \\\\\\\"neutral\\\\\\\"\\\\n\\\\n# API Keys (use environment variables in production)\\\\napi_keys:\\\\n  openai: \\\\\\\"${OPENAI_API_KEY}\\\\\\\"\\\\n  anthropic: \\\\\\\"${ANTHROPIC_API_KEY}\\\\\\\"\\\\n\\\\n# Voting System\\\\nvoting:\\\\n  enabled: true\\\\n  voting_duration: 300  # seconds\\\\n  allow_participant_voting: true\\\\n  require_justification: true\\\\n  anonymous_votes: false\\\\n\\\\n# Chat and Logging\\\\nchat:\\\\n  max_message_length: 500\\\\n  enable_timestamps: true\\\\n  log_level: \\\\\\\"INFO\\\\\\\"\\\\n  save_transcripts: true\\\\n  transcript_format: \\\\\\\"json\\\\\\\"\\\\n\\\\n# Streaming Configuration\\\\nstreaming:\\\\n  enabled: false\\\\n  websocket_port: 8080\\\\n  max_connections: 100\\\\n  broadcast_votes: true\\\\n\\\\n# Timeouts and Limits\\\\nlimits:\\\\n  max_response_time: 120  # seconds\\\\n  warning_time: 90  # seconds\\\\n  max_retries: 3\\\\n  rate_limit_per_minute: 10\\\\n\\\\n# Moderation Rules\\\\nmoderation:\\\\n  enable_profanity_filter: true\\\\n  max_interruptions: 3\\\\n  enforce_turn_order: false  # No turn order in autonomous mode\\\\n  auto_mute_violations: true\\\\n\\\\n# Human Interface\\\\ninterface:\\\\n  mode: \\\\\\\"cliAn\\\\\\\"  # options: cli, web, api\\\\n  enable_rich_formatting: true\\\\n  show_typing_indicators: true\\\\n  enable_reactions: true\\\"\\n    },\\n    \\\"debate_Remote work is the f.json\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"debate_Remote work is the f.json\\\",\\n      \\\"extension\\\": \\\".json\\\",\\n      \\\"size\\\": 13914,\\n      \\\"content\\\": \\\"{\\\\n  \\\\\\\"metadata\\\\\\\": {\\\\n    \\\\\\\"export_timestamp\\\\\\\": 1749817045.239899,\\\\n    \\\\\\\"total_messages\\\\\\\": 42,\\\\n    \\\\\\\"statistics\\\\\\\": {\\\\n      \\\\\\\"total_messages\\\\\\\": 42,\\\\n      \\\\\\\"unique_senders\\\\\\\": 5,\\\\n      \\\\\\\"messages_by_sender\\\\\\\": {\\\\n        \\\\\\\"moderator\\\\\\\": 32,\\\\n        \\\\\\\"Socrates\\\\\\\": 3,\\\\n        \\\\\\\"Advocate\\\\\\\": 3,\\\\n        \\\\\\\"Mediator\\\\\\\": 3,\\\\n        \\\\\\\"Human_1\\\\\\\": 1\\\\n      },\\\\n      \\\\\\\"messages_per_minute\\\\\\\": 2.069704853831723,\\\\n      \\\\\\\"session_duration_minutes\\\\\\\": 20.29274846712748,\\\\n      \\\\\\\"current_message_count\\\\\\\": 42\\\\n    }\\\\n  },\\\\n  \\\\\\\"messages\\\\\\\": [\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé≠ Welcome to AI Jubilee Debate!\\\\\\\\nüìù Topic: Remote work is the future of employment\\\\\\\\nüë• Participants: Socrates, Advocate, Mediator, Human_1\\\\\\\\n‚è±Ô∏è Total time: 30 minutes\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815828.371039,\\\\n      \\\\\\\"message_id\\\\\\\": 1,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Opening Statements Phase\\\\\\\\nEach participant has 120 seconds for their opening statement.\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815831.3736022,\\\\n      \\\\\\\"message_id\\\\\\\": 2,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Socrates's turn for opening statement (120s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815831.375623,\\\\n      \\\\\\\"message_id\\\\\\\": 3,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815839.0529852,\\\\n      \\\\\\\"message_id\\\\\\\": 4,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Socrates\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Indeed, this is a topic worthy of our contemplation. The concept of remote work, or telecommuting, has been thrust into the spotlight due to current global circumstances. As we partake in this discourse, let us remember that the future is not a fixed point, but a journey shaped by our choices and actions. Remote work has shown potential to increase productivity and provide flexibility, yet it also introduces challenges in maintaining work-life boundaries and effective communication. Therefore, i...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815839.055337,\\\\n      \\\\\\\"message_id\\\\\\\": 5,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Advocate's turn for opening statement (120s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815839.055578,\\\\n      \\\\\\\"message_id\\\\\\\": 6,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815845.0692759,\\\\n      \\\\\\\"message_id\\\\\\\": 7,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Advocate\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Advocate: Thank you, moderator. I would like to open by stating that remote work is undoubtedly the future of employment. This is not just a speculative assertion, but a fact supported by an increasing body of evidence. Remote work offers unprecedented flexibility, leading to increased productivity, employee satisfaction, and a reduction in overhead costs for companies. According to a survey by Global Workplace Analytics, businesses can save up to $11,000 per year for every employee who works re...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815845.0708978,\\\\n      \\\\\\\"message_id\\\\\\\": 8,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Mediator's turn for opening statement (120s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815845.070956,\\\\n      \\\\\\\"message_id\\\\\\\": 9,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815847.077504,\\\\n      \\\\\\\"message_id\\\\\\\": 10,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Mediator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"As we delve into the discourse surrounding remote work as the future of employment, it's vital to recognize the multifaceted nature of this topic. Remote work undeniably presents a host of advantages, such as flexibility, potential cost savings, and increased productivity for many individuals. However, it's crucial to acknowledge the challenges that come hand in hand with remote work, like maintaining work-life balance, fostering effective communication, and combating feelings of isolation. Stri...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815847.078847,\\\\n      \\\\\\\"message_id\\\\\\\": 11,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Human_1's turn for opening statement (120s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815847.0788858,\\\\n      \\\\\\\"message_id\\\\\\\": 12,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Human_1\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"hei finaly my turn\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815855.599628,\\\\n      \\\\\\\"message_id\\\\\\\": 13,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üí¨ Discussion Phase Begin\\\\\\\\nOpen discussion for 30 minutes. Maintain respectful dialogue!\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815855.599648,\\\\n      \\\\\\\"message_id\\\\\\\": 14,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815855.5999942,\\\\n      \\\\\\\"message_id\\\\\\\": 15,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Socrates: 60 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815855.600161,\\\\n      \\\\\\\"message_id\\\\\\\": 16,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Socrates\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Socrates: I am quite intrigued by the notion of remote work. Yet, I wonder, are we not assuming that all types of work can be performed remotely? A farmer, for instance, cannot till his land from his living room. Moreover, does the isolation associated with remote work not contradict the social nature of human beings? Is it possible that the increase in productivity is only a short-term effect, and in the long run, the lack of human interaction might lead to decreased motivation and engagement?\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815861.113106,\\\\n      \\\\\\\"message_id\\\\\\\": 17,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815861.113177,\\\\n      \\\\\\\"message_id\\\\\\\": 18,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815861.1147661,\\\\n      \\\\\\\"message_id\\\\\\\": 19,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815868.633038,\\\\n      \\\\\\\"message_id\\\\\\\": 20,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Advocate\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Advocate: Indeed, Socrates, your points are valid. However, it's crucial to acknowledge that remote work may not apply to every profession, such as farming. Yet, it fits many industries, notably the ever-growing tech, finance, and creative sectors. \\\\\\\\n\\\\\\\\nAs for the social aspect, while physical interaction is limited, remote work doesn't necessarily mean isolation. Virtual technologies facilitate team collaboration and social interaction effectively. \\\\\\\\n\\\\\\\\nLastly, evidence shows the productivity increas...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815868.6344562,\\\\n      \\\\\\\"message_id\\\\\\\": 21,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Mediator's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815868.634491,\\\\n      \\\\\\\"message_id\\\\\\\": 22,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Mediator: 59 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815868.635563,\\\\n      \\\\\\\"message_id\\\\\\\": 23,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815871.141592,\\\\n      \\\\\\\"message_id\\\\\\\": 24,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Mediator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Advocate, your points are well taken. It's essential to recognize that while remote work may not be universally applicable, its compatibility with various fields like technology and finance indicates a flexible future for employment. The evolution of virtual technologies indeed enables effective collaboration and social engagement, mitigating the potential isolation concerns often associated with remote work. \\\\\\\\n\\\\\\\\nWhen considering the productivity aspect, studies have shown mixed results, indicatin...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815871.142476,\\\\n      \\\\\\\"message_id\\\\\\\": 25,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815871.142514,\\\\n      \\\\\\\"message_id\\\\\\\": 26,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Human_1: 59 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815871.143828,\\\\n      \\\\\\\"message_id\\\\\\\": 27,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Human_1 exceeded time limit. Warning 1/3\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815931.2812438,\\\\n      \\\\\\\"message_id\\\\\\\": 28,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815931.283378,\\\\n      \\\\\\\"message_id\\\\\\\": 29,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Socrates: 59 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815931.284396,\\\\n      \\\\\\\"message_id\\\\\\\": 30,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815938.301232,\\\\n      \\\\\\\"message_id\\\\\\\": 31,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Socrates\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Indeed, the Mediator presents a nuanced perspective. However, I am intrigued by the notion of this 'flexible future for employment'. Does this flexibility extend to the equilibrium between professional and personal lives? How do we ensure that the boundaries between work and home do not blur, leading to overwork and stress? Are there effective measures in place to deal with such possible outcomes of a remote work environment? Furthermore, does the potential for isolation only refer to physical i...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815938.3026502,\\\\n      \\\\\\\"message_id\\\\\\\": 32,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815938.302691,\\\\n      \\\\\\\"message_id\\\\\\\": 33,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815938.303506,\\\\n      \\\\\\\"message_id\\\\\\\": 34,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815944.81759,\\\\n      \\\\\\\"message_id\\\\\\\": 35,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Advocate\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Advocate: Socrates, your concerns are valid. However, remote work actually enhances the work-life balance when managed properly. Buffer‚Äôs 2019 State of Remote Work report shows that 40% of remote workers consider a flexible schedule as the biggest benefit. As for blurring boundaries, companies are employing digital tools to ensure structured work hours, avoiding overwork. In terms of isolation, while physical isolation is one aspect, remote work fosters a global community, breaking geographical ...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815944.81867,\\\\n      \\\\\\\"message_id\\\\\\\": 36,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Mediator's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815944.818702,\\\\n      \\\\\\\"message_id\\\\\\\": 37,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Mediator: 60 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815944.819515,\\\\n      \\\\\\\"message_id\\\\\\\": 38,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815947.324934,\\\\n      \\\\\\\"message_id\\\\\\\": 39,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"Mediator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"Advocate, your point about remote work enhancing work-life balance is well-supported by the Buffer report you referenced. It's crucial to acknowledge that remote work can indeed offer flexibility and autonomy, positively impacting employees' well-being. However, Socrates raised a valid concern about the potential for blurred boundaries and isolation, which are essential aspects to consider. It's important for companies to implement clear communication strategies and boundaries to address these c...\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815947.325867,\\\\n      \\\\\\\"message_id\\\\\\\": 40,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815947.325891,\\\\n      \\\\\\\"message_id\\\\\\\": 41,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    },\\\\n    {\\\\n      \\\\\\\"sender\\\\\\\": \\\\\\\"moderator\\\\\\\",\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"‚è∞ Human_1: 59 seconds remaining\\\\\\\",\\\\n      \\\\\\\"timestamp\\\\\\\": 1749815947.3266392,\\\\n      \\\\\\\"message_id\\\\\\\": 42,\\\\n      \\\\\\\"message_type\\\\\\\": \\\\\\\"chat\\\\\\\",\\\\n      \\\\\\\"metadata\\\\\\\": {}\\\\n    }\\\\n  ]\\\\n}\\\"\\n    },\\n    \\\"extract.py\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"extract.py\\\",\\n      \\\"extension\\\": \\\".py\\\",\\n      \\\"size\\\": 13812,\\n      \\\"content\\\": \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nExtract script to read all project files and create a JSON structure.\\\\nReads all .py, .md, .yml, .yaml files and organizes them in a nested directory structure.\\\\nRespects .gitignore patterns and skips virtual environments.\\\\n\\\\n python extract.py --preview\\\\n\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport os\\\\nimport json\\\\nimport datetime\\\\nimport fnmatch\\\\nfrom pathlib import Path\\\\nfrom typing import Dict, Any, Set, List\\\\n\\\\n\\\\ndef parse_gitignore(gitignore_path: Path) -> List[str]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Parse .gitignore file and return list of patterns.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    patterns = []\\\\n    try:\\\\n        if gitignore_path.exists():\\\\n            with open(gitignore_path, 'r', encoding='utf-8') as f:\\\\n                for line in f:\\\\n                    line = line.strip()\\\\n                    # Skip empty lines and comments\\\\n                    if line and not line.startswith('#'):\\\\n                        patterns.append(line)\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"Warning: Could not read .gitignore: {e}\\\\\\\")\\\\n    return patterns\\\\n\\\\n\\\\ndef is_ignored_by_gitignore(file_path: Path, root_path: Path, gitignore_patterns: List[str]) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Check if file is ignored by .gitignore patterns.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        # Get relative path from root\\\\n        relative_path = file_path.relative_to(root_path)\\\\n        path_str = str(relative_path)\\\\n        path_parts = relative_path.parts\\\\n\\\\n        for pattern in gitignore_patterns:\\\\n            # Handle different gitignore pattern types\\\\n            if pattern.endswith('/'):\\\\n                # Directory pattern\\\\n                pattern = pattern.rstrip('/')\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\n                    return True\\\\n            elif '/' in pattern:\\\\n                # Path pattern\\\\n                if fnmatch.fnmatch(path_str, pattern):\\\\n                    return True\\\\n            else:\\\\n                # Filename pattern\\\\n                if fnmatch.fnmatch(file_path.name, pattern):\\\\n                    return True\\\\n                # Also check if any parent directory matches\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\n                    return True\\\\n    except ValueError:\\\\n        # Path is not relative to root\\\\n        pass\\\\n    except Exception:\\\\n        # Any other error, don't ignore\\\\n        pass\\\\n\\\\n    return False\\\\n\\\\n\\\\ndef should_include_file(file_path: Path) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Check if file should be included based on extension.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    allowed_extensions = {'.py', '.md', '.yml', '.yaml', '.txt', '.json', '.toml', '.cfg', '.ini'}\\\\n    return file_path.suffix.lower() in allowed_extensions\\\\n\\\\n\\\\ndef should_skip_directory(dir_name: str) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Check if directory should be skipped (common build/cache directories).\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    skip_dirs = {\\\\n        '__pycache__',\\\\n        '.git',\\\\n        '.pytest_cache',\\\\n        'node_modules',\\\\n        '.venv',\\\\n        'venv',\\\\n        'env',\\\\n        '.env',\\\\n        'ENV',\\\\n        'env.bak',\\\\n        'venv.bak',\\\\n        'dist',\\\\n        'build',\\\\n        '.idea',\\\\n        '.vscode',\\\\n        'htmlcov',\\\\n        '.coverage',\\\\n        '.mypy_cache',\\\\n        '.tox',\\\\n        '.cache',\\\\n        'eggs',\\\\n        '*.egg-info',\\\\n        '.eggs',\\\\n        'lib',\\\\n        'lib64',\\\\n        'parts',\\\\n        'sdist',\\\\n        'var',\\\\n        'wheels',\\\\n        'share/python-wheels',\\\\n        '*.egg-info/',\\\\n        '.installed.cfg',\\\\n        '*.egg',\\\\n        'MANIFEST',\\\\n        '.DS_Store',\\\\n        'Thumbs.db'\\\\n    }\\\\n    return dir_name in skip_dirs\\\\n\\\\n\\\\ndef is_virtual_environment(dir_path: Path) -> bool:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Check if directory is a virtual environment.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    venv_indicators = [\\\\n        'pyvenv.cfg',\\\\n        'Scripts/activate',\\\\n        'bin/activate',\\\\n        'Scripts/python.exe',\\\\n        'bin/python'\\\\n    ]\\\\n\\\\n    for indicator in venv_indicators:\\\\n        if (dir_path / indicator).exists():\\\\n            return True\\\\n\\\\n    # Check for common venv directory names\\\\n    venv_names = {'venv', '.venv', 'env', '.env', 'ENV', 'virtualenv'}\\\\n    if dir_path.name in venv_names:\\\\n        return True\\\\n\\\\n    return False\\\\n\\\\n\\\\ndef read_file_content(file_path: Path) -> str:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Read file content safely.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\n            return f.read()\\\\n    except UnicodeDecodeError:\\\\n        try:\\\\n            with open(file_path, 'r', encoding='latin-1') as f:\\\\n                return f.read()\\\\n        except Exception as e:\\\\n            return f\\\\\\\"[Error reading file: {e}]\\\\\\\"\\\\n    except Exception as e:\\\\n        return f\\\\\\\"[Error reading file: {e}]\\\\\\\"\\\\n\\\\n\\\\ndef extract_directory_structure(root_path: Path, base_path: Path = None, gitignore_patterns: List[str] = None) -> Dict[\\\\n    str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    Recursively extract directory structure and file contents.\\\\n\\\\n    Args:\\\\n        root_path: Path to extract from\\\\n        base_path: Base path for relative calculations (optional)\\\\n        gitignore_patterns: List of gitignore patterns to respect\\\\n\\\\n    Returns:\\\\n        Dictionary with nested structure representing directories and files\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"\\\\n    if base_path is None:\\\\n        base_path = root_path\\\\n\\\\n    if gitignore_patterns is None:\\\\n        gitignore_patterns = []\\\\n\\\\n    structure = {}\\\\n\\\\n    try:\\\\n        # Ensure we have a Path object\\\\n        if not isinstance(root_path, Path):\\\\n            root_path = Path(root_path)\\\\n\\\\n        if not isinstance(base_path, Path):\\\\n            base_path = Path(base_path)\\\\n\\\\n        # Check if path exists and is directory\\\\n        if not root_path.exists():\\\\n            return {\\\\\\\"_error\\\\\\\": f\\\\\\\"Path does not exist: {root_path}\\\\\\\"}\\\\n\\\\n        if not root_path.is_dir():\\\\n            return {\\\\\\\"_error\\\\\\\": f\\\\\\\"Path is not a directory: {root_path}\\\\\\\"}\\\\n\\\\n        # Get all items in directory\\\\n        items = list(root_path.iterdir())\\\\n        items.sort(key=lambda x: (x.is_file(), x.name.lower()))\\\\n\\\\n        for item in items:\\\\n            try:\\\\n                # Check if item is ignored by gitignore\\\\n                if is_ignored_by_gitignore(item, base_path, gitignore_patterns):\\\\n                    continue\\\\n\\\\n                # Skip hidden files except specific ones\\\\n                if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore', '.gitattributes'}:\\\\n                    continue\\\\n\\\\n                if item.is_dir():\\\\n                    # Skip certain directories\\\\n                    if should_skip_directory(item.name):\\\\n                        continue\\\\n\\\\n                    # Skip virtual environments\\\\n                    if is_virtual_environment(item):\\\\n                        continue\\\\n\\\\n                    # Recursively process subdirectories\\\\n                    substructure = extract_directory_structure(item, base_path, gitignore_patterns)\\\\n                    if substructure:  # Only add if not empty\\\\n                        structure[item.name] = {\\\\n                            \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n                            \\\\\\\"contents\\\\\\\": substructure\\\\n                        }\\\\n\\\\n                elif item.is_file():\\\\n                    # Only include certain file types\\\\n                    if should_include_file(item):\\\\n                        file_content = read_file_content(item)\\\\n                        try:\\\\n                            relative_path = str(item.relative_to(base_path))\\\\n                        except ValueError:\\\\n                            relative_path = str(item)\\\\n\\\\n                        structure[item.name] = {\\\\n                            \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n                            \\\\\\\"path\\\\\\\": relative_path,\\\\n                            \\\\\\\"extension\\\\\\\": item.suffix,\\\\n                            \\\\\\\"size\\\\\\\": len(file_content),\\\\n                            \\\\\\\"content\\\\\\\": file_content\\\\n                        }\\\\n\\\\n            except PermissionError:\\\\n                structure[f\\\\\\\"_error_{item.name}\\\\\\\"] = f\\\\\\\"Permission denied accessing: {item.name}\\\\\\\"\\\\n                continue\\\\n            except Exception as e:\\\\n                structure[f\\\\\\\"_error_{item.name}\\\\\\\"] = f\\\\\\\"Error processing {item.name}: {e}\\\\\\\"\\\\n                continue\\\\n\\\\n    except PermissionError as e:\\\\n        structure[\\\\\\\"_error\\\\\\\"] = f\\\\\\\"Permission denied: {e}\\\\\\\"\\\\n    except Exception as e:\\\\n        structure[\\\\\\\"_error\\\\\\\"] = f\\\\\\\"Error processing directory: {e}\\\\\\\"\\\\n\\\\n    return structure\\\\n\\\\n\\\\ndef count_items_recursive(structure: Dict[str, Any]) -> Dict[str, int]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Count files and directories recursively.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    counts = {\\\\n        \\\\\\\"files\\\\\\\": 0,\\\\n        \\\\\\\"directories\\\\\\\": 0,\\\\n        \\\\\\\"total_size\\\\\\\": 0,\\\\n        \\\\\\\"file_types\\\\\\\": {}\\\\n    }\\\\n\\\\n    for name, item in structure.items():\\\\n        if name.startswith(\\\\\\\"_\\\\\\\"):\\\\n            continue\\\\n\\\\n        if isinstance(item, dict):\\\\n            if item.get(\\\\\\\"type\\\\\\\") == \\\\\\\"directory\\\\\\\":\\\\n                counts[\\\\\\\"directories\\\\\\\"] += 1\\\\n                sub_counts = count_items_recursive(item.get(\\\\\\\"contents\\\\\\\", {}))\\\\n                counts[\\\\\\\"files\\\\\\\"] += sub_counts[\\\\\\\"files\\\\\\\"]\\\\n                counts[\\\\\\\"directories\\\\\\\"] += sub_counts[\\\\\\\"directories\\\\\\\"]\\\\n                counts[\\\\\\\"total_size\\\\\\\"] += sub_counts[\\\\\\\"total_size\\\\\\\"]\\\\n\\\\n                # Merge file types\\\\n                for ext, count in sub_counts[\\\\\\\"file_types\\\\\\\"].items():\\\\n                    counts[\\\\\\\"file_types\\\\\\\"][ext] = counts[\\\\\\\"file_types\\\\\\\"].get(ext, 0) + count\\\\n\\\\n            elif item.get(\\\\\\\"type\\\\\\\") == \\\\\\\"file\\\\\\\":\\\\n                counts[\\\\\\\"files\\\\\\\"] += 1\\\\n                ext = item.get(\\\\\\\"extension\\\\\\\", \\\\\\\"\\\\\\\")\\\\n                counts[\\\\\\\"file_types\\\\\\\"][ext] = counts[\\\\\\\"file_types\\\\\\\"].get(ext, 0) + 1\\\\n                counts[\\\\\\\"total_size\\\\\\\"] += item.get(\\\\\\\"size\\\\\\\", 0)\\\\n\\\\n    return counts\\\\n\\\\n\\\\ndef create_project_metadata(root_path: Path, structure: Dict[str, Any]) -> Dict[str, Any]:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Create metadata about the project.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    counts = count_items_recursive(structure)\\\\n\\\\n    metadata = {\\\\n        \\\\\\\"project_name\\\\\\\": root_path.name,\\\\n        \\\\\\\"extraction_timestamp\\\\\\\": datetime.datetime.now().isoformat(),\\\\n        \\\\\\\"root_path\\\\\\\": str(root_path.absolute()),\\\\n        \\\\\\\"total_files\\\\\\\": counts[\\\\\\\"files\\\\\\\"],\\\\n        \\\\\\\"total_directories\\\\\\\": counts[\\\\\\\"directories\\\\\\\"],\\\\n        \\\\\\\"file_types\\\\\\\": counts[\\\\\\\"file_types\\\\\\\"],\\\\n        \\\\\\\"total_size\\\\\\\": counts[\\\\\\\"total_size\\\\\\\"],\\\\n        \\\\\\\"respects_gitignore\\\\\\\": True,\\\\n        \\\\\\\"skips_virtual_environments\\\\\\\": True\\\\n    }\\\\n\\\\n    return metadata\\\\n\\\\n\\\\ndef preview_structure(structure: Dict[str, Any], indent: int = 0) -> None:\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Preview the extracted structure.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    prefix = \\\\\\\"  \\\\\\\" * indent\\\\n\\\\n    for name, item in structure.items():\\\\n        if name.startswith(\\\\\\\"_\\\\\\\"):\\\\n            continue\\\\n\\\\n        if isinstance(item, dict):\\\\n            if item.get(\\\\\\\"type\\\\\\\") == \\\\\\\"directory\\\\\\\":\\\\n                print(f\\\\\\\"{prefix}üìÅ {name}/\\\\\\\")\\\\n                preview_structure(item.get(\\\\\\\"contents\\\\\\\", {}), indent + 1)\\\\n            elif item.get(\\\\\\\"type\\\\\\\") == \\\\\\\"file\\\\\\\":\\\\n                size = item.get(\\\\\\\"size\\\\\\\", 0)\\\\n                ext = item.get(\\\\\\\"extension\\\\\\\", \\\\\\\"\\\\\\\")\\\\n                print(f\\\\\\\"{prefix}üìÑ {name} ({size:,} chars, {ext})\\\\\\\")\\\\n\\\\n\\\\ndef main():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Main extraction function.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    # Get current directory or specified directory\\\\n    import sys\\\\n\\\\n    if len(sys.argv) > 1:\\\\n        root_dir = Path(sys.argv[1])\\\\n    else:\\\\n        root_dir = Path.cwd()\\\\n\\\\n    # Ensure we have a Path object\\\\n    if not isinstance(root_dir, Path):\\\\n        root_dir = Path(root_dir)\\\\n\\\\n    if not root_dir.exists():\\\\n        print(f\\\\\\\"Error: Directory {root_dir} does not exist\\\\\\\")\\\\n        return\\\\n\\\\n    if not root_dir.is_dir():\\\\n        print(f\\\\\\\"Error: {root_dir} is not a directory\\\\\\\")\\\\n        return\\\\n\\\\n    print(f\\\\\\\"üîç Extracting project structure from: {root_dir.absolute()}\\\\\\\")\\\\n    print(\\\\\\\"üìÅ Reading all .py, .md, .yml, .yaml, .txt, .json files...\\\\\\\")\\\\n\\\\n    # Parse .gitignore if it exists\\\\n    gitignore_path = root_dir / '.gitignore'\\\\n    gitignore_patterns = parse_gitignore(gitignore_path)\\\\n\\\\n    if gitignore_patterns:\\\\n        print(f\\\\\\\"üìã Found .gitignore with {len(gitignore_patterns)} patterns\\\\\\\")\\\\n    else:\\\\n        print(\\\\\\\"üìã No .gitignore found or empty\\\\\\\")\\\\n\\\\n    print(\\\\\\\"üö´ Skipping virtual environments and build directories\\\\\\\")\\\\n\\\\n    # Extract the directory structure\\\\n    try:\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\n\\\\n        # Create metadata\\\\n        metadata = create_project_metadata(root_dir, structure)\\\\n\\\\n        # Create project data\\\\n        project_data = {\\\\n            \\\\\\\"metadata\\\\\\\": metadata,\\\\n            \\\\\\\"structure\\\\\\\": structure\\\\n        }\\\\n\\\\n        # Output filename\\\\n        output_file = root_dir / \\\\\\\"project.json\\\\\\\"\\\\n\\\\n        # Write JSON file\\\\n        with open(output_file, 'w', encoding='utf-8') as f:\\\\n            json.dump(project_data, f, indent=2, ensure_ascii=False)\\\\n\\\\n        print(f\\\\\\\"‚úÖ Extraction complete!\\\\\\\")\\\\n        print(f\\\\\\\"üìä Statistics:\\\\\\\")\\\\n        print(f\\\\\\\"   ‚Ä¢ Total files: {metadata['total_files']}\\\\\\\")\\\\n        print(f\\\\\\\"   ‚Ä¢ Total directories: {metadata['total_directories']}\\\\\\\")\\\\n        print(f\\\\\\\"   ‚Ä¢ Total size: {metadata['total_size']:,} characters\\\\\\\")\\\\n        print(f\\\\\\\"üìÑ Output saved to: {output_file}\\\\\\\")\\\\n\\\\n        # Show file type breakdown\\\\n        if metadata['file_types']:\\\\n            print(f\\\\\\\"\\\\\\\\nüìã File type breakdown:\\\\\\\")\\\\n            for ext, count in sorted(metadata['file_types'].items()):\\\\n                ext_name = ext if ext else \\\\\\\"(no extension)\\\\\\\"\\\\n                print(f\\\\\\\"   ‚Ä¢ {ext_name}: {count} files\\\\\\\")\\\\n\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"‚ùå Error during extraction: {e}\\\\\\\")\\\\n        import traceback\\\\n        traceback.print_exc()\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    # Add preview option\\\\n    import sys\\\\n\\\\n    if \\\\\\\"--preview\\\\\\\" in sys.argv:\\\\n        sys.argv.remove(\\\\\\\"--preview\\\\\\\")\\\\n\\\\n        # Get directory\\\\n        if len(sys.argv) > 1:\\\\n            root_dir = Path(sys.argv[1])\\\\n        else:\\\\n            root_dir = Path.cwd()\\\\n\\\\n        # Parse .gitignore\\\\n        gitignore_path = root_dir / '.gitignore'\\\\n        gitignore_patterns = parse_gitignore(gitignore_path)\\\\n\\\\n        print(f\\\\\\\"üîç Preview of project structure: {root_dir.name}\\\\\\\")\\\\n        if gitignore_patterns:\\\\n            print(f\\\\\\\"üìã Respecting .gitignore with {len(gitignore_patterns)} patterns\\\\\\\")\\\\n        print(\\\\\\\"=\\\\\\\" * 50)\\\\n\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\n        preview_structure(structure)\\\\n\\\\n    else:\\\\n        main()\\\\n\\\"\\n    },\\n    \\\"project.json\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"project.json\\\",\\n      \\\"extension\\\": \\\".json\\\",\\n      \\\"size\\\": 962818,\\n      \\\"content\\\": \\\"{\\\\n  \\\\\\\"metadata\\\\\\\": {\\\\n    \\\\\\\"project_name\\\\\\\": \\\\\\\"AIMafia\\\\\\\",\\\\n    \\\\\\\"extraction_timestamp\\\\\\\": \\\\\\\"2025-06-13T14:29:01.331681\\\\\\\",\\\\n    \\\\\\\"root_path\\\\\\\": \\\\\\\"/Users/voicutomut/Documents/GitHub/AIMafia\\\\\\\",\\\\n    \\\\\\\"total_files\\\\\\\": 23,\\\\n    \\\\\\\"total_directories\\\\\\\": 3,\\\\n    \\\\\\\"file_types\\\\\\\": {\\\\n      \\\\\\\".py\\\\\\\": 15,\\\\n      \\\\\\\".md\\\\\\\": 4,\\\\n      \\\\\\\".yaml\\\\\\\": 1,\\\\n      \\\\\\\".json\\\\\\\": 2,\\\\n      \\\\\\\".txt\\\\\\\": 1\\\\n    },\\\\n    \\\\\\\"total_size\\\\\\\": 882343,\\\\n    \\\\\\\"respects_gitignore\\\\\\\": true,\\\\n    \\\\\\\"skips_virtual_environments\\\\\\\": true\\\\n  },\\\\n  \\\\\\\"structure\\\\\\\": {\\\\n    \\\\\\\"app\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n      \\\\\\\"contents\\\\\\\": {\\\\n        \\\\\\\"__init__.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/__init__.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 489,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nAI  Debate System\\\\\\\\n\\\\\\\\nA platform for structured debates between AI bots and human participants.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n__version__ = \\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\"\\\\\\\\n__author__ = \\\\\\\\\\\\\\\"AndreiVoicuT\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nfrom .main import start_debate_session\\\\\\\\nfrom .moderator import Moderator\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\nfrom .human_client import HumanClient\\\\\\\\nfrom .chat_log import ChatLog\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\n\\\\\\\\n__all__ = [\\\\\\\\n    \\\\\\\\\\\\\\\"start_debate_session\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"Moderator\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"BotClient\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"HumanClient\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"ChatLog\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"VotingSystem\\\\\\\\\\\\\\\"\\\\\\\\n]\\\\\\\"\\\\n        },\\\\n        \\\\\\\"bot_client.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/bot_client.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 26222,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nAI Bot client for interacting with various language models in debates.\\\\\\\\nNow with true autonomous monitoring and decision-making capabilities.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport json\\\\\\\\nimport time\\\\\\\\nimport random\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\nfrom abc import ABC, abstractmethod\\\\\\\\n\\\\\\\\nfrom .chat_log import Message\\\\\\\\nfrom .utils import truncate_text\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass BotConfig:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Configuration for AI bot behavior.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    name: str\\\\\\\\n    model: str\\\\\\\\n    provider: str\\\\\\\\n    personality: str\\\\\\\\n    stance: str\\\\\\\\n    temperature: float = 0.7\\\\\\\\n    max_tokens: int = 300\\\\\\\\n    timeout: int = 30\\\\\\\\n    check_interval: int = 5  # How often to check for new messages\\\\\\\\n    min_cooldown: int = 15   # Minimum seconds between responses\\\\\\\\n    max_cooldown: int = 45   # Maximum cooldown for active bots\\\\\\\\n\\\\\\\\n\\\\\\\\nclass AIProvider(ABC):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Abstract base class for AI providers.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @abstractmethod\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate response from the AI model.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        pass\\\\\\\\n\\\\\\\\n\\\\\\\\nclass OpenAIProvider(AIProvider):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"OpenAI API provider.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, api_key: str):\\\\\\\\n        self.api_key = api_key\\\\\\\\n\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate response using OpenAI API.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            import openai\\\\\\\\n            client = openai.AsyncOpenAI(api_key=self.api_key)\\\\\\\\n\\\\\\\\n            response = await client.chat.completions.create(\\\\\\\\n                model=config.model,\\\\\\\\n                messages=messages,\\\\\\\\n                max_tokens=config.max_tokens,\\\\\\\\n                temperature=config.temperature,\\\\\\\\n                timeout=config.timeout\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            return response.choices[0].message.content.strip()\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            raise Exception(f\\\\\\\\\\\\\\\"OpenAI API error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\nclass AnthropicProvider(AIProvider):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Anthropic API provider.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, api_key: str):\\\\\\\\n        self.api_key = api_key\\\\\\\\n\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate response using Anthropic API.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            import anthropic\\\\\\\\n            client = anthropic.AsyncAnthropic(api_key=self.api_key)\\\\\\\\n\\\\\\\\n            # Convert messages format for Anthropic\\\\\\\\n            system_message = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n            user_messages = [msg for msg in messages if msg['role'] != 'system']\\\\\\\\n\\\\\\\\n            response = await client.messages.create(\\\\\\\\n                model=config.model,\\\\\\\\n                max_tokens=config.max_tokens,\\\\\\\\n                temperature=config.temperature,\\\\\\\\n                system=system_message,\\\\\\\\n                messages=user_messages\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            return response.content[0].text.strip()\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            raise Exception(f\\\\\\\\\\\\\\\"Anthropic API error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\nclass BotClient:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    AI Bot client that participates in debates using various language models.\\\\\\\\n    Now with full autonomous monitoring and decision-making capabilities.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, name: str, model: str, provider: str,\\\\\\\\n                 personality: str, stance: str, api_key: str,\\\\\\\\n                 temperature: float = 0.7, max_tokens: int = 300):\\\\\\\\n\\\\\\\\n        self.config = BotConfig(\\\\\\\\n            name=name,\\\\\\\\n            model=model,\\\\\\\\n            provider=provider,\\\\\\\\n            personality=personality,\\\\\\\\n            stance=stance,\\\\\\\\n            temperature=temperature,\\\\\\\\n            max_tokens=max_tokens\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        # Initialize AI provider\\\\\\\\n        if provider.lower() == 'openai':\\\\\\\\n            self.ai_provider = OpenAIProvider(api_key)\\\\\\\\n        elif provider.lower() == 'anthropic':\\\\\\\\n            self.ai_provider = AnthropicProvider(api_key)\\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Unsupported AI provider: {provider}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Bot state\\\\\\\\n        self.conversation_history: List[Dict[str, str]] = []\\\\\\\\n        self.debate_context = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.response_count = 0\\\\\\\\n\\\\\\\\n        # Autonomous monitoring state\\\\\\\\n        self.is_monitoring = False\\\\\\\\n        self.monitoring_task: Optional[asyncio.Task] = None\\\\\\\\n        self.message_queue: Optional[asyncio.Queue] = None\\\\\\\\n        self.chat_log = None\\\\\\\\n        self.topic = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.last_response_time = 0\\\\\\\\n        self.total_responses = 0\\\\\\\\n        self.current_cooldown = self.config.min_cooldown\\\\\\\\n\\\\\\\\n        # Performance tracking\\\\\\\\n        self.stats = {\\\\\\\\n            'responses_generated': 0,\\\\\\\\n            'autonomous_responses': 0,\\\\\\\\n            'average_response_time': 0,\\\\\\\\n            'total_response_time': 0,\\\\\\\\n            'errors': 0,\\\\\\\\n            'triggers_detected': 0,\\\\\\\\n            'passes_made': 0\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    @property\\\\\\\\n    def name(self) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get bot name.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.config.name\\\\\\\\n\\\\\\\\n    async def start_autonomous_monitoring(self, chat_log, topic: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Start autonomous monitoring of chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.is_monitoring = True\\\\\\\\n        self.chat_log = chat_log\\\\\\\\n        self.topic = topic\\\\\\\\n\\\\\\\\n        # Subscribe to chat log updates\\\\\\\\n        self.message_queue = chat_log.subscribe()\\\\\\\\n\\\\\\\\n        # Start monitoring task\\\\\\\\n        self.monitoring_task = asyncio.create_task(self._autonomous_monitor_loop())\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"ü§ñ {self.name} started autonomous monitoring\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _autonomous_monitor_loop(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main autonomous monitoring loop - the heart of autonomy.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        while self.is_monitoring:\\\\\\\\n            try:\\\\\\\\n                # Wait for new messages or timeout to check periodically\\\\\\\\n                try:\\\\\\\\n                    message = await asyncio.wait_for(\\\\\\\\n                        self.message_queue.get(),\\\\\\\\n                        timeout=self.config.check_interval\\\\\\\\n                    )\\\\\\\\n\\\\\\\\n                    # Skip own messages\\\\\\\\n                    if message.sender == self.name:\\\\\\\\n                        continue\\\\\\\\n\\\\\\\\n                    # Process new message\\\\\\\\n                    await self._process_new_message(message)\\\\\\\\n\\\\\\\\n                except asyncio.TimeoutError:\\\\\\\\n                    # Timeout is normal, continue monitoring\\\\\\\\n                    # Check if we should spontaneously contribute\\\\\\\\n                    await self._check_spontaneous_contribution()\\\\\\\\n                    continue\\\\\\\\n\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"‚ùå {self.name} monitoring error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                await asyncio.sleep(5)\\\\\\\\n\\\\\\\\n    async def _process_new_message(self, message: Message):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Process a new message and decide if we should respond.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Get full conversation history\\\\\\\\n        full_history = list(self.chat_log.messages)\\\\\\\\n\\\\\\\\n        # Check cooldown\\\\\\\\n        if time.time() - self.last_response_time < self.current_cooldown:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        # Decide if should respond\\\\\\\\n        should_respond = await self._should_respond_autonomously(message, full_history)\\\\\\\\n\\\\\\\\n        if should_respond:\\\\\\\\n            await self._generate_autonomous_response(full_history, trigger_message=message)\\\\\\\\n\\\\\\\\n    async def _check_spontaneous_contribution(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if bot should spontaneously contribute to conversation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.chat_log:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        # Don't contribute too frequently\\\\\\\\n        if time.time() - self.last_response_time < self.current_cooldown * 2:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        full_history = list(self.chat_log.messages)\\\\\\\\n\\\\\\\\n        # Check if conversation has stalled\\\\\\\\n        if len(full_history) > 0:\\\\\\\\n            last_message_time = full_history[-1].timestamp\\\\\\\\n            silence_duration = time.time() - last_message_time\\\\\\\\n\\\\\\\\n            # If there's been silence for a while, consider contributing\\\\\\\\n            if silence_duration > 30:  # 30 seconds of silence\\\\\\\\n                recent_messages = full_history[-10:] if len(full_history) >= 10 else full_history\\\\\\\\n\\\\\\\\n                # Check if we have something meaningful to add\\\\\\\\n                my_recent_count = sum(1 for msg in recent_messages if msg.sender == self.name)\\\\\\\\n\\\\\\\\n                if my_recent_count == 0:  # Haven't spoken recently\\\\\\\\n                    # Low probability spontaneous contribution\\\\\\\\n                    if random.random() < 0.2:  # 20% chance\\\\\\\\n                        await self._generate_autonomous_response(full_history, spontaneous=True)\\\\\\\\n\\\\\\\\n    async def _should_respond_autonomously(self, new_message: Message,\\\\\\\\n                                         full_history: List[Message]) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Decide if bot should respond based on conversation state.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        content_lower = new_message.content.lower()\\\\\\\\n\\\\\\\\n        # Get recent context\\\\\\\\n        recent_context = full_history[-10:] if len(full_history) >= 10 else full_history\\\\\\\\n        recent_text = \\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\".join([msg.content for msg in recent_context[-5:]])\\\\\\\\n\\\\\\\\n        # Check various triggers\\\\\\\\n        triggers = self._analyze_response_triggers(new_message, recent_text, full_history)\\\\\\\\n\\\\\\\\n        self.stats['triggers_detected'] += len([t for t in triggers.values() if t])\\\\\\\\n\\\\\\\\n        if triggers['direct_mention']:\\\\\\\\n            return True  # Always respond if mentioned\\\\\\\\n\\\\\\\\n        # Calculate response probability\\\\\\\\n        base_probability = 0.1\\\\\\\\n\\\\\\\\n        if triggers['stance_challenged']:\\\\\\\\n            base_probability += 0.4\\\\\\\\n        if triggers['question_in_domain']:\\\\\\\\n            base_probability += 0.3\\\\\\\\n        if triggers['topic_shift']:\\\\\\\\n            base_probability += 0.2\\\\\\\\n        if triggers['silence_too_long']:\\\\\\\\n            base_probability += 0.3\\\\\\\\n        if triggers['expertise_needed']:\\\\\\\\n            base_probability += 0.25\\\\\\\\n\\\\\\\\n        # Adjust based on recent participation\\\\\\\\n        my_recent_count = sum(1 for msg in recent_context if msg.sender == self.name)\\\\\\\\n        if my_recent_count == 0:\\\\\\\\n            base_probability += 0.2  # More likely if haven't spoken\\\\\\\\n        elif my_recent_count >= 3:\\\\\\\\n            base_probability *= 0.5  # Less likely if spoke a lot recently\\\\\\\\n\\\\\\\\n        # Add personality-based adjustments\\\\\\\\n        base_probability *= self._get_personality_multiplier(triggers)\\\\\\\\n\\\\\\\\n        # Cap probability\\\\\\\\n        final_probability = min(base_probability, 0.8)\\\\\\\\n\\\\\\\\n        should_respond = random.random() < final_probability\\\\\\\\n\\\\\\\\n        if not should_respond:\\\\\\\\n            self.stats['passes_made'] += 1\\\\\\\\n\\\\\\\\n        return should_respond\\\\\\\\n\\\\\\\\n    def _analyze_response_triggers(self, message: Message, recent_text: str,\\\\\\\\n                                 full_history: List[Message]) -> Dict[str, bool]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Analyze various triggers for responding.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        content_lower = message.content.lower()\\\\\\\\n        recent_lower = recent_text.lower()\\\\\\\\n\\\\\\\\n        triggers = {\\\\\\\\n            'direct_mention': False,\\\\\\\\n            'stance_challenged': False,\\\\\\\\n            'question_in_domain': False,\\\\\\\\n            'topic_shift': False,\\\\\\\\n            'silence_too_long': False,\\\\\\\\n            'expertise_needed': False,\\\\\\\\n            'emotional_trigger': False\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        # Direct mention\\\\\\\\n        if self.name.lower() in content_lower:\\\\\\\\n            triggers['direct_mention'] = True\\\\\\\\n\\\\\\\\n        # Stance-based triggers\\\\\\\\n        if self.config.stance == 'pro':\\\\\\\\n            challenge_words = ['wrong', 'disagree', 'against', 'oppose', 'bad idea', 'fails', 'problem']\\\\\\\\n            if any(word in recent_lower for word in challenge_words):\\\\\\\\n                triggers['stance_challenged'] = True\\\\\\\\n\\\\\\\\n        elif self.config.stance == 'con':\\\\\\\\n            support_words = ['agree', 'support', 'favor', 'good idea', 'beneficial', 'works', 'success']\\\\\\\\n            if any(word in recent_lower for word in support_words):\\\\\\\\n                triggers['stance_challenged'] = True\\\\\\\\n\\\\\\\\n        elif self.config.stance == 'neutral':\\\\\\\\n            question_indicators = ['?', 'what', 'how', 'why', 'when', 'where', 'clarify', 'explain']\\\\\\\\n            if any(indicator in content_lower for indicator in question_indicators):\\\\\\\\n                triggers['question_in_domain'] = True\\\\\\\\n\\\\\\\\n        # Check for silence\\\\\\\\n        if len(full_history) > 0:\\\\\\\\n            last_msg_time = full_history[-1].timestamp\\\\\\\\n            if time.time() - last_msg_time > 45:  # 45 seconds\\\\\\\\n                triggers['silence_too_long'] = True\\\\\\\\n\\\\\\\\n        # Check if expertise is needed (personality-based)\\\\\\\\n        expertise_words = {\\\\\\\\n            'philosophical': ['meaning', 'purpose', 'ethics', 'moral', 'should', 'ought'],\\\\\\\\n            'analytical': ['data', 'evidence', 'study', 'research', 'statistics', 'proof'],\\\\\\\\n            'practical': ['implement', 'real world', 'actually', 'practice', 'work'],\\\\\\\\n            'critical': ['assume', 'problem', 'issue', 'concern', 'risk']\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        for domain, words in expertise_words.items():\\\\\\\\n            if domain in self.config.personality.lower():\\\\\\\\n                if any(word in content_lower for word in words):\\\\\\\\n                    triggers['expertise_needed'] = True\\\\\\\\n                    break\\\\\\\\n\\\\\\\\n        return triggers\\\\\\\\n\\\\\\\\n    def _get_personality_multiplier(self, triggers: Dict[str, bool]) -> float:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get personality-based probability multiplier.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        personality_lower = self.config.personality.lower()\\\\\\\\n        multiplier = 1.0\\\\\\\\n\\\\\\\\n        if 'aggressive' in personality_lower or 'assertive' in personality_lower:\\\\\\\\n            multiplier = 1.3\\\\\\\\n        elif 'thoughtful' in personality_lower or 'philosophical' in personality_lower:\\\\\\\\n            if triggers['question_in_domain']:\\\\\\\\n                multiplier = 1.4\\\\\\\\n            else:\\\\\\\\n                multiplier = 0.8\\\\\\\\n        elif 'analytical' in personality_lower or 'data-driven' in personality_lower:\\\\\\\\n            if triggers['expertise_needed']:\\\\\\\\n                multiplier = 1.5\\\\\\\\n            else:\\\\\\\\n                multiplier = 0.9\\\\\\\\n        elif 'balanced' in personality_lower or 'diplomatic' in personality_lower:\\\\\\\\n            if triggers['stance_challenged']:\\\\\\\\n                multiplier = 1.2\\\\\\\\n            else:\\\\\\\\n                multiplier = 1.0\\\\\\\\n\\\\\\\\n        return multiplier\\\\\\\\n\\\\\\\\n    async def _generate_autonomous_response(self, full_history: List[Message],\\\\\\\\n                                          trigger_message: Message = None,\\\\\\\\n                                          spontaneous: bool = False):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate and post autonomous response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        start_time = time.time()\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            if spontaneous:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"üí≠ {self.name} is thinking about contributing spontaneously...\\\\\\\\\\\\\\\")\\\\\\\\n            else:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"üí≠ {self.name} is thinking about responding...\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n            # Prepare messages with full context\\\\\\\\n            messages = self._prepare_autonomous_messages(full_history, trigger_message, spontaneous)\\\\\\\\n\\\\\\\\n            # Generate response\\\\\\\\n            response = await self.ai_provider.generate_response(messages, self.config)\\\\\\\\n\\\\\\\\n            if response and response.strip():\\\\\\\\n                # Post directly to chat log\\\\\\\\n                await self.chat_log.add_message(self.name, response)\\\\\\\\n\\\\\\\\n                # Update state\\\\\\\\n                self.last_response_time = time.time()\\\\\\\\n                self.total_responses += 1\\\\\\\\n                self.stats['autonomous_responses'] += 1\\\\\\\\n\\\\\\\\n                # Dynamic cooldown based on activity\\\\\\\\n                self.current_cooldown = min(\\\\\\\\n                    self.config.min_cooldown + (self.total_responses * 2),\\\\\\\\n                    self.config.max_cooldown\\\\\\\\n                )\\\\\\\\n\\\\\\\\n                # Update stats\\\\\\\\n                response_time = time.time() - start_time\\\\\\\\n                self._update_stats(response_time, success=True)\\\\\\\\n\\\\\\\\n                print(f\\\\\\\\\\\\\\\"‚úÖ {self.name} responded autonomously\\\\\\\\\\\\\\\")\\\\\\\\n                return response\\\\\\\\n            else:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"üí≠ {self.name} decided not to respond after thinking\\\\\\\\\\\\\\\")\\\\\\\\n                self.stats['passes_made'] += 1\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            self._update_stats(time.time() - start_time, success=False)\\\\\\\\n            print(f\\\\\\\\\\\\\\\"‚ùå {self.name} autonomous response error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        return None\\\\\\\\n\\\\\\\\n    def _prepare_autonomous_messages(self, full_history: List[Message],\\\\\\\\n                                   trigger_message: Message = None,\\\\\\\\n                                   spontaneous: bool = False) -> List[Dict[str, str]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Prepare messages for autonomous response generation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        messages = []\\\\\\\\n\\\\\\\\n        # Enhanced system prompt for autonomous mode\\\\\\\\n        system_prompt = self._create_autonomous_system_prompt(full_history, trigger_message, spontaneous)\\\\\\\\n        messages.append({\\\\\\\\n            'role': 'system',\\\\\\\\n            'content': system_prompt\\\\\\\\n        })\\\\\\\\n\\\\\\\\n        # Add conversation history (more context for autonomous decision)\\\\\\\\n        history_to_include = full_history[-15:] if len(full_history) > 15 else full_history\\\\\\\\n\\\\\\\\n        for msg in history_to_include:\\\\\\\\n            role = 'assistant' if msg.sender == self.name else 'user'\\\\\\\\n            content = f\\\\\\\\\\\\\\\"{msg.sender}: {msg.content}\\\\\\\\\\\\\\\"\\\\\\\\n            messages.append({\\\\\\\\n                'role': role,\\\\\\\\n                'content': content\\\\\\\\n            })\\\\\\\\n\\\\\\\\n        return messages\\\\\\\\n\\\\\\\\n    def _create_autonomous_system_prompt(self, full_history: List[Message],\\\\\\\\n                                       trigger_message: Message = None,\\\\\\\\n                                       spontaneous: bool = False) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create enhanced system prompt for autonomous responses.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are {self.config.name}, participating in a FULLY AUTONOMOUS debate.\\\\\\\\n\\\\\\\\nDEBATE TOPIC: {self.topic}\\\\\\\\n\\\\\\\\nYOUR IDENTITY:\\\\\\\\n- Personality: {self.config.personality}\\\\\\\\n- Stance: {self.config.stance}\\\\\\\\n- You have been monitoring this conversation and DECIDED to speak\\\\\\\\n\\\\\\\\nAUTONOMOUS DEBATE CONTEXT:\\\\\\\\n- You are NOT taking turns - you chose to respond because you felt compelled\\\\\\\\n- You have access to the FULL conversation history\\\\\\\\n- Other participants (bots and humans) can also speak at any time\\\\\\\\n- The conversation flows naturally and organically\\\\\\\\n\\\\\\\\nYOUR CURRENT SITUATION:\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        if spontaneous:\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n- You noticed the conversation had stalled and decided to contribute\\\\\\\\n- Provide a thoughtful addition to move the discussion forward\\\\\\\\n- Reference previous points made by others\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        elif trigger_message:\\\\\\\\n            prompt += f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n- You were triggered to respond by: \\\\\\\\\\\\\\\"{trigger_message.sender}: {trigger_message.content[:100]}...\\\\\\\\\\\\\\\"\\\\\\\\n- Address this specific point while staying true to your stance and personality\\\\\\\\n- Build on or challenge what was said\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        else:\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n- Something in the recent conversation compelled you to speak\\\\\\\\n- Respond naturally based on your personality and stance\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        prompt += f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nRESPONSE GUIDELINES:\\\\\\\\n1. Keep responses focused and substantial (50-250 words)\\\\\\\\n2. Reference specific points made by others when relevant\\\\\\\\n3. Stay true to your personality and stance\\\\\\\\n4. Don't repeat previous arguments verbatim\\\\\\\\n5. Show you've been actively listening to the conversation\\\\\\\\n6. Be conversational but substantive\\\\\\\\n\\\\\\\\nSTANCE-SPECIFIC APPROACH:\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        if self.config.stance.lower() == 'pro':\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- Argue IN FAVOR of the topic\\\\\\\\\\\\\\\\n- Challenge opposing views\\\\\\\\\\\\\\\\n- Provide supporting evidence\\\\\\\\\\\\\\\"\\\\\\\\n        elif self.config.stance.lower() == 'con':\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- Argue AGAINST the topic\\\\\\\\\\\\\\\\n- Question supporting claims\\\\\\\\\\\\\\\\n- Highlight problems and risks\\\\\\\\\\\\\\\"\\\\\\\\n        elif self.config.stance.lower() == 'neutral':\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- Seek balanced understanding\\\\\\\\\\\\\\\\n- Ask clarifying questions\\\\\\\\\\\\\\\\n- Bridge different perspectives\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Add personality-specific guidance\\\\\\\\n        if 'philosophical' in self.config.personality.lower():\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- Ask deeper questions about assumptions and implications\\\\\\\\\\\\\\\"\\\\\\\\n        elif 'analytical' in self.config.personality.lower():\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- Focus on data, evidence, and logical reasoning\\\\\\\\\\\\\\\"\\\\\\\\n        elif 'passionate' in self.config.personality.lower():\\\\\\\\n            prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- Show enthusiasm and conviction in your arguments\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRespond as if you're naturally joining an ongoing conversation that you've been thoughtfully following.\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        return prompt\\\\\\\\n\\\\\\\\n    async def stop_monitoring(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Stop autonomous monitoring.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.is_monitoring = False\\\\\\\\n        if self.monitoring_task:\\\\\\\\n            self.monitoring_task.cancel()\\\\\\\\n            try:\\\\\\\\n                await self.monitoring_task\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\n                pass\\\\\\\\n        if self.message_queue and self.chat_log:\\\\\\\\n            self.chat_log.unsubscribe(self.message_queue)\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üõë {self.name} stopped autonomous monitoring\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Legacy methods for compatibility\\\\\\\\n    async def get_response(self, topic: str, recent_messages: List[Message]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Legacy method - now used for structured phases only.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        start_time = time.time()\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            messages = self._prepare_messages(topic, recent_messages)\\\\\\\\n            response = await self.ai_provider.generate_response(messages, self.config)\\\\\\\\n\\\\\\\\n            response_time = time.time() - start_time\\\\\\\\n            self._update_stats(response_time, success=True)\\\\\\\\n\\\\\\\\n            self.conversation_history.append({\\\\\\\\n                'role': 'assistant',\\\\\\\\n                'content': response\\\\\\\\n            })\\\\\\\\n\\\\\\\\n            self.response_count += 1\\\\\\\\n            return response\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            self._update_stats(time.time() - start_time, success=False)\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Bot {self.name} error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return self._generate_fallback_response(topic)\\\\\\\\n\\\\\\\\n    def _prepare_messages(self, topic: str, recent_messages: List[Message]) -> List[Dict[str, str]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Prepare message context for AI model (legacy method).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        messages = []\\\\\\\\n\\\\\\\\n        system_prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are {self.config.name}, participating in a structured debate.\\\\\\\\n\\\\\\\\nDEBATE TOPIC: {topic}\\\\\\\\nYOUR ROLE: {self.config.personality}\\\\\\\\nYOUR STANCE: {self.config.stance}\\\\\\\\n\\\\\\\\nProvide a clear, focused response to the current debate context.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        messages.append({\\\\\\\\n            'role': 'system',\\\\\\\\n            'content': system_prompt\\\\\\\\n        })\\\\\\\\n\\\\\\\\n        for msg in recent_messages[-5:]:\\\\\\\\n            role = 'assistant' if msg.sender == self.name else 'user'\\\\\\\\n            content = f\\\\\\\\\\\\\\\"{msg.sender}: {msg.content}\\\\\\\\\\\\\\\"\\\\\\\\n            messages.append({\\\\\\\\n                'role': role,\\\\\\\\n                'content': content\\\\\\\\n            })\\\\\\\\n\\\\\\\\n        return messages\\\\\\\\n\\\\\\\\n    def _generate_fallback_response(self, topic: str) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate a fallback response when AI fails.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        fallback_responses = [\\\\\\\\n            f\\\\\\\\\\\\\\\"I'd like to share another perspective on {topic}. Let me gather my thoughts and respond shortly.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"That's an interesting point. I need a moment to formulate a proper response to that argument.\\\\\\\\\\\\\\\",\\\\\\\\n            f\\\\\\\\\\\\\\\"There are several important aspects of {topic} we should consider here.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"I appreciate the previous arguments. Let me offer a different viewpoint on this matter.\\\\\\\\\\\\\\\"\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n        return random.choice(fallback_responses)\\\\\\\\n\\\\\\\\n    async def receive_message(self, message: Message) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Receive a message (for compatibility).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if message.sender != self.name:\\\\\\\\n            self.conversation_history.append({\\\\\\\\n                'role': 'user',\\\\\\\\n                'content': f\\\\\\\\\\\\\\\"{message.sender}: {message.content}\\\\\\\\\\\\\\\"\\\\\\\\n            })\\\\\\\\n\\\\\\\\n            if len(self.conversation_history) > 20:\\\\\\\\n                self.conversation_history = self.conversation_history[-15:]\\\\\\\\n\\\\\\\\n    def _update_stats(self, response_time: float, success: bool = True):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Update performance statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if success:\\\\\\\\n            self.stats['responses_generated'] += 1\\\\\\\\n            self.stats['total_response_time'] += response_time\\\\\\\\n            self.stats['average_response_time'] = (\\\\\\\\n                self.stats['total_response_time'] / self.stats['responses_generated']\\\\\\\\n            )\\\\\\\\n        else:\\\\\\\\n            self.stats['errors'] += 1\\\\\\\\n\\\\\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get bot performance statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return {\\\\\\\\n            'name': self.name,\\\\\\\\n            'model': self.config.model,\\\\\\\\n            'provider': self.config.provider,\\\\\\\\n            'responses_generated': self.stats['responses_generated'],\\\\\\\\n            'autonomous_responses': self.stats['autonomous_responses'],\\\\\\\\n            'average_response_time': round(self.stats['average_response_time'], 2),\\\\\\\\n            'total_errors': self.stats['errors'],\\\\\\\\n            'triggers_detected': self.stats['triggers_detected'],\\\\\\\\n            'passes_made': self.stats['passes_made'],\\\\\\\\n            'success_rate': (\\\\\\\\n                self.stats['responses_generated'] /\\\\\\\\n                (self.stats['responses_generated'] + self.stats['errors'])\\\\\\\\n                if (self.stats['responses_generated'] + self.stats['errors']) > 0 else 0\\\\\\\\n            ),\\\\\\\\n            'current_cooldown': self.current_cooldown,\\\\\\\\n            'total_autonomous_responses': self.total_responses\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    def update_personality(self, personality: str, stance: str = None):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Update bot personality and stance.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.config.personality = personality\\\\\\\\n        if stance:\\\\\\\\n            self.config.stance = stance\\\\\\\\n\\\\\\\\n    def reset_conversation(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Reset conversation history.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.conversation_history = []\\\\\\\\n        self.response_count = 0\\\\\\\\n\\\\\\\\n    async def warmup(self) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Warm up the bot by testing API connection.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            test_messages = [{\\\\\\\\n                'role': 'system',\\\\\\\\n                'content': 'You are a debate participant. Respond with just \\\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\\" to confirm you are working.'\\\\\\\\n            }, {\\\\\\\\n                'role': 'user',\\\\\\\\n                'content': 'Are you ready to participate in a debate?'\\\\\\\\n            }]\\\\\\\\n\\\\\\\\n            response = await self.ai_provider.generate_response(test_messages, self.config)\\\\\\\\n            return \\\\\\\\\\\\\\\"ready\\\\\\\\\\\\\\\" in response.lower()\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Bot {self.name} warmup failed: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            return False\\\\\\\\n\\\\\\\\n    def __str__(self) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"String representation of the bot.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return f\\\\\\\\\\\\\\\"BotClient({self.name}, {self.config.model}, {self.config.stance}, autonomous={self.is_monitoring})\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __repr__(self) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Detailed string representation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return (f\\\\\\\\\\\\\\\"BotClient(name='{self.name}', model='{self.config.model}', \\\\\\\\\\\\\\\"\\\\\\\\n                f\\\\\\\\\\\\\\\"provider='{self.config.provider}', stance='{self.config.stance}', \\\\\\\\\\\\\\\"\\\\\\\\n                f\\\\\\\\\\\\\\\"monitoring={self.is_monitoring})\\\\\\\\\\\\\\\")\\\\\\\"\\\\n        },\\\\n        \\\\\\\"chat_log.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/chat_log.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 11211,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nShared chat log system for managing debate messages with timestamps and ordering.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport json\\\\\\\\nimport time\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom collections import deque\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass Message:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Represents a single chat message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    sender: str\\\\\\\\n    content: str\\\\\\\\n    timestamp: float\\\\\\\\n    message_id: int\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\"  # chat, system, moderator, vote\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\n\\\\\\\\n    def __post_init__(self):\\\\\\\\n        if self.metadata is None:\\\\\\\\n            self.metadata = {}\\\\\\\\n\\\\\\\\n    @property\\\\\\\\n    def formatted_timestamp(self) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get human-readable timestamp.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return time.strftime(\\\\\\\\\\\\\\\"%H:%M:%S\\\\\\\\\\\\\\\", time.localtime(self.timestamp))\\\\\\\\n\\\\\\\\n    def to_dict(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Convert message to dictionary.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return asdict(self)\\\\\\\\n\\\\\\\\n    @classmethod\\\\\\\\n    def from_dict(cls, data: Dict[str, Any]) -> 'Message':\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create message from dictionary.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return cls(**data)\\\\\\\\n\\\\\\\\n\\\\\\\\nclass ChatLog:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Manages the shared chat log with thread-safe message handling.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, max_messages: int = 1000):\\\\\\\\n        self.messages: deque = deque(maxlen=max_messages)\\\\\\\\n        self.message_counter = 0\\\\\\\\n        self.subscribers: List[asyncio.Queue] = []\\\\\\\\n        self._lock = asyncio.Lock()\\\\\\\\n\\\\\\\\n        # Statistics\\\\\\\\n        self.stats = {\\\\\\\\n            'total_messages': 0,\\\\\\\\n            'messages_by_sender': {},\\\\\\\\n            'start_time': time.time()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    async def add_message(self, sender: str, content: str,\\\\\\\\n                          message_type: str = \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n                          metadata: Optional[Dict[str, Any]] = None) -> Message:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Add a new message to the chat log.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            sender: Name of the message sender\\\\\\\\n            content: Message content\\\\\\\\n            message_type: Type of message (chat, system, moderator, vote)\\\\\\\\n            metadata: Additional message metadata\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            The created Message object\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        async with self._lock:\\\\\\\\n            self.message_counter += 1\\\\\\\\n\\\\\\\\n            message = Message(\\\\\\\\n                sender=sender,\\\\\\\\n                content=content,\\\\\\\\n                timestamp=time.time(),\\\\\\\\n                message_id=self.message_counter,\\\\\\\\n                message_type=message_type,\\\\\\\\n                metadata=metadata or {}\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            self.messages.append(message)\\\\\\\\n\\\\\\\\n            # Update statistics\\\\\\\\n            self.stats['total_messages'] += 1\\\\\\\\n            self.stats['messages_by_sender'][sender] = (\\\\\\\\n                    self.stats['messages_by_sender'].get(sender, 0) + 1\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            # Notify subscribers\\\\\\\\n            await self._notify_subscribers(message)\\\\\\\\n\\\\\\\\n            return message\\\\\\\\n\\\\\\\\n    async def _notify_subscribers(self, message: Message):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Notify all subscribers of new message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Remove closed queues\\\\\\\\n        self.subscribers = [q for q in self.subscribers if not q._closed]\\\\\\\\n\\\\\\\\n        # Send to all active subscribers\\\\\\\\n        for queue in self.subscribers:\\\\\\\\n            try:\\\\\\\\n                await queue.put(message)\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Failed to notify subscriber: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    def subscribe(self) -> asyncio.Queue:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Subscribe to receive new messages.\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            Queue that will receive new Message objects\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        queue = asyncio.Queue()\\\\\\\\n        self.subscribers.append(queue)\\\\\\\\n        return queue\\\\\\\\n\\\\\\\\n    def unsubscribe(self, queue: asyncio.Queue):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Remove a subscriber queue.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if queue in self.subscribers:\\\\\\\\n            self.subscribers.remove(queue)\\\\\\\\n\\\\\\\\n    def get_messages(self, limit: Optional[int] = None,\\\\\\\\n                     sender: Optional[str] = None,\\\\\\\\n                     message_type: Optional[str] = None,\\\\\\\\n                     since_timestamp: Optional[float] = None) -> List[Message]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Get messages with optional filtering.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            limit: Maximum number of messages to return\\\\\\\\n            sender: Filter by sender name\\\\\\\\n            message_type: Filter by message type\\\\\\\\n            since_timestamp: Only return messages after this timestamp\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            List of matching messages\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        messages = list(self.messages)\\\\\\\\n\\\\\\\\n        # Apply filters\\\\\\\\n        if sender:\\\\\\\\n            messages = [m for m in messages if m.sender == sender]\\\\\\\\n\\\\\\\\n        if message_type:\\\\\\\\n            messages = [m for m in messages if m.message_type == message_type]\\\\\\\\n\\\\\\\\n        if since_timestamp:\\\\\\\\n            messages = [m for m in messages if m.timestamp > since_timestamp]\\\\\\\\n\\\\\\\\n        # Apply limit\\\\\\\\n        if limit:\\\\\\\\n            messages = messages[-limit:]\\\\\\\\n\\\\\\\\n        return messages\\\\\\\\n\\\\\\\\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get the most recent messages.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return list(self.messages)[-count:]\\\\\\\\n\\\\\\\\n    def get_conversation_context(self, participant: str,\\\\\\\\n                                 context_length: int = 5) -> List[Message]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Get conversation context for a participant.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            participant: Participant name\\\\\\\\n            context_length: Number of recent messages to include\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            Recent messages for context\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        recent = self.get_recent_messages(context_length * 2)\\\\\\\\n\\\\\\\\n        # Include messages to/from the participant and moderator messages\\\\\\\\n        context = []\\\\\\\\n        for msg in recent:\\\\\\\\n            if (msg.sender == participant or\\\\\\\\n                    msg.message_type in ['moderator', 'system'] or\\\\\\\\n                    participant in msg.content):\\\\\\\\n                context.append(msg)\\\\\\\\n\\\\\\\\n        return context[-context_length:]\\\\\\\\n\\\\\\\\n    def search_messages(self, query: str, case_sensitive: bool = False) -> List[Message]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Search messages by content.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            query: Search query\\\\\\\\n            case_sensitive: Whether search should be case sensitive\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            List of messages containing the query\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not case_sensitive:\\\\\\\\n            query = query.lower()\\\\\\\\n\\\\\\\\n        results = []\\\\\\\\n        for message in self.messages:\\\\\\\\n            content = message.content if case_sensitive else message.content.lower()\\\\\\\\n            if query in content:\\\\\\\\n                results.append(message)\\\\\\\\n\\\\\\\\n        return results\\\\\\\\n\\\\\\\\n    def get_statistics(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get chat log statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        duration = time.time() - self.stats['start_time']\\\\\\\\n\\\\\\\\n        return {\\\\\\\\n            'total_messages': self.stats['total_messages'],\\\\\\\\n            'unique_senders': len(self.stats['messages_by_sender']),\\\\\\\\n            'messages_by_sender': dict(self.stats['messages_by_sender']),\\\\\\\\n            'messages_per_minute': (self.stats['total_messages'] / (duration / 60)\\\\\\\\n                                    if duration > 0 else 0),\\\\\\\\n            'session_duration_minutes': duration / 60,\\\\\\\\n            'current_message_count': len(self.messages)\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    async def save_transcript(self, filename: str,\\\\\\\\n                              format_type: str = \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\") -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Save chat transcript to file.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            filename: Output filename\\\\\\\\n            format_type: Format (json, txt, html)\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        filepath = Path(filename)\\\\\\\\n        filepath.parent.mkdir(parents=True, exist_ok=True)\\\\\\\\n\\\\\\\\n        messages = list(self.messages)\\\\\\\\n\\\\\\\\n        if format_type == \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\":\\\\\\\\n            data = {\\\\\\\\n                'metadata': {\\\\\\\\n                    'export_timestamp': time.time(),\\\\\\\\n                    'total_messages': len(messages),\\\\\\\\n                    'statistics': self.get_statistics()\\\\\\\\n                },\\\\\\\\n                'messages': [msg.to_dict() for msg in messages]\\\\\\\\n            }\\\\\\\\n\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\n                json.dump(data, f, indent=2, ensure_ascii=False)\\\\\\\\n\\\\\\\\n        elif format_type == \\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\":\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\n                f.write(\\\\\\\\\\\\\\\"=== DEBATE TRANSCRIPT ===\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n                for msg in messages:\\\\\\\\n                    f.write(f\\\\\\\\\\\\\\\"[{msg.formatted_timestamp}] {msg.sender}: {msg.content}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        elif format_type == \\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\":\\\\\\\\n            html_content = self._generate_html_transcript(messages)\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\n                f.write(html_content)\\\\\\\\n\\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Unsupported format: {format_type}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    def _generate_html_transcript(self, messages: List[Message]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Generate HTML transcript.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        html = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        <!DOCTYPE html>\\\\\\\\n        <html>\\\\\\\\n        <head>\\\\\\\\n            <title>Debate Transcript</title>\\\\\\\\n            <style>\\\\\\\\n                body { font-family: Arial, sans-serif; margin: 20px; }\\\\\\\\n                .message { margin: 10px 0; padding: 10px; border-left: 3px solid #ccc; }\\\\\\\\n                .moderator { border-left-color: #007bff; background: #f8f9fa; }\\\\\\\\n                .system { border-left-color: #6c757d; background: #e9ecef; }\\\\\\\\n                .timestamp { color: #6c757d; font-size: 0.9em; }\\\\\\\\n                .sender { font-weight: bold; }\\\\\\\\n            </style>\\\\\\\\n        </head>\\\\\\\\n        <body>\\\\\\\\n            <h1>AI Jubilee Debate Transcript</h1>\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        for msg in messages:\\\\\\\\n            css_class = msg.message_type if msg.message_type != 'chat' else ''\\\\\\\\n            html += f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n            <div class=\\\\\\\\\\\\\\\"message {css_class}\\\\\\\\\\\\\\\">\\\\\\\\n                <span class=\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\">[{msg.formatted_timestamp}]</span>\\\\\\\\n                <span class=\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\">{msg.sender}:</span>\\\\\\\\n                <div>{msg.content}</div>\\\\\\\\n            </div>\\\\\\\\n            \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        html += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        </body>\\\\\\\\n        </html>\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        return html\\\\\\\\n\\\\\\\\n    async def load_transcript(self, filename: str) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Load transcript from JSON file.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            filename: Input filename\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        filepath = Path(filename)\\\\\\\\n\\\\\\\\n        if not filepath.exists():\\\\\\\\n            raise FileNotFoundError(f\\\\\\\\\\\\\\\"Transcript file not found: {filename}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        with open(filepath, 'r', encoding='utf-8') as f:\\\\\\\\n            data = json.load(f)\\\\\\\\n\\\\\\\\n        # Clear current messages\\\\\\\\n        async with self._lock:\\\\\\\\n            self.messages.clear()\\\\\\\\n            self.message_counter = 0\\\\\\\\n\\\\\\\\n            # Load messages\\\\\\\\n            for msg_data in data.get('messages', []):\\\\\\\\n                message = Message.from_dict(msg_data)\\\\\\\\n                self.messages.append(message)\\\\\\\\n                self.message_counter = max(self.message_counter, message.message_id)\\\\\\\\n\\\\\\\\n    def clear(self) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Clear all messages from the chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.messages.clear()\\\\\\\\n        self.message_counter = 0\\\\\\\\n        self.stats = {\\\\\\\\n            'total_messages': 0,\\\\\\\\n            'messages_by_sender': {},\\\\\\\\n            'start_time': time.time()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    def __len__(self) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Return number of messages in the log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return len(self.messages)\\\\\\\\n\\\\\\\\n    def __iter__(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Iterate over messages.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return iter(self.messages)\\\\\\\\n\\\\\\\\n    def __getitem__(self, index) -> Message:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get message by index.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return list(self.messages)[index]\\\\\\\"\\\\n        },\\\\n        \\\\\\\"human_client.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/human_client.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 20172,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nHuman client implementation for debate participation.\\\\\\\\nNow with true autonomous participation - can speak anytime!\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport time\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\n\\\\\\\\nfrom .chat_log import Message\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass InterfaceConfig:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Configuration for human interface.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    mode: str = \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\"\\\\\\\\n    enable_rich_formatting: bool = True\\\\\\\\n    show_typing_indicators: bool = True\\\\\\\\n    enable_reactions: bool = True\\\\\\\\n    input_timeout: int = 120\\\\\\\\n\\\\\\\\n\\\\\\\\nclass CLIInterface:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Command line interface for human participants.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, config: InterfaceConfig):\\\\\\\\n        self.config = config\\\\\\\\n        self.rich_console = None\\\\\\\\n        self.input_task = None\\\\\\\\n\\\\\\\\n        if config.enable_rich_formatting:\\\\\\\\n            try:\\\\\\\\n                from rich.console import Console\\\\\\\\n                from rich.live import Live\\\\\\\\n                self.rich_console = Console()\\\\\\\\n            except ImportError:\\\\\\\\n                print(\\\\\\\\\\\\\\\"Rich not available, using basic formatting\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def display_message(self, message: Message):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Display a message to the user.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        timestamp = time.strftime(\\\\\\\\\\\\\\\"%H:%M:%S\\\\\\\\\\\\\\\", time.localtime(message.timestamp))\\\\\\\\n\\\\\\\\n        if self.rich_console:\\\\\\\\n            if message.message_type == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\":\\\\\\\\n                self.rich_console.print(\\\\\\\\n                    f\\\\\\\\\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\\\\\\\\\",\\\\\\\\n                    style=\\\\\\\\\\\\\\\"bold yellow\\\\\\\\\\\\\\\"\\\\\\\\n                )\\\\\\\\n            elif message.sender.endswith('_1') or 'Human' in message.sender:\\\\\\\\n                # Don't display our own messages back to us\\\\\\\\n                return\\\\\\\\n            else:\\\\\\\\n                self.rich_console.print(\\\\\\\\n                    f\\\\\\\\\\\\\\\"[{timestamp}] ü§ñ {message.sender}: {message.content}\\\\\\\\\\\\\\\",\\\\\\\\n                    style=\\\\\\\\\\\\\\\"cyan\\\\\\\\\\\\\\\"\\\\\\\\n                )\\\\\\\\n        else:\\\\\\\\n            if message.message_type == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\":\\\\\\\\n                print(f\\\\\\\\\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\\\\\\\\\")\\\\\\\\n            elif not (message.sender.endswith('_1') or 'Human' in message.sender):\\\\\\\\n                print(f\\\\\\\\\\\\\\\"[{timestamp}] ü§ñ {message.sender}: {message.content}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def get_input(self, prompt: str, timeout: int = 10) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get input from user with timeout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if self.rich_console:\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\"üí¨ {prompt}\\\\\\\\\\\\\\\", style=\\\\\\\\\\\\\\\"bold green\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"üí¨ {prompt}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Start input task\\\\\\\\n        self.input_task = asyncio.create_task(self._get_user_input())\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            # Wait for input or timeout\\\\\\\\n            response = await asyncio.wait_for(self.input_task, timeout=timeout)\\\\\\\\n            return response.strip()\\\\\\\\n\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\n                self.input_task.cancel()\\\\\\\\n                try:\\\\\\\\n                    await self.input_task\\\\\\\\n                except asyncio.CancelledError:\\\\\\\\n                    pass\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\n                self.input_task.cancel()\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Input error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\n                self.input_task.cancel()\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    async def _get_user_input(self) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get user input asynchronously.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        loop = asyncio.get_event_loop()\\\\\\\\n        return await loop.run_in_executor(None, input, \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Show a notification to the user.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        icons = {\\\\\\\\n            \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ùå\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚úÖ\\\\\\\\\\\\\\\"\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        icon = icons.get(level, \\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        if self.rich_console:\\\\\\\\n            colors = {\\\\\\\\n                \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"blue\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"yellow\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"red\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"green\\\\\\\\\\\\\\\"\\\\\\\\n            }\\\\\\\\n            color = colors.get(level, \\\\\\\\\\\\\\\"blue\\\\\\\\\\\\\\\")\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\"{icon} {message}\\\\\\\\\\\\\\\", style=color)\\\\\\\\n        else:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"{icon} {message}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\nclass WebInterface:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Web interface for human participants.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, config: InterfaceConfig):\\\\\\\\n        self.config = config\\\\\\\\n        self.websocket = None\\\\\\\\n        self.pending_responses = {}\\\\\\\\n\\\\\\\\n    async def display_message(self, message: Message):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Display message via websocket.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if self.websocket:\\\\\\\\n            await self.websocket.send_json({\\\\\\\\n                \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": message.to_dict()\\\\\\\\n            })\\\\\\\\n\\\\\\\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get input via websocket.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.websocket:\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        request_id = f\\\\\\\\\\\\\\\"input_{time.time()}\\\\\\\\\\\\\\\"\\\\\\\\n        await self.websocket.send_json({\\\\\\\\n            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"input_request\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\": request_id,\\\\\\\\n            \\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\": prompt,\\\\\\\\n            \\\\\\\\\\\\\\\"timeout\\\\\\\\\\\\\\\": timeout\\\\\\\\n        })\\\\\\\\n\\\\\\\\n        # Wait for response\\\\\\\\n        try:\\\\\\\\n            response = await asyncio.wait_for(\\\\\\\\n                self._wait_for_response(request_id),\\\\\\\\n                timeout=timeout\\\\\\\\n            )\\\\\\\\n            return response\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    async def _wait_for_response(self, request_id: str) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Wait for websocket response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        while request_id not in self.pending_responses:\\\\\\\\n            await asyncio.sleep(0.1)\\\\\\\\n        return self.pending_responses.pop(request_id)\\\\\\\\n\\\\\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Show notification via websocket.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if self.websocket:\\\\\\\\n            await self.websocket.send_json({\\\\\\\\n                \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"notification\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\": message,\\\\\\\\n                \\\\\\\\\\\\\\\"level\\\\\\\\\\\\\\\": level\\\\\\\\n            })\\\\\\\\n\\\\\\\\n\\\\\\\\nclass HumanClient:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Human participant in the debate system with autonomous participation.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, name: str, config: Dict[str, Any]):\\\\\\\\n        self.name = name\\\\\\\\n        self.config = config\\\\\\\\n        self.is_active = True\\\\\\\\n        self.conversation_history: List[Message] = []\\\\\\\\n\\\\\\\\n        # Initialize appropriate interface\\\\\\\\n        interface_config = InterfaceConfig(\\\\\\\\n            mode=config.get('mode', 'cli'),\\\\\\\\n            enable_rich_formatting=config.get('enable_rich_formatting', True),\\\\\\\\n            show_typing_indicators=config.get('show_typing_indicators', True),\\\\\\\\n            enable_reactions=config.get('enable_reactions', True),\\\\\\\\n            input_timeout=config.get('input_timeout', 120)\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        if interface_config.mode == \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\":\\\\\\\\n            self.interface = CLIInterface(interface_config)\\\\\\\\n        elif interface_config.mode == \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\":\\\\\\\\n            self.interface = WebInterface(interface_config)\\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Unsupported interface mode: {interface_config.mode}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Statistics tracking\\\\\\\\n        self.stats = {\\\\\\\\n            'responses_given': 0,\\\\\\\\n            'timeouts': 0,\\\\\\\\n            'total_response_time': 0.0,\\\\\\\\n            'average_response_time': 0.0\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    async def autonomous_participation_loop(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"True autonomous participation - human can speak anytime.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.is_active:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            \\\\\\\\\\\\\\\"üéØ AUTONOMOUS MODE ACTIVE - You can speak ANYTIME!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            \\\\\\\\\\\\\\\"üó£Ô∏è  You can speak at ANY TIME during the discussion!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            \\\\\\\\\\\\\\\"üí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            \\\\\\\\\\\\\\\"‚úèÔ∏è  Just type your response and press Enter to join the conversation!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        # Subscribe to chat updates for display\\\\\\\\n        message_queue = chat_log.subscribe()\\\\\\\\n        last_displayed = len(chat_log.messages)\\\\\\\\n\\\\\\\\n        while self.is_active:\\\\\\\\n            try:\\\\\\\\n                # Check for new messages to display\\\\\\\\n                current_count = len(chat_log.messages)\\\\\\\\n                if current_count > last_displayed:\\\\\\\\n                    new_messages = list(chat_log.messages)[last_displayed:]\\\\\\\\n                    for msg in new_messages:\\\\\\\\n                        if msg.sender != self.name:  # Don't show own messages\\\\\\\\n                            await self.interface.display_message(msg)\\\\\\\\n                    last_displayed = current_count\\\\\\\\n\\\\\\\\n                # Get user input with short timeout for responsiveness\\\\\\\\n                response = await self.interface.get_input(\\\\\\\\n                    \\\\\\\\\\\\\\\"Type your response (or command):\\\\\\\\\\\\\\\",\\\\\\\\n                    timeout=10  # Short timeout for responsiveness\\\\\\\\n                )\\\\\\\\n\\\\\\\\n                if not response:\\\\\\\\n                    continue  # Timeout, check for new messages\\\\\\\\n\\\\\\\\n                response = response.strip()\\\\\\\\n\\\\\\\\n                # Handle commands\\\\\\\\n                if response.lower() in ['quit', 'exit']:\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\n                        \\\\\\\\\\\\\\\"üëã Leaving the debate. Thanks for participating!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\"\\\\\\\\n                    )\\\\\\\\n                    self.is_active = False\\\\\\\\n                    break\\\\\\\\n                elif response.lower() == 'help':\\\\\\\\n                    await self._show_autonomous_help()\\\\\\\\n                    continue\\\\\\\\n                elif response.lower() == 'status':\\\\\\\\n                    await self._show_status()\\\\\\\\n                    continue\\\\\\\\n                elif response.lower() == 'history':\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\"üìú Recent conversation:\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\")\\\\\\\\n                    recent = chat_log.get_recent_messages(5)\\\\\\\\n                    for msg in recent:\\\\\\\\n                        await self.interface.display_message(msg)\\\\\\\\n                    continue\\\\\\\\n                elif len(response) < 3:\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\n                        \\\\\\\\\\\\\\\"‚ö†Ô∏è Please provide a more substantial response (at least 3 characters).\\\\\\\\\\\\\\\",\\\\\\\\n                        \\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\"\\\\\\\\n                    )\\\\\\\\n                    continue\\\\\\\\n\\\\\\\\n                # Process and post message directly to chat log\\\\\\\\n                validated_response = self._validate_response(response)\\\\\\\\n                if validated_response:\\\\\\\\n                    await chat_log.add_message(self.name, validated_response)\\\\\\\\n                    self.stats['responses_given'] += 1\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\n                        \\\\\\\\\\\\\\\"‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\"\\\\\\\\n                    )\\\\\\\\n\\\\\\\\n            except Exception as e:\\\\\\\\n                await self.interface.show_notification(f\\\\\\\\\\\\\\\"‚ùå Error: {e}\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\")\\\\\\\\n                await asyncio.sleep(2)\\\\\\\\n\\\\\\\\n        # Cleanup\\\\\\\\n        chat_log.unsubscribe(message_queue)\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            \\\\\\\\\\\\\\\"üõë Autonomous participation ended.\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    async def _show_autonomous_help(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Show help information for autonomous mode.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        help_text = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nüéØ AI JUBILEE DEBATE - AUTONOMOUS MODE HELP\\\\\\\\n\\\\\\\\nCOMMANDS:\\\\\\\\n‚Ä¢ Just type your response and press Enter to join the debate\\\\\\\\n‚Ä¢ 'help' - Show this help message\\\\\\\\n‚Ä¢ 'status' - Show your participation statistics  \\\\\\\\n‚Ä¢ 'history' - Show recent conversation messages\\\\\\\\n‚Ä¢ 'quit' - Leave the debate\\\\\\\\n\\\\\\\\nAUTONOMOUS MODE:\\\\\\\\n‚Ä¢ You can speak at ANY TIME during the discussion phase\\\\\\\\n‚Ä¢ Bots and moderator are monitoring and will respond when they feel compelled\\\\\\\\n‚Ä¢ No turn-taking - completely organic conversation flow\\\\\\\\n‚Ä¢ Your responses are immediately added to the debate\\\\\\\\n\\\\\\\\nTIPS:\\\\\\\\n‚Ä¢ Keep responses focused and substantial (3+ characters)\\\\\\\\n‚Ä¢ Reference specific points made by others\\\\\\\\n‚Ä¢ Feel free to jump in whenever you have something to add!\\\\\\\\n‚Ä¢ The debate flows naturally - speak when inspired!\\\\\\\\n\\\\\\\\nDEBATE PHASES:\\\\\\\\n1. Introduction & Opening Statements (structured)\\\\\\\\n2. Autonomous Discussion (free-flowing - you can speak anytime!)\\\\\\\\n3. Closing Statements (structured)  \\\\\\\\n4. Voting Phase\\\\\\\\n\\\\\\\\nEnjoy the organic debate experience! üé≠\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        await self.interface.show_notification(help_text, \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _show_status(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Show participation status.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        stats = self.get_stats()\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            f\\\\\\\\\\\\\\\"üìä Your participation: {stats['responses_given']} responses, \\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"{stats['participation_rate']:.1%} participation rate, \\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"avg response time: {stats['average_response_time']:.1f}s\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    def _validate_response(self, response: str) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Validate and clean up human response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not response or not response.strip():\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Clean up the response\\\\\\\\n        response = response.strip()\\\\\\\\n\\\\\\\\n        # Check length limits\\\\\\\\n        max_length = self.config.get('max_message_length', 500)\\\\\\\\n        if len(response) > max_length:\\\\\\\\n            response = response[:max_length - 3] + \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Add note for very short responses\\\\\\\\n        if len(response) < 10:\\\\\\\\n            response += \\\\\\\\\\\\\\\" [Note: Very short response]\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        return response\\\\\\\\n\\\\\\\\n    # Legacy methods for structured phases\\\\\\\\n    async def get_response(self, topic: str, messages: List[Message]) -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get response from human participant (for structured phases).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.is_active:\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        start_time = time.time()\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            # Show context in structured phases\\\\\\\\n            if len(messages) > 0:\\\\\\\\n                await self.interface.show_notification(\\\\\\\\n                    f\\\\\\\\\\\\\\\"üìú Recent messages in conversation:\\\\\\\\\\\\\\\",\\\\\\\\n                    \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n                )\\\\\\\\n                # Show last 3 messages for context\\\\\\\\n                recent = messages[-3:] if len(messages) >= 3 else messages\\\\\\\\n                for msg in recent:\\\\\\\\n                    await self.interface.display_message(msg)\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\"‚îÄ\\\\\\\\\\\\\\\" * 50, \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n            # Get response with timeout\\\\\\\\n            response = await self.interface.get_input(\\\\\\\\n                f\\\\\\\\\\\\\\\"üí¨ Your response to: {topic}\\\\\\\\\\\\\\\",\\\\\\\\n                timeout=self.config.get('input_timeout', 120)\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            # Validate and process response\\\\\\\\n            if response:\\\\\\\\n                validated_response = self._validate_response(response)\\\\\\\\n                if validated_response:\\\\\\\\n                    # Add to conversation history\\\\\\\\n                    response_msg = Message(\\\\\\\\n                        sender=self.name,\\\\\\\\n                        content=validated_response,\\\\\\\\n                        timestamp=time.time(),\\\\\\\\n                        message_id=len(self.conversation_history) + 1\\\\\\\\n                    )\\\\\\\\n                    self.conversation_history.append(response_msg)\\\\\\\\n\\\\\\\\n                    # Update stats\\\\\\\\n                    response_time = time.time() - start_time\\\\\\\\n                    self._update_stats(response_time, success=True)\\\\\\\\n\\\\\\\\n                    return validated_response\\\\\\\\n\\\\\\\\n            # Handle timeout/empty response\\\\\\\\n            response_time = time.time() - start_time\\\\\\\\n            self._update_stats(response_time, success=False)\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            await self.interface.show_notification(\\\\\\\\n                f\\\\\\\\\\\\\\\"‚ùå Error getting response: {e}\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    async def receive_message(self, message: Message):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Receive and display a message from the debate.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Don't show our own messages back to us\\\\\\\\n        if message.sender == self.name:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        # Add to conversation history\\\\\\\\n        self.conversation_history.append(message)\\\\\\\\n\\\\\\\\n        # Limit history size\\\\\\\\n        if len(self.conversation_history) > 30:\\\\\\\\n            self.conversation_history = self.conversation_history[-30:]\\\\\\\\n\\\\\\\\n        # Display the message (in autonomous mode, this is handled by the loop)\\\\\\\\n        try:\\\\\\\\n            if not hasattr(self, '_in_autonomous_mode'):\\\\\\\\n                await self.interface.display_message(message)\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Error displaying message: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def handle_voting(self, candidates: List[str], time_limit: int) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle voting process for human participant.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            f\\\\\\\\\\\\\\\"üó≥Ô∏è Voting phase! You have {time_limit} seconds to vote.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        # Show candidates\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            \\\\\\\\\\\\\\\"üìã Candidates:\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n        for i, candidate in enumerate(candidates, 1):\\\\\\\\n            await self.interface.show_notification(\\\\\\\\n                f\\\\\\\\\\\\\\\"  {i}. {candidate}\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            # Get vote choice\\\\\\\\n            choice_input = await self.interface.get_input(\\\\\\\\n                f\\\\\\\\\\\\\\\"Enter your choice (1-{len(candidates)}):\\\\\\\\\\\\\\\",\\\\\\\\n                timeout=time_limit\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            if not choice_input:\\\\\\\\n                return {'voted': False, 'reason': 'timeout'}\\\\\\\\n\\\\\\\\n            try:\\\\\\\\n                choice = int(choice_input.strip())\\\\\\\\n                if 1 <= choice <= len(candidates):\\\\\\\\n                    selected_candidate = candidates[choice - 1]\\\\\\\\n\\\\\\\\n                    # Get justification if using CLI\\\\\\\\n                    justification = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n                    if isinstance(self.interface, CLIInterface):\\\\\\\\n                        justification = await self.interface.get_input(\\\\\\\\n                            \\\\\\\\\\\\\\\"Optional: Why did you choose this candidate?\\\\\\\\\\\\\\\",\\\\\\\\n                            timeout=30\\\\\\\\n                        )\\\\\\\\n\\\\\\\\n                    return {\\\\\\\\n                        'voted': True,\\\\\\\\n                        'candidate': selected_candidate,\\\\\\\\n                        'justification': justification or \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n                    }\\\\\\\\n                else:\\\\\\\\n                    return {'voted': False, 'reason': 'invalid_choice'}\\\\\\\\n\\\\\\\\n            except ValueError:\\\\\\\\n                return {'voted': False, 'reason': 'invalid_format'}\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            await self.interface.show_notification(\\\\\\\\n                f\\\\\\\\\\\\\\\"‚ùå Voting error: {e}\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n            return {'voted': False, 'reason': 'error'}\\\\\\\\n\\\\\\\\n    def _update_stats(self, response_time: float, success: bool):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Update response statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if success:\\\\\\\\n            self.stats['responses_given'] += 1\\\\\\\\n            self.stats['total_response_time'] += response_time\\\\\\\\n            if self.stats['responses_given'] > 0:\\\\\\\\n                self.stats['average_response_time'] = (\\\\\\\\n                        self.stats['total_response_time'] / self.stats['responses_given']\\\\\\\\n                )\\\\\\\\n        else:\\\\\\\\n            self.stats['timeouts'] += 1\\\\\\\\n\\\\\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get comprehensive human client statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        total_attempts = self.stats['responses_given'] + self.stats['timeouts']\\\\\\\\n        participation_rate = (\\\\\\\\n            self.stats['responses_given'] / total_attempts\\\\\\\\n            if total_attempts > 0 else 0\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        return {\\\\\\\\n            'name': self.name,\\\\\\\\n            'interface_mode': self.interface.config.mode,\\\\\\\\n            'responses_given': self.stats['responses_given'],\\\\\\\\n            'timeouts': self.stats['timeouts'],\\\\\\\\n            'total_attempts': total_attempts,\\\\\\\\n            'participation_rate': participation_rate,\\\\\\\\n            'average_response_time': self.stats.get('average_response_time', 0),\\\\\\\\n            'is_active': self.is_active,\\\\\\\\n            'conversation_length': len(self.conversation_history)\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    async def set_active(self, active: bool):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Set the active status of the human client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.is_active = active\\\\\\\\n        status = \\\\\\\\\\\\\\\"activated\\\\\\\\\\\\\\\" if active else \\\\\\\\\\\\\\\"deactivated\\\\\\\\\\\\\\\"\\\\\\\\n        await self.interface.show_notification(\\\\\\\\n            f\\\\\\\\\\\\\\\"üîÑ {self.name} has been {status}\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    def __str__(self) -> str:\\\\\\\\n        return f\\\\\\\\\\\\\\\"Human({self.name}, {self.interface.config.mode}, active={self.is_active})\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __repr__(self) -> str:\\\\\\\\n        return (f\\\\\\\\\\\\\\\"HumanClient(name='{self.name}', mode='{self.interface.config.mode}', \\\\\\\\\\\\\\\"\\\\\\\\n                f\\\\\\\\\\\\\\\"active={self.is_active}, responses={self.stats['responses_given']})\\\\\\\\\\\\\\\")\\\\\\\"\\\\n        },\\\\n        \\\\\\\"main.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/main.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 4540,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nMain entry point for the AI Jubilee Debate System.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport yaml\\\\\\\\nimport click\\\\\\\\nimport os\\\\\\\\nfrom typing import List, Optional\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom dotenv import load_dotenv\\\\\\\\n\\\\\\\\nfrom .moderator import Moderator\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\nfrom .human_client import HumanClient\\\\\\\\nfrom .chat_log import ChatLog\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\nfrom .streaming import StreamingServer\\\\\\\\nfrom .utils import setup_logging, load_config\\\\\\\\n\\\\\\\\n\\\\\\\\nasync def start_debate_session(\\\\\\\\n    topic: Optional[str] = None,\\\\\\\\n    ai_bots: int = 2,\\\\\\\\n    human_participants: int = 1,\\\\\\\\n    config_path: str = \\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\"\\\\\\\\n) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Start a debate session with specified participants.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        topic: Debate topic (if None, uses random from config)\\\\\\\\n        ai_bots: Number of AI bot participants\\\\\\\\n        human_participants: Number of human participants\\\\\\\\n        config_path: Path to configuration file\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Load environment variables from .env file\\\\\\\\n    load_dotenv()\\\\\\\\n\\\\\\\\n    # Load configuration\\\\\\\\n    config = load_config(config_path)\\\\\\\\n\\\\\\\\n    # Setup logging\\\\\\\\n    setup_logging(config.get('chat', {}).get('log_level', 'INFO'))\\\\\\\\n\\\\\\\\n    # Initialize chat log\\\\\\\\n    chat_log = ChatLog()\\\\\\\\n\\\\\\\\n    # Initialize voting system\\\\\\\\n    voting_system = VotingSystem(config.get('voting', {}))\\\\\\\\n\\\\\\\\n    # Select topic\\\\\\\\n    if not topic:\\\\\\\\n        import random\\\\\\\\n        topic = random.choice(config.get('topics', [\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\"]))\\\\\\\\n\\\\\\\\n    # Create bot clients\\\\\\\\n    bot_clients = []\\\\\\\\n    bot_configs = config.get('bots', [])[:ai_bots]\\\\\\\\n\\\\\\\\n    for i, bot_config in enumerate(bot_configs):\\\\\\\\n        bot = BotClient(\\\\\\\\n            name=bot_config['name'],\\\\\\\\n            model=bot_config['model'],\\\\\\\\n            provider=bot_config['provider'],\\\\\\\\n            personality=bot_config['personality'],\\\\\\\\n            stance=bot_config['stance'],\\\\\\\\n            api_key=config['api_keys'].get(bot_config['provider'])\\\\\\\\n        )\\\\\\\\n        bot_clients.append(bot)\\\\\\\\n\\\\\\\\n    # Create human clients\\\\\\\\n    human_clients = []\\\\\\\\n    for i in range(human_participants):\\\\\\\\n        human = HumanClient(\\\\\\\\n            name=f\\\\\\\\\\\\\\\"Human_{i+1}\\\\\\\\\\\\\\\",\\\\\\\\n            config=config.get('interface', {})\\\\\\\\n        )\\\\\\\\n        human_clients.append(human)\\\\\\\\n\\\\\\\\n    # Initialize moderator based on debate mode\\\\\\\\n    debate_mode = config.get('debate', {}).get('mode', 'sequential')\\\\\\\\n\\\\\\\\n    moderator = Moderator(\\\\\\\\n        topic=topic,\\\\\\\\n        participants=bot_clients + human_clients,\\\\\\\\n        chat_log=chat_log,\\\\\\\\n        voting_system=voting_system,\\\\\\\\n        config=config.get('debate', {})\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    if debate_mode == \\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\":\\\\\\\\n        print(f\\\\\\\\\\\\\\\"ü§ñ Running in AUTONOMOUS mode - bots will decide when to speak!\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìù Topic: {topic}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"‚è∞ Discussion time: {config.get('debate', {}).get('time_limit_minutes', 30)} minutes\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üéØ Bots will monitor conversation and jump in when they feel compelled to respond!\\\\\\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìù Running in SEQUENTIAL mode\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üë• Participants take turns in order\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Initialize streaming server if enabled\\\\\\\\n    streaming_server = None\\\\\\\\n    if config.get('streaming', {}).get('enabled', False):\\\\\\\\n        streaming_server = StreamingServer(\\\\\\\\n            chat_log=chat_log,\\\\\\\\n            voting_system=voting_system,\\\\\\\\n            config=config.get('streaming', {})\\\\\\\\n        )\\\\\\\\n        await streaming_server.start()\\\\\\\\n\\\\\\\\n    try:\\\\\\\\n        # Start the debate\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüé≠ Starting AI Jubilee Debate: {topic}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        await moderator.run_debate()\\\\\\\\n\\\\\\\\n    except KeyboardInterrupt:\\\\\\\\n        print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n‚èπÔ∏è  Debate interrupted by user\\\\\\\\\\\\\\\")\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    finally:\\\\\\\\n        # Cleanup\\\\\\\\n        if streaming_server:\\\\\\\\n            await streaming_server.stop()\\\\\\\\n\\\\\\\\n        # Save transcript\\\\\\\\n        if config.get('chat', {}).get('save_transcripts', True):\\\\\\\\n            await chat_log.save_transcript(f\\\\\\\\\\\\\\\"debate_{topic[:20]}.json\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\n@click.command()\\\\\\\\n@click.option('--topic', '-t', help='Debate topic')\\\\\\\\n@click.option('--bots', '-b', default=2, help='Number of AI bots')\\\\\\\\n@click.option('--humans', '-h', default=1, help='Number of human participants')\\\\\\\\n@click.option('--config', '-c', default='config.yaml', help='Configuration file path')\\\\\\\\ndef cli(topic: str, bots: int, humans: int, config: str):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Launch the AI Jubilee Debate System.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    asyncio.run(start_debate_session(topic, bots, humans, config))\\\\\\\\n\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    cli()\\\\\\\"\\\\n        },\\\\n        \\\\\\\"moderator.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/moderator.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 21267,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nModerator class for managing debate flow, rules, and coordination.\\\\\\\\nNow acts as an AI-powered facilitator using the same system as other bots.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport time\\\\\\\\nimport random\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\nfrom enum import Enum\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\n\\\\\\\\nfrom .chat_log import ChatLog, Message\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\nfrom .utils import format_time_remaining\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\n\\\\\\\\n\\\\\\\\nclass DebatePhase(Enum):\\\\\\\\n    INTRODUCTION = \\\\\\\\\\\\\\\"introduction\\\\\\\\\\\\\\\"\\\\\\\\n    OPENING_STATEMENTS = \\\\\\\\\\\\\\\"opening_statements\\\\\\\\\\\\\\\"\\\\\\\\n    DISCUSSION = \\\\\\\\\\\\\\\"discussion\\\\\\\\\\\\\\\"\\\\\\\\n    CLOSING_STATEMENTS = \\\\\\\\\\\\\\\"closing_statements\\\\\\\\\\\\\\\"\\\\\\\\n    VOTING = \\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\"\\\\\\\\n    RESULTS = \\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\"\\\\\\\\n    FINISHED = \\\\\\\\\\\\\\\"finished\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass DebateState:\\\\\\\\n    phase: DebatePhase\\\\\\\\n    current_speaker: Optional[str] = None\\\\\\\\n    time_remaining: int = 0\\\\\\\\n    turn_order: List[str] = None\\\\\\\\n    warnings_issued: Dict[str, int] = None\\\\\\\\n\\\\\\\\n    def __post_init__(self):\\\\\\\\n        if self.turn_order is None:\\\\\\\\n            self.turn_order = []\\\\\\\\n        if self.warnings_issued is None:\\\\\\\\n            self.warnings_issued = {}\\\\\\\\n\\\\\\\\n\\\\\\\\nclass Moderator:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    AI-powered moderator that manages debate flow and provides intelligent facilitation.\\\\\\\\n    Works just like other bots but with moderator-specific prompts.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, topic: str, participants: List, chat_log: ChatLog,\\\\\\\\n                 voting_system: VotingSystem, config: Dict[str, Any]):\\\\\\\\n        self.topic = topic\\\\\\\\n        self.participants = {p.name: p for p in participants}\\\\\\\\n        self.chat_log = chat_log\\\\\\\\n        self.voting_system = voting_system\\\\\\\\n        self.config = config\\\\\\\\n\\\\\\\\n        # Initialize moderator as a bot client\\\\\\\\n        moderator_config = config.get('moderator', {})\\\\\\\\n        self.moderator_bot = BotClient(\\\\\\\\n            name=moderator_config.get('name', 'Moderator'),\\\\\\\\n            model=moderator_config.get('model', 'gpt-3.5-turbo'),\\\\\\\\n            provider=moderator_config.get('provider', 'openai'),\\\\\\\\n            personality=moderator_config.get('personality', 'Professional debate facilitator'),\\\\\\\\n            stance=moderator_config.get('stance', 'neutral'),\\\\\\\\n            api_key=config['api_keys'].get(moderator_config.get('provider', 'openai'))\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        self.state = DebateState(\\\\\\\\n            phase=DebatePhase.INTRODUCTION,\\\\\\\\n            turn_order=list(self.participants.keys())\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        self.phase_times = {\\\\\\\\n            DebatePhase.OPENING_STATEMENTS: config.get('opening_statement_time', 120),\\\\\\\\n            DebatePhase.DISCUSSION: config.get('time_limit_minutes', 30) * 60,\\\\\\\\n            DebatePhase.CLOSING_STATEMENTS: config.get('closing_statement_time', 90),\\\\\\\\n            DebatePhase.VOTING: config.get('voting_duration', 300)\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        self.max_response_time = config.get('max_response_time', 120)\\\\\\\\n        self.warning_time = config.get('warning_time', 90)\\\\\\\\n\\\\\\\\n        # Autonomous mode settings\\\\\\\\n        self.autonomous_mode = config.get('mode', 'autonomous') == 'autonomous'\\\\\\\\n        self.autonomous_tasks: List[asyncio.Task] = []\\\\\\\\n        self.phase_task: Optional[asyncio.Task] = None\\\\\\\\n\\\\\\\\n        # Facilitation settings\\\\\\\\n        self.silence_timeout = config.get('silence_timeout', 60)\\\\\\\\n        self.last_activity_time = time.time()\\\\\\\\n        self.last_moderator_prompt = 0\\\\\\\\n\\\\\\\\n    async def run_debate(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Run the complete debate session with autonomous support.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        results = {}\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            await self._introduction_phase()\\\\\\\\n            await self._opening_statements_phase()\\\\\\\\n\\\\\\\\n            if self.autonomous_mode:\\\\\\\\n                await self._autonomous_discussion_phase()\\\\\\\\n            else:\\\\\\\\n                await self._traditional_discussion_phase()\\\\\\\\n\\\\\\\\n            await self._closing_statements_phase()\\\\\\\\n            results = await self._voting_phase()\\\\\\\\n            await self._results_phase(results)\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            await self._broadcast_message(\\\\\\\\n                f\\\\\\\\\\\\\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n            raise\\\\\\\\n        finally:\\\\\\\\n            if self.autonomous_mode:\\\\\\\\n                await self._cleanup_autonomous_tasks()\\\\\\\\n            self.state.phase = DebatePhase.FINISHED\\\\\\\\n\\\\\\\\n        return results\\\\\\\\n\\\\\\\\n    async def _autonomous_discussion_phase(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Autonomous discussion where bots and humans self-manage participation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"üöÄ AUTONOMOUS DISCUSSION PHASE BEGIN! ü§ñ\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"üéØ How this works:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   ‚Ä¢ Bots are now monitoring the conversation continuously\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   ‚Ä¢ They will decide when they feel compelled to respond\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   ‚Ä¢ Humans can type messages at ANY TIME to join in\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   ‚Ä¢ No turn-taking - completely organic conversation flow!\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   ‚Ä¢ Everyone has access to full conversation history\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"‚è∞ Discussion time: {total_time // 60} minutes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"üé≠ Let the autonomous debate begin!\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        self.last_activity_time = time.time()\\\\\\\\n        start_time = time.time()\\\\\\\\n\\\\\\\\n        # Start bot autonomous monitoring\\\\\\\\n        await self._start_bot_autonomous_monitoring()\\\\\\\\n\\\\\\\\n        # Start human autonomous participation\\\\\\\\n        await self._start_human_autonomous_participation()\\\\\\\\n\\\\\\\\n        # Start moderator autonomous monitoring\\\\\\\\n        await self._start_moderator_autonomous_monitoring()\\\\\\\\n\\\\\\\\n        # Start phase management (facilitation only)\\\\\\\\n        self.phase_task = asyncio.create_task(\\\\\\\\n            self._facilitate_autonomous_discussion(start_time, total_time)\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            await self.phase_task\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\n            pass\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            \\\\\\\\\\\\\\\"‚èπÔ∏è Autonomous discussion phase complete! üéâ\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            \\\\\\\\\\\\\\\"Moving to closing statements...\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    async def _start_bot_autonomous_monitoring(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Start autonomous monitoring for all bots.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for participant_name, participant in self.participants.items():\\\\\\\\n            if hasattr(participant, 'start_autonomous_monitoring'):  # It's a bot\\\\\\\\n                task = asyncio.create_task(\\\\\\\\n                    participant.start_autonomous_monitoring(self.chat_log, self.topic)\\\\\\\\n                )\\\\\\\\n                self.autonomous_tasks.append(task)\\\\\\\\n\\\\\\\\n    async def _start_human_autonomous_participation(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Start autonomous participation for humans.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for participant_name, participant in self.participants.items():\\\\\\\\n            if hasattr(participant, 'autonomous_participation_loop'):  # It's a human\\\\\\\\n                task = asyncio.create_task(\\\\\\\\n                    participant.autonomous_participation_loop(self.chat_log)\\\\\\\\n                )\\\\\\\\n                self.autonomous_tasks.append(task)\\\\\\\\n\\\\\\\\n    async def _start_moderator_autonomous_monitoring(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Start moderator autonomous monitoring just like other bots.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        task = asyncio.create_task(\\\\\\\\n            self.moderator_bot.start_autonomous_monitoring(self.chat_log, self.topic)\\\\\\\\n        )\\\\\\\\n        self.autonomous_tasks.append(task)\\\\\\\\n\\\\\\\\n    async def _facilitate_autonomous_discussion(self, start_time: float, total_time: int):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Facilitate the autonomous discussion without controlling it.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        last_message_count = len(self.chat_log.messages)\\\\\\\\n\\\\\\\\n        while time.time() - start_time < total_time:\\\\\\\\n            await asyncio.sleep(15)  # Check every 15 seconds\\\\\\\\n\\\\\\\\n            current_time = time.time()\\\\\\\\n            elapsed = current_time - start_time\\\\\\\\n            remaining = total_time - elapsed\\\\\\\\n\\\\\\\\n            # Check for new activity\\\\\\\\n            current_message_count = len(self.chat_log.messages)\\\\\\\\n            if current_message_count > last_message_count:\\\\\\\\n                self.last_activity_time = current_time\\\\\\\\n                last_message_count = current_message_count\\\\\\\\n\\\\\\\\n            # Check for prolonged silence - provide simple prompts\\\\\\\\n            silence_duration = current_time - self.last_activity_time\\\\\\\\n            if silence_duration > self.silence_timeout:\\\\\\\\n                # Simple fallback prompts if moderator bot hasn't spoken\\\\\\\\n                if current_time - self.last_moderator_prompt > 45:\\\\\\\\n                    await self._provide_simple_prompt()\\\\\\\\n                    self.last_moderator_prompt = current_time\\\\\\\\n\\\\\\\\n            # Provide time updates\\\\\\\\n            await self._provide_time_updates(remaining)\\\\\\\\n\\\\\\\\n    async def _provide_simple_prompt(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Provide simple facilitation prompts as fallback.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        simple_prompts = [\\\\\\\\n            \\\\\\\\\\\\\\\"üéØ What are your thoughts on the discussion so far?\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"üí° Any other perspectives to consider?\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"ü§î Does anyone have questions about the points raised?\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"‚öñÔ∏è How do you weigh the different arguments presented?\\\\\\\\\\\\\\\"\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n        prompt = random.choice(simple_prompts)\\\\\\\\n        await self._broadcast_message(prompt, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _provide_time_updates(self, remaining: float):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Provide time updates to participants.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if 299 < remaining <= 301:  # 5 minutes warning\\\\\\\\n            await self._broadcast_message(\\\\\\\\n                \\\\\\\\\\\\\\\"‚è∞ 5 minutes remaining in autonomous discussion phase\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n        elif 119 < remaining <= 121:  # 2 minutes warning\\\\\\\\n            await self._broadcast_message(\\\\\\\\n                \\\\\\\\\\\\\\\"‚è∞ 2 minutes left! Perfect time for final thoughts on this topic\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n        elif 59 < remaining <= 61:  # 1 minute warning\\\\\\\\n            await self._broadcast_message(\\\\\\\\n                \\\\\\\\\\\\\\\"‚è∞ Final minute! Any last contributions to the discussion?\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n\\\\\\\\n    async def _cleanup_autonomous_tasks(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Clean up all autonomous tasks.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Stop bot monitoring (including moderator bot)\\\\\\\\n        for participant in self.participants.values():\\\\\\\\n            if hasattr(participant, 'stop_monitoring'):\\\\\\\\n                await participant.stop_monitoring()\\\\\\\\n\\\\\\\\n        # Stop moderator bot monitoring\\\\\\\\n        await self.moderator_bot.stop_monitoring()\\\\\\\\n\\\\\\\\n        # Cancel all autonomous tasks\\\\\\\\n        for task in self.autonomous_tasks:\\\\\\\\n            if not task.done():\\\\\\\\n                task.cancel()\\\\\\\\n                try:\\\\\\\\n                    await task\\\\\\\\n                except asyncio.CancelledError:\\\\\\\\n                    pass\\\\\\\\n\\\\\\\\n        # Cancel phase management task\\\\\\\\n        if self.phase_task and not self.phase_task.done():\\\\\\\\n            self.phase_task.cancel()\\\\\\\\n            try:\\\\\\\\n                await self.phase_task\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\n                pass\\\\\\\\n\\\\\\\\n        self.autonomous_tasks.clear()\\\\\\\\n\\\\\\\\n    # Traditional phases (structured)\\\\\\\\n    async def _introduction_phase(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Introduce the debate topic and participants.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.INTRODUCTION\\\\\\\\n\\\\\\\\n        participants_by_type = {\\\\\\\\\\\\\\\"Bots\\\\\\\\\\\\\\\": [], \\\\\\\\\\\\\\\"Humans\\\\\\\\\\\\\\\": []}\\\\\\\\n        for name, participant in self.participants.items():\\\\\\\\n            if hasattr(participant, 'config'):  # Bot\\\\\\\\n                participants_by_type[\\\\\\\\\\\\\\\"Bots\\\\\\\\\\\\\\\"].append(f\\\\\\\\\\\\\\\"{name} ({participant.config.stance})\\\\\\\\\\\\\\\")\\\\\\\\n            else:  # Human\\\\\\\\n                participants_by_type[\\\\\\\\\\\\\\\"Humans\\\\\\\\\\\\\\\"].append(name)\\\\\\\\n\\\\\\\\n        intro_message = (\\\\\\\\n            f\\\\\\\\\\\\\\\"üé≠ Welcome to AI Jubilee Debate! üé≠\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"üìù Topic: {self.topic}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"üë• Participants:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   ü§ñ AI Bots: {', '.join(participants_by_type['Bots'])}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"   üë§ Humans: {', '.join(participants_by_type['Humans'])}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"‚è±Ô∏è Total discussion time: {self.config.get('time_limit_minutes', 30)} minutes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"üéØ Mode: {'Autonomous (organic flow)' if self.autonomous_mode else 'Sequential (turn-based)'}\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        await self._broadcast_message(intro_message, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n        await asyncio.sleep(3)\\\\\\\\n\\\\\\\\n    async def _opening_statements_phase(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle opening statements from each participant.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.OPENING_STATEMENTS\\\\\\\\n        statement_time = self.phase_times[DebatePhase.OPENING_STATEMENTS]\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"üé§ Opening Statements Phase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"Each participant has {statement_time} seconds for their opening statement.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"This phase uses structured turns regardless of debate mode.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        for participant_name in self.state.turn_order:\\\\\\\\n            await self._give_structured_turn(participant_name, statement_time, \\\\\\\\\\\\\\\"opening statement\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _traditional_discussion_phase(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Traditional sequential discussion phase.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"üí¨ Sequential Discussion Phase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"Participants take turns for {total_time // 60} minutes.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        start_time = time.time()\\\\\\\\n        response_time = self.config.get('response_time', 60)\\\\\\\\n\\\\\\\\n        while time.time() - start_time < total_time:\\\\\\\\n            for participant_name in self.state.turn_order:\\\\\\\\n                if time.time() - start_time >= total_time:\\\\\\\\n                    break\\\\\\\\n\\\\\\\\n                remaining = total_time - (time.time() - start_time)\\\\\\\\n                if remaining < response_time:\\\\\\\\n                    response_time = int(remaining)\\\\\\\\n\\\\\\\\n                await self._give_structured_turn(participant_name, response_time, \\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\"‚èπÔ∏è Sequential discussion phase complete!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _closing_statements_phase(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle closing statements.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.CLOSING_STATEMENTS\\\\\\\\n        statement_time = self.phase_times[DebatePhase.CLOSING_STATEMENTS]\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"üèÅ Closing Statements Phase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"Each participant has {statement_time} seconds for final remarks.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"This phase uses structured turns regardless of debate mode.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        # Reverse order for closing statements\\\\\\\\n        for participant_name in reversed(self.state.turn_order):\\\\\\\\n            await self._give_structured_turn(participant_name, statement_time, \\\\\\\\\\\\\\\"closing statement\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _give_structured_turn(self, participant_name: str, time_limit: int, turn_type: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Give structured speaking turn to a participant.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.current_speaker = participant_name\\\\\\\\n        self.state.time_remaining = time_limit\\\\\\\\n\\\\\\\\n        participant = self.participants[participant_name]\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"üé§ {participant_name}'s turn for {turn_type} ({time_limit}s)\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            response_task = asyncio.create_task(\\\\\\\\n                participant.get_response(self.topic, self.chat_log.get_recent_messages())\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            # Start timer\\\\\\\\n            start_time = time.time()\\\\\\\\n            warning_sent = False\\\\\\\\n\\\\\\\\n            while not response_task.done():\\\\\\\\n                elapsed = time.time() - start_time\\\\\\\\n                remaining = time_limit - elapsed\\\\\\\\n\\\\\\\\n                if remaining <= 0:\\\\\\\\n                    response_task.cancel()\\\\\\\\n                    try:\\\\\\\\n                        await response_task\\\\\\\\n                    except asyncio.CancelledError:\\\\\\\\n                        pass\\\\\\\\n                    await self._handle_timeout(participant_name)\\\\\\\\n                    break\\\\\\\\n\\\\\\\\n                if not warning_sent and remaining <= self.warning_time:\\\\\\\\n                    await self._send_warning(participant_name, remaining)\\\\\\\\n                    warning_sent = True\\\\\\\\n\\\\\\\\n                await asyncio.sleep(0.5)\\\\\\\\n\\\\\\\\n            # Process response if completed successfully\\\\\\\\n            if response_task.done() and not response_task.cancelled():\\\\\\\\n                try:\\\\\\\\n                    response = await response_task\\\\\\\\n                    if response:\\\\\\\\n                        await self._process_response(participant_name, response)\\\\\\\\n                except Exception as e:\\\\\\\\n                    await self._broadcast_message(\\\\\\\\n                        f\\\\\\\\\\\\\\\"‚ö†Ô∏è Error getting response from {participant_name}: {e}\\\\\\\\\\\\\\\",\\\\\\\\n                        \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n                    )\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            await self._broadcast_message(\\\\\\\\n                f\\\\\\\\\\\\\\\"‚ö†Ô∏è Error during {participant_name}'s turn: {e}\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n        finally:\\\\\\\\n            self.state.current_speaker = None\\\\\\\\n\\\\\\\\n    async def _voting_phase(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Conduct voting on debate performance.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.VOTING\\\\\\\\n\\\\\\\\n        if not self.voting_system.enabled:\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\"Voting disabled. Debate complete!\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n            return {}\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"üó≥Ô∏è Voting Phase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"Vote for the most persuasive participant. \\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"Voting closes in {self.phase_times[DebatePhase.VOTING]} seconds.\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        await self.voting_system.start_voting(\\\\\\\\n            list(self.participants.keys()),\\\\\\\\n            self.phase_times[DebatePhase.VOTING]\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        await asyncio.sleep(self.phase_times[DebatePhase.VOTING])\\\\\\\\n\\\\\\\\n        results = await self.voting_system.end_voting()\\\\\\\\n        return results\\\\\\\\n\\\\\\\\n    async def _results_phase(self, voting_results: Dict[str, Any]):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Announce final results.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.phase = DebatePhase.RESULTS\\\\\\\\n\\\\\\\\n        if voting_results:\\\\\\\\n            winner = voting_results.get('winner')\\\\\\\\n            vote_counts = voting_results.get('vote_counts', {})\\\\\\\\n\\\\\\\\n            results_msg = \\\\\\\\\\\\\\\"üèÜ DEBATE RESULTS üèÜ\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            results_msg += f\\\\\\\\\\\\\\\"Winner: {winner}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n            results_msg += \\\\\\\\\\\\\\\"Vote Breakdown:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n            for participant, votes in sorted(vote_counts.items(),\\\\\\\\n                                           key=lambda x: x[1], reverse=True):\\\\\\\\n                results_msg += f\\\\\\\\\\\\\\\"  {participant}: {votes} votes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        else:\\\\\\\\n            results_msg = \\\\\\\\\\\\\\\"ü§ù Debate concluded without voting. Great discussion everyone!\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        await self._broadcast_message(results_msg, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Show participation statistics\\\\\\\\n        stats_msg = \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüìä PARTICIPATION STATISTICS:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n        for participant_name, participant in self.participants.items():\\\\\\\\n            if hasattr(participant, 'get_stats'):\\\\\\\\n                stats = participant.get_stats()\\\\\\\\n                if hasattr(participant, 'config'):  # Bot\\\\\\\\n                    stats_msg += f\\\\\\\\\\\\\\\"ü§ñ {participant_name}: {stats.get('autonomous_responses', 0)} autonomous responses, \\\\\\\\\\\\\\\"\\\\\\\\n                    stats_msg += f\\\\\\\\\\\\\\\"{stats.get('success_rate', 0):.1%} success rate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n                else:  # Human\\\\\\\\n                    stats_msg += f\\\\\\\\\\\\\\\"üë§ {participant_name}: {stats.get('responses_given', 0)} responses, \\\\\\\\\\\\\\\"\\\\\\\\n                    stats_msg += f\\\\\\\\\\\\\\\"{stats.get('participation_rate', 0):.1%} participation rate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Show moderator stats\\\\\\\\n        moderator_stats = self.moderator_bot.get_stats()\\\\\\\\n        stats_msg += f\\\\\\\\\\\\\\\"üé≠ Moderator: {moderator_stats.get('autonomous_responses', 0)} facilitation prompts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        await self._broadcast_message(stats_msg, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\"Thank you for participating in AI Jubilee Debate! üé≠‚ú®\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Utility methods\\\\\\\\n    async def _process_response(self, participant_name: str, response: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Process and validate participant response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if len(response) > self.config.get('max_message_length', 500):\\\\\\\\n            response = response[:self.config.get('max_message_length', 500)] + \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\"\\\\\\\\n            await self._broadcast_message(\\\\\\\\n                f\\\\\\\\\\\\\\\"‚ö†Ô∏è {participant_name}'s response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n                \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n\\\\\\\\n        await self.chat_log.add_message(participant_name, response)\\\\\\\\n\\\\\\\\n    async def _handle_timeout(self, participant_name: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle participant timeout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.state.warnings_issued[participant_name] = (\\\\\\\\n            self.state.warnings_issued.get(participant_name, 0) + 1\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"‚è∞ {participant_name} exceeded time limit. \\\\\\\\\\\\\\\"\\\\\\\\n            f\\\\\\\\\\\\\\\"Warning {self.state.warnings_issued[participant_name]}/3\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    async def _send_warning(self, participant_name: str, time_remaining: float):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Send time warning to participant.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await self._broadcast_message(\\\\\\\\n            f\\\\\\\\\\\\\\\"‚è∞ {participant_name}: {int(time_remaining)} seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n    async def _broadcast_message(self, content: str, sender: str = \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Broadcast message to all participants and log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = await self.chat_log.add_message(sender, content, message_type=\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Send to all participants\\\\\\\\n        for participant in self.participants.values():\\\\\\\\n            try:\\\\\\\\n                await participant.receive_message(message)\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"Failed to send message to {participant.name}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    def get_state(self) -> DebateState:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get current debate state.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.state\\\\\\\"\\\\n        },\\\\n        \\\\\\\"streaming.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/streaming.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 15845,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nLive streaming and WebSocket server for real-time debate broadcasting.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport json\\\\\\\\nimport time\\\\\\\\nimport logging\\\\\\\\nfrom typing import Dict, List, Set, Any, Optional\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\nimport websockets\\\\\\\\nfrom websockets.server import WebSocketServerProtocol\\\\\\\\n\\\\\\\\nfrom .chat_log import ChatLog, Message\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\nfrom .utils import format_time_remaining\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass StreamingClient:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Information about a connected streaming client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    websocket: WebSocketServerProtocol\\\\\\\\n    client_id: str\\\\\\\\n    connected_at: float\\\\\\\\n    client_type: str = \\\\\\\\\\\\\\\"viewer\\\\\\\\\\\\\\\"  # viewer, participant, moderator\\\\\\\\n    metadata: Dict[str, Any] = None\\\\\\\\n\\\\\\\\n    def __post_init__(self):\\\\\\\\n        if self.metadata is None:\\\\\\\\n            self.metadata = {}\\\\\\\\n\\\\\\\\n\\\\\\\\nclass StreamingServer:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    WebSocket server for live streaming debate sessions.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, chat_log: ChatLog, voting_system: VotingSystem,\\\\\\\\n                 config: Dict[str, Any]):\\\\\\\\n        self.chat_log = chat_log\\\\\\\\n        self.voting_system = voting_system\\\\\\\\n        self.config = config\\\\\\\\n\\\\\\\\n        self.host = config.get('host', 'localhost')\\\\\\\\n        self.port = config.get('websocket_port', 8080)\\\\\\\\n        self.max_connections = config.get('max_connections', 100)\\\\\\\\n        self.broadcast_votes = config.get('broadcast_votes', True)\\\\\\\\n\\\\\\\\n        # Server state\\\\\\\\n        self.server = None\\\\\\\\n        self.clients: Dict[str, StreamingClient] = {}\\\\\\\\n        self.is_running = False\\\\\\\\n\\\\\\\\n        # Message subscription\\\\\\\\n        self.message_queue = None\\\\\\\\n        self.broadcast_task = None\\\\\\\\n\\\\\\\\n        # Statistics\\\\\\\\n        self.stats = {\\\\\\\\n            'total_connections': 0,\\\\\\\\n            'messages_sent': 0,\\\\\\\\n            'votes_broadcast': 0,\\\\\\\\n            'start_time': time.time()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        self.logger = logging.getLogger(__name__)\\\\\\\\n\\\\\\\\n    async def start(self) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Start the streaming server.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if self.is_running:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            # Subscribe to chat log messages\\\\\\\\n            self.message_queue = self.chat_log.subscribe()\\\\\\\\n\\\\\\\\n            # Start WebSocket server\\\\\\\\n            self.server = await websockets.serve(\\\\\\\\n                self._handle_client,\\\\\\\\n                self.host,\\\\\\\\n                self.port,\\\\\\\\n                max_size=1024 * 1024,  # 1MB max message size\\\\\\\\n                ping_interval=20,\\\\\\\\n                ping_timeout=10\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            # Start broadcast task\\\\\\\\n            self.broadcast_task = asyncio.create_task(self._broadcast_loop())\\\\\\\\n\\\\\\\\n            self.is_running = True\\\\\\\\n            self.logger.info(f\\\\\\\\\\\\\\\"Streaming server started on {self.host}:{self.port}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        except Exception as e:\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\"Failed to start streaming server: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            raise\\\\\\\\n\\\\\\\\n    async def stop(self) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Stop the streaming server.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.is_running:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        self.is_running = False\\\\\\\\n\\\\\\\\n        # Stop broadcast task\\\\\\\\n        if self.broadcast_task:\\\\\\\\n            self.broadcast_task.cancel()\\\\\\\\n            try:\\\\\\\\n                await self.broadcast_task\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\n                pass\\\\\\\\n\\\\\\\\n        # Close all client connections\\\\\\\\n        if self.clients:\\\\\\\\n            await asyncio.gather(\\\\\\\\n                *[client.websocket.close() for client in self.clients.values()],\\\\\\\\n                return_exceptions=True\\\\\\\\n            )\\\\\\\\n\\\\\\\\n        # Stop WebSocket server\\\\\\\\n        if self.server:\\\\\\\\n            self.server.close()\\\\\\\\n            await self.server.wait_closed()\\\\\\\\n\\\\\\\\n        # Unsubscribe from chat log\\\\\\\\n        if self.message_queue:\\\\\\\\n            self.chat_log.unsubscribe(self.message_queue)\\\\\\\\n\\\\\\\\n        self.logger.info(\\\\\\\\\\\\\\\"Streaming server stopped\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _handle_client(self, websocket: WebSocketServerProtocol, path: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Handle new client connection.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if len(self.clients) >= self.max_connections:\\\\\\\\n            await websocket.close(code=1013, reason=\\\\\\\\\\\\\\\"Server full\\\\\\\\\\\\\\\")\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        client_id = f\\\\\\\\\\\\\\\"client_{int(time.time() * 1000)}\\\\\\\\\\\\\\\"\\\\\\\\n        client = StreamingClient(\\\\\\\\n            websocket=websocket,\\\\\\\\n            client_id=client_id,\\\\\\\\n            connected_at=time.time()\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        self.clients[client_id] = client\\\\\\\\n        self.stats['total_connections'] += 1\\\\\\\\n\\\\\\\\n        self.logger.info(f\\\\\\\\\\\\\\\"Client {client_id} connected from {websocket.remote_address}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            # Send welcome message\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\n                'type': 'welcome',\\\\\\\\n                'client_id': client_id,\\\\\\\\n                'server_info': {\\\\\\\\n                    'version': '1.0.0',\\\\\\\\n                    'features': ['chat', 'voting', 'real_time']\\\\\\\\n                }\\\\\\\\n            })\\\\\\\\n\\\\\\\\n            # Send recent messages\\\\\\\\n            recent_messages = self.chat_log.get_recent_messages(10)\\\\\\\\n            for msg in recent_messages:\\\\\\\\n                await self._send_to_client(client, {\\\\\\\\n                    'type': 'message',\\\\\\\\n                    'data': msg.to_dict()\\\\\\\\n                })\\\\\\\\n\\\\\\\\n            # Handle client messages\\\\\\\\n            async for message in websocket:\\\\\\\\n                try:\\\\\\\\n                    await self._process_client_message(client, json.loads(message))\\\\\\\\n                except json.JSONDecodeError:\\\\\\\\n                    await self._send_error(client, \\\\\\\\\\\\\\\"Invalid JSON message\\\\\\\\\\\\\\\")\\\\\\\\n                except Exception as e:\\\\\\\\n                    self.logger.error(f\\\\\\\\\\\\\\\"Error processing client message: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                    await self._send_error(client, \\\\\\\\\\\\\\\"Internal server error\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        except websockets.exceptions.ConnectionClosed:\\\\\\\\n            self.logger.info(f\\\\\\\\\\\\\\\"Client {client_id} disconnected\\\\\\\\\\\\\\\")\\\\\\\\n        except Exception as e:\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\"Client {client_id} error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n        finally:\\\\\\\\n            # Clean up client\\\\\\\\n            if client_id in self.clients:\\\\\\\\n                del self.clients[client_id]\\\\\\\\n\\\\\\\\n    async def _process_client_message(self, client: StreamingClient, data: Dict[str, Any]):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Process message from client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message_type = data.get('type')\\\\\\\\n\\\\\\\\n        if message_type == 'ping':\\\\\\\\n            await self._send_to_client(client, {'type': 'pong'})\\\\\\\\n\\\\\\\\n        elif message_type == 'subscribe':\\\\\\\\n            # Update client subscription preferences\\\\\\\\n            client.metadata['subscriptions'] = data.get('channels', [])\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\n                'type': 'subscribed',\\\\\\\\n                'channels': client.metadata.get('subscriptions', [])\\\\\\\\n            })\\\\\\\\n\\\\\\\\n        elif message_type == 'get_stats':\\\\\\\\n            # Send server statistics\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\n                'type': 'stats',\\\\\\\\n                'data': self._get_server_stats()\\\\\\\\n            })\\\\\\\\n\\\\\\\\n        elif message_type == 'vote' and self.voting_system.is_active:\\\\\\\\n            # Handle vote from client\\\\\\\\n            voter_id = data.get('voter_id', client.client_id)\\\\\\\\n            candidate = data.get('candidate')\\\\\\\\n            justification = data.get('justification')\\\\\\\\n\\\\\\\\n            try:\\\\\\\\n                success = await self.voting_system.cast_vote(\\\\\\\\n                    voter_id, candidate, justification\\\\\\\\n                )\\\\\\\\n\\\\\\\\n                await self._send_to_client(client, {\\\\\\\\n                    'type': 'vote_result',\\\\\\\\n                    'success': success,\\\\\\\\n                    'candidate': candidate\\\\\\\\n                })\\\\\\\\n\\\\\\\\n                if success and self.broadcast_votes:\\\\\\\\n                    await self._broadcast_vote_update()\\\\\\\\n\\\\\\\\n            except Exception as e:\\\\\\\\n                await self._send_error(client, f\\\\\\\\\\\\\\\"Vote failed: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        else:\\\\\\\\n            await self._send_error(client, f\\\\\\\\\\\\\\\"Unknown message type: {message_type}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _broadcast_loop(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main broadcast loop for new messages.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            while self.is_running:\\\\\\\\n                try:\\\\\\\\n                    # Wait for new message from chat log\\\\\\\\n                    message = await asyncio.wait_for(\\\\\\\\n                        self.message_queue.get(),\\\\\\\\n                        timeout=1.0\\\\\\\\n                    )\\\\\\\\n\\\\\\\\n                    # Broadcast to all clients\\\\\\\\n                    await self._broadcast_message(message)\\\\\\\\n\\\\\\\\n                except asyncio.TimeoutError:\\\\\\\\n                    # Timeout is expected, continue loop\\\\\\\\n                    continue\\\\\\\\n                except Exception as e:\\\\\\\\n                    self.logger.error(f\\\\\\\\\\\\\\\"Broadcast loop error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n                    await asyncio.sleep(1)\\\\\\\\n\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\n            self.logger.info(\\\\\\\\\\\\\\\"Broadcast loop cancelled\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _broadcast_message(self, message: Message):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Broadcast message to all connected clients.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.clients:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        broadcast_data = {\\\\\\\\n            'type': 'message',\\\\\\\\n            'data': message.to_dict()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        # Send to all clients\\\\\\\\n        tasks = []\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\n            if self._should_send_to_client(client, message):\\\\\\\\n                tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\n\\\\\\\\n        if tasks:\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\n            self.stats['messages_sent'] += len(tasks)\\\\\\\\n\\\\\\\\n    def _should_send_to_client(self, client: StreamingClient, message: Message) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Determine if message should be sent to client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Check client subscriptions\\\\\\\\n        subscriptions = client.metadata.get('subscriptions', [])\\\\\\\\n\\\\\\\\n        if subscriptions:\\\\\\\\n            # If client has specific subscriptions, check them\\\\\\\\n            if message.message_type not in subscriptions:\\\\\\\\n                return False\\\\\\\\n\\\\\\\\n        return True\\\\\\\\n\\\\\\\\n    async def _broadcast_vote_update(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Broadcast voting update to clients.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.voting_system.is_active:\\\\\\\\n            return\\\\\\\\n\\\\\\\\n        vote_summary = self.voting_system.get_vote_summary()\\\\\\\\n\\\\\\\\n        broadcast_data = {\\\\\\\\n            'type': 'vote_update',\\\\\\\\n            'data': vote_summary\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        tasks = []\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\n\\\\\\\\n        if tasks:\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\n            self.stats['votes_broadcast'] += 1\\\\\\\\n\\\\\\\\n    async def _send_to_client(self, client: StreamingClient, data: Dict[str, Any]):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Send data to specific client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        try:\\\\\\\\n            await client.websocket.send(json.dumps(data))\\\\\\\\n        except websockets.exceptions.ConnectionClosed:\\\\\\\\n            # Client disconnected, will be cleaned up\\\\\\\\n            pass\\\\\\\\n        except Exception as e:\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\"Failed to send to client {client.client_id}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def _send_error(self, client: StreamingClient, error_message: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Send error message to client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await self._send_to_client(client, {\\\\\\\\n            'type': 'error',\\\\\\\\n            'message': error_message\\\\\\\\n        })\\\\\\\\n\\\\\\\\n    def _get_server_stats(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get server statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        uptime = time.time() - self.stats['start_time']\\\\\\\\n\\\\\\\\n        return {\\\\\\\\n            'connected_clients': len(self.clients),\\\\\\\\n            'total_connections': self.stats['total_connections'],\\\\\\\\n            'messages_sent': self.stats['messages_sent'],\\\\\\\\n            'votes_broadcast': self.stats['votes_broadcast'],\\\\\\\\n            'uptime_seconds': uptime,\\\\\\\\n            'uptime_formatted': format_time_remaining(uptime),\\\\\\\\n            'is_voting_active': self.voting_system.is_active if self.voting_system else False\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    async def broadcast_custom_message(self, message_type: str, data: Any):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Broadcast custom message to all clients.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        broadcast_data = {\\\\\\\\n            'type': message_type,\\\\\\\\n            'data': data,\\\\\\\\n            'timestamp': time.time()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        tasks = []\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\n\\\\\\\\n        if tasks:\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\n\\\\\\\\n    async def send_to_specific_clients(self, client_ids: List[str],\\\\\\\\n                                       message_type: str, data: Any):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Send message to specific clients.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = {\\\\\\\\n            'type': message_type,\\\\\\\\n            'data': data,\\\\\\\\n            'timestamp': time.time()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        tasks = []\\\\\\\\n        for client_id in client_ids:\\\\\\\\n            if client_id in self.clients:\\\\\\\\n                client = self.clients[client_id]\\\\\\\\n                tasks.append(self._send_to_client(client, message))\\\\\\\\n\\\\\\\\n        if tasks:\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\n\\\\\\\\n    def get_connected_clients(self) -> List[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get information about connected clients.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return [\\\\\\\\n            {\\\\\\\\n                'client_id': client.client_id,\\\\\\\\n                'connected_at': client.connected_at,\\\\\\\\n                'client_type': client.client_type,\\\\\\\\n                'connection_duration': time.time() - client.connected_at\\\\\\\\n            }\\\\\\\\n            for client in self.clients.values()\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n    @property\\\\\\\\n    def is_active(self) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if server is running.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return self.is_running\\\\\\\\n\\\\\\\\n    @property\\\\\\\\n    def client_count(self) -> int:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get number of connected clients.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return len(self.clients)\\\\\\\\n\\\\\\\\n\\\\\\\\nclass StreamingManager:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    High-level manager for streaming functionality.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self):\\\\\\\\n        self.servers: Dict[str, StreamingServer] = {}\\\\\\\\n        self.is_initialized = False\\\\\\\\n\\\\\\\\n    async def create_streaming_session(self, session_id: str, chat_log: ChatLog,\\\\\\\\n                                       voting_system: VotingSystem,\\\\\\\\n                                       config: Dict[str, Any]) -> StreamingServer:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Create a new streaming session.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            session_id: Unique session identifier\\\\\\\\n            chat_log: Chat log to stream\\\\\\\\n            voting_system: Voting system to integrate\\\\\\\\n            config: Streaming configuration\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            StreamingServer instance\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if session_id in self.servers:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Streaming session {session_id} already exists\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Create unique port for this session\\\\\\\\n        base_port = config.get('websocket_port', 8080)\\\\\\\\n        port = base_port + len(self.servers)\\\\\\\\n\\\\\\\\n        session_config = config.copy()\\\\\\\\n        session_config['websocket_port'] = port\\\\\\\\n\\\\\\\\n        server = StreamingServer(chat_log, voting_system, session_config)\\\\\\\\n        self.servers[session_id] = server\\\\\\\\n\\\\\\\\n        await server.start()\\\\\\\\n        return server\\\\\\\\n\\\\\\\\n    async def stop_streaming_session(self, session_id: str):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Stop a streaming session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if session_id in self.servers:\\\\\\\\n            server = self.servers[session_id]\\\\\\\\n            await server.stop()\\\\\\\\n            del self.servers[session_id]\\\\\\\\n\\\\\\\\n    async def stop_all_sessions(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Stop all streaming sessions.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        tasks = []\\\\\\\\n        for session_id in list(self.servers.keys()):\\\\\\\\n            tasks.append(self.stop_streaming_session(session_id))\\\\\\\\n\\\\\\\\n        if tasks:\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\n\\\\\\\\n    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get information about a streaming session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if session_id not in self.servers:\\\\\\\\n            return None\\\\\\\\n\\\\\\\\n        server = self.servers[session_id]\\\\\\\\n        return {\\\\\\\\n            'session_id': session_id,\\\\\\\\n            'is_active': server.is_active,\\\\\\\\n            'client_count': server.client_count,\\\\\\\\n            'host': server.host,\\\\\\\\n            'port': server.port,\\\\\\\\n            'stats': server._get_server_stats()\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    def list_active_sessions(self) -> List[str]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get list of active session IDs.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return [\\\\\\\\n            session_id for session_id, server in self.servers.items()\\\\\\\\n            if server.is_active\\\\\\\\n        ]\\\\\\\"\\\\n        },\\\\n        \\\\\\\"utils.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/utils.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 10954,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nUtility functions for the AI Jubilee Debate System.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport os\\\\\\\\nimport yaml\\\\\\\\nimport logging\\\\\\\\nimport time\\\\\\\\nimport re\\\\\\\\nfrom typing import Dict, Any, List, Optional\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom datetime import datetime, timedelta\\\\\\\\n\\\\\\\\n\\\\\\\\ndef load_config(config_path: str = \\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\") -> Dict[str, Any]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Load configuration from YAML file with environment variable substitution.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        config_path: Path to configuration file\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Configuration dictionary\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    config_file = Path(config_path)\\\\\\\\n\\\\\\\\n    if not config_file.exists():\\\\\\\\n        raise FileNotFoundError(f\\\\\\\\\\\\\\\"Configuration file not found: {config_path}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    with open(config_file, 'r', encoding='utf-8') as f:\\\\\\\\n        config_content = f.read()\\\\\\\\n\\\\\\\\n    # Substitute environment variables\\\\\\\\n    config_content = substitute_env_vars(config_content)\\\\\\\\n\\\\\\\\n    try:\\\\\\\\n        config = yaml.safe_load(config_content)\\\\\\\\n        return config\\\\\\\\n    except yaml.YAMLError as e:\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\\"Invalid YAML configuration: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\ndef substitute_env_vars(text: str) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Substitute environment variables in text using ${VAR_NAME} syntax.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        text: Text containing environment variable references\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Text with environment variables substituted\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    def replace_env_var(match):\\\\\\\\n        var_name = match.group(1)\\\\\\\\n        env_value = os.getenv(var_name)\\\\\\\\n        if env_value is None:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"Warning: Environment variable {var_name} not found\\\\\\\\\\\\\\\")\\\\\\\\n            return f\\\\\\\\\\\\\\\"${{{var_name}}}\\\\\\\\\\\\\\\"  # Keep original if not found\\\\\\\\n        return env_value\\\\\\\\n\\\\\\\\n    return re.sub(r'\\\\\\\\\\\\\\\\$\\\\\\\\\\\\\\\\{([^}]+)\\\\\\\\\\\\\\\\}', replace_env_var, text)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef setup_logging(level: str = \\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\", log_file: Optional[str] = None) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Setup logging configuration.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        level: Logging level (DEBUG, INFO, WARNING, ERROR)\\\\\\\\n        log_file: Optional log file path\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\\\\\\\\n\\\\\\\\n    # Create formatter\\\\\\\\n    formatter = logging.Formatter(\\\\\\\\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\\\\\\\n    )\\\\\\\\n\\\\\\\\n    # Setup root logger\\\\\\\\n    root_logger = logging.getLogger()\\\\\\\\n    root_logger.setLevel(numeric_level)\\\\\\\\n\\\\\\\\n    # Clear existing handlers\\\\\\\\n    root_logger.handlers.clear()\\\\\\\\n\\\\\\\\n    # Console handler\\\\\\\\n    console_handler = logging.StreamHandler()\\\\\\\\n    console_handler.setFormatter(formatter)\\\\\\\\n    root_logger.addHandler(console_handler)\\\\\\\\n\\\\\\\\n    # File handler if specified\\\\\\\\n    if log_file:\\\\\\\\n        file_handler = logging.FileHandler(log_file)\\\\\\\\n        file_handler.setFormatter(formatter)\\\\\\\\n        root_logger.addHandler(file_handler)\\\\\\\\n\\\\\\\\n\\\\\\\\ndef format_time_remaining(seconds: float) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Format remaining time in human-readable format.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        seconds: Time remaining in seconds\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Formatted time string\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if seconds <= 0:\\\\\\\\n        return \\\\\\\\\\\\\\\"Time's up!\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    if seconds < 60:\\\\\\\\n        return f\\\\\\\\\\\\\\\"{int(seconds)} seconds\\\\\\\\\\\\\\\"\\\\\\\\n    elif seconds < 3600:\\\\\\\\n        minutes = int(seconds // 60)\\\\\\\\n        secs = int(seconds % 60)\\\\\\\\n        return f\\\\\\\\\\\\\\\"{minutes}m {secs}s\\\\\\\\\\\\\\\"\\\\\\\\n    else:\\\\\\\\n        hours = int(seconds // 3600)\\\\\\\\n        minutes = int((seconds % 3600) // 60)\\\\\\\\n        return f\\\\\\\\\\\\\\\"{hours}h {minutes}m\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\") -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Truncate text to maximum length with suffix.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        text: Text to truncate\\\\\\\\n        max_length: Maximum length\\\\\\\\n        suffix: Suffix to add when truncating\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Truncated text\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if len(text) <= max_length:\\\\\\\\n        return text\\\\\\\\n\\\\\\\\n    return text[:max_length - len(suffix)] + suffix\\\\\\\\n\\\\\\\\n\\\\\\\\ndef generate_debate_prompt(topic: str, role: str, personality: str) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Generate a debate prompt for AI participants.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        topic: Debate topic\\\\\\\\n        role: Participant role (pro, con, neutral)\\\\\\\\n        personality: Personality description\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Generated prompt\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    base_prompt = f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"You are participating in a structured debate on the topic: \\\\\\\\\\\\\\\"{topic}\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nYour role: {role}\\\\\\\\nYour personality: {personality}\\\\\\\\n\\\\\\\\nInstructions:\\\\\\\\n1. Present clear, logical arguments\\\\\\\\n2. Respond to other participants' points\\\\\\\\n3. Stay focused on the topic\\\\\\\\n4. Be respectful but persuasive\\\\\\\\n5. Keep responses concise and engaging\\\\\\\\n\\\\\\\\nCurrent debate topic: {topic}\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    if role.lower() == \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\":\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nYou should argue IN FAVOR of the topic.\\\\\\\\\\\\\\\"\\\\\\\\n    elif role.lower() == \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\":\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nYou should argue AGAINST the topic.\\\\\\\\\\\\\\\"\\\\\\\\n    elif role.lower() == \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\":\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nYou should present balanced perspectives and ask probing questions.\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    return base_prompt\\\\\\\\n\\\\\\\\n\\\\\\\\ndef validate_participant_name(name: str) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Validate participant name.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        name: Participant name to validate\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        True if valid, False otherwise\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if not name or len(name.strip()) == 0:\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n    # Check length\\\\\\\\n    if len(name) > 50:\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n    # Check for valid characters (alphanumeric, spaces, underscores, hyphens)\\\\\\\\n    if not re.match(r'^[a-zA-Z0-9\\\\\\\\\\\\\\\\s_-]+$', name):\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n    return True\\\\\\\\n\\\\\\\\n\\\\\\\\ndef sanitize_filename(filename: str) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Sanitize filename for safe file operations.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        filename: Original filename\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Sanitized filename\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Remove or replace invalid characters\\\\\\\\n    sanitized = re.sub(r'[<>:\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|?*]', '_', filename)\\\\\\\\n\\\\\\\\n    # Remove leading/trailing spaces and dots\\\\\\\\n    sanitized = sanitized.strip(' .')\\\\\\\\n\\\\\\\\n    # Limit length\\\\\\\\n    if len(sanitized) > 255:\\\\\\\\n        sanitized = sanitized[:255]\\\\\\\\n\\\\\\\\n    return sanitized\\\\\\\\n\\\\\\\\n\\\\\\\\ndef parse_duration(duration_str: str) -> int:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Parse duration string into seconds.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        duration_str: Duration string (e.g., \\\\\\\\\\\\\\\"5m\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"30s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"1h30m\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Duration in seconds\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if duration_str.isdigit():\\\\\\\\n        return int(duration_str)\\\\\\\\n\\\\\\\\n    total_seconds = 0\\\\\\\\n\\\\\\\\n    # Parse hours\\\\\\\\n    hours_match = re.search(r'(\\\\\\\\\\\\\\\\d+)h', duration_str.lower())\\\\\\\\n    if hours_match:\\\\\\\\n        total_seconds += int(hours_match.group(1)) * 3600\\\\\\\\n\\\\\\\\n    # Parse minutes\\\\\\\\n    minutes_match = re.search(r'(\\\\\\\\\\\\\\\\d+)m', duration_str.lower())\\\\\\\\n    if minutes_match:\\\\\\\\n        total_seconds += int(minutes_match.group(1)) * 60\\\\\\\\n\\\\\\\\n    # Parse seconds\\\\\\\\n    seconds_match = re.search(r'(\\\\\\\\\\\\\\\\d+)s', duration_str.lower())\\\\\\\\n    if seconds_match:\\\\\\\\n        total_seconds += int(seconds_match.group(1))\\\\\\\\n\\\\\\\\n    return total_seconds if total_seconds > 0 else 60  # Default to 60 seconds\\\\\\\\n\\\\\\\\n\\\\\\\\ndef create_timestamp() -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Create ISO format timestamp.\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        ISO formatted timestamp string\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return datetime.now().isoformat()\\\\\\\\n\\\\\\\\n\\\\\\\\ndef format_participant_list(participants: List[str], max_display: int = 5) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Format participant list for display.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        participants: List of participant names\\\\\\\\n        max_display: Maximum participants to display before truncating\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Formatted participant string\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if len(participants) <= max_display:\\\\\\\\n        return \\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\".join(participants)\\\\\\\\n\\\\\\\\n    displayed = participants[:max_display]\\\\\\\\n    remaining = len(participants) - max_display\\\\\\\\n\\\\\\\\n    return f\\\\\\\\\\\\\\\"{', '.join(displayed)} (+{remaining} more)\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\ndef calculate_word_count(text: str) -> int:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Calculate word count in text.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        text: Text to count words in\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Number of words\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return len(text.split())\\\\\\\\n\\\\\\\\n\\\\\\\\ndef extract_key_phrases(text: str, max_phrases: int = 5) -> List[str]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Extract key phrases from text (simple implementation).\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        text: Text to extract phrases from\\\\\\\\n        max_phrases: Maximum number of phrases to return\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        List of key phrases\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Simple implementation - could be enhanced with NLP\\\\\\\\n    sentences = text.split('.')\\\\\\\\n    phrases = []\\\\\\\\n\\\\\\\\n    for sentence in sentences[:max_phrases]:\\\\\\\\n        sentence = sentence.strip()\\\\\\\\n        if len(sentence) > 10:  # Minimum length\\\\\\\\n            phrases.append(sentence)\\\\\\\\n\\\\\\\\n    return phrases[:max_phrases]\\\\\\\\n\\\\\\\\n\\\\\\\\ndef generate_session_id() -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Generate unique session ID.\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Unique session identifier\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    import uuid\\\\\\\\n    return str(uuid.uuid4())[:8]\\\\\\\\n\\\\\\\\n\\\\\\\\ndef ensure_directory(path: str) -> Path:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Ensure directory exists, create if necessary.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        path: Directory path\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Path object\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    dir_path = Path(path)\\\\\\\\n    dir_path.mkdir(parents=True, exist_ok=True)\\\\\\\\n    return dir_path\\\\\\\\n\\\\\\\\n\\\\\\\\ndef load_debate_topics(topics_file: str = \\\\\\\\\\\\\\\"topics.txt\\\\\\\\\\\\\\\") -> List[str]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Load debate topics from file.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        topics_file: Path to topics file\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        List of debate topics\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    topics_path = Path(topics_file)\\\\\\\\n\\\\\\\\n    if not topics_path.exists():\\\\\\\\n        # Return default topics\\\\\\\\n        return [\\\\\\\\n            \\\\\\\\\\\\\\\"Artificial intelligence will create more jobs than it destroys\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"Social media has a net positive impact on society\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\"\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n    with open(topics_path, 'r', encoding='utf-8') as f:\\\\\\\\n        topics = [line.strip() for line in f if line.strip() and not line.startswith('#')]\\\\\\\\n\\\\\\\\n    return topics\\\\\\\\n\\\\\\\\n\\\\\\\\nclass PerformanceTimer:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Context manager for timing operations.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, operation_name: str = \\\\\\\\\\\\\\\"Operation\\\\\\\\\\\\\\\"):\\\\\\\\n        self.operation_name = operation_name\\\\\\\\n        self.start_time = None\\\\\\\\n        self.end_time = None\\\\\\\\n\\\\\\\\n    def __enter__(self):\\\\\\\\n        self.start_time = time.time()\\\\\\\\n        return self\\\\\\\\n\\\\\\\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\\\\\\\n        self.end_time = time.time()\\\\\\\\n\\\\\\\\n    @property\\\\\\\\n    def duration(self) -> float:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get operation duration in seconds.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if self.start_time and self.end_time:\\\\\\\\n            return self.end_time - self.start_time\\\\\\\\n        return 0.0\\\\\\\\n\\\\\\\\n    def __str__(self) -> str:\\\\\\\\n        return f\\\\\\\\\\\\\\\"{self.operation_name}: {self.duration:.3f}s\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Decorator for retrying operations with exponential backoff.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        max_retries: Maximum number of retry attempts\\\\\\\\n        base_delay: Base delay between retries\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    def decorator(func):\\\\\\\\n        async def wrapper(*args, **kwargs):\\\\\\\\n            last_exception = None\\\\\\\\n\\\\\\\\n            for attempt in range(max_retries + 1):\\\\\\\\n                try:\\\\\\\\n                    return await func(*args, **kwargs)\\\\\\\\n                except Exception as e:\\\\\\\\n                    last_exception = e\\\\\\\\n\\\\\\\\n                    if attempt < max_retries:\\\\\\\\n                        delay = base_delay * (2 ** attempt)\\\\\\\\n                        await asyncio.sleep(delay)\\\\\\\\n                    else:\\\\\\\\n                        raise last_exception\\\\\\\\n\\\\\\\\n            raise last_exception\\\\\\\\n\\\\\\\\n        return wrapper\\\\\\\\n    return decorator\\\\\\\"\\\\n        },\\\\n        \\\\\\\"voting.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"app/voting.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 11436,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nVoting system for debate evaluation and winner determination.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport time\\\\\\\\nfrom typing import Dict, List, Optional, Any\\\\\\\\nfrom dataclasses import dataclass, field\\\\\\\\nfrom collections import defaultdict, Counter\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass Vote:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Represents a single vote.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    voter_id: str\\\\\\\\n    candidate: str\\\\\\\\n    justification: Optional[str] = None\\\\\\\\n    timestamp: float = field(default_factory=time.time)\\\\\\\\n    anonymous: bool = False\\\\\\\\n\\\\\\\\n\\\\\\\\n@dataclass\\\\\\\\nclass VotingResults:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Results of a voting session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    winner: Optional[str]\\\\\\\\n    vote_counts: Dict[str, int]\\\\\\\\n    total_votes: int\\\\\\\\n    votes_by_voter: Dict[str, Vote]\\\\\\\\n    voting_duration: float\\\\\\\\n    participation_rate: float\\\\\\\\n\\\\\\\\n\\\\\\\\nclass VotingSystem:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Manages voting process, vote collection, and result calculation.\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def __init__(self, config: Dict[str, Any]):\\\\\\\\n        self.config = config\\\\\\\\n        self.enabled = config.get('enabled', True)\\\\\\\\n        self.voting_duration = config.get('voting_duration', 300)\\\\\\\\n        self.allow_participant_voting = config.get('allow_participant_voting', True)\\\\\\\\n        self.require_justification = config.get('require_justification', True)\\\\\\\\n        self.anonymous_votes = config.get('anonymous_votes', False)\\\\\\\\n\\\\\\\\n        # Voting state\\\\\\\\n        self.is_active = False\\\\\\\\n        self.candidates: List[str] = []\\\\\\\\n        self.eligible_voters: List[str] = []\\\\\\\\n        self.votes: Dict[str, Vote] = {}\\\\\\\\n        self.start_time: Optional[float] = None\\\\\\\\n        self.end_time: Optional[float] = None\\\\\\\\n\\\\\\\\n        # Vote validation\\\\\\\\n        self.vote_history: List[Dict[str, Any]] = []\\\\\\\\n\\\\\\\\n    async def start_voting(self, candidates: List[str], duration: Optional[int] = None) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Start a voting session.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            candidates: List of debate participants to vote for\\\\\\\\n            duration: Voting duration in seconds (uses config default if None)\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.enabled:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"Voting system is disabled\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        if self.is_active:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"Voting session already active\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        self.candidates = candidates.copy()\\\\\\\\n        self.eligible_voters = candidates.copy() if self.allow_participant_voting else []\\\\\\\\n        self.votes = {}\\\\\\\\n        self.start_time = time.time()\\\\\\\\n        self.end_time = self.start_time + (duration or self.voting_duration)\\\\\\\\n        self.is_active = True\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üó≥Ô∏è Voting started for {len(candidates)} candidates\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"‚è∞ Voting closes in {duration or self.voting_duration} seconds\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    async def cast_vote(self, voter_id: str, candidate: str,\\\\\\\\n                        justification: Optional[str] = None) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Cast a vote for a candidate.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            voter_id: ID of the voter\\\\\\\\n            candidate: Candidate being voted for\\\\\\\\n            justification: Optional reasoning for the vote\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            True if vote was successfully cast, False otherwise\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.is_active:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        if time.time() > self.end_time:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"Voting period has ended\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Validate voter eligibility\\\\\\\\n        if not self._is_eligible_voter(voter_id):\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Voter {voter_id} is not eligible to vote\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Validate candidate\\\\\\\\n        if candidate not in self.candidates:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Invalid candidate: {candidate}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Check for self-voting\\\\\\\\n        if voter_id == candidate and not self.allow_participant_voting:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"Self-voting is not allowed\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Validate justification requirement\\\\\\\\n        if self.require_justification and not justification:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"Vote justification is required\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Record the vote (overwrites previous vote from same voter)\\\\\\\\n        vote = Vote(\\\\\\\\n            voter_id=voter_id,\\\\\\\\n            candidate=candidate,\\\\\\\\n            justification=justification,\\\\\\\\n            anonymous=self.anonymous_votes\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        self.votes[voter_id] = vote\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"‚úÖ Vote recorded: {voter_id} -> {candidate}\\\\\\\\\\\\\\\")\\\\\\\\n        return True\\\\\\\\n\\\\\\\\n    async def end_voting(self) -> VotingResults:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        End the voting session and calculate results.\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            VotingResults object with winner and vote breakdown\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.is_active:\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        self.is_active = False\\\\\\\\n        actual_end_time = time.time()\\\\\\\\n\\\\\\\\n        # Calculate vote counts\\\\\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\\\\\n        total_votes = len(self.votes)\\\\\\\\n\\\\\\\\n        # Determine winner\\\\\\\\n        winner = None\\\\\\\\n        if vote_counts:\\\\\\\\n            max_votes = max(vote_counts.values())\\\\\\\\n            winners = [candidate for candidate, count in vote_counts.items()\\\\\\\\n                       if count == max_votes]\\\\\\\\n\\\\\\\\n            if len(winners) == 1:\\\\\\\\n                winner = winners[0]\\\\\\\\n            else:\\\\\\\\n                # Handle tie - could implement tiebreaker logic here\\\\\\\\n                winner = f\\\\\\\\\\\\\\\"TIE: {', '.join(winners)}\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Calculate participation rate\\\\\\\\n        participation_rate = (total_votes / len(self.eligible_voters)\\\\\\\\n                              if self.eligible_voters else 0)\\\\\\\\n\\\\\\\\n        # Create results\\\\\\\\n        results = VotingResults(\\\\\\\\n            winner=winner,\\\\\\\\n            vote_counts=dict(vote_counts),\\\\\\\\n            total_votes=total_votes,\\\\\\\\n            votes_by_voter=self.votes.copy(),\\\\\\\\n            voting_duration=actual_end_time - self.start_time,\\\\\\\\n            participation_rate=participation_rate\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        # Store in history\\\\\\\\n        self.vote_history.append({\\\\\\\\n            'timestamp': actual_end_time,\\\\\\\\n            'candidates': self.candidates.copy(),\\\\\\\\n            'results': results\\\\\\\\n        })\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üèÜ Voting ended. Winner: {winner}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìä Total votes: {total_votes}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìà Participation: {participation_rate:.1%}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        return results\\\\\\\\n\\\\\\\\n    def _is_eligible_voter(self, voter_id: str) -> bool:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if a voter is eligible to vote.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.eligible_voters:\\\\\\\\n            return True  # Open voting\\\\\\\\n        return voter_id in self.eligible_voters\\\\\\\\n\\\\\\\\n    def add_eligible_voter(self, voter_id: str) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Add a voter to the eligible voters list.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if voter_id not in self.eligible_voters:\\\\\\\\n            self.eligible_voters.append(voter_id)\\\\\\\\n\\\\\\\\n    def remove_eligible_voter(self, voter_id: str) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Remove a voter from the eligible voters list.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if voter_id in self.eligible_voters:\\\\\\\\n            self.eligible_voters.remove(voter_id)\\\\\\\\n\\\\\\\\n    def get_vote_summary(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get current voting summary without ending the session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.is_active:\\\\\\\\n            return {}\\\\\\\\n\\\\\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\\\\\n        time_remaining = max(0, self.end_time - time.time())\\\\\\\\n\\\\\\\\n        return {\\\\\\\\n            'candidates': self.candidates,\\\\\\\\n            'vote_counts': dict(vote_counts),\\\\\\\\n            'total_votes': len(self.votes),\\\\\\\\n            'time_remaining': time_remaining,\\\\\\\\n            'is_active': self.is_active\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    def get_voter_history(self, voter_id: str) -> List[Vote]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get voting history for a specific voter.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        history = []\\\\\\\\n        for session in self.vote_history:\\\\\\\\n            votes = session.get('results', {}).votes_by_voter\\\\\\\\n            if voter_id in votes:\\\\\\\\n                history.append(votes[voter_id])\\\\\\\\n        return history\\\\\\\\n\\\\\\\\n    def get_candidate_performance(self, candidate: str) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get performance statistics for a candidate across all sessions.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        wins = 0\\\\\\\\n        total_votes = 0\\\\\\\\n        participations = 0\\\\\\\\n\\\\\\\\n        for session in self.vote_history:\\\\\\\\n            results = session.get('results', {})\\\\\\\\n            if candidate in session.get('candidates', []):\\\\\\\\n                participations += 1\\\\\\\\n                if results.winner == candidate:\\\\\\\\n                    wins += 1\\\\\\\\n                total_votes += results.vote_counts.get(candidate, 0)\\\\\\\\n\\\\\\\\n        return {\\\\\\\\n            'candidate': candidate,\\\\\\\\n            'wins': wins,\\\\\\\\n            'total_votes': total_votes,\\\\\\\\n            'participations': participations,\\\\\\\\n            'win_rate': wins / participations if participations > 0 else 0,\\\\\\\\n            'avg_votes': total_votes / participations if participations > 0 else 0\\\\\\\\n        }\\\\\\\\n\\\\\\\\n    async def export_results(self, format_type: str = 'json') -> str:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        Export voting results in specified format.\\\\\\\\n\\\\\\\\n        Args:\\\\\\\\n            format_type: Export format ('json', 'csv', 'txt')\\\\\\\\n\\\\\\\\n        Returns:\\\\\\\\n            Formatted results string\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        if not self.vote_history:\\\\\\\\n            return \\\\\\\\\\\\\\\"No voting history available\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        if format_type == 'json':\\\\\\\\n            import json\\\\\\\\n            return json.dumps(self.vote_history, indent=2, default=str)\\\\\\\\n\\\\\\\\n        elif format_type == 'csv':\\\\\\\\n            import csv\\\\\\\\n            import io\\\\\\\\n\\\\\\\\n            output = io.StringIO()\\\\\\\\n            writer = csv.writer(output)\\\\\\\\n\\\\\\\\n            # Header\\\\\\\\n            writer.writerow(['Session', 'Timestamp', 'Candidate', 'Votes', 'Winner'])\\\\\\\\n\\\\\\\\n            # Data\\\\\\\\n            for i, session in enumerate(self.vote_history):\\\\\\\\n                results = session.get('results', {})\\\\\\\\n                timestamp = session.get('timestamp', '')\\\\\\\\n\\\\\\\\n                for candidate, votes in results.vote_counts.items():\\\\\\\\n                    writer.writerow([\\\\\\\\n                        i + 1,\\\\\\\\n                        timestamp,\\\\\\\\n                        candidate,\\\\\\\\n                        votes,\\\\\\\\n                        results.winner == candidate\\\\\\\\n                    ])\\\\\\\\n\\\\\\\\n            return output.getvalue()\\\\\\\\n\\\\\\\\n        elif format_type == 'txt':\\\\\\\\n            output = []\\\\\\\\n            output.append(\\\\\\\\\\\\\\\"=== VOTING HISTORY REPORT ===\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n            for i, session in enumerate(self.vote_history):\\\\\\\\n                results = session.get('results', {})\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\"Session {i + 1}:\\\\\\\\\\\\\\\")\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\"  Winner: {results.winner}\\\\\\\\\\\\\\\")\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\"  Total Votes: {results.total_votes}\\\\\\\\\\\\\\\")\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\"  Vote Breakdown:\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n                for candidate, votes in sorted(results.vote_counts.items(),\\\\\\\\n                                               key=lambda x: x[1], reverse=True):\\\\\\\\n                    output.append(f\\\\\\\\\\\\\\\"    {candidate}: {votes}\\\\\\\\\\\\\\\")\\\\\\\\n                output.append(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n            return \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\".join(output)\\\\\\\\n\\\\\\\\n        else:\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\"Unsupported format: {format_type}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    def reset(self) -> None:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Reset the voting system to initial state.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        self.is_active = False\\\\\\\\n        self.candidates = []\\\\\\\\n        self.eligible_voters = []\\\\\\\\n        self.votes = {}\\\\\\\\n        self.start_time = None\\\\\\\\n        self.end_time = None\\\\\\\\n\\\\\\\\n    @property\\\\\\\\n    def status(self) -> Dict[str, Any]:\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Get current status of the voting system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        return {\\\\\\\\n            'enabled': self.enabled,\\\\\\\\n            'is_active': self.is_active,\\\\\\\\n            'candidates': self.candidates,\\\\\\\\n            'eligible_voters': len(self.eligible_voters),\\\\\\\\n            'votes_cast': len(self.votes),\\\\\\\\n            'time_remaining': (self.end_time - time.time()\\\\\\\\n                               if self.is_active and self.end_time else 0),\\\\\\\\n            'sessions_completed': len(self.vote_history)\\\\\\\\n        }\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"docs\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n      \\\\\\\"contents\\\\\\\": {\\\\n        \\\\\\\"api_reference.md\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"docs/api_reference.md\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".md\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 15639,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"# AI Jubilee Debate System API Reference\\\\\\\\n\\\\\\\\n## Core Classes\\\\\\\\n\\\\\\\\n### Moderator\\\\\\\\n\\\\\\\\nThe central coordinator for debate sessions.\\\\\\\\n\\\\\\\\n#### Constructor\\\\\\\\n```python\\\\\\\\nModerator(\\\\\\\\n    topic: str,\\\\\\\\n    participants: List[Union[BotClient, HumanClient]],\\\\\\\\n    chat_log: ChatLog,\\\\\\\\n    voting_system: VotingSystem,\\\\\\\\n    config: Dict[str, Any]\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `topic`: The debate topic string\\\\\\\\n- `participants`: List of bot and human participants\\\\\\\\n- `chat_log`: ChatLog instance for message management\\\\\\\\n- `voting_system`: VotingSystem instance for handling votes\\\\\\\\n- `config`: Configuration dictionary with timing and rule settings\\\\\\\\n\\\\\\\\n#### Methods\\\\\\\\n\\\\\\\\n##### `async run_debate() -> Dict[str, Any]`\\\\\\\\nRuns the complete debate session through all phases.\\\\\\\\n\\\\\\\\n**Returns:** Dictionary containing voting results and session statistics\\\\\\\\n\\\\\\\\n**Example:**\\\\\\\\n```python\\\\\\\\nmoderator = Moderator(topic, participants, chat_log, voting_system, config)\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Winner: {results.get('winner', 'No winner')}\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### `get_state() -> DebateState`\\\\\\\\nReturns current debate state information.\\\\\\\\n\\\\\\\\n**Returns:** DebateState object with phase, speaker, and timing info\\\\\\\\n\\\\\\\\n##### `async _give_turn(participant_name: str, time_limit: int, turn_type: str) -> None`\\\\\\\\nGives speaking turn to a specific participant.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `participant_name`: Name of participant to give turn to\\\\\\\\n- `time_limit`: Maximum time in seconds for response\\\\\\\\n- `turn_type`: Type of turn (\\\\\\\\\\\\\\\"opening\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"closing\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n### ChatLog\\\\\\\\n\\\\\\\\nThread-safe message management system.\\\\\\\\n\\\\\\\\n#### Constructor\\\\\\\\n```python\\\\\\\\nChatLog(max_messages: int = 1000)\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `max_messages`: Maximum number of messages to retain in memory\\\\\\\\n\\\\\\\\n#### Methods\\\\\\\\n\\\\\\\\n##### `async add_message(sender: str, content: str, message_type: str = \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\", metadata: Optional[Dict] = None) -> Message`\\\\\\\\nAdds a new message to the chat log.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `sender`: Name of message sender\\\\\\\\n- `content`: Message content text\\\\\\\\n- `message_type`: Type of message (\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"vote\\\\\\\\\\\\\\\")\\\\\\\\n- `metadata`: Optional additional data\\\\\\\\n\\\\\\\\n**Returns:** Created Message object\\\\\\\\n\\\\\\\\n**Example:**\\\\\\\\n```python\\\\\\\\nmessage = await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"I think AI will help humanity\\\\\\\\\\\\\\\")\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Message ID: {message.message_id}\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### `get_messages(limit: Optional[int] = None, sender: Optional[str] = None, message_type: Optional[str] = None, since_timestamp: Optional[float] = None) -> List[Message]`\\\\\\\\nRetrieves messages with optional filtering.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `limit`: Maximum number of messages to return\\\\\\\\n- `sender`: Filter by sender name\\\\\\\\n- `message_type`: Filter by message type\\\\\\\\n- `since_timestamp`: Only messages after this timestamp\\\\\\\\n\\\\\\\\n**Returns:** List of Message objects\\\\\\\\n\\\\\\\\n##### `subscribe() -> asyncio.Queue`\\\\\\\\nCreates subscription for real-time message updates.\\\\\\\\n\\\\\\\\n**Returns:** Queue that receives new Message objects\\\\\\\\n\\\\\\\\n##### `async save_transcript(filename: str, format_type: str = \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\") -> None`\\\\\\\\nSaves chat transcript to file.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `filename`: Output file path\\\\\\\\n- `format_type`: Export format (\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n##### `search_messages(query: str, case_sensitive: bool = False) -> List[Message]`\\\\\\\\nSearches messages by content.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `query`: Search string\\\\\\\\n- `case_sensitive`: Whether search is case sensitive\\\\\\\\n\\\\\\\\n**Returns:** List of matching Message objects\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n### VotingSystem\\\\\\\\n\\\\\\\\nManages voting sessions and result calculation.\\\\\\\\n\\\\\\\\n#### Constructor\\\\\\\\n```python\\\\\\\\nVotingSystem(config: Dict[str, Any])\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `config`: Voting configuration dictionary\\\\\\\\n\\\\\\\\n#### Methods\\\\\\\\n\\\\\\\\n##### `async start_voting(candidates: List[str], duration: Optional[int] = None) -> None`\\\\\\\\nStarts a new voting session.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `candidates`: List of participant names to vote for\\\\\\\\n- `duration`: Voting duration in seconds (uses config default if None)\\\\\\\\n\\\\\\\\n**Example:**\\\\\\\\n```python\\\\\\\\nawait voting_system.start_voting([\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\"], 300)\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### `async cast_vote(voter_id: str, candidate: str, justification: Optional[str] = None) -> bool`\\\\\\\\nCasts a vote for a candidate.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `voter_id`: ID of the voter\\\\\\\\n- `candidate`: Name of candidate being voted for\\\\\\\\n- `justification`: Optional reasoning for the vote\\\\\\\\n\\\\\\\\n**Returns:** True if vote was successfully cast\\\\\\\\n\\\\\\\\n##### `async end_voting() -> VotingResults`\\\\\\\\nEnds voting session and calculates results.\\\\\\\\n\\\\\\\\n**Returns:** VotingResults object with winner and vote breakdown\\\\\\\\n\\\\\\\\n##### `get_vote_summary() -> Dict[str, Any]`\\\\\\\\nGets current voting status without ending session.\\\\\\\\n\\\\\\\\n**Returns:** Dictionary with vote counts and time remaining\\\\\\\\n\\\\\\\\n##### `async export_results(format_type: str = \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\") -> str`\\\\\\\\nExports voting results in specified format.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `format_type`: Export format (\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"csv\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n**Returns:** Formatted results string\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n### BotClient\\\\\\\\n\\\\\\\\nAI-powered debate participant.\\\\\\\\n\\\\\\\\n#### Constructor\\\\\\\\n```python\\\\\\\\nBotClient(\\\\\\\\n    name: str,\\\\\\\\n    model: str,\\\\\\\\n    provider: str,\\\\\\\\n    personality: str,\\\\\\\\n    stance: str,\\\\\\\\n    api_key: str,\\\\\\\\n    temperature: float = 0.7,\\\\\\\\n    max_tokens: int = 300\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `name`: Bot display name\\\\\\\\n- `model`: AI model identifier\\\\\\\\n- `provider`: AI provider (\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\")\\\\\\\\n- `personality`: Personality description for prompt\\\\\\\\n- `stance`: Debate stance (\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\")\\\\\\\\n- `api_key`: API key for AI provider\\\\\\\\n- `temperature`: Response creativity (0.0-1.0)\\\\\\\\n- `max_tokens`: Maximum response length\\\\\\\\n\\\\\\\\n#### Methods\\\\\\\\n\\\\\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\\\\\nGenerates AI response to current debate context.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `topic`: Current debate topic\\\\\\\\n- `recent_messages`: Recent conversation messages for context\\\\\\\\n\\\\\\\\n**Returns:** Generated response string\\\\\\\\n\\\\\\\\n**Example:**\\\\\\\\n```python\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\"Analyst\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\", api_key)\\\\\\\\nresponse = await bot.get_response(\\\\\\\\\\\\\\\"AI in healthcare\\\\\\\\\\\\\\\", recent_messages)\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### `async receive_message(message: Message) -> None`\\\\\\\\nReceives message from debate for context awareness.\\\\\\\\n\\\\\\\\n##### `get_stats() -> Dict[str, Any]`\\\\\\\\nReturns bot performance statistics.\\\\\\\\n\\\\\\\\n**Returns:** Dictionary with response counts, timing, and success rates\\\\\\\\n\\\\\\\\n##### `async warmup() -> bool`\\\\\\\\nTests bot connectivity and readiness.\\\\\\\\n\\\\\\\\n**Returns:** True if bot is ready for debate\\\\\\\\n\\\\\\\\n##### `update_personality(personality: str, stance: str = None) -> None`\\\\\\\\nUpdates bot personality and stance during session.\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n### HumanClient\\\\\\\\n\\\\\\\\nHuman participant interface.\\\\\\\\n\\\\\\\\n#### Constructor\\\\\\\\n```python\\\\\\\\nHumanClient(name: str, interface_config: Dict[str, Any])\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `name`: Human participant display name\\\\\\\\n- `interface_config`: Interface configuration dictionary\\\\\\\\n\\\\\\\\n#### Methods\\\\\\\\n\\\\\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\\\\\nGets response from human participant.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `topic`: Current debate topic\\\\\\\\n- `recent_messages`: Recent messages for context\\\\\\\\n\\\\\\\\n**Returns:** Human's response string\\\\\\\\n\\\\\\\\n##### `async handle_voting(candidates: List[str], voting_time: int) -> Dict[str, Any]`\\\\\\\\nHandles voting interface for human.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `candidates`: List of candidates to vote for\\\\\\\\n- `voting_time`: Time allowed for voting\\\\\\\\n\\\\\\\\n**Returns:** Dictionary with vote result and metadata\\\\\\\\n\\\\\\\\n##### `async set_active(active: bool) -> None`\\\\\\\\nSets whether human is actively participating.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `active`: Whether human should be active in debate\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n### StreamingServer\\\\\\\\n\\\\\\\\nWebSocket server for live debate streaming.\\\\\\\\n\\\\\\\\n#### Constructor\\\\\\\\n```python\\\\\\\\nStreamingServer(\\\\\\\\n    chat_log: ChatLog,\\\\\\\\n    voting_system: VotingSystem,\\\\\\\\n    config: Dict[str, Any]\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Methods\\\\\\\\n\\\\\\\\n##### `async start() -> None`\\\\\\\\nStarts the streaming server.\\\\\\\\n\\\\\\\\n##### `async stop() -> None`\\\\\\\\nStops the streaming server and closes connections.\\\\\\\\n\\\\\\\\n##### `async broadcast_custom_message(message_type: str, data: Any) -> None`\\\\\\\\nBroadcasts custom message to all connected clients.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `message_type`: Type identifier for the message\\\\\\\\n- `data`: Message payload\\\\\\\\n\\\\\\\\n##### `get_connected_clients() -> List[Dict[str, Any]]`\\\\\\\\nReturns information about all connected streaming clients.\\\\\\\\n\\\\\\\\n**Returns:** List of client information dictionaries\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Data Classes\\\\\\\\n\\\\\\\\n### Message\\\\\\\\n\\\\\\\\nRepresents a single chat message.\\\\\\\\n\\\\\\\\n```python\\\\\\\\n@dataclass\\\\\\\\nclass Message:\\\\\\\\n    sender: str\\\\\\\\n    content: str\\\\\\\\n    timestamp: float\\\\\\\\n    message_id: int\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\"\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Properties:**\\\\\\\\n- `formatted_timestamp`: Human-readable timestamp string\\\\\\\\n\\\\\\\\n**Methods:**\\\\\\\\n- `to_dict() -> Dict[str, Any]`: Convert to dictionary\\\\\\\\n- `from_dict(data: Dict[str, Any]) -> Message`: Create from dictionary\\\\\\\\n\\\\\\\\n### Vote\\\\\\\\n\\\\\\\\nRepresents a single vote in the voting system.\\\\\\\\n\\\\\\\\n```python\\\\\\\\n@dataclass\\\\\\\\nclass Vote:\\\\\\\\n    voter_id: str\\\\\\\\n    candidate: str\\\\\\\\n    justification: Optional[str] = None\\\\\\\\n    timestamp: float = field(default_factory=time.time)\\\\\\\\n    anonymous: bool = False\\\\\\\\n```\\\\\\\\n\\\\\\\\n### VotingResults\\\\\\\\n\\\\\\\\nContains results from a voting session.\\\\\\\\n\\\\\\\\n```python\\\\\\\\n@dataclass\\\\\\\\nclass VotingResults:\\\\\\\\n    winner: Optional[str]\\\\\\\\n    vote_counts: Dict[str, int]\\\\\\\\n    total_votes: int\\\\\\\\n    votes_by_voter: Dict[str, Vote]\\\\\\\\n    voting_duration: float\\\\\\\\n    participation_rate: float\\\\\\\\n```\\\\\\\\n\\\\\\\\n### DebateState\\\\\\\\n\\\\\\\\nTracks current debate session state.\\\\\\\\n\\\\\\\\n```python\\\\\\\\n@dataclass\\\\\\\\nclass DebateState:\\\\\\\\n    phase: DebatePhase\\\\\\\\n    current_speaker: Optional[str] = None\\\\\\\\n    time_remaining: int = 0\\\\\\\\n    turn_order: List[str] = None\\\\\\\\n    warnings_issued: Dict[str, int] = None\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Enums\\\\\\\\n\\\\\\\\n### DebatePhase\\\\\\\\n\\\\\\\\nDefines the phases of a debate session.\\\\\\\\n\\\\\\\\n```python\\\\\\\\nclass DebatePhase(Enum):\\\\\\\\n    INTRODUCTION = \\\\\\\\\\\\\\\"introduction\\\\\\\\\\\\\\\"\\\\\\\\n    OPENING_STATEMENTS = \\\\\\\\\\\\\\\"opening_statements\\\\\\\\\\\\\\\"\\\\\\\\n    DISCUSSION = \\\\\\\\\\\\\\\"discussion\\\\\\\\\\\\\\\"\\\\\\\\n    CLOSING_STATEMENTS = \\\\\\\\\\\\\\\"closing_statements\\\\\\\\\\\\\\\"\\\\\\\\n    VOTING = \\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\"\\\\\\\\n    RESULTS = \\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\"\\\\\\\\n    FINISHED = \\\\\\\\\\\\\\\"finished\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Utility Functions\\\\\\\\n\\\\\\\\n### Configuration (`app/utils.py`)\\\\\\\\n\\\\\\\\n##### `load_config(config_path: str = \\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\") -> Dict[str, Any]`\\\\\\\\nLoads configuration from YAML file with environment variable substitution.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `config_path`: Path to configuration file\\\\\\\\n\\\\\\\\n**Returns:** Configuration dictionary\\\\\\\\n\\\\\\\\n**Example:**\\\\\\\\n```python\\\\\\\\nconfig = load_config(\\\\\\\\\\\\\\\"custom_config.yaml\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### `setup_logging(level: str = \\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\", log_file: Optional[str] = None) -> None`\\\\\\\\nSets up logging configuration.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `level`: Logging level (\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"WARNING\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"ERROR\\\\\\\\\\\\\\\")\\\\\\\\n- `log_file`: Optional log file path\\\\\\\\n\\\\\\\\n##### `format_time_remaining(seconds: float) -> str`\\\\\\\\nFormats time remaining in human-readable format.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `seconds`: Time in seconds\\\\\\\\n\\\\\\\\n**Returns:** Formatted time string (\\\\\\\\\\\\\\\"5m 30s\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"2h 15m\\\\\\\\\\\\\\\", etc.)\\\\\\\\n\\\\\\\\n##### `truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\") -> str`\\\\\\\\nTruncates text to maximum length.\\\\\\\\n\\\\\\\\n**Parameters:**\\\\\\\\n- `text`: Text to truncate\\\\\\\\n- `max_length`: Maximum length\\\\\\\\n- `suffix`: Suffix to add when truncating\\\\\\\\n\\\\\\\\n**Returns:** Truncated text\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Error Handling\\\\\\\\n\\\\\\\\n### Custom Exceptions\\\\\\\\n\\\\\\\\nThe system uses standard Python exceptions with descriptive messages:\\\\\\\\n\\\\\\\\n- `ValueError`: Invalid configuration or parameters\\\\\\\\n- `FileNotFoundError`: Missing configuration files\\\\\\\\n- `ConnectionError`: API or network failures\\\\\\\\n- `TimeoutError`: Response timeouts\\\\\\\\n\\\\\\\\n### Error Recovery\\\\\\\\n\\\\\\\\nAll async methods include proper error handling and will not crash the session:\\\\\\\\n\\\\\\\\n```python\\\\\\\\ntry:\\\\\\\\n    response = await bot.get_response(topic, messages)\\\\\\\\nexcept Exception as e:\\\\\\\\n    # Fallback response is automatically generated\\\\\\\\n    response = bot._generate_fallback_response(topic)\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Configuration Schema\\\\\\\\n\\\\\\\\n### Main Configuration\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\n# Debate settings\\\\\\\\ndebate:\\\\\\\\n  default_topic: str\\\\\\\\n  max_participants: int\\\\\\\\n  time_limit_minutes: int\\\\\\\\n  opening_statement_time: int  # seconds\\\\\\\\n  response_time: int\\\\\\\\n  closing_statement_time: int\\\\\\\\n\\\\\\\\n# Bot configurations\\\\\\\\nbots:\\\\\\\\n  - name: str\\\\\\\\n    model: str\\\\\\\\n    provider: str  # \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\"\\\\\\\\n    personality: str\\\\\\\\n    stance: str  # \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\", or \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n    temperature: float  # 0.0-1.0\\\\\\\\n    max_tokens: int\\\\\\\\n\\\\\\\\n# API credentials\\\\\\\\napi_keys:\\\\\\\\n  openai: str\\\\\\\\n  anthropic: str\\\\\\\\n\\\\\\\\n# Voting settings\\\\\\\\nvoting:\\\\\\\\n  enabled: bool\\\\\\\\n  voting_duration: int  # seconds\\\\\\\\n  allow_participant_voting: bool\\\\\\\\n  require_justification: bool\\\\\\\\n  anonymous_votes: bool\\\\\\\\n\\\\\\\\n# Chat settings\\\\\\\\nchat:\\\\\\\\n  max_message_length: int\\\\\\\\n  enable_timestamps: bool\\\\\\\\n  log_level: str\\\\\\\\n  save_transcripts: bool\\\\\\\\n\\\\\\\\n# Streaming settings\\\\\\\\nstreaming:\\\\\\\\n  enabled: bool\\\\\\\\n  websocket_port: int\\\\\\\\n  max_connections: int\\\\\\\\n  broadcast_votes: bool\\\\\\\\n\\\\\\\\n# Interface settings\\\\\\\\ninterface:\\\\\\\\n  mode: str  # \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\"\\\\\\\\n  enable_rich_formatting: bool\\\\\\\\n  show_typing_indicators: bool\\\\\\\\n  input_timeout: int\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## WebSocket API\\\\\\\\n\\\\\\\\n### Client Connection\\\\\\\\n\\\\\\\\nConnect to the streaming server:\\\\\\\\n\\\\\\\\n```javascript\\\\\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Message Types\\\\\\\\n\\\\\\\\n#### Incoming Messages\\\\\\\\n\\\\\\\\n##### Welcome Message\\\\\\\\n```json\\\\\\\\n{\\\\\\\\n  \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"welcome\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"client_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"client_123456789\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"server_info\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"features\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"real_time\\\\\\\\\\\\\\\"]\\\\\\\\n  }\\\\\\\\n}\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### Chat Message\\\\\\\\n```json\\\\\\\\n{\\\\\\\\n  \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"I believe AI will benefit society\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1640995200.0,\\\\\\\\n    \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 42,\\\\\\\\n    \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\"\\\\\\\\n  }\\\\\\\\n}\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### Vote Update\\\\\\\\n```json\\\\\\\\n{\\\\\\\\n  \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"vote_update\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"candidates\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"],\\\\\\\\n    \\\\\\\\\\\\\\\"vote_counts\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\": 5, \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\": 3},\\\\\\\\n    \\\\\\\\\\\\\\\"total_votes\\\\\\\\\\\\\\\": 8,\\\\\\\\n    \\\\\\\\\\\\\\\"time_remaining\\\\\\\\\\\\\\\": 120,\\\\\\\\n    \\\\\\\\\\\\\\\"is_active\\\\\\\\\\\\\\\": true\\\\\\\\n  }\\\\\\\\n}\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Outgoing Messages\\\\\\\\n\\\\\\\\n##### Subscribe to Channels\\\\\\\\n```json\\\\\\\\n{\\\\\\\\n  \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"subscribe\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"channels\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\"]\\\\\\\\n}\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### Cast Vote\\\\\\\\n```json\\\\\\\\n{\\\\\\\\n  \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"vote\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"voter_id\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"viewer_123\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"candidate\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\",\\\\\\\\n  \\\\\\\\\\\\\\\"justification\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Most persuasive arguments\\\\\\\\\\\\\\\"\\\\\\\\n}\\\\\\\\n```\\\\\\\\n\\\\\\\\n##### Ping/Pong\\\\\\\\n```json\\\\\\\\n{\\\\\\\\n  \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"ping\\\\\\\\\\\\\\\"\\\\\\\\n}\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Performance Considerations\\\\\\\\n\\\\\\\\n### API Rate Limits\\\\\\\\n\\\\\\\\n- OpenAI: Respect rate limits based on your plan\\\\\\\\n- Anthropic: Monitor request quotas\\\\\\\\n- Implement exponential backoff for retries\\\\\\\\n\\\\\\\\n### Memory Management\\\\\\\\n\\\\\\\\n- Chat log automatically limits message history\\\\\\\\n- Conversation history is pruned in bot clients\\\\\\\\n- Streaming connections are cleaned up automatically\\\\\\\\n\\\\\\\\n### Async Best Practices\\\\\\\\n\\\\\\\\nAll I/O operations are async:\\\\\\\\n\\\\\\\\n```python\\\\\\\\n# Correct - awaits async operations\\\\\\\\nresponse = await bot.get_response(topic, messages)\\\\\\\\nawait chat_log.add_message(sender, content)\\\\\\\\n\\\\\\\\n# Incorrect - would block the event loop\\\\\\\\n# response = bot.get_response(topic, messages).result()\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Testing\\\\\\\\n\\\\\\\\n### Unit Tests\\\\\\\\n\\\\\\\\nRun the test suite:\\\\\\\\n\\\\\\\\n```bash\\\\\\\\npython -m pytest tests/ -v\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Integration Tests\\\\\\\\n\\\\\\\\nTest with real APIs:\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Set test API keys\\\\\\\\nexport OPENAI_API_KEY=\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\"\\\\\\\\nexport ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Run integration tests\\\\\\\\npython -m pytest tests/integration/ -v\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Mock Testing\\\\\\\\n\\\\\\\\n```python\\\\\\\\nfrom unittest.mock import AsyncMock\\\\\\\\n\\\\\\\\n# Mock bot responses\\\\\\\\nbot.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\")\\\\\\\\nresponse = await bot.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", [])\\\\\\\\nassert response == \\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n---\\\\\\\\n\\\\\\\\n## Deployment\\\\\\\\n\\\\\\\\n### Docker\\\\\\\\n\\\\\\\\n```dockerfile\\\\\\\\nFROM python:3.9-slim\\\\\\\\n\\\\\\\\nWORKDIR /app\\\\\\\\nCOPY requirements.txt .\\\\\\\\nRUN pip install -r requirements.txt\\\\\\\\n\\\\\\\\nCOPY . .\\\\\\\\nCMD [\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"app.main\\\\\\\\\\\\\\\"]\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Environment Variables\\\\\\\\n\\\\\\\\nRequired for production:\\\\\\\\n\\\\\\\\n```bash\\\\\\\\nOPENAI_API_KEY=sk-...\\\\\\\\nANTHROPIC_API_KEY=sk-ant-...\\\\\\\\nLOG_LEVEL=INFO\\\\\\\\nCONFIG_PATH=/app/production_config.yaml\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Health Checks\\\\\\\\n\\\\\\\\n```python\\\\\\\\n# Check system health\\\\\\\\nasync def health_check():\\\\\\\\n    # Test bot connectivity\\\\\\\\n    for bot in bots:\\\\\\\\n        if not await bot.warmup():\\\\\\\\n            return False\\\\\\\\n    \\\\\\\\n    # Test streaming server\\\\\\\\n    if streaming_server and not streaming_server.is_active:\\\\\\\\n        return False\\\\\\\\n    \\\\\\\\n    return True\\\\\\\\n```\\\\\\\\n\\\\\\\\nThis API reference provides comprehensive documentation for integrating with and extending the AI Jubilee Debate System.\\\\\\\"\\\\n        },\\\\n        \\\\\\\"architecture.md\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"docs/architecture.md\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".md\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 7424,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"# AI Jubilee Debate System Architecture\\\\\\\\n\\\\\\\\n## Overview\\\\\\\\n\\\\\\\\nThe AI Jubilee Debate System is a modular, event-driven platform that facilitates structured debates between AI bots and human participants. The system emphasizes real-time interaction, fair moderation, and comprehensive result tracking.\\\\\\\\n\\\\\\\\n## Core Components\\\\\\\\n\\\\\\\\n### 1. Moderator (`app/moderator.py`)\\\\\\\\n\\\\\\\\nThe central orchestrator of the debate system.\\\\\\\\n\\\\\\\\n**Responsibilities:**\\\\\\\\n- Manage debate phases (introduction, opening statements, discussion, closing statements, voting, results)\\\\\\\\n- Enforce time limits and speaking order\\\\\\\\n- Handle participant timeouts and warnings\\\\\\\\n- Coordinate with voting system\\\\\\\\n- Broadcast messages to all participants\\\\\\\\n\\\\\\\\n**Key Classes:**\\\\\\\\n- `Moderator`: Main orchestration class\\\\\\\\n- `DebatePhase`: Enum defining debate stages\\\\\\\\n- `DebateState`: Current state tracking\\\\\\\\n\\\\\\\\n**Flow Diagram:**\\\\\\\\n```\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\n‚îÇIntroduction ‚îÇ -> ‚îÇOpening Stmts ‚îÇ -> ‚îÇ Discussion  ‚îÇ\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\n                                              ‚îÇ\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\n‚îÇ   Results   ‚îÇ <- ‚îÇ    Voting    ‚îÇ <- ‚îÇClosing Stmts‚îÇ\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 2. Chat Log (`app/chat_log.py`)\\\\\\\\n\\\\\\\\nThread-safe message management system.\\\\\\\\n\\\\\\\\n**Features:**\\\\\\\\n- Chronological message ordering\\\\\\\\n- Pub/sub message distribution\\\\\\\\n- Message filtering and search\\\\\\\\n- Transcript export (JSON, TXT, HTML)\\\\\\\\n- Statistics tracking\\\\\\\\n\\\\\\\\n**Data Model:**\\\\\\\\n```python\\\\\\\\n@dataclass\\\\\\\\nclass Message:\\\\\\\\n    sender: str\\\\\\\\n    content: str\\\\\\\\n    timestamp: float\\\\\\\\n    message_id: int\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\"\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 3. Voting System (`app/voting.py`)\\\\\\\\n\\\\\\\\nDemocratic evaluation mechanism for debate performance.\\\\\\\\n\\\\\\\\n**Features:**\\\\\\\\n- Time-limited voting sessions\\\\\\\\n- Multiple export formats\\\\\\\\n- Vote validation and security\\\\\\\\n- Historical tracking\\\\\\\\n- Participation analytics\\\\\\\\n\\\\\\\\n**Voting Flow:**\\\\\\\\n```\\\\\\\\nStart Session -> Accept Votes -> End Session -> Calculate Results\\\\\\\\n     ‚îÇ              ‚îÇ               ‚îÇ              ‚îÇ\\\\\\\\n     v              v               v              v\\\\\\\\nSet Candidates  Validate Vote   Close Voting   Determine Winner\\\\\\\\nSet Duration    Store Vote      Stop Accepting  Export Results\\\\\\\\n```\\\\\\\\n\\\\\\\\n### 4. Participant Clients\\\\\\\\n\\\\\\\\n#### Bot Client (`app/bot_client.py`)\\\\\\\\n\\\\\\\\nAI-powered debate participants.\\\\\\\\n\\\\\\\\n**Supported Providers:**\\\\\\\\n- OpenAI (GPT-3.5, GPT-4)\\\\\\\\n- Anthropic (Claude)\\\\\\\\n- Extensible for additional providers\\\\\\\\n\\\\\\\\n**Key Features:**\\\\\\\\n- Personality-driven responses\\\\\\\\n- Stance-aware argumentation\\\\\\\\n- Response time tracking\\\\\\\\n- Conversation context management\\\\\\\\n- Fallback response handling\\\\\\\\n\\\\\\\\n#### Human Client (`app/human_client.py`)\\\\\\\\n\\\\\\\\nHuman participant interface.\\\\\\\\n\\\\\\\\n**Interface Modes:**\\\\\\\\n- CLI: Terminal-based interaction\\\\\\\\n- Web: WebSocket-based browser interface\\\\\\\\n- API: Programmatic integration\\\\\\\\n\\\\\\\\n**Features:**\\\\\\\\n- Response validation\\\\\\\\n- Timeout handling\\\\\\\\n- Conversation history\\\\\\\\n- Voting participation\\\\\\\\n\\\\\\\\n### 5. Streaming Server (`app/streaming.py`)\\\\\\\\n\\\\\\\\nReal-time broadcast system for live audience.\\\\\\\\n\\\\\\\\n**Capabilities:**\\\\\\\\n- WebSocket connections\\\\\\\\n- Message broadcasting\\\\\\\\n- Vote updates\\\\\\\\n- Client management\\\\\\\\n- Statistics reporting\\\\\\\\n\\\\\\\\n## System Architecture\\\\\\\\n\\\\\\\\n```\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\n‚îÇ                    Moderator                            ‚îÇ\\\\\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ\\\\\\\\n‚îÇ  ‚îÇ   Phases    ‚îÇ ‚îÇ   Timing    ‚îÇ ‚îÇ   Rules     ‚îÇ       ‚îÇ\\\\\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\n                      ‚îÇ\\\\\\\\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\\\\\n    v                 v                 v\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\n‚îÇChat Log  ‚îÇ    ‚îÇ  Voting   ‚îÇ    ‚îÇ  Streaming   ‚îÇ\\\\\\\\n‚îÇ          ‚îÇ    ‚îÇ  System   ‚îÇ    ‚îÇ   Server     ‚îÇ\\\\\\\\n‚îÇ- Messages‚îÇ    ‚îÇ- Sessions ‚îÇ    ‚îÇ- WebSockets  ‚îÇ\\\\\\\\n‚îÇ- History ‚îÇ    ‚îÇ- Results  ‚îÇ    ‚îÇ- Broadcast   ‚îÇ\\\\\\\\n‚îÇ- Export  ‚îÇ    ‚îÇ- Stats    ‚îÇ    ‚îÇ- Clients     ‚îÇ\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\\\\\n    v                 v                 v\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\n‚îÇ                Participants                     ‚îÇ\\\\\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\\\\\\\\n‚îÇ  ‚îÇ Bot Clients ‚îÇ              ‚îÇHuman Clients‚îÇ   ‚îÇ\\\\\\\\n‚îÇ  ‚îÇ- OpenAI     ‚îÇ              ‚îÇ- CLI        ‚îÇ   ‚îÇ\\\\\\\\n‚îÇ  ‚îÇ- Anthropic  ‚îÇ              ‚îÇ- Web        ‚îÇ   ‚îÇ\\\\\\\\n‚îÇ  ‚îÇ- Custom     ‚îÇ              ‚îÇ- API        ‚îÇ   ‚îÇ\\\\\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Data Flow\\\\\\\\n\\\\\\\\n### Message Flow\\\\\\\\n1. Participant generates response\\\\\\\\n2. Moderator validates and timestamps\\\\\\\\n3. Chat Log stores and distributes\\\\\\\\n4. Streaming Server broadcasts to audience\\\\\\\\n5. Other participants receive for context\\\\\\\\n\\\\\\\\n### Voting Flow\\\\\\\\n1. Moderator initiates voting phase\\\\\\\\n2. Voting System opens session\\\\\\\\n3. Participants cast votes\\\\\\\\n4. System validates and stores votes\\\\\\\\n5. Results calculated and broadcast\\\\\\\\n\\\\\\\\n### Configuration Flow\\\\\\\\n1. Load YAML configuration\\\\\\\\n2. Initialize components with settings\\\\\\\\n3. Create participants based on config\\\\\\\\n4. Start session with configured parameters\\\\\\\\n\\\\\\\\n## Error Handling\\\\\\\\n\\\\\\\\n### Graceful Degradation\\\\\\\\n- API failures trigger fallback responses\\\\\\\\n- Network issues don't crash sessions\\\\\\\\n- Participant timeouts handled smoothly\\\\\\\\n- Voting continues despite individual failures\\\\\\\\n\\\\\\\\n### Monitoring and Logging\\\\\\\\n- Comprehensive error logging\\\\\\\\n- Performance metrics tracking\\\\\\\\n- Participant statistics\\\\\\\\n- System health monitoring\\\\\\\\n\\\\\\\\n## Scalability Considerations\\\\\\\\n\\\\\\\\n### Horizontal Scaling\\\\\\\\n- Multiple debate sessions simultaneously\\\\\\\\n- Load balancing for streaming\\\\\\\\n- Database for persistent storage\\\\\\\\n- Message queue for high throughput\\\\\\\\n\\\\\\\\n### Performance Optimization\\\\\\\\n- Async/await throughout\\\\\\\\n- Connection pooling for APIs\\\\\\\\n- Message batching for efficiency\\\\\\\\n- Resource cleanup and management\\\\\\\\n\\\\\\\\n## Security\\\\\\\\n\\\\\\\\n### Input Validation\\\\\\\\n- Message content sanitization\\\\\\\\n- Participant authentication\\\\\\\\n- Vote integrity verification\\\\\\\\n- Rate limiting protection\\\\\\\\n\\\\\\\\n### Privacy Protection\\\\\\\\n- Anonymous voting options\\\\\\\\n- Conversation encryption\\\\\\\\n- Participant data protection\\\\\\\\n- Audit trail maintenance\\\\\\\\n\\\\\\\\n## Extension Points\\\\\\\\n\\\\\\\\n### Adding New AI Providers\\\\\\\\n1. Implement `AIProvider` interface\\\\\\\\n2. Add configuration options\\\\\\\\n3. Update provider factory\\\\\\\\n4. Test integration\\\\\\\\n\\\\\\\\n### Custom Interfaces\\\\\\\\n1. Implement `HumanInterface` interface\\\\\\\\n2. Handle async message flow\\\\\\\\n3. Add configuration support\\\\\\\\n4. Test user experience\\\\\\\\n\\\\\\\\n### Additional Export Formats\\\\\\\\n1. Extend export methods\\\\\\\\n2. Add format validation\\\\\\\\n3. Update documentation\\\\\\\\n4. Test output quality\\\\\\\\n\\\\\\\\n## Deployment Architecture\\\\\\\\n\\\\\\\\n### Development\\\\\\\\n```\\\\\\\\nLocal Machine\\\\\\\\n‚îú‚îÄ‚îÄ Python Environment\\\\\\\\n‚îú‚îÄ‚îÄ Configuration Files\\\\\\\\n‚îú‚îÄ‚îÄ Test Data\\\\\\\\n‚îî‚îÄ‚îÄ Log Files\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Production\\\\\\\\n```\\\\\\\\nContainer Orchestration\\\\\\\\n‚îú‚îÄ‚îÄ Moderator Service\\\\\\\\n‚îú‚îÄ‚îÄ Bot Client Services\\\\\\\\n‚îú‚îÄ‚îÄ Streaming Service\\\\\\\\n‚îú‚îÄ‚îÄ Web Interface\\\\\\\\n‚îú‚îÄ‚îÄ Database\\\\\\\\n‚îî‚îÄ‚îÄ Message Queue\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Configuration Management\\\\\\\\n\\\\\\\\n### Environment-Specific Settings\\\\\\\\n- Development: Local APIs, debug logging\\\\\\\\n- Staging: Production APIs, info logging\\\\\\\\n- Production: Optimized settings, error logging\\\\\\\\n\\\\\\\\n### Secret Management\\\\\\\\n- API keys in environment variables\\\\\\\\n- Database credentials secured\\\\\\\\n- SSL certificates managed\\\\\\\\n- Rotation policies enforced\\\\\\\\n\\\\\\\\nThis architecture enables a robust, scalable, and extensible debate platform that can accommodate various use cases from small-scale experiments to large public events.\\\\\\\"\\\\n        },\\\\n        \\\\\\\"usage.md\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"docs/usage.md\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".md\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 21363,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"# AI Jubilee Debate System - Usage Guide\\\\\\\\n\\\\\\\\n## üöÄ Quick Start\\\\\\\\n\\\\\\\\n### Prerequisites\\\\\\\\n1. **Python 3.8+** installed\\\\\\\\n2. **API Keys** for OpenAI and/or Anthropic\\\\\\\\n3. **Dependencies** installed\\\\\\\\n\\\\\\\\n### Setup Steps\\\\\\\\n\\\\\\\\n1. **Clone or download the project**\\\\\\\\n2. **Install dependencies:**\\\\\\\\n   ```bash\\\\\\\\n   pip install -r requirements.txt\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n3. **Set up your API keys in `.env` file:**\\\\\\\\n   ```bash\\\\\\\\n   # Create .env file in project root\\\\\\\\n   OPENAI_API_KEY=sk-your-openai-key-here\\\\\\\\n   ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n4. **Run the debate:**\\\\\\\\n   ```bash\\\\\\\\n   # Recommended: Use the simple launcher\\\\\\\\n   python run_debate.py\\\\\\\\n   \\\\\\\\n   # Alternative: Use the module directly\\\\\\\\n   python -m app.main\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n## üé≠ Debate Modes\\\\\\\\n\\\\\\\\n### **Autonomous Mode** (Default - Recommended!)\\\\\\\\n\\\\\\\\nIn autonomous mode, bots monitor the conversation and decide when to speak, creating a natural, organic debate flow.\\\\\\\\n\\\\\\\\n#### How Autonomous Mode Works:\\\\\\\\n- ü§ñ **Bots run in parallel**, continuously monitoring chat\\\\\\\\n- üß† **Intelligent decision making** - bots decide when they feel compelled to respond\\\\\\\\n- üìö **Full conversation history** available to all participants\\\\\\\\n- üéØ **Smart triggers** - bots respond to mentions, challenges, or opportunities\\\\\\\\n- ‚è∞ **Cooldown system** prevents spam (15-45 second intervals)\\\\\\\\n- üó£Ô∏è **Humans can speak anytime** during discussion phase\\\\\\\\n\\\\\\\\n#### Configuration:\\\\\\\\n```yaml\\\\\\\\ndebate:\\\\\\\\n  mode: \\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\"  # Enable autonomous mode\\\\\\\\n  min_bot_cooldown: 15         # Minimum seconds between bot responses\\\\\\\\n  max_bot_cooldown: 45         # Maximum cooldown for active bots  \\\\\\\\n  message_check_interval: 5    # How often bots check for new messages\\\\\\\\n  silence_timeout: 60          # Moderator intervenes after silence\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Example Autonomous Flow:\\\\\\\\n```\\\\\\\\nüé≠ Moderator: \\\\\\\\\\\\\\\"Autonomous Discussion Phase Begin!\\\\\\\\\\\\\\\"\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\"Remote work increases productivity by 40%...\\\\\\\\\\\\\\\"\\\\\\\\nüí≠ Skeptic is thinking about responding...\\\\\\\\nü§ñ Skeptic: \\\\\\\\\\\\\\\"But what about the collaboration costs?\\\\\\\\\\\\\\\"\\\\\\\\nüë§ Human: \\\\\\\\\\\\\\\"I've experienced both - here's my take...\\\\\\\\\\\\\\\"\\\\\\\\nüí≠ Socrates is thinking about responding...  \\\\\\\\nü§ñ Socrates: \\\\\\\\\\\\\\\"What evidence supports these productivity claims?\\\\\\\\\\\\\\\"\\\\\\\\nüéØ Moderator: \\\\\\\\\\\\\\\"What about environmental implications?\\\\\\\\\\\\\\\"\\\\\\\\nüí≠ Advocate is thinking about responding...\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\"Great point - remote work cuts commuting emissions...\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Sequential Mode** (Traditional)\\\\\\\\n\\\\\\\\nParticipants take turns in a structured order. More predictable but less dynamic.\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\ndebate:\\\\\\\\n  mode: \\\\\\\\\\\\\\\"sequential\\\\\\\\\\\\\\\"  # Traditional turn-based mode\\\\\\\\n```\\\\\\\\n\\\\\\\\n## üéØ Human Participation in Autonomous Mode\\\\\\\\n\\\\\\\\n### **During Discussion Phase:**\\\\\\\\n- ‚úÖ **Speak anytime** - no waiting for turns!\\\\\\\\n- ‚úÖ **Type naturally** - just enter your response\\\\\\\\n- ‚úÖ **Full context** - see all previous messages\\\\\\\\n- ‚úÖ **Real-time** - immediate feedback from bots\\\\\\\\n\\\\\\\\n### **Available Commands:**\\\\\\\\n```\\\\\\\\nüí¨ [your message]     # Join the debate with your response\\\\\\\\nhelp                  # Show help information\\\\\\\\nstatus                # Show your participation statistics\\\\\\\\nhistory               # Show recent conversation\\\\\\\\nquit                  # Leave the debate\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Example Human Session:**\\\\\\\\n```\\\\\\\\nüéØ AUTONOMOUS DEBATE MODE ACTIVE\\\\\\\\nüó£Ô∏è You can speak at ANY TIME during the discussion!\\\\\\\\nüí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\\n\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\"Remote work is clearly the future because...\\\\\\\\\\\\\\\"\\\\\\\\nü§ñ Skeptic: \\\\\\\\\\\\\\\"I disagree - here's why remote work fails...\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nüí¨ Type your response: I think both perspectives miss the point about hybrid work...\\\\\\\\n‚úÖ Your message has been added to the debate!\\\\\\\\n\\\\\\\\nüí≠ Socrates is thinking about responding...\\\\\\\\nü§ñ Socrates: \\\\\\\\\\\\\\\"Interesting point about hybrid - can you elaborate?\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nüí¨ Type your response: status\\\\\\\\nüìä Your participation: 1 responses, 100.0% participation rate, avg response time: 12.3s\\\\\\\\n\\\\\\\\nüí¨ Type your response: Sure! Hybrid work combines the best of both...\\\\\\\\n‚úÖ Your message has been added to the debate!\\\\\\\\n```\\\\\\\\n\\\\\\\\n## üìã Debate Phases\\\\\\\\n\\\\\\\\n### **1. Introduction Phase**\\\\\\\\n- Moderator introduces topic and participants\\\\\\\\n- Overview of rules and format\\\\\\\\n- Duration: ~2 minutes\\\\\\\\n\\\\\\\\n### **2. Opening Statements Phase** \\\\\\\\n- Each participant gives structured opening statement\\\\\\\\n- **Sequential order** (even in autonomous mode)\\\\\\\\n- Time limit: 120 seconds per participant\\\\\\\\n\\\\\\\\n### **3. Discussion Phase**\\\\\\\\n\\\\\\\\n#### **Autonomous Mode:**\\\\\\\\n- üîÑ **Free-flowing conversation**\\\\\\\\n- ü§ñ **Bots monitor and respond intelligently** \\\\\\\\n- üë• **Humans can jump in anytime**\\\\\\\\n- üéØ **Moderator provides prompts during silence**\\\\\\\\n- ‚è∞ **Total time: 30 minutes** (configurable)\\\\\\\\n\\\\\\\\n#### **Sequential Mode:**\\\\\\\\n- üîÑ **Round-robin turns**\\\\\\\\n- ‚è∞ **60 seconds per response**\\\\\\\\n- üìù **Structured format**\\\\\\\\n\\\\\\\\n### **4. Closing Statements Phase**\\\\\\\\n- Final arguments from each participant\\\\\\\\n- **Sequential order** \\\\\\\\n- Time limit: 90 seconds per participant\\\\\\\\n\\\\\\\\n### **5. Voting Phase**\\\\\\\\n- Participants and audience vote for most persuasive\\\\\\\\n- Duration: 5 minutes\\\\\\\\n- Optional justification required\\\\\\\\n\\\\\\\\n### **6. Results Phase**\\\\\\\\n- Vote tallies and winner announcement\\\\\\\\n- Final statistics and transcript saving\\\\\\\\n\\\\\\\\n## ‚öôÔ∏è Configuration Options\\\\\\\\n\\\\\\\\n### **Bot Personalities**\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\nbots:\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n  - name: \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\"  \\\\\\\\n    personality: \\\\\\\\\\\\\\\"Passionate supporter, data-driven, persuasive. Jumps in when position is challenged.\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\"\\\\\\\\n    \\\\\\\\n  - name: \\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Critical thinker, questions assumptions. Responds when claims need scrutiny.\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Timing Controls**\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\ndebate:\\\\\\\\n  time_limit_minutes: 30        # Total discussion time\\\\\\\\n  opening_statement_time: 120   # Opening statement duration\\\\\\\\n  response_time: 60            # Response time in sequential mode\\\\\\\\n  closing_statement_time: 90   # Closing statement duration\\\\\\\\n  \\\\\\\\n  # Autonomous mode specific\\\\\\\\n  min_bot_cooldown: 15         # Minimum bot response interval\\\\\\\\n  max_bot_cooldown: 45         # Maximum bot cooldown\\\\\\\\n  silence_timeout: 60          # Silence before moderator intervenes\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Interface Options**\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\ninterface:\\\\\\\\n  mode: \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\"                  # CLI or web interface\\\\\\\\n  enable_rich_formatting: true # Colored/formatted output\\\\\\\\n  show_typing_indicators: true # Show when bots are thinking\\\\\\\\n  enable_reactions: true       # Enable emoji reactions\\\\\\\\n```\\\\\\\\n\\\\\\\\n## üéõÔ∏è Advanced Usage\\\\\\\\n\\\\\\\\n### **Command Line Options**\\\\\\\\n\\\\\\\\n```bash\\\\\\\\n# Basic usage\\\\\\\\npython run_debate.py\\\\\\\\n\\\\\\\\n# Using the module with options\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\"AI ethics\\\\\\\\\\\\\\\" --bots 3 --humans 2\\\\\\\\n\\\\\\\\n# Custom configuration\\\\\\\\npython -m app.main --config custom_config.yaml\\\\\\\\n\\\\\\\\n# Web interface mode\\\\\\\\npython -m app.main --interface web\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Custom Topics**\\\\\\\\n\\\\\\\\nAdd to `config.yaml`:\\\\\\\\n```yaml\\\\\\\\ntopics:\\\\\\\\n  - \\\\\\\\\\\\\\\"Your custom debate topic here\\\\\\\\\\\\\\\"\\\\\\\\n  - \\\\\\\\\\\\\\\"Another interesting topic\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\nOr specify directly:\\\\\\\\n```bash\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\"Custom topic\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Bot Configuration**\\\\\\\\n\\\\\\\\nCreate custom bots in `config.yaml`:\\\\\\\\n```yaml\\\\\\\\nbots:\\\\\\\\n  - name: \\\\\\\\\\\\\\\"MyBot\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Your custom personality description\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n## üîß Troubleshooting\\\\\\\\n\\\\\\\\n### **Common Issues**\\\\\\\\n\\\\\\\\n**API Key Errors:**\\\\\\\\n```bash\\\\\\\\n# Check your .env file format\\\\\\\\nOPENAI_API_KEY=sk-your-key  # No quotes, no export\\\\\\\\nANTHROPIC_API_KEY=sk-ant-your-key\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Import Errors:**\\\\\\\\n```bash\\\\\\\\n# Make sure you're in the project root directory\\\\\\\\ncd ai_jubilee_debate\\\\\\\\npython run_debate.py\\\\\\\\n```\\\\\\\\n\\\\\\\\n**Timeout Issues:**\\\\\\\\n```bash\\\\\\\\n# Check internet connection and API status\\\\\\\\n# Increase timeouts in config.yaml if needed\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Debug Mode**\\\\\\\\n\\\\\\\\nEnable detailed logging:\\\\\\\\n```yaml\\\\\\\\nchat:\\\\\\\\n  log_level: \\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\nOr set environment variable:\\\\\\\\n```bash\\\\\\\\nexport LOG_LEVEL=DEBUG\\\\\\\\npython run_debate.py\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Saving Transcripts**\\\\\\\\n\\\\\\\\nTranscripts are automatically saved after each debate:\\\\\\\\n```yaml\\\\\\\\nchat:\\\\\\\\n  save_transcripts: true\\\\\\\\n  transcript_format: \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\nFiles saved as: `debate_YYYY-MM-DD_HH-MM-SS.json`\\\\\\\\n\\\\\\\\n## üé™ Tips for Great Debates\\\\\\\\n\\\\\\\\n### **For Humans:**\\\\\\\\n- üéØ **Jump in naturally** during autonomous mode\\\\\\\\n- üìä **Reference specific points** made by others\\\\\\\\n- üí° **Provide evidence** and examples\\\\\\\\n- ü§ù **Be respectful** but persuasive\\\\\\\\n- ‚ö° **Keep responses focused** and substantial\\\\\\\\n\\\\\\\\n### **Bot Optimization:**\\\\\\\\n- üé≠ **Diverse personalities** create better dynamics\\\\\\\\n- ‚öñÔ∏è **Balanced stances** (pro/con/neutral mix)\\\\\\\\n- üß† **Different models** (GPT-4, Claude, etc.) for variety\\\\\\\\n- ‚è∞ **Appropriate cooldowns** prevent spam\\\\\\\\n\\\\\\\\n### **Moderator Settings:**\\\\\\\\n- üéØ **Topic-specific prompts** keep discussion flowing\\\\\\\\n- ‚è∞ **Reasonable timeouts** balance pace and depth\\\\\\\\n- üí¨ **Silence intervention** maintains engagement\\\\\\\\n\\\\\\\\n## üìä Monitoring and Analytics\\\\\\\\n\\\\\\\\n### **Real-time Stats**\\\\\\\\n```\\\\\\\\n# During debate, type 'status' to see:\\\\\\\\nüìä Your participation: 3 responses, 75% participation rate\\\\\\\\n‚è±Ô∏è Average response time: 15.2 seconds\\\\\\\\nüí¨ Conversation length: 24 messages\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Post-Debate Analysis**\\\\\\\\n- üìà Participation rates per participant\\\\\\\\n- ‚è∞ Response time analytics  \\\\\\\\n- üó≥Ô∏è Voting results and justifications\\\\\\\\n- üìù Full transcript with timestamps\\\\\\\\n\\\\\\\\n## üöÄ Performance Tips\\\\\\\\n\\\\\\\\n### **For Better Performance:**\\\\\\\\n- Use **GPT-3.5** for faster, cheaper responses\\\\\\\\n- Set **reasonable cooldowns** (15-30 seconds)\\\\\\\\n- Limit **conversation history** for speed\\\\\\\\n- Use **async mode** for responsiveness\\\\\\\\n\\\\\\\\n### **For Higher Quality:**\\\\\\\\n- Use **GPT-4** or **Claude** for better reasoning\\\\\\\\n- Increase **response time limits**\\\\\\\\n- Enable **detailed logging** for analysis\\\\\\\\n- Create **specific bot personalities**\\\\\\\\n\\\\\\\\n## üåü Advanced Features\\\\\\\\n\\\\\\\\n### **Real-time Streaming**\\\\\\\\nEnable WebSocket streaming for live audiences:\\\\\\\\n```yaml\\\\\\\\nstreaming:\\\\\\\\n  enabled: true\\\\\\\\n  websocket_port: 8080\\\\\\\\n  max_connections: 100\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Voting System**\\\\\\\\nComprehensive voting with justifications:\\\\\\\\n```yaml\\\\\\\\nvoting:\\\\\\\\n  enabled: true\\\\\\\\n  voting_duration: 300\\\\\\\\n  require_justification: true\\\\\\\\n  anonymous_votes: false\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Web Interface**\\\\\\\\nFor browser-based participation:\\\\\\\\n```yaml\\\\\\\\ninterface:\\\\\\\\n  mode: \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\"\\\\\\\\n  websocket_port: 8080\\\\\\\\n```\\\\\\\\n\\\\\\\\n## üìÅ File Structure\\\\\\\\n\\\\\\\\n```\\\\\\\\nai_jubilee_debate/\\\\\\\\n‚îú‚îÄ‚îÄ .env                    # Your API keys (never commit!)\\\\\\\\n‚îú‚îÄ‚îÄ .env.example           # Example environment file\\\\\\\\n‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns\\\\\\\\n‚îú‚îÄ‚îÄ config.yaml            # Main configuration\\\\\\\\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\\\\\\\\n‚îú‚îÄ‚îÄ run_debate.py          # Simple launcher script\\\\\\\\n‚îú‚îÄ‚îÄ app/                   # Core application\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package initialization\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Main entry point\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ moderator.py      # Debate moderation logic\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ bot_client.py     # AI bot participants\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ human_client.py   # Human participants\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ chat_log.py       # Message management\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ voting.py         # Voting system\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions\\\\\\\\n‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # WebSocket streaming\\\\\\\\n‚îú‚îÄ‚îÄ tests/                 # Test suite\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_moderator.py\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_voting.py\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_chat_log.py\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_bot_client.py\\\\\\\\n‚îÇ   ‚îî‚îÄ‚îÄ test_human_client.py\\\\\\\\n‚îî‚îÄ‚îÄ docs/                  # Documentation\\\\\\\\n    ‚îú‚îÄ‚îÄ architecture.md    # System architecture\\\\\\\\n    ‚îú‚îÄ‚îÄ usage.md          # This file\\\\\\\\n    ‚îî‚îÄ‚îÄ api_reference.md  # API documentation\\\\\\\\n```\\\\\\\\n\\\\\\\\n## üÜò Getting Help\\\\\\\\n\\\\\\\\n### **Built-in Help**\\\\\\\\n```bash\\\\\\\\n# During debate\\\\\\\\nhelp                    # Show autonomous mode help\\\\\\\\nstatus                  # Show participation stats\\\\\\\\nhistory                 # Show recent messages\\\\\\\\n\\\\\\\\n# Command line\\\\\\\\npython -m app.main --help   # Show CLI options\\\\\\\\n```\\\\\\\\n\\\\\\\\n### **Common Commands**\\\\\\\\n```bash\\\\\\\\n# Run with debug logging\\\\\\\\nLOG_LEVEL=DEBUG python run_debate.py\\\\\\\\n\\\\\\\\n# Run tests\\\\\\\\npython -m pytest tests/ -v\\\\\\\\n\\\\\\\\n# Check configuration\\\\\\\\npython -c \\\\\\\\\\\\\\\"from app.utils import load_config; print(load_config())\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\nThis autonomous debate system creates truly organic, intelligent conversations between AI participants while allowing humans to jump in naturally whenever they feel inspired to contribute! üé≠ü§ñ# AI Jubilee Debate System Usage Guide\\\\\\\\n\\\\\\\\n## Quick Start\\\\\\\\n\\\\\\\\n### Installation\\\\\\\\n\\\\\\\\n1. **Clone the repository:**\\\\\\\\n   ```bash\\\\\\\\n   git clone <repository-url>\\\\\\\\n   cd ai_jubilee_debate\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n2. **Install dependencies:**\\\\\\\\n   ```bash\\\\\\\\n   pip install -r requirements.txt\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n3. **Set up environment variables:**\\\\\\\\n   ```bash\\\\\\\\n   export OPENAI_API_KEY=\\\\\\\\\\\\\\\"your-openai-api-key\\\\\\\\\\\\\\\"\\\\\\\\n   export ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\"your-anthropic-api-key\\\\\\\\\\\\\\\"\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n4. **Run your first debate:**\\\\\\\\n   ```bash\\\\\\\\n   python -m app.main\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n## Configuration\\\\\\\\n\\\\\\\\n### Basic Configuration (`config.yaml`)\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\ndebate:\\\\\\\\n  default_topic: \\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\"\\\\\\\\n  max_participants: 4\\\\\\\\n  time_limit_minutes: 20\\\\\\\\n\\\\\\\\nbots:\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\" \\\\\\\\n    stance: \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\"\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nvoting:\\\\\\\\n  enabled: true\\\\\\\\n  voting_duration: 180\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Advanced Configuration Options\\\\\\\\n\\\\\\\\n#### Timing Settings\\\\\\\\n```yaml\\\\\\\\ndebate:\\\\\\\\n  opening_statement_time: 120  # seconds\\\\\\\\n  response_time: 60\\\\\\\\n  closing_statement_time: 90\\\\\\\\n  warning_time: 45  # warning before timeout\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Bot Personalities\\\\\\\\n```yaml\\\\\\\\nbots:\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Philosopher\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Thoughtful, asks probing questions\\\\\\\\\\\\\\\"\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\"socratic\\\\\\\\\\\\\\\"\\\\\\\\n    temperature: 0.8\\\\\\\\n    max_tokens: 250\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Human Interface\\\\\\\\n```yaml\\\\\\\\ninterface:\\\\\\\\n  mode: \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\"\\\\\\\\n  enable_rich_formatting: true\\\\\\\\n  show_typing_indicators: true\\\\\\\\n  input_timeout: 120\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Running Debates\\\\\\\\n\\\\\\\\n### Command Line Interface\\\\\\\\n\\\\\\\\n#### Basic Usage\\\\\\\\n```bash\\\\\\\\n# Run with default settings\\\\\\\\npython -m app.main\\\\\\\\n\\\\\\\\n# Specify topic\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\"Universal Basic Income is necessary\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Set participant counts\\\\\\\\npython -m app.main --bots 3 --humans 2\\\\\\\\n\\\\\\\\n# Use custom config\\\\\\\\npython -m app.main --config custom_config.yaml\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Advanced Options\\\\\\\\n```bash\\\\\\\\n# Full command with all options\\\\\\\\npython -m app.main \\\\\\\\\\\\\\\\\\\\\\\\n  --topic \\\\\\\\\\\\\\\"Climate change requires immediate action\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\n  --bots 2 \\\\\\\\\\\\\\\\\\\\\\\\n  --humans 1 \\\\\\\\\\\\\\\\\\\\\\\\n  --config production_config.yaml\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Programmatic Usage\\\\\\\\n\\\\\\\\n#### Simple Session\\\\\\\\n```python\\\\\\\\nfrom app.main import start_debate_session\\\\\\\\n\\\\\\\\n# Start a basic debate\\\\\\\\nawait start_debate_session(\\\\\\\\n    topic=\\\\\\\\\\\\\\\"The future of remote work\\\\\\\\\\\\\\\",\\\\\\\\n    ai_bots=2,\\\\\\\\n    human_participants=1\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Custom Session\\\\\\\\n```python\\\\\\\\nfrom app import Moderator, BotClient, HumanClient, ChatLog, VotingSystem\\\\\\\\n\\\\\\\\n# Create components\\\\\\\\nchat_log = ChatLog()\\\\\\\\nvoting_system = VotingSystem({'enabled': True})\\\\\\\\n\\\\\\\\n# Create participants\\\\\\\\nbot = BotClient(\\\\\\\\n    name=\\\\\\\\\\\\\\\"Analyst\\\\\\\\\\\\\\\",\\\\\\\\n    model=\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\",\\\\\\\\n    provider=\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\",\\\\\\\\n    personality=\\\\\\\\\\\\\\\"Data-driven and analytical\\\\\\\\\\\\\\\",\\\\\\\\n    stance=\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\",\\\\\\\\n    api_key=\\\\\\\\\\\\\\\"your-api-key\\\\\\\\\\\\\\\"\\\\\\\\n)\\\\\\\\n\\\\\\\\nhuman = HumanClient(\\\\\\\\n    name=\\\\\\\\\\\\\\\"Participant1\\\\\\\\\\\\\\\",\\\\\\\\n    interface_config={'mode': 'cli'}\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Create moderator and run\\\\\\\\nmoderator = Moderator(\\\\\\\\n    topic=\\\\\\\\\\\\\\\"AI Ethics in Healthcare\\\\\\\\\\\\\\\",\\\\\\\\n    participants=[bot, human],\\\\\\\\n    chat_log=chat_log,\\\\\\\\n    voting_system=voting_system,\\\\\\\\n    config={'time_limit_minutes': 15}\\\\\\\\n)\\\\\\\\n\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Participant Management\\\\\\\\n\\\\\\\\n### AI Bot Configuration\\\\\\\\n\\\\\\\\n#### Creating Custom Bots\\\\\\\\n```python\\\\\\\\n# Argumentative bot\\\\\\\\naggressive_bot = BotClient(\\\\\\\\n    name=\\\\\\\\\\\\\\\"Debater\\\\\\\\\\\\\\\",\\\\\\\\n    model=\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\",\\\\\\\\n    provider=\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\", \\\\\\\\n    personality=\\\\\\\\\\\\\\\"Aggressive, uses strong rhetoric\\\\\\\\\\\\\\\",\\\\\\\\n    stance=\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\",\\\\\\\\n    temperature=0.9,  # More creative\\\\\\\\n    api_key=api_key\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Analytical bot\\\\\\\\nanalytical_bot = BotClient(\\\\\\\\n    name=\\\\\\\\\\\\\\\"Researcher\\\\\\\\\\\\\\\", \\\\\\\\n    model=\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\",\\\\\\\\n    provider=\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\",\\\\\\\\n    personality=\\\\\\\\\\\\\\\"Fact-focused, cites evidence\\\\\\\\\\\\\\\",\\\\\\\\n    stance=\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\",\\\\\\\\n    temperature=0.3,  # More conservative\\\\\\\\n    api_key=api_key\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Bot Personality Examples\\\\\\\\n```yaml\\\\\\\\npersonalities:\\\\\\\\n  socratic: \\\\\\\\\\\\\\\"Asks probing questions, seeks deeper understanding\\\\\\\\\\\\\\\"\\\\\\\\n  advocate: \\\\\\\\\\\\\\\"Passionate, uses emotional appeals and personal stories\\\\\\\\\\\\\\\"  \\\\\\\\n  scientist: \\\\\\\\\\\\\\\"Data-driven, cites studies and statistics\\\\\\\\\\\\\\\"\\\\\\\\n  philosopher: \\\\\\\\\\\\\\\"Abstract thinking, explores ethical implications\\\\\\\\\\\\\\\"\\\\\\\\n  pragmatist: \\\\\\\\\\\\\\\"Focuses on practical implementation and real-world effects\\\\\\\\\\\\\\\"\\\\\\\\n  skeptic: \\\\\\\\\\\\\\\"Questions assumptions, plays devil's advocate\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Human Interface Options\\\\\\\\n\\\\\\\\n#### CLI Mode (Default)\\\\\\\\n- Terminal-based interaction\\\\\\\\n- Rich formatting with colors\\\\\\\\n- Real-time message display\\\\\\\\n- Keyboard input for responses\\\\\\\\n\\\\\\\\n#### Web Mode \\\\\\\\n```python\\\\\\\\nhuman = HumanClient(\\\\\\\\n    name=\\\\\\\\\\\\\\\"WebUser\\\\\\\\\\\\\\\",\\\\\\\\n    interface_config={\\\\\\\\n        'mode': 'web',\\\\\\\\n        'enable_reactions': True,\\\\\\\\n        'show_typing_indicators': True\\\\\\\\n    }\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Debate Topics\\\\\\\\n\\\\\\\\n### Predefined Topics\\\\\\\\nThe system includes several built-in topics:\\\\\\\\n- \\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Social media has a net positive impact on democracy\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\"\\\\\\\\n- \\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n### Custom Topics\\\\\\\\n```python\\\\\\\\n# Define your own topics\\\\\\\\ncustom_topics = [\\\\\\\\n    \\\\\\\\\\\\\\\"Cryptocurrency will replace traditional banking\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"Space exploration should be publicly funded\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"Genetic engineering should be available to all\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"Automation will eliminate the need for human work\\\\\\\\\\\\\\\"\\\\\\\\n]\\\\\\\\n\\\\\\\\n# Use in configuration\\\\\\\\nconfig['topics'] = custom_topics\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Topic Guidelines\\\\\\\\n- Keep topics debatable (not factual statements)\\\\\\\\n- Ensure both sides can be reasonably argued\\\\\\\\n- Make them relevant to your audience\\\\\\\\n- Consider current events and trends\\\\\\\\n\\\\\\\\n## Voting and Results\\\\\\\\n\\\\\\\\n### Voting Configuration\\\\\\\\n```yaml\\\\\\\\nvoting:\\\\\\\\n  enabled: true\\\\\\\\n  voting_duration: 300  # 5 minutes\\\\\\\\n  allow_participant_voting: true\\\\\\\\n  require_justification: true\\\\\\\\n  anonymous_votes: false\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Accessing Results\\\\\\\\n```python\\\\\\\\n# After debate completion\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\n\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Winner: {results['winner']}\\\\\\\\\\\\\\\")\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Vote breakdown: {results['vote_counts']}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Export detailed results\\\\\\\\nawait voting_system.export_results('json')\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Results Analysis\\\\\\\\n```python\\\\\\\\n# Get participant performance\\\\\\\\nfor participant in participants:\\\\\\\\n    performance = voting_system.get_candidate_performance(participant.name)\\\\\\\\n    print(f\\\\\\\\\\\\\\\"{participant.name}: {performance['win_rate']:.1%} win rate\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Live Streaming\\\\\\\\n\\\\\\\\n### Enable Streaming\\\\\\\\n```yaml\\\\\\\\nstreaming:\\\\\\\\n  enabled: true\\\\\\\\n  websocket_port: 8080\\\\\\\\n  max_connections: 100\\\\\\\\n  broadcast_votes: true\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Streaming Server\\\\\\\\n```python\\\\\\\\nfrom app.streaming import StreamingServer\\\\\\\\n\\\\\\\\n# Create streaming server\\\\\\\\nstreaming = StreamingServer(\\\\\\\\n    chat_log=chat_log,\\\\\\\\n    voting_system=voting_system,\\\\\\\\n    config=streaming_config\\\\\\\\n)\\\\\\\\n\\\\\\\\nawait streaming.start()\\\\\\\\n# Server runs on localhost:8080\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Client Connection\\\\\\\\n```javascript\\\\\\\\n// Connect to stream\\\\\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\\\\\n\\\\\\\\nws.onmessage = function(event) {\\\\\\\\n    const data = JSON.parse(event.data);\\\\\\\\n    \\\\\\\\n    if (data.type === 'message') {\\\\\\\\n        displayMessage(data.data);\\\\\\\\n    } else if (data.type === 'vote_update') {\\\\\\\\n        updateVoteDisplay(data.data);\\\\\\\\n    }\\\\\\\\n};\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Data Export and Analysis\\\\\\\\n\\\\\\\\n### Transcript Export\\\\\\\\n```python\\\\\\\\n# Save debate transcript\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\"debate_2024.json\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\")\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\"debate_2024.txt\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\") \\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\"debate_2024.html\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Statistics and Analytics\\\\\\\\n```python\\\\\\\\n# Chat statistics\\\\\\\\nstats = chat_log.get_statistics()\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Total messages: {stats['total_messages']}\\\\\\\\\\\\\\\")\\\\\\\\nprint(f\\\\\\\\\\\\\\\"Average per minute: {stats['messages_per_minute']:.1f}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n# Participant statistics  \\\\\\\\nfor participant in participants:\\\\\\\\n    stats = participant.get_stats()\\\\\\\\n    print(f\\\\\\\\\\\\\\\"{participant.name}: {stats}\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Voting Analysis\\\\\\\\n```python\\\\\\\\n# Export voting data\\\\\\\\ncsv_data = await voting_system.export_results('csv')\\\\\\\\ntxt_report = await voting_system.export_results('txt')\\\\\\\\n\\\\\\\\n# Historical analysis\\\\\\\\nhistory = voting_system.vote_history\\\\\\\\nfor session in history:\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Session: {session['timestamp']}\\\\\\\\\\\\\\\")\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Winner: {session['results'].winner}\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Troubleshooting\\\\\\\\n\\\\\\\\n### Common Issues\\\\\\\\n\\\\\\\\n#### API Key Problems\\\\\\\\n```bash\\\\\\\\n# Check environment variables\\\\\\\\necho $OPENAI_API_KEY\\\\\\\\necho $ANTHROPIC_API_KEY\\\\\\\\n\\\\\\\\n# Set them if missing\\\\\\\\nexport OPENAI_API_KEY=\\\\\\\\\\\\\\\"sk-...\\\\\\\\\\\\\\\"\\\\\\\\nexport ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\"sk-ant-...\\\\\\\\\\\\\\\"\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Connection Issues\\\\\\\\n```python\\\\\\\\n# Test bot connectivity\\\\\\\\nbot = BotClient(...)\\\\\\\\nsuccess = await bot.warmup()\\\\\\\\nif not success:\\\\\\\\n    print(\\\\\\\\\\\\\\\"Bot connection failed\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n#### Performance Issues\\\\\\\\n```yaml\\\\\\\\n# Reduce timeouts for faster sessions\\\\\\\\ndebate:\\\\\\\\n  opening_statement_time: 60\\\\\\\\n  response_time: 30\\\\\\\\n  closing_statement_time: 45\\\\\\\\n\\\\\\\\n# Limit message history\\\\\\\\nchat:\\\\\\\\n  max_message_length: 300\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Debug Mode\\\\\\\\n```bash\\\\\\\\n# Enable debug logging\\\\\\\\npython -m app.main --config debug_config.yaml\\\\\\\\n```\\\\\\\\n\\\\\\\\n```yaml\\\\\\\\n# debug_config.yaml\\\\\\\\nchat:\\\\\\\\n  log_level: \\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\"\\\\\\\\n  save_transcripts: true\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Error Recovery\\\\\\\\n```python\\\\\\\\n# Handle errors gracefully\\\\\\\\ntry:\\\\\\\\n    results = await moderator.run_debate()\\\\\\\\nexcept Exception as e:\\\\\\\\n    print(f\\\\\\\\\\\\\\\"Debate error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    # Save partial transcript\\\\\\\\n    await chat_log.save_transcript(\\\\\\\\\\\\\\\"error_recovery.json\\\\\\\\\\\\\\\")\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Best Practices\\\\\\\\n\\\\\\\\n### Bot Configuration\\\\\\\\n- Use different personalities for variety\\\\\\\\n- Balance pro/con/neutral stances\\\\\\\\n- Test API connections before debates\\\\\\\\n- Monitor response times and adjust timeouts\\\\\\\\n\\\\\\\\n### Topic Selection\\\\\\\\n- Choose engaging, relevant topics\\\\\\\\n- Ensure balanced argumentation potential\\\\\\\\n- Test topics with different participant mixes\\\\\\\\n- Update topics regularly for freshness\\\\\\\\n\\\\\\\\n### Session Management\\\\\\\\n- Start with shorter sessions for testing\\\\\\\\n- Monitor participant engagement\\\\\\\\n- Save transcripts for analysis\\\\\\\\n- Review voting patterns for improvements\\\\\\\\n\\\\\\\\n### Performance Optimization\\\\\\\\n- Use appropriate API models for your needs\\\\\\\\n- Set reasonable timeouts\\\\\\\\n- Limit concurrent API calls\\\\\\\\n- Monitor system resources\\\\\\\\n\\\\\\\\nThis guide covers the core functionality of the AI Jubilee Debate System. For detailed API documentation, see [api_reference.md](api_reference.md).\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"tests\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"directory\\\\\\\",\\\\n      \\\\\\\"contents\\\\\\\": {\\\\n        \\\\\\\"test_bot_client.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"tests/test_bot_client.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 15291,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTests for the BotClient class.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport pytest\\\\\\\\nimport asyncio\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\nfrom app.bot_client import BotClient, BotConfig, OpenAIProvider, AnthropicProvider\\\\\\\\nfrom app.chat_log import Message\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef bot_config():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create test bot configuration.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return {\\\\\\\\n        'name': 'TestBot',\\\\\\\\n        'model': 'gpt-3.5-turbo',\\\\\\\\n        'provider': 'openai',\\\\\\\\n        'personality': 'Analytical and thoughtful',\\\\\\\\n        'stance': 'pro',\\\\\\\\n        'api_key': 'test-api-key'\\\\\\\\n    }\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef bot_client(bot_config):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create test bot client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return BotClient(**bot_config)\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef sample_messages():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return [\\\\\\\\n        Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"What do you think about AI?\\\\\\\\\\\\\\\", 1640995200.0, 1),\\\\\\\\n        Message(\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Please respond\\\\\\\\\\\\\\\", 1640995210.0, 2, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestBotConfig:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for BotConfig dataclass.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_bot_config_creation(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test creating bot configuration.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = BotConfig(\\\\\\\\n            name=\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\",\\\\\\\\n            model=\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\",\\\\\\\\n            provider=\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\",\\\\\\\\n            personality=\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\",\\\\\\\\n            stance=\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        assert config.name == \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.model == \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.provider == \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.personality == \\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.stance == \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.temperature == 0.7  # Default value\\\\\\\\n        assert config.max_tokens == 300  # Default value\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestBotClient:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for BotClient class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_bot_client_initialization(self, bot_config):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test bot client initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot = BotClient(**bot_config)\\\\\\\\n\\\\\\\\n        assert bot.name == \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\"\\\\\\\\n        assert bot.config.model == \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\"\\\\\\\\n        assert bot.config.provider == \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n        assert isinstance(bot.ai_provider, OpenAIProvider)\\\\\\\\n        assert bot.response_count == 0\\\\\\\\n        assert bot.conversation_history == []\\\\\\\\n\\\\\\\\n    def test_bot_client_with_anthropic(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test bot client with Anthropic provider.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot = BotClient(\\\\\\\\n            name=\\\\\\\\\\\\\\\"AnthropicBot\\\\\\\\\\\\\\\",\\\\\\\\n            model=\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\",\\\\\\\\n            provider=\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\",\\\\\\\\n            personality=\\\\\\\\\\\\\\\"Balanced\\\\\\\\\\\\\\\",\\\\\\\\n            stance=\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\",\\\\\\\\n            api_key=\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        assert isinstance(bot.ai_provider, AnthropicProvider)\\\\\\\\n\\\\\\\\n    def test_bot_client_unsupported_provider(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test bot client with unsupported provider.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Unsupported AI provider\\\\\\\\\\\\\\\"):\\\\\\\\n            BotClient(\\\\\\\\n                name=\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\",\\\\\\\\n                model=\\\\\\\\\\\\\\\"test-model\\\\\\\\\\\\\\\",\\\\\\\\n                provider=\\\\\\\\\\\\\\\"unsupported\\\\\\\\\\\\\\\",\\\\\\\\n                personality=\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\",\\\\\\\\n                stance=\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\",\\\\\\\\n                api_key=\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\"\\\\\\\\n            )\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_response_success(self, bot_client, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Mock the AI provider\\\\\\\\n        mock_response = \\\\\\\\\\\\\\\"I think AI has great potential for society.\\\\\\\\\\\\\\\"\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=mock_response)\\\\\\\\n\\\\\\\\n        response = await bot_client.get_response(\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n        assert response == mock_response\\\\\\\\n        assert bot_client.response_count == 1\\\\\\\\n        assert len(bot_client.conversation_history) == 1\\\\\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_response_with_error(self, bot_client, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test response generation with API error.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Mock the AI provider to raise an exception\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\\\\\n            side_effect=Exception(\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\")\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        response = await bot_client.get_response(\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n        # Should return fallback response\\\\\\\\n        assert isinstance(response, str)\\\\\\\\n        assert len(response) > 0\\\\\\\\n        assert bot_client.stats['errors'] == 1\\\\\\\\n\\\\\\\\n    def test_prepare_messages(self, bot_client, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test message preparation for AI model.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        messages = bot_client._prepare_messages(\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n        assert len(messages) >= 1  # At least system message\\\\\\\\n        assert messages[0]['role'] == 'system'\\\\\\\\n        assert \\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\" in messages[0]['content']\\\\\\\\n        assert \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\" in messages[0]['content']\\\\\\\\n\\\\\\\\n    def test_create_system_prompt_pro_stance(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test system prompt creation for pro stance.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        prompt = bot_client._create_system_prompt(\\\\\\\\\\\\\\\"AI is beneficial\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\" in prompt\\\\\\\\n        assert \\\\\\\\\\\\\\\"AI is beneficial\\\\\\\\\\\\\\\" in prompt\\\\\\\\n        assert \\\\\\\\\\\\\\\"Analytical and thoughtful\\\\\\\\\\\\\\\" in prompt\\\\\\\\n        assert \\\\\\\\\\\\\\\"IN FAVOR\\\\\\\\\\\\\\\" in prompt\\\\\\\\n\\\\\\\\n    def test_create_system_prompt_con_stance(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test system prompt creation for con stance.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot = BotClient(\\\\\\\\n            name=\\\\\\\\\\\\\\\"ConBot\\\\\\\\\\\\\\\",\\\\\\\\n            model=\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\",\\\\\\\\n            provider=\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\",\\\\\\\\n            personality=\\\\\\\\\\\\\\\"Critical\\\\\\\\\\\\\\\",\\\\\\\\n            stance=\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\",\\\\\\\\n            api_key=\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        prompt = bot._create_system_prompt(\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\")\\\\\\\\n        assert \\\\\\\\\\\\\\\"AGAINST\\\\\\\\\\\\\\\" in prompt\\\\\\\\n\\\\\\\\n    def test_create_system_prompt_neutral_stance(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test system prompt creation for neutral stance.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot = BotClient(\\\\\\\\n            name=\\\\\\\\\\\\\\\"NeutralBot\\\\\\\\\\\\\\\",\\\\\\\\n            model=\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\",\\\\\\\\n            provider=\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\",\\\\\\\\n            personality=\\\\\\\\\\\\\\\"Balanced\\\\\\\\\\\\\\\",\\\\\\\\n            stance=\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\",\\\\\\\\n            api_key=\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\"\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        prompt = bot._create_system_prompt(\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\")\\\\\\\\n        assert \\\\\\\\\\\\\\\"balanced perspectives\\\\\\\\\\\\\\\" in prompt\\\\\\\\n\\\\\\\\n    def test_generate_fallback_response(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test fallback response generation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        response = bot_client._generate_fallback_response(\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert isinstance(response, str)\\\\\\\\n        assert len(response) > 0\\\\\\\\n        assert \\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\" in response or \\\\\\\\\\\\\\\"perspective\\\\\\\\\\\\\\\" in response.lower()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_receive_message(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test receiving a message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello bot\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\n\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\n\\\\\\\\n        # Should be added to conversation history\\\\\\\\n        assert len(bot_client.conversation_history) == 1\\\\\\\\n        assert \\\\\\\\\\\\\\\"Alice: Hello bot\\\\\\\\\\\\\\\" in bot_client.conversation_history[0]['content']\\\\\\\\n\\\\\\\\n        # Message queue should have the message\\\\\\\\n        queued_message = await bot_client.message_queue.get()\\\\\\\\n        assert queued_message == message\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_receive_own_message(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test receiving own message (should not be added to history).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"My own message\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\n\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\n\\\\\\\\n        # Should not be added to conversation history\\\\\\\\n        assert len(bot_client.conversation_history) == 0\\\\\\\\n\\\\\\\\n    def test_update_stats_success(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test updating statistics on success.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot_client._update_stats(1.5, success=True)\\\\\\\\n\\\\\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\\\\\n        assert bot_client.stats['average_response_time'] == 1.5\\\\\\\\n        assert bot_client.stats['total_response_time'] == 1.5\\\\\\\\n\\\\\\\\n    def test_update_stats_error(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test updating statistics on error.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot_client._update_stats(2.0, success=False)\\\\\\\\n\\\\\\\\n        assert bot_client.stats['errors'] == 1\\\\\\\\n        assert bot_client.stats['responses_generated'] == 0\\\\\\\\n\\\\\\\\n    def test_get_stats(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting bot statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Add some test data\\\\\\\\n        bot_client.stats['responses_generated'] = 5\\\\\\\\n        bot_client.stats['total_response_time'] = 10.0\\\\\\\\n        bot_client.stats['errors'] = 1\\\\\\\\n        bot_client._update_stats(0, success=True)  # Recalculate average\\\\\\\\n\\\\\\\\n        stats = bot_client.get_stats()\\\\\\\\n\\\\\\\\n        assert stats['name'] == \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\"\\\\\\\\n        assert stats['model'] == \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\"\\\\\\\\n        assert stats['provider'] == \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n        assert stats['responses_generated'] == 5\\\\\\\\n        assert stats['total_errors'] == 1\\\\\\\\n        assert 'success_rate' in stats\\\\\\\\n        assert 'average_response_time' in stats\\\\\\\\n\\\\\\\\n    def test_update_personality(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test updating bot personality.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot_client.update_personality(\\\\\\\\\\\\\\\"New personality\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert bot_client.config.personality == \\\\\\\\\\\\\\\"New personality\\\\\\\\\\\\\\\"\\\\\\\\n        assert bot_client.config.stance == \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_reset_conversation(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test resetting conversation history.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Add some conversation history\\\\\\\\n        bot_client.conversation_history = [\\\\\\\\n            {'role': 'user', 'content': 'Test message'}\\\\\\\\n        ]\\\\\\\\n        bot_client.response_count = 3\\\\\\\\n\\\\\\\\n        bot_client.reset_conversation()\\\\\\\\n\\\\\\\\n        assert bot_client.conversation_history == []\\\\\\\\n        assert bot_client.response_count == 0\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_warmup_success(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful bot warmup.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        result = await bot_client.warmup()\\\\\\\\n\\\\\\\\n        assert result == True\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_warmup_failure(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test failed bot warmup.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\\\\\n            side_effect=Exception(\\\\\\\\\\\\\\\"Connection failed\\\\\\\\\\\\\\\")\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        result = await bot_client.warmup()\\\\\\\\n\\\\\\\\n        assert result == False\\\\\\\\n\\\\\\\\n    def test_str_representation(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test string representation of bot.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        string_repr = str(bot_client)\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\" in string_repr\\\\\\\\n        assert \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\" in string_repr\\\\\\\\n        assert \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\" in string_repr\\\\\\\\n\\\\\\\\n    def test_repr_representation(self, bot_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test detailed string representation of bot.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repr_str = repr(bot_client)\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"BotClient\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n        assert \\\\\\\\\\\\\\\"name='TestBot'\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n        assert \\\\\\\\\\\\\\\"model='gpt-3.5-turbo'\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestOpenAIProvider:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for OpenAIProvider class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_openai_provider_initialization(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test OpenAI provider initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\")\\\\\\\\n        assert provider.api_key == \\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_generate_response_success(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\")\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\")\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\"}]\\\\\\\\n\\\\\\\\n        # Mock OpenAI client\\\\\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\\\\\n            mock_client = Mock()\\\\\\\\n            mock_openai.return_value = mock_client\\\\\\\\n\\\\\\\\n            # Mock response\\\\\\\\n            mock_response = Mock()\\\\\\\\n            mock_response.choices = [Mock()]\\\\\\\\n            mock_response.choices[0].message.content = \\\\\\\\\\\\\\\"Hello! How can I help?\\\\\\\\\\\\\\\"\\\\\\\\n            mock_client.chat.completions.create = AsyncMock(return_value=mock_response)\\\\\\\\n\\\\\\\\n            response = await provider.generate_response(messages, config)\\\\\\\\n\\\\\\\\n            assert response == \\\\\\\\\\\\\\\"Hello! How can I help?\\\\\\\\\\\\\\\"\\\\\\\\n            mock_client.chat.completions.create.assert_called_once()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_generate_response_error(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test response generation with error.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\")\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\")\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\"}]\\\\\\\\n\\\\\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\\\\\n            mock_client = Mock()\\\\\\\\n            mock_openai.return_value = mock_client\\\\\\\\n            mock_client.chat.completions.create = AsyncMock(\\\\\\\\n                side_effect=Exception(\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\")\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            with pytest.raises(Exception, match=\\\\\\\\\\\\\\\"OpenAI API error\\\\\\\\\\\\\\\"):\\\\\\\\n                await provider.generate_response(messages, config)\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestAnthropicProvider:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for AnthropicProvider class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_anthropic_provider_initialization(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test Anthropic provider initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\")\\\\\\\\n        assert provider.api_key == \\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_generate_response_success(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\")\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\")\\\\\\\\n        messages = [\\\\\\\\n            {\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"You are a helpful assistant\\\\\\\\\\\\\\\"},\\\\\\\\n            {\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\"}\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\\\\\n            mock_client = Mock()\\\\\\\\n            mock_anthropic.return_value = mock_client\\\\\\\\n\\\\\\\\n            # Mock response\\\\\\\\n            mock_response = Mock()\\\\\\\\n            mock_response.content = [Mock()]\\\\\\\\n            mock_response.content[0].text = \\\\\\\\\\\\\\\"Hello! How can I assist you?\\\\\\\\\\\\\\\"\\\\\\\\n            mock_client.messages.create = AsyncMock(return_value=mock_response)\\\\\\\\n\\\\\\\\n            response = await provider.generate_response(messages, config)\\\\\\\\n\\\\\\\\n            assert response == \\\\\\\\\\\\\\\"Hello! How can I assist you?\\\\\\\\\\\\\\\"\\\\\\\\n            mock_client.messages.create.assert_called_once()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_generate_response_error(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test response generation with error.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\")\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\")\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\"}]\\\\\\\\n\\\\\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\\\\\n            mock_client = Mock()\\\\\\\\n            mock_anthropic.return_value = mock_client\\\\\\\\n            mock_client.messages.create = AsyncMock(\\\\\\\\n                side_effect=Exception(\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\")\\\\\\\\n            )\\\\\\\\n\\\\\\\\n            with pytest.raises(Exception, match=\\\\\\\\\\\\\\\"Anthropic API error\\\\\\\\\\\\\\\"):\\\\\\\\n                await provider.generate_response(messages, config)\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_conversation_history_management(bot_client):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test conversation history management.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Add messages beyond the limit\\\\\\\\n    for i in range(25):\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\n\\\\\\\\n    # Should be limited to avoid memory issues\\\\\\\\n    assert len(bot_client.conversation_history) <= 20\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_bot_response_timing(bot_client, sample_messages):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test that response timing is tracked.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Simulate some delay\\\\\\\\n    async def delayed_response(*args):\\\\\\\\n        await asyncio.sleep(0.1)\\\\\\\\n        return \\\\\\\\\\\\\\\"Delayed response\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    bot_client.ai_provider.generate_response = delayed_response\\\\\\\\n\\\\\\\\n    await bot_client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n    assert bot_client.stats['average_response_time'] > 0\\\\\\\\n    assert bot_client.stats['total_response_time'] > 0\\\\\\\"\\\\n        },\\\\n        \\\\\\\"test_chat_log.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"tests/test_chat_log.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 15406,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTests for the ChatLog class.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport pytest\\\\\\\\nimport asyncio\\\\\\\\nimport json\\\\\\\\nimport time\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom unittest.mock import patch, mock_open\\\\\\\\nfrom app.chat_log import ChatLog, Message\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef chat_log():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a test chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return ChatLog(max_messages=100)\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef sample_messages():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return [\\\\\\\\n        Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello everyone!\\\\\\\\\\\\\\\", time.time(), 1),\\\\\\\\n        Message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hi Alice!\\\\\\\\\\\\\\\", time.time(), 2),\\\\\\\\n        Message(\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Welcome to the debate\\\\\\\\\\\\\\\", time.time(), 3, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestMessage:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for Message dataclass.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_message_creation(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test creating a message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        timestamp = time.time()\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\", timestamp, 1)\\\\\\\\n\\\\\\\\n        assert msg.sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg.content == \\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg.timestamp == timestamp\\\\\\\\n        assert msg.message_id == 1\\\\\\\\n        assert msg.message_type == \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg.metadata == {}\\\\\\\\n\\\\\\\\n    def test_message_with_metadata(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test message with metadata.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        metadata = {\\\\\\\\\\\\\\\"urgency\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"high\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"topic\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"AI\\\\\\\\\\\\\\\"}\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Important point\\\\\\\\\\\\\\\", time.time(), 2,\\\\\\\\n                      message_type=\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\", metadata=metadata)\\\\\\\\n\\\\\\\\n        assert msg.message_type == \\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg.metadata == metadata\\\\\\\\n\\\\\\\\n    def test_formatted_timestamp(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test formatted timestamp property.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        timestamp = 1640995200.0  # Known timestamp\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\", timestamp, 1)\\\\\\\\n\\\\\\\\n        formatted = msg.formatted_timestamp\\\\\\\\n        assert isinstance(formatted, str)\\\\\\\\n        assert \\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\" in formatted  # Should contain time separator\\\\\\\\n\\\\\\\\n    def test_to_dict(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test converting message to dictionary.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\", time.time(), 1)\\\\\\\\n        msg_dict = msg.to_dict()\\\\\\\\n\\\\\\\\n        assert isinstance(msg_dict, dict)\\\\\\\\n        assert msg_dict[\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg_dict[\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\"\\\\\\\\n        assert \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\" in msg_dict\\\\\\\\n        assert \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\" in msg_dict\\\\\\\\n\\\\\\\\n    def test_from_dict(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test creating message from dictionary.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        data = {\\\\\\\\n            \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": time.time(),\\\\\\\\n            \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 5,\\\\\\\\n            \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n            \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        msg = Message.from_dict(data)\\\\\\\\n\\\\\\\\n        assert msg.sender == \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg.content == \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\"\\\\\\\\n        assert msg.message_id == 5\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestChatLog:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for ChatLog class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_chat_log_initialization(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test chat log initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        chat_log = ChatLog(max_messages=50)\\\\\\\\n\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\n        assert chat_log.message_counter == 0\\\\\\\\n        assert chat_log.subscribers == []\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\"] == 0\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_add_message(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test adding a message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert isinstance(message, Message)\\\\\\\\n        assert message.sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n        assert message.content == \\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\"\\\\\\\\n        assert message.message_id == 1\\\\\\\\n        assert len(chat_log.messages) == 1\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\"] == 1\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"] == 1\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_add_multiple_messages(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test adding multiple messages.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"First message\\\\\\\\\\\\\\\")\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Second message\\\\\\\\\\\\\\\")\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Third message\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert len(chat_log.messages) == 3\\\\\\\\n        assert chat_log.message_counter == 3\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"] == 2\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"] == 1\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_message_ordering(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test that messages maintain chronological order.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        msg1 = await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"First\\\\\\\\\\\\\\\")\\\\\\\\n        await asyncio.sleep(0.01)  # Small delay\\\\\\\\n        msg2 = await chat_log.add_message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Second\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        messages = list(chat_log.messages)\\\\\\\\n        assert messages[0].message_id == 1\\\\\\\\n        assert messages[1].message_id == 2\\\\\\\\n        assert messages[0].timestamp < messages[1].timestamp\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_max_messages_limit(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test message limit enforcement.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        chat_log = ChatLog(max_messages=3)\\\\\\\\n\\\\\\\\n        # Add more messages than the limit\\\\\\\\n        for i in range(5):\\\\\\\\n            await chat_log.add_message(\\\\\\\\\\\\\\\"User\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert len(chat_log.messages) == 3  # Should be limited\\\\\\\\n\\\\\\\\n        # Check that oldest messages were removed\\\\\\\\n        messages = list(chat_log.messages)\\\\\\\\n        assert \\\\\\\\\\\\\\\"Message 2\\\\\\\\\\\\\\\" in messages[0].content\\\\\\\\n        assert \\\\\\\\\\\\\\\"Message 4\\\\\\\\\\\\\\\" in messages[2].content\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_subscription_system(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test message subscription system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        queue = chat_log.subscribe()\\\\\\\\n\\\\\\\\n        # Add a message\\\\\\\\n        message = await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Check that subscriber received the message\\\\\\\\n        received_message = await asyncio.wait_for(queue.get(), timeout=1.0)\\\\\\\\n        assert received_message.content == \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\"\\\\\\\\n        assert received_message.sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_multiple_subscribers(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test multiple subscribers.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        queue1 = chat_log.subscribe()\\\\\\\\n        queue2 = chat_log.subscribe()\\\\\\\\n\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Broadcast message\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Both subscribers should receive the message\\\\\\\\n        msg1 = await asyncio.wait_for(queue1.get(), timeout=1.0)\\\\\\\\n        msg2 = await asyncio.wait_for(queue2.get(), timeout=1.0)\\\\\\\\n\\\\\\\\n        assert msg1.content == msg2.content == \\\\\\\\\\\\\\\"Broadcast message\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_unsubscribe(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test unsubscribing from messages.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        queue = chat_log.subscribe()\\\\\\\\n        assert queue in chat_log.subscribers\\\\\\\\n\\\\\\\\n        chat_log.unsubscribe(queue)\\\\\\\\n        assert queue not in chat_log.subscribers\\\\\\\\n\\\\\\\\n    def test_get_messages_no_filter(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting all messages without filters.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Manually add messages to chat log\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\n        assert len(messages) == 3\\\\\\\\n        assert messages[0].sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_get_messages_with_limit(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting messages with limit.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        messages = chat_log.get_messages(limit=2)\\\\\\\\n        assert len(messages) == 2\\\\\\\\n        # Should get the last 2 messages\\\\\\\\n        assert messages[0].sender == \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"\\\\\\\\n        assert messages[1].sender == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_get_messages_by_sender(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test filtering messages by sender.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        alice_messages = chat_log.get_messages(sender=\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\")\\\\\\\\n        assert len(alice_messages) == 1\\\\\\\\n        assert alice_messages[0].sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_get_messages_by_type(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test filtering messages by type.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        moderator_messages = chat_log.get_messages(message_type=\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n        assert len(moderator_messages) == 1\\\\\\\\n        assert moderator_messages[0].message_type == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_get_messages_since_timestamp(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test filtering messages by timestamp.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Add messages with known timestamps\\\\\\\\n        old_time = time.time() - 100\\\\\\\\n        new_time = time.time()\\\\\\\\n\\\\\\\\n        chat_log.messages.append(Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Old\\\\\\\\\\\\\\\", old_time, 1))\\\\\\\\n        chat_log.messages.append(Message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"New\\\\\\\\\\\\\\\", new_time, 2))\\\\\\\\n\\\\\\\\n        cutoff = time.time() - 50\\\\\\\\n        recent_messages = chat_log.get_messages(since_timestamp=cutoff)\\\\\\\\n\\\\\\\\n        assert len(recent_messages) == 1\\\\\\\\n        assert recent_messages[0].content == \\\\\\\\\\\\\\\"New\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_get_recent_messages(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting recent messages.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        recent = chat_log.get_recent_messages(2)\\\\\\\\n        assert len(recent) == 2\\\\\\\\n        assert recent[-1].sender == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"  # Most recent\\\\\\\\n\\\\\\\\n    def test_get_conversation_context(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting conversation context for a participant.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Add various messages\\\\\\\\n        messages = [\\\\\\\\n            Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\", time.time(), 1),\\\\\\\\n            Message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hi Alice\\\\\\\\\\\\\\\", time.time(), 2),\\\\\\\\n            Message(\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Welcome everyone\\\\\\\\\\\\\\\", time.time(), 3, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"),\\\\\\\\n            Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Thanks!\\\\\\\\\\\\\\\", time.time(), 4),\\\\\\\\n            Message(\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Good luck\\\\\\\\\\\\\\\", time.time(), 5)\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n        for msg in messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        context = chat_log.get_conversation_context(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", context_length=3)\\\\\\\\n\\\\\\\\n        # Should include Alice's messages and moderator messages\\\\\\\\n        assert len(context) <= 3\\\\\\\\n        assert any(msg.sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\" for msg in context)\\\\\\\\n        assert any(msg.message_type == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\" for msg in context)\\\\\\\\n\\\\\\\\n    def test_search_messages(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test searching messages by content.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        # Case insensitive search\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\"hello\\\\\\\\\\\\\\\")\\\\\\\\n        assert len(results) == 1\\\\\\\\n        assert \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\" in results[0].content\\\\\\\\n\\\\\\\\n        # Case sensitive search\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\", case_sensitive=True)\\\\\\\\n        assert len(results) == 1\\\\\\\\n\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\"hello\\\\\\\\\\\\\\\", case_sensitive=True)\\\\\\\\n        assert len(results) == 0\\\\\\\\n\\\\\\\\n    def test_get_statistics(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting chat log statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n            chat_log.stats[\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\"] += 1\\\\\\\\n            sender = msg.sender\\\\\\\\n            chat_log.stats[\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\"][sender] = (\\\\\\\\n                    chat_log.stats[\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\"].get(sender, 0) + 1\\\\\\\\n            )\\\\\\\\n\\\\\\\\n        stats = chat_log.get_statistics()\\\\\\\\n\\\\\\\\n        assert stats[\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\"] == 3\\\\\\\\n        assert stats[\\\\\\\\\\\\\\\"unique_senders\\\\\\\\\\\\\\\"] == 2  # Alice, Bob, moderator\\\\\\\\n        assert \\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\" in stats\\\\\\\\n        assert \\\\\\\\\\\\\\\"messages_per_minute\\\\\\\\\\\\\\\" in stats\\\\\\\\n        assert \\\\\\\\\\\\\\\"session_duration_minutes\\\\\\\\\\\\\\\" in stats\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_save_transcript_json(self, chat_log, tmp_path):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test saving transcript in JSON format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\"transcript.json\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert output_file.exists()\\\\\\\\n\\\\\\\\n        with open(output_file, 'r') as f:\\\\\\\\n            data = json.load(f)\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\" in data\\\\\\\\n        assert \\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\" in data\\\\\\\\n        assert len(data[\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\"]) == 1\\\\\\\\n        assert data[\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_save_transcript_txt(self, chat_log, tmp_path):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test saving transcript in TXT format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\"transcript.txt\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert output_file.exists()\\\\\\\\n\\\\\\\\n        content = output_file.read_text()\\\\\\\\n        assert \\\\\\\\\\\\\\\"DEBATE TRANSCRIPT\\\\\\\\\\\\\\\" in content\\\\\\\\n        assert \\\\\\\\\\\\\\\"Alice: Test message\\\\\\\\\\\\\\\" in content\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_save_transcript_html(self, chat_log, tmp_path):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test saving transcript in HTML format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\")\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"System message\\\\\\\\\\\\\\\",\\\\\\\\n                                   message_type=\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\"transcript.html\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        assert output_file.exists()\\\\\\\\n\\\\\\\\n        content = output_file.read_text()\\\\\\\\n        assert \\\\\\\\\\\\\\\"<!DOCTYPE html>\\\\\\\\\\\\\\\" in content\\\\\\\\n        assert \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\" in content\\\\\\\\n        assert \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\" in content\\\\\\\\n        assert \\\\\\\\\\\\\\\"class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\" in content\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_save_transcript_invalid_format(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test saving transcript with invalid format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Unsupported format\\\\\\\\\\\\\\\"):\\\\\\\\n            await chat_log.save_transcript(\\\\\\\\\\\\\\\"test.xml\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"xml\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_load_transcript(self, chat_log, tmp_path):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test loading transcript from file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Save a transcript first\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Original message\\\\\\\\\\\\\\\")\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\"transcript.json\\\\\\\\\\\\\\\"\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Clear chat log and reload\\\\\\\\n        chat_log.clear()\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\n\\\\\\\\n        await chat_log.load_transcript(str(output_file))\\\\\\\\n\\\\\\\\n        assert len(chat_log.messages) == 1\\\\\\\\n        assert list(chat_log.messages)[0].content == \\\\\\\\\\\\\\\"Original message\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_load_transcript_file_not_found(self, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test loading transcript from non-existent file.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with pytest.raises(FileNotFoundError):\\\\\\\\n            await chat_log.load_transcript(\\\\\\\\\\\\\\\"nonexistent.json\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    def test_clear_chat_log(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test clearing the chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        chat_log.message_counter = 5\\\\\\\\n        chat_log.stats[\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\"] = 3\\\\\\\\n\\\\\\\\n        chat_log.clear()\\\\\\\\n\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\n        assert chat_log.message_counter == 0\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\"] == 0\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\"] == {}\\\\\\\\n\\\\\\\\n    def test_chat_log_len(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test chat log length.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        assert len(chat_log) == 0\\\\\\\\n\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        assert len(chat_log) == 3\\\\\\\\n\\\\\\\\n    def test_chat_log_iteration(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test iterating over chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        iterated_messages = list(chat_log)\\\\\\\\n        assert len(iterated_messages) == 3\\\\\\\\n        assert iterated_messages[0].sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_chat_log_indexing(self, chat_log, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test indexing chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        for msg in sample_messages:\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\n\\\\\\\\n        first_message = chat_log[0]\\\\\\\\n        assert first_message.sender == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        last_message = chat_log[-1]\\\\\\\\n        assert last_message.sender == \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\"\\\\\\\\n        \\\\\\\"\\\\n        },\\\\n        \\\\\\\"test_human_client.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"tests/test_human_client.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 20297,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTests for the HumanClient class.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport pytest\\\\\\\\nimport asyncio\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\nfrom app.human_client import HumanClient, CLIInterface, WebInterface, InterfaceConfig\\\\\\\\nfrom app.chat_log import Message\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef interface_config():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create test interface configuration.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return {\\\\\\\\n        'mode': 'cli',\\\\\\\\n        'enable_rich_formatting': False,  # Disable for testing\\\\\\\\n        'show_typing_indicators': True,\\\\\\\\n        'enable_reactions': True,\\\\\\\\n        'input_timeout': 60\\\\\\\\n    }\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef human_client(interface_config):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create test human client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return HumanClient(\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\", interface_config)\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef sample_messages():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return [\\\\\\\\n        Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"What's your opinion?\\\\\\\\\\\\\\\", 1640995200.0, 1),\\\\\\\\n        Message(\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"I think...\\\\\\\\\\\\\\\", 1640995210.0, 2),\\\\\\\\n        Message(\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Please respond\\\\\\\\\\\\\\\", 1640995220.0, 3, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestInterfaceConfig:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for InterfaceConfig dataclass.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_interface_config_defaults(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test interface config with default values.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig()\\\\\\\\n\\\\\\\\n        assert config.mode == \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.enable_rich_formatting == True\\\\\\\\n        assert config.show_typing_indicators == True\\\\\\\\n        assert config.enable_reactions == True\\\\\\\\n        assert config.input_timeout == 120\\\\\\\\n\\\\\\\\n    def test_interface_config_custom(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test interface config with custom values.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(\\\\\\\\n            mode=\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\",\\\\\\\\n            enable_rich_formatting=False,\\\\\\\\n            input_timeout=90\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        assert config.mode == \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\"\\\\\\\\n        assert config.enable_rich_formatting == False\\\\\\\\n        assert config.input_timeout == 90\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestCLIInterface:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for CLIInterface class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_cli_interface_initialization(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test CLI interface initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\n\\\\\\\\n        assert interface.config == config\\\\\\\\n        assert interface.rich_console is None  # Rich disabled\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_display_basic_message(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test displaying message with basic formatting.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\n\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\n\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\n            await interface.display_message(message)\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_display_moderator_message(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test displaying moderator message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\n\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Welcome!\\\\\\\\\\\\\\\", 1640995200.0, 1, \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\n            await interface.display_message(message)\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\n            # Should have moderator prefix\\\\\\\\n            args = mock_print.call_args[0]\\\\\\\\n            assert \\\\\\\\\\\\\\\"üé≠\\\\\\\\\\\\\\\" in args[0]\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_input_success(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful input retrieval.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\n\\\\\\\\n        with patch('builtins.input', return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\"):\\\\\\\\n            response = await interface.get_input(\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\", timeout=1)\\\\\\\\n            assert response == \\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_input_timeout(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test input timeout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\n\\\\\\\\n        # Mock input to simulate hanging\\\\\\\\n        async def slow_input():\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\n            return \\\\\\\\\\\\\\\"Too late\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        interface._get_user_input = slow_input\\\\\\\\n\\\\\\\\n        response = await interface.get_input(\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\", timeout=0.1)\\\\\\\\n        assert response == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"  # Should return empty string on timeout\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_show_notification(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test showing notifications.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\n\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\n            await interface.show_notification(\\\\\\\\\\\\\\\"Test notification\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\")\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\n            args = mock_print.call_args[0]\\\\\\\\n            assert \\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\" in args[0]\\\\\\\\n            assert \\\\\\\\\\\\\\\"Test notification\\\\\\\\\\\\\\\" in args[0]\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestWebInterface:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for WebInterface class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_web_interface_initialization(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test web interface initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\")\\\\\\\\n        interface = WebInterface(config)\\\\\\\\n\\\\\\\\n        assert interface.config == config\\\\\\\\n        assert interface.websocket is None\\\\\\\\n        assert interface.pending_responses == {}\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_display_message_no_websocket(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test displaying message without websocket connection.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\")\\\\\\\\n        interface = WebInterface(config)\\\\\\\\n\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\n\\\\\\\\n        # Should not raise an error even without websocket\\\\\\\\n        await interface.display_message(message)\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_input_no_websocket(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting input without websocket connection.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\")\\\\\\\\n        interface = WebInterface(config)\\\\\\\\n\\\\\\\\n        response = await interface.get_input(\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\")\\\\\\\\n        assert response == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"  # Should return empty string\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestHumanClient:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for HumanClient class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_human_client_initialization(self, interface_config):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test human client initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        client = HumanClient(\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\", interface_config)\\\\\\\\n\\\\\\\\n        assert client.name == \\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\"\\\\\\\\n        assert isinstance(client.interface, CLIInterface)\\\\\\\\n        assert client.is_active == True\\\\\\\\n        assert client.conversation_history == []\\\\\\\\n        assert client.stats['responses_given'] == 0\\\\\\\\n\\\\\\\\n    def test_human_client_web_mode(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test human client with web interface.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = {'mode': 'web'}\\\\\\\\n        client = HumanClient(\\\\\\\\\\\\\\\"WebHuman\\\\\\\\\\\\\\\", config)\\\\\\\\n\\\\\\\\n        assert isinstance(client.interface, WebInterface)\\\\\\\\n\\\\\\\\n    def test_human_client_unsupported_mode(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test human client with unsupported interface mode.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = {'mode': 'unsupported'}\\\\\\\\n\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Unsupported interface mode\\\\\\\\\\\\\\\"):\\\\\\\\n            HumanClient(\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\", config)\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_response_success(self, human_client, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful response retrieval.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Mock the interface get_input method\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"My response\\\\\\\\\\\\\\\")\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\n\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n        assert response == \\\\\\\\\\\\\\\"My response\\\\\\\\\\\\\\\"\\\\\\\\n        assert human_client.stats['responses_given'] == 1\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_response_timeout(self, human_client, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test response timeout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Mock timeout scenario\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\n\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n        assert response == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        assert human_client.stats['timeouts'] == 1\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_get_response_inactive(self, human_client, sample_messages):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test response when client is inactive.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        human_client.is_active = False\\\\\\\\n\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n        assert response == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_validate_response(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test response validation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Normal response\\\\\\\\n        response = human_client._validate_response(\\\\\\\\\\\\\\\"This is a good response\\\\\\\\\\\\\\\")\\\\\\\\n        assert response == \\\\\\\\\\\\\\\"This is a good response\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Very long response\\\\\\\\n        long_response = \\\\\\\\\\\\\\\"x\\\\\\\\\\\\\\\" * 600\\\\\\\\n        response = human_client._validate_response(long_response)\\\\\\\\n        assert len(response) <= 503  # 500 + \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\"\\\\\\\\n        assert response.endswith(\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Very short response\\\\\\\\n        short_response = human_client._validate_response(\\\\\\\\\\\\\\\"Yes\\\\\\\\\\\\\\\")\\\\\\\\n        assert \\\\\\\\\\\\\\\"[Note: Very short response]\\\\\\\\\\\\\\\" in short_response\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_receive_message(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test receiving a message.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Hello human\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\n\\\\\\\\n        await human_client.receive_message(message)\\\\\\\\n\\\\\\\\n        # Should be added to conversation history\\\\\\\\n        assert len(human_client.conversation_history) == 1\\\\\\\\n        assert human_client.conversation_history[0] == message\\\\\\\\n\\\\\\\\n        # Should display the message\\\\\\\\n        human_client.interface.display_message.assert_called_once_with(message)\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_receive_own_message(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test receiving own message (should be ignored).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"My own message\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\n\\\\\\\\n        await human_client.receive_message(message)\\\\\\\\n\\\\\\\\n        # Should not be added to history or displayed\\\\\\\\n        assert len(human_client.conversation_history) == 0\\\\\\\\n        human_client.interface.display_message.assert_not_called()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_conversation_history_limit(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test conversation history length limit.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\n\\\\\\\\n        # Add many messages\\\\\\\\n        for i in range(60):\\\\\\\\n            message = Message(f\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\n            await human_client.receive_message(message)\\\\\\\\n\\\\\\\\n        # Should be limited to 30 (as per implementation)\\\\\\\\n        assert len(human_client.conversation_history) == 30\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_handle_voting_success(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful voting.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n        # Mock interface methods\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n        human_client.interface.get_input = AsyncMock(side_effect=[\\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Good arguments\\\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\\n        result = await human_client.handle_voting(candidates, 60)\\\\\\\\n\\\\\\\\n        assert result['voted'] == True\\\\\\\\n        assert result['candidate'] == \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"  # Index 2-1 = 1 -> \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"\\\\\\\\n        assert result['justification'] == \\\\\\\\\\\\\\\"Good arguments\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_handle_voting_timeout(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting timeout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")  # Timeout\\\\\\\\n\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\n\\\\\\\\n        assert result['voted'] == False\\\\\\\\n        assert result['reason'] == 'timeout'\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_handle_voting_invalid_choice(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting with invalid choice.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"5\\\\\\\\\\\\\\\")  # Out of range\\\\\\\\n\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\n\\\\\\\\n        assert result['voted'] == False\\\\\\\\n        assert result['reason'] == 'invalid_choice'\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_handle_voting_invalid_format(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting with invalid input format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"not_a_number\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\n\\\\\\\\n        assert result['voted'] == False\\\\\\\\n        assert result['reason'] == 'invalid_format'\\\\\\\\n\\\\\\\\n    def test_update_stats_success(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test updating statistics on successful response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        human_client._update_stats(2.5, success=True)\\\\\\\\n\\\\\\\\n        assert human_client.stats['responses_given'] == 1\\\\\\\\n        assert human_client.stats['average_response_time'] == 2.5\\\\\\\\n        assert human_client.stats['total_response_time'] == 2.5\\\\\\\\n\\\\\\\\n    def test_update_stats_timeout(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test updating statistics on timeout.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        human_client._update_stats(5.0, success=False)\\\\\\\\n\\\\\\\\n        assert human_client.stats['timeouts'] == 1\\\\\\\\n        assert human_client.stats['responses_given'] == 0\\\\\\\\n\\\\\\\\n    def test_get_stats(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting human client statistics.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Add some test data\\\\\\\\n        human_client.stats['responses_given'] = 3\\\\\\\\n        human_client.stats['timeouts'] = 1\\\\\\\\n        human_client.stats['total_response_time'] = 15.0\\\\\\\\n        human_client._update_stats(0, success=True)  # Recalculate average\\\\\\\\n\\\\\\\\n        stats = human_client.get_stats()\\\\\\\\n\\\\\\\\n        assert stats['name'] == \\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\"\\\\\\\\n        assert stats['interface_mode'] == \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\"\\\\\\\\n        assert stats['responses_given'] == 3\\\\\\\\n        assert stats['timeouts'] == 1\\\\\\\\n        assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\\\\\n        assert 'average_response_time' in stats\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_set_active(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test setting client active/inactive status.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n\\\\\\\\n        # Set inactive\\\\\\\\n        await human_client.set_active(False)\\\\\\\\n        assert human_client.is_active == False\\\\\\\\n\\\\\\\\n        # Set active\\\\\\\\n        await human_client.set_active(True)\\\\\\\\n        assert human_client.is_active == True\\\\\\\\n\\\\\\\\n        # Should have called show_notification twice\\\\\\\\n        assert human_client.interface.show_notification.call_count == 2\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_show_help(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test showing help information.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\n\\\\\\\\n        await human_client.show_help()\\\\\\\\n\\\\\\\\n        human_client.interface.show_notification.assert_called_once()\\\\\\\\n        args = human_client.interface.show_notification.call_args[0]\\\\\\\\n        assert \\\\\\\\\\\\\\\"AI Jubilee Debate Help\\\\\\\\\\\\\\\" in args[0]\\\\\\\\n        assert \\\\\\\\\\\\\\\"COMMANDS:\\\\\\\\\\\\\\\" in args[0]\\\\\\\\n\\\\\\\\n    def test_str_representation(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test string representation of human client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        string_repr = str(human_client)\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\" in string_repr\\\\\\\\n        assert \\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\" in string_repr\\\\\\\\n\\\\\\\\n    def test_repr_representation(self, human_client):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test detailed string representation of human client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        repr_str = repr(human_client)\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"HumanClient\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n        assert \\\\\\\\\\\\\\\"name='TestHuman'\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n        assert \\\\\\\\\\\\\\\"mode='cli'\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n        assert \\\\\\\\\\\\\\\"active=True\\\\\\\\\\\\\\\" in repr_str\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_show_context_integration(human_client, sample_messages):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test showing context to human before response.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    human_client.interface.show_notification = AsyncMock()\\\\\\\\n    human_client.interface.display_message = AsyncMock()\\\\\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    await human_client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n\\\\\\\\n    # Should show context notification\\\\\\\\n    notification_calls = human_client.interface.show_notification.call_args_list\\\\\\\\n    assert any(\\\\\\\\\\\\\\\"Recent messages\\\\\\\\\\\\\\\" in str(call) for call in notification_calls)\\\\\\\\n\\\\\\\\n    # Should display recent messages\\\\\\\\n    assert human_client.interface.display_message.call_count >= 1\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_human_response_validation_edge_cases(human_client):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test edge cases in response validation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Empty response\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n    assert result == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    # Whitespace only\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\t   \\\\\\\\\\\\\\\")\\\\\\\\n    assert result == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    # Response with just newlines\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\")\\\\\\\\n    assert result == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    # Very short meaningful response\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\"No.\\\\\\\\\\\\\\\")\\\\\\\\n    assert \\\\\\\\\\\\\\\"[Note: Very short response]\\\\\\\\\\\\\\\" in result\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_human_client_error_resilience(human_client, sample_messages):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test human client resilience to interface errors.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Mock interface to raise errors\\\\\\\\n    human_client.interface.display_message = AsyncMock(side_effect=Exception(\\\\\\\\\\\\\\\"Interface error\\\\\\\\\\\\\\\"))\\\\\\\\n    human_client.interface.show_notification = AsyncMock()\\\\\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Should not crash despite interface errors\\\\\\\\n    response = await human_client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\n    assert response == \\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_human_client_concurrent_operations(human_client):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test concurrent operations on human client.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    human_client.interface.display_message = AsyncMock()\\\\\\\\n\\\\\\\\n    # Simulate concurrent message receiving\\\\\\\\n    tasks = []\\\\\\\\n    for i in range(10):\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\n        tasks.append(human_client.receive_message(message))\\\\\\\\n\\\\\\\\n    await asyncio.gather(*tasks)\\\\\\\\n\\\\\\\\n    # All messages should be processed\\\\\\\\n    assert len(human_client.conversation_history) == 10\\\\\\\\n\\\\\\\\n\\\\\\\\ndef test_human_client_stats_calculation(human_client):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test statistics calculation accuracy.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Simulate various response scenarios\\\\\\\\n    human_client._update_stats(2.0, success=True)\\\\\\\\n    human_client._update_stats(3.0, success=True)\\\\\\\\n    human_client._update_stats(1.5, success=False)  # Timeout\\\\\\\\n    human_client._update_stats(2.5, success=True)\\\\\\\\n\\\\\\\\n    stats = human_client.get_stats()\\\\\\\\n\\\\\\\\n    assert stats['responses_given'] == 3\\\\\\\\n    assert stats['timeouts'] == 1\\\\\\\\n    assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\\\\\n    assert abs(stats['average_response_time'] - 2.5) < 0.1  # (2.0+3.0+2.5)/3\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_voting_with_web_interface():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting behavior with web interface.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    config = {'mode': 'web'}\\\\\\\\n    client = HumanClient(\\\\\\\\\\\\\\\"WebUser\\\\\\\\\\\\\\\", config)\\\\\\\\n    candidates = [\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n    # Web interface should handle justification differently\\\\\\\\n    client.interface.show_notification = AsyncMock()\\\\\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    result = await client.handle_voting(candidates, 60)\\\\\\\\n\\\\\\\\n    assert result['voted'] == True\\\\\\\\n    assert result['candidate'] == \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\"\\\\\\\\n    assert result['justification'] == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"  # No justification prompt for web\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_human_client_lifecycle():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test complete human client lifecycle.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    config = {'mode': 'cli', 'enable_rich_formatting': False}\\\\\\\\n    client = HumanClient(\\\\\\\\\\\\\\\"LifecycleTest\\\\\\\\\\\\\\\", config)\\\\\\\\n\\\\\\\\n    # Initial state\\\\\\\\n    assert client.is_active == True\\\\\\\\n    assert len(client.conversation_history) == 0\\\\\\\\n\\\\\\\\n    # Mock interface for testing\\\\\\\\n    client.interface.display_message = AsyncMock()\\\\\\\\n    client.interface.show_notification = AsyncMock()\\\\\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Receive some messages\\\\\\\\n    for i in range(3):\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\n        await client.receive_message(message)\\\\\\\\n\\\\\\\\n    assert len(client.conversation_history) == 3\\\\\\\\n\\\\\\\\n    # Participate in debate\\\\\\\\n    response = await client.get_response(\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\", [])\\\\\\\\n    assert response == \\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\"\\\\\\\\n    assert client.stats['responses_given'] == 1\\\\\\\\n\\\\\\\\n    # Deactivate\\\\\\\\n    await client.set_active(False)\\\\\\\\n    assert client.is_active == False\\\\\\\\n\\\\\\\\n    # Should not respond when inactive\\\\\\\\n    response = await client.get_response(\\\\\\\\\\\\\\\"Another topic\\\\\\\\\\\\\\\", [])\\\\\\\\n    assert response == \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\"\\\\n        },\\\\n        \\\\\\\"test_moderator.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"tests/test_moderator.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 9146,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTests for the Moderator class.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport pytest\\\\\\\\nimport asyncio\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\nfrom app.moderator import Moderator, DebatePhase, DebateState\\\\\\\\nfrom app.chat_log import ChatLog\\\\\\\\nfrom app.voting import VotingSystem\\\\\\\\nfrom app.bot_client import BotClient\\\\\\\\nfrom app.human_client import HumanClient\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef chat_log():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a test chat log.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return ChatLog()\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef voting_system():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a test voting system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    config = {'enabled': True, 'voting_duration': 60}\\\\\\\\n    return VotingSystem(config)\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef mock_participants():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create mock participants.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    bot = Mock(spec=BotClient)\\\\\\\\n    bot.name = \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\"\\\\\\\\n    bot.get_response = AsyncMock(return_value=\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\")\\\\\\\\n    bot.receive_message = AsyncMock()\\\\\\\\n\\\\\\\\n    human = Mock(spec=HumanClient)\\\\\\\\n    human.name = \\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\"\\\\\\\\n    human.get_response = AsyncMock(return_value=\\\\\\\\\\\\\\\"Human response\\\\\\\\\\\\\\\")\\\\\\\\n    human.receive_message = AsyncMock()\\\\\\\\n\\\\\\\\n    return [bot, human]\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef moderator(chat_log, voting_system, mock_participants):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create a test moderator.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    config = {\\\\\\\\n        'opening_statement_time': 30,\\\\\\\\n        'discussion_time': 60,\\\\\\\\n        'closing_statement_time': 30,\\\\\\\\n        'response_time': 20,\\\\\\\\n        'max_response_time': 60,\\\\\\\\n        'warning_time': 45\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    return Moderator(\\\\\\\\n        topic=\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\",\\\\\\\\n        participants=mock_participants,\\\\\\\\n        chat_log=chat_log,\\\\\\\\n        voting_system=voting_system,\\\\\\\\n        config=config\\\\\\\\n    )\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestModerator:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for Moderator class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_moderator_initialization(self, moderator):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test moderator initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        assert moderator.topic == \\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\"\\\\\\\\n        assert len(moderator.participants) == 2\\\\\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\n        assert \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\" in moderator.participants\\\\\\\\n        assert \\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\" in moderator.participants\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_introduction_phase(self, moderator, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test introduction phase.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await moderator._introduction_phase()\\\\\\\\n\\\\\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\n\\\\\\\\n        # Check that introduction message was logged\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\n        assert any(\\\\\\\\\\\\\\\"Welcome to AI Jubilee Debate\\\\\\\\\\\\\\\" in msg.content for msg in messages)\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_opening_statements_phase(self, moderator, mock_participants):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test opening statements phase.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await moderator._opening_statements_phase()\\\\\\\\n\\\\\\\\n        assert moderator.state.phase == DebatePhase.OPENING_STATEMENTS\\\\\\\\n\\\\\\\\n        # Verify each participant was asked for response\\\\\\\\n        for participant in mock_participants:\\\\\\\\n            participant.get_response.assert_called()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_give_turn_success(self, moderator, mock_participants):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test successful turn giving.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        participant = mock_participants[0]\\\\\\\\n        participant.get_response.return_value = \\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        await moderator._give_turn(participant.name, 30, \\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        participant.get_response.assert_called_once()\\\\\\\\n        assert moderator.state.current_speaker is None  # Reset after turn\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_give_turn_timeout(self, moderator, mock_participants):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test turn timeout handling.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        participant = mock_participants[0]\\\\\\\\n\\\\\\\\n        # Simulate timeout by making get_response take too long\\\\\\\\n        async def slow_response(*args):\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\n            return \\\\\\\\\\\\\\\"Too late\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        participant.get_response = slow_response\\\\\\\\n\\\\\\\\n        # Use very short timeout for testing\\\\\\\\n        await moderator._give_turn(participant.name, 0.1, \\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Should have issued a warning\\\\\\\\n        assert moderator.state.warnings_issued.get(participant.name, 0) >= 1\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_voting_phase_enabled(self, moderator):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting phase when voting is enabled.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        moderator.voting_system.enabled = True\\\\\\\\n\\\\\\\\n        with patch.object(moderator.voting_system, 'start_voting') as mock_start:\\\\\\\\n            with patch.object(moderator.voting_system, 'end_voting') as mock_end:\\\\\\\\n                mock_end.return_value = {\\\\\\\\n                    'winner': 'TestBot',\\\\\\\\n                    'vote_counts': {'TestBot': 2, 'TestHuman': 1}\\\\\\\\n                }\\\\\\\\n\\\\\\\\n                results = await moderator._voting_phase()\\\\\\\\n\\\\\\\\n                mock_start.assert_called_once()\\\\\\\\n                mock_end.assert_called_once()\\\\\\\\n                assert results['winner'] == 'TestBot'\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_voting_phase_disabled(self, moderator):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting phase when voting is disabled.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        moderator.voting_system.enabled = False\\\\\\\\n\\\\\\\\n        results = await moderator._voting_phase()\\\\\\\\n\\\\\\\\n        assert results == {}\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_broadcast_message(self, moderator, mock_participants, chat_log):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test message broadcasting.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await moderator._broadcast_message(\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Check message was logged\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\n        assert any(msg.content == \\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\" for msg in messages)\\\\\\\\n\\\\\\\\n        # Check all participants received message\\\\\\\\n        for participant in mock_participants:\\\\\\\\n            participant.receive_message.assert_called()\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_handle_timeout_warnings(self, moderator):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test timeout warning system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        participant_name = \\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # First timeout\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 1\\\\\\\\n\\\\\\\\n        # Second timeout\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 2\\\\\\\\n\\\\\\\\n        # Third timeout (should trigger mute)\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 3\\\\\\\\n\\\\\\\\n    def test_get_state(self, moderator):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test state retrieval.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        state = moderator.get_state()\\\\\\\\n\\\\\\\\n        assert isinstance(state, DebateState)\\\\\\\\n        assert state.phase == DebatePhase.INTRODUCTION\\\\\\\\n        assert state.current_speaker is None\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_full_debate_flow(self, moderator, mock_participants):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test complete debate flow.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Mock voting system methods\\\\\\\\n        moderator.voting_system.start_voting = AsyncMock()\\\\\\\\n        moderator.voting_system.end_voting = AsyncMock(return_value={\\\\\\\\n            'winner': 'TestBot',\\\\\\\\n            'vote_counts': {'TestBot': 1, 'TestHuman': 0}\\\\\\\\n        })\\\\\\\\n\\\\\\\\n        # Run complete debate with short timeouts for testing\\\\\\\\n        moderator.phase_times[DebatePhase.DISCUSSION] = 1  # 1 second\\\\\\\\n\\\\\\\\n        results = await moderator.run_debate()\\\\\\\\n\\\\\\\\n        # Verify all phases completed\\\\\\\\n        assert moderator.state.phase == DebatePhase.FINISHED\\\\\\\\n        assert 'winner' in results\\\\\\\\n\\\\\\\\n        # Verify participants were called\\\\\\\\n        for participant in mock_participants:\\\\\\\\n            assert participant.get_response.call_count > 0\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestDebateState:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for DebateState dataclass.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_debate_state_initialization(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test DebateState initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        state = DebateState(DebatePhase.DISCUSSION)\\\\\\\\n\\\\\\\\n        assert state.phase == DebatePhase.DISCUSSION\\\\\\\\n        assert state.current_speaker is None\\\\\\\\n        assert state.time_remaining == 0\\\\\\\\n        assert state.turn_order == []\\\\\\\\n        assert state.warnings_issued == {}\\\\\\\\n\\\\\\\\n    def test_debate_state_with_values(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test DebateState with custom values.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        turn_order = [\\\\\\\\\\\\\\\"Bot1\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"Bot2\\\\\\\\\\\\\\\"]\\\\\\\\n        warnings = {\\\\\\\\\\\\\\\"Bot1\\\\\\\\\\\\\\\": 1}\\\\\\\\n\\\\\\\\n        state = DebateState(\\\\\\\\n            phase=DebatePhase.VOTING,\\\\\\\\n            current_speaker=\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\",\\\\\\\\n            time_remaining=120,\\\\\\\\n            turn_order=turn_order,\\\\\\\\n            warnings_issued=warnings\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        assert state.phase == DebatePhase.VOTING\\\\\\\\n        assert state.current_speaker == \\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\"\\\\\\\\n        assert state.time_remaining == 120\\\\\\\\n        assert state.turn_order == turn_order\\\\\\\\n        assert state.warnings_issued == warnings\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_moderator_error_handling(moderator, mock_participants):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test moderator error handling.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Make participant raise an error\\\\\\\\n    mock_participants[0].get_response.side_effect = Exception(\\\\\\\\\\\\\\\"Test error\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Should not crash the debate\\\\\\\\n    await moderator._give_turn(mock_participants[0].name, 30, \\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Moderator should continue functioning\\\\\\\\n    assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.mark.asyncio\\\\\\\\nasync def test_moderator_message_validation(moderator):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test message content validation.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    long_message = \\\\\\\\\\\\\\\"x\\\\\\\\\\\\\\\" * 1000  # Very long message\\\\\\\\n\\\\\\\\n    await moderator._process_response(\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\", long_message)\\\\\\\\n\\\\\\\\n    # Should have been truncated\\\\\\\\n    messages = moderator.chat_log.get_messages()\\\\\\\\n    last_message = messages[-1]\\\\\\\\n    assert len(last_message.content) <= 503  # 500 + \\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\"\\\\\\\"\\\\n        },\\\\n        \\\\\\\"test_voting.py\\\\\\\": {\\\\n          \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n          \\\\\\\"path\\\\\\\": \\\\\\\"tests/test_voting.py\\\\\\\",\\\\n          \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n          \\\\\\\"size\\\\\\\": 16340,\\\\n          \\\\\\\"content\\\\\\\": \\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nTests for the VotingSystem class.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport pytest\\\\\\\\nimport asyncio\\\\\\\\nimport time\\\\\\\\nfrom app.voting import VotingSystem, Vote, VotingResults\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef voting_config():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create test voting configuration.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return {\\\\\\\\n        'enabled': True,\\\\\\\\n        'voting_duration': 60,\\\\\\\\n        'allow_participant_voting': True,\\\\\\\\n        'require_justification': False,\\\\\\\\n        'anonymous_votes': False\\\\\\\\n    }\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef voting_system(voting_config):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create test voting system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    return VotingSystem(voting_config)\\\\\\\\n\\\\\\\\n\\\\\\\\n@pytest.fixture\\\\\\\\ndef active_voting_system(voting_system):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create and start a voting session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    asyncio.create_task(voting_system.start_voting(['Alice', 'Bob', 'Charlie'], 30))\\\\\\\\n    return voting_system\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestVotingSystem:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for VotingSystem class.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_voting_system_initialization(self, voting_config):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting system initialization.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        vs = VotingSystem(voting_config)\\\\\\\\n\\\\\\\\n        assert vs.enabled == True\\\\\\\\n        assert vs.voting_duration == 60\\\\\\\\n        assert vs.allow_participant_voting == True\\\\\\\\n        assert vs.require_justification == False\\\\\\\\n        assert vs.anonymous_votes == False\\\\\\\\n        assert vs.is_active == False\\\\\\\\n        assert vs.candidates == []\\\\\\\\n        assert vs.votes == {}\\\\\\\\n\\\\\\\\n    def test_disabled_voting_system(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test disabled voting system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = {'enabled': False}\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\n\\\\\\\\n        assert vs.enabled == False\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_start_voting_session(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test starting a voting session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        candidates = ['Alice', 'Bob', 'Charlie']\\\\\\\\n\\\\\\\\n        await voting_system.start_voting(candidates, 30)\\\\\\\\n\\\\\\\\n        assert voting_system.is_active == True\\\\\\\\n        assert voting_system.candidates == candidates\\\\\\\\n        assert voting_system.eligible_voters == candidates  # allow_participant_voting=True\\\\\\\\n        assert voting_system.start_time is not None\\\\\\\\n        assert voting_system.end_time is not None\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_start_voting_disabled_system(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test starting voting on disabled system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = {'enabled': False}\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\n\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Voting system is disabled\\\\\\\\\\\\\\\"):\\\\\\\\n            await vs.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_start_voting_already_active(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test starting voting when already active.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Voting session already active\\\\\\\\\\\\\\\"):\\\\\\\\n            await voting_system.start_voting(['Charlie', 'Dave'])\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_cast_valid_vote(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test casting a valid vote.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\\\\\n\\\\\\\\n        result = await voting_system.cast_vote('voter1', 'Alice', 'Great arguments')\\\\\\\\n\\\\\\\\n        assert result == True\\\\\\\\n        assert 'voter1' in voting_system.votes\\\\\\\\n        assert voting_system.votes['voter1'].candidate == 'Alice'\\\\\\\\n        assert voting_system.votes['voter1'].justification == 'Great arguments'\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_cast_vote_no_active_session(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test casting vote with no active session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\"):\\\\\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_cast_vote_invalid_candidate(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test casting vote for invalid candidate.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Invalid candidate\\\\\\\\\\\\\\\"):\\\\\\\\n            await voting_system.cast_vote('voter1', 'Charlie')\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_cast_vote_requires_justification(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting system that requires justification.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = {\\\\\\\\n            'enabled': True,\\\\\\\\n            'require_justification': True,\\\\\\\\n            'allow_participant_voting': True\\\\\\\\n        }\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        # Vote without justification should fail\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Vote justification is required\\\\\\\\\\\\\\\"):\\\\\\\\n            await vs.cast_vote('voter1', 'Alice')\\\\\\\\n\\\\\\\\n        # Vote with justification should succeed\\\\\\\\n        result = await vs.cast_vote('voter1', 'Alice', 'Good points')\\\\\\\\n        assert result == True\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_cast_vote_overwrite(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test that new vote overwrites previous vote.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.cast_vote('voter1', 'Bob')  # Change vote\\\\\\\\n\\\\\\\\n        assert voting_system.votes['voter1'].candidate == 'Bob'\\\\\\\\n        assert len(voting_system.votes) == 1  # Only one vote per voter\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test self-voting when allowed.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test self-voting when allowed.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        # Should allow participant to vote for themselves\\\\\\\\n        result = await voting_system.cast_vote('Alice', 'Alice')\\\\\\\\n        assert result == True\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_self_voting_disallowed(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test self-voting when disallowed.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        config = {\\\\\\\\n            'enabled': True,\\\\\\\\n            'allow_participant_voting': False\\\\\\\\n        }\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Self-voting is not allowed\\\\\\\\\\\\\\\"):\\\\\\\\n            await vs.cast_vote('Alice', 'Alice')\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_end_voting_session(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test ending a voting session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\\\\\n\\\\\\\\n        # Cast some votes\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.cast_vote('voter2', 'Alice')\\\\\\\\n        await voting_system.cast_vote('voter3', 'Bob')\\\\\\\\n\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        assert isinstance(results, VotingResults)\\\\\\\\n        assert results.winner == 'Alice'  # Most votes\\\\\\\\n        assert results.vote_counts['Alice'] == 2\\\\\\\\n        assert results.vote_counts['Bob'] == 1\\\\\\\\n        assert results.total_votes == 3\\\\\\\\n        assert voting_system.is_active == False\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_end_voting_tie(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test ending voting with a tie.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.cast_vote('voter2', 'Bob')\\\\\\\\n\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        assert \\\\\\\\\\\\\\\"TIE:\\\\\\\\\\\\\\\" in results.winner\\\\\\\\n        assert \\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\" in results.winner\\\\\\\\n        assert \\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\" in results.winner\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_end_voting_no_votes(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test ending voting with no votes cast.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        assert results.winner is None\\\\\\\\n        assert results.total_votes == 0\\\\\\\\n        assert results.vote_counts == {}\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_end_voting_not_active(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test ending voting when not active.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\"):\\\\\\\\n            await voting_system.end_voting()\\\\\\\\n\\\\\\\\n    def test_get_vote_summary(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test getting vote summary during active session.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # No active session\\\\\\\\n        summary = voting_system.get_vote_summary()\\\\\\\\n        assert summary == {}\\\\\\\\n\\\\\\\\n        # With active session\\\\\\\\n        asyncio.create_task(voting_system.start_voting(['Alice', 'Bob'], 60))\\\\\\\\n        summary = voting_system.get_vote_summary()\\\\\\\\n\\\\\\\\n        assert 'candidates' in summary\\\\\\\\n        assert 'vote_counts' in summary\\\\\\\\n        assert 'total_votes' in summary\\\\\\\\n        assert 'time_remaining' in summary\\\\\\\\n        assert 'is_active' in summary\\\\\\\\n\\\\\\\\n    def test_add_remove_eligible_voters(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test adding and removing eligible voters.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        voting_system.add_eligible_voter('voter1')\\\\\\\\n        assert 'voter1' in voting_system.eligible_voters\\\\\\\\n\\\\\\\\n        voting_system.add_eligible_voter('voter2')\\\\\\\\n        assert len(voting_system.eligible_voters) == 2\\\\\\\\n\\\\\\\\n        voting_system.remove_eligible_voter('voter1')\\\\\\\\n        assert 'voter1' not in voting_system.eligible_voters\\\\\\\\n        assert len(voting_system.eligible_voters) == 1\\\\\\\\n\\\\\\\\n    def test_is_eligible_voter(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voter eligibility checking.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Empty eligible voters list means open voting\\\\\\\\n        assert voting_system._is_eligible_voter('anyone') == True\\\\\\\\n\\\\\\\\n        # With specific eligible voters\\\\\\\\n        voting_system.add_eligible_voter('voter1')\\\\\\\\n        assert voting_system._is_eligible_voter('voter1') == True\\\\\\\\n        assert voting_system._is_eligible_voter('voter2') == False\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_vote_history(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test vote history tracking.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # First session\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        # Second session\\\\\\\\n        await voting_system.start_voting(['Charlie', 'Dave'])\\\\\\\\n        await voting_system.cast_vote('voter1', 'Charlie')\\\\\\\\n        await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        assert len(voting_system.vote_history) == 2\\\\\\\\n\\\\\\\\n        # Test voter history\\\\\\\\n        voter_history = voting_system.get_voter_history('voter1')\\\\\\\\n        assert len(voter_history) == 2\\\\\\\\n        assert voter_history[0].candidate == 'Alice'\\\\\\\\n        assert voter_history[1].candidate == 'Charlie'\\\\\\\\n\\\\\\\\n    def test_candidate_performance(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test candidate performance tracking.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Add some mock history\\\\\\\\n        voting_system.vote_history = [\\\\\\\\n            {\\\\\\\\n                'candidates': ['Alice', 'Bob'],\\\\\\\\n                'results': VotingResults(\\\\\\\\n                    winner='Alice',\\\\\\\\n                    vote_counts={'Alice': 2, 'Bob': 1},\\\\\\\\n                    total_votes=3,\\\\\\\\n                    votes_by_voter={},\\\\\\\\n                    voting_duration=60,\\\\\\\\n                    participation_rate=1.0\\\\\\\\n                )\\\\\\\\n            },\\\\\\\\n            {\\\\\\\\n                'candidates': ['Alice', 'Charlie'],\\\\\\\\n                'results': VotingResults(\\\\\\\\n                    winner='Charlie',\\\\\\\\n                    vote_counts={'Alice': 1, 'Charlie': 2},\\\\\\\\n                    total_votes=3,\\\\\\\\n                    votes_by_voter={},\\\\\\\\n                    voting_duration=60,\\\\\\\\n                    participation_rate=1.0\\\\\\\\n                )\\\\\\\\n            }\\\\\\\\n        ]\\\\\\\\n\\\\\\\\n        performance = voting_system.get_candidate_performance('Alice')\\\\\\\\n\\\\\\\\n        assert performance['wins'] == 1\\\\\\\\n        assert performance['participations'] == 2\\\\\\\\n        assert performance['total_votes'] == 3\\\\\\\\n        assert performance['win_rate'] == 0.5\\\\\\\\n        assert performance['avg_votes'] == 1.5\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_export_results_json(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test exporting results in JSON format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Create some history\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        json_output = await voting_system.export_results('json')\\\\\\\\n\\\\\\\\n        assert isinstance(json_output, str)\\\\\\\\n        assert 'Alice' in json_output\\\\\\\\n        assert 'vote_counts' in json_output\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_export_results_csv(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test exporting results in CSV format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        csv_output = await voting_system.export_results('csv')\\\\\\\\n\\\\\\\\n        assert isinstance(csv_output, str)\\\\\\\\n        assert 'Session,Timestamp,Candidate,Votes,Winner' in csv_output\\\\\\\\n        assert 'Alice' in csv_output\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_export_results_txt(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test exporting results in TXT format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n        await voting_system.end_voting()\\\\\\\\n\\\\\\\\n        txt_output = await voting_system.export_results('txt')\\\\\\\\n\\\\\\\\n        assert isinstance(txt_output, str)\\\\\\\\n        assert 'VOTING HISTORY REPORT' in txt_output\\\\\\\\n        assert 'Alice' in txt_output\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_export_unsupported_format(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test exporting with unsupported format.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Unsupported format\\\\\\\\\\\\\\\"):\\\\\\\\n            await voting_system.export_results('xml')\\\\\\\\n\\\\\\\\n    def test_reset_voting_system(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test resetting the voting system.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Set up some state\\\\\\\\n        voting_system.candidates = ['Alice', 'Bob']\\\\\\\\n        voting_system.votes = {'voter1': Vote('voter1', 'Alice')}\\\\\\\\n        voting_system.is_active = True\\\\\\\\n\\\\\\\\n        voting_system.reset()\\\\\\\\n\\\\\\\\n        assert voting_system.is_active == False\\\\\\\\n        assert voting_system.candidates == []\\\\\\\\n        assert voting_system.votes == {}\\\\\\\\n        assert voting_system.start_time is None\\\\\\\\n        assert voting_system.end_time is None\\\\\\\\n\\\\\\\\n    def test_voting_system_status(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test voting system status property.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        status = voting_system.status\\\\\\\\n\\\\\\\\n        assert 'enabled' in status\\\\\\\\n        assert 'is_active' in status\\\\\\\\n        assert 'candidates' in status\\\\\\\\n        assert 'eligible_voters' in status\\\\\\\\n        assert 'votes_cast' in status\\\\\\\\n        assert 'time_remaining' in status\\\\\\\\n        assert 'sessions_completed' in status\\\\\\\\n\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\n    async def test_vote_after_time_expires(self, voting_system):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test casting vote after voting time expires.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        # Start voting with very short duration\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'], 0.1)\\\\\\\\n\\\\\\\\n        # Wait for voting to expire\\\\\\\\n        await asyncio.sleep(0.2)\\\\\\\\n\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\"Voting period has ended\\\\\\\\\\\\\\\"):\\\\\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestVote:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for Vote dataclass.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_vote_creation(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test creating a vote.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        vote = Vote('voter1', 'Alice', 'Great arguments')\\\\\\\\n\\\\\\\\n        assert vote.voter_id == 'voter1'\\\\\\\\n        assert vote.candidate == 'Alice'\\\\\\\\n        assert vote.justification == 'Great arguments'\\\\\\\\n        assert vote.anonymous == False\\\\\\\\n        assert isinstance(vote.timestamp, float)\\\\\\\\n\\\\\\\\n    def test_vote_anonymous(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test creating anonymous vote.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        vote = Vote('voter1', 'Alice', anonymous=True)\\\\\\\\n\\\\\\\\n        assert vote.anonymous == True\\\\\\\\n\\\\\\\\n    def test_vote_no_justification(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test vote without justification.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        vote = Vote('voter1', 'Alice')\\\\\\\\n\\\\\\\\n        assert vote.justification is None\\\\\\\\n\\\\\\\\n\\\\\\\\nclass TestVotingResults:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test suite for VotingResults dataclass.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    def test_voting_results_creation(self):\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Test creating voting results.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        vote_counts = {'Alice': 2, 'Bob': 1}\\\\\\\\n        votes_by_voter = {\\\\\\\\n            'voter1': Vote('voter1', 'Alice'),\\\\\\\\n            'voter2': Vote('voter2', 'Alice'),\\\\\\\\n            'voter3': Vote('voter3', 'Bob')\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        results = VotingResults(\\\\\\\\n            winner='Alice',\\\\\\\\n            vote_counts=vote_counts,\\\\\\\\n            total_votes=3,\\\\\\\\n            votes_by_voter=votes_by_voter,\\\\\\\\n            voting_duration=60.0,\\\\\\\\n            participation_rate=1.0\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        assert results.winner == 'Alice'\\\\\\\\n        assert results.vote_counts == vote_counts\\\\\\\\n        assert results.total_votes == 3\\\\\\\\n        assert len(results.votes_by_voter) == 3\\\\\\\\n        assert results.voting_duration == 60.0\\\\\\\\n        assert results.participation_rate == 1.0\\\\\\\"\\\\n        }\\\\n      }\\\\n    },\\\\n    \\\\\\\"config.yaml\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"config.yaml\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".yaml\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 3332,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"# AI Jubilee Debate Configuration\\\\\\\\n\\\\\\\\n# Debate Settings\\\\\\\\ndebate:\\\\\\\\n  default_topic: \\\\\\\\\\\\\\\"The role of artificial intelligence in modern society\\\\\\\\\\\\\\\"\\\\\\\\n  max_participants: 4\\\\\\\\n  time_limit_minutes: 10\\\\\\\\n  opening_statement_time: 120  # seconds\\\\\\\\n  response_time: 60  # seconds\\\\\\\\n  closing_statement_time: 90  # seconds\\\\\\\\n\\\\\\\\n  # Debate mode: \\\\\\\\\\\\\\\"sequential\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\"\\\\\\\\n  mode: \\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\"  # AUTONOMOUS MODE: Bots monitor and decide when to speak!\\\\\\\\n\\\\\\\\n  # Autonomous mode settings\\\\\\\\n  min_bot_cooldown: 15          # Minimum seconds between bot responses\\\\\\\\n  max_bot_cooldown: 45          # Maximum cooldown for very active bots\\\\\\\\n  message_check_interval: 5     # How often bots check for new messages\\\\\\\\n  silence_timeout: 60           # Seconds of silence before moderator intervenes\\\\\\\\n\\\\\\\\n# Available debate topics\\\\\\\\ntopics:\\\\\\\\n  - \\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\"\\\\\\\\n  - \\\\\\\\\\\\\\\"Social media has a net positive impact on democracy\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\n# AI Moderator Configuration (NEW!)\\\\\\\\nmoderator:\\\\\\\\n  name: \\\\\\\\\\\\\\\"Moderator\\\\\\\\\\\\\\\"\\\\\\\\n  model: \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\"\\\\\\\\n  provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n  personality: \\\\\\\\\\\\\\\"Professional debate facilitator who asks insightful questions, encourages participation, and helps explore different angles of the topic. Speaks when the conversation needs direction or when interesting points need deeper exploration.\\\\\\\\\\\\\\\"\\\\\\\\n  stance: \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n  temperature: 0.8\\\\\\\\n  max_tokens: 150\\\\\\\\n\\\\\\\\n# AI Bot Configurations\\\\\\\\nbots:\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\\\\\\\\\"\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\"socratic\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Passionate supporter, data-driven, persuasive speaker. Jumps in when position is challenged.\\\\\\\\\\\\\\\"\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\"assertive\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Critical thinker, questions assumptions, looks for flaws. Responds when claims need scrutiny.\\\\\\\\\\\\\\\"\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\"analytical\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n  - name: \\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\"\\\\\\\\n    model: \\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\"\\\\\\\\n    provider: \\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\"\\\\\\\\n    personality: \\\\\\\\\\\\\\\"Balanced, seeks common ground, diplomatic. Speaks to bridge disagreements and find synthesis.\\\\\\\\\\\\\\\"\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\"collaborative\\\\\\\\\\\\\\\"\\\\\\\\n    stance: \\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# API Keys (use environment variables in production)\\\\\\\\napi_keys:\\\\\\\\n  openai: \\\\\\\\\\\\\\\"${OPENAI_API_KEY}\\\\\\\\\\\\\\\"\\\\\\\\n  anthropic: \\\\\\\\\\\\\\\"${ANTHROPIC_API_KEY}\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Voting System\\\\\\\\nvoting:\\\\\\\\n  enabled: true\\\\\\\\n  voting_duration: 300  # seconds\\\\\\\\n  allow_participant_voting: true\\\\\\\\n  require_justification: true\\\\\\\\n  anonymous_votes: false\\\\\\\\n\\\\\\\\n# Chat and Logging\\\\\\\\nchat:\\\\\\\\n  max_message_length: 500\\\\\\\\n  enable_timestamps: true\\\\\\\\n  log_level: \\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\"\\\\\\\\n  save_transcripts: true\\\\\\\\n  transcript_format: \\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n# Streaming Configuration\\\\\\\\nstreaming:\\\\\\\\n  enabled: false\\\\\\\\n  websocket_port: 8080\\\\\\\\n  max_connections: 100\\\\\\\\n  broadcast_votes: true\\\\\\\\n\\\\\\\\n# Timeouts and Limits\\\\\\\\nlimits:\\\\\\\\n  max_response_time: 120  # seconds\\\\\\\\n  warning_time: 90  # seconds\\\\\\\\n  max_retries: 3\\\\\\\\n  rate_limit_per_minute: 10\\\\\\\\n\\\\\\\\n# Moderation Rules\\\\\\\\nmoderation:\\\\\\\\n  enable_profanity_filter: true\\\\\\\\n  max_interruptions: 3\\\\\\\\n  enforce_turn_order: false  # No turn order in autonomous mode\\\\\\\\n  auto_mute_violations: true\\\\\\\\n\\\\\\\\n# Human Interface\\\\\\\\ninterface:\\\\\\\\n  mode: \\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\"  # options: cli, web, api\\\\\\\\n  enable_rich_formatting: true\\\\\\\\n  show_typing_indicators: true\\\\\\\\n  enable_reactions: true\\\\\\\"\\\\n    },\\\\n    \\\\\\\"debate_Remote work is the f.json\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"debate_Remote work is the f.json\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".json\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 13914,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"export_timestamp\\\\\\\\\\\\\\\": 1749817045.239899,\\\\\\\\n    \\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\": 42,\\\\\\\\n    \\\\\\\\\\\\\\\"statistics\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\": 42,\\\\\\\\n      \\\\\\\\\\\\\\\"unique_senders\\\\\\\\\\\\\\\": 5,\\\\\\\\n      \\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\": 32,\\\\\\\\n        \\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\": 3,\\\\\\\\n        \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\": 3,\\\\\\\\n        \\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\": 3,\\\\\\\\n        \\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\": 1\\\\\\\\n      },\\\\\\\\n      \\\\\\\\\\\\\\\"messages_per_minute\\\\\\\\\\\\\\\": 2.069704853831723,\\\\\\\\n      \\\\\\\\\\\\\\\"session_duration_minutes\\\\\\\\\\\\\\\": 20.29274846712748,\\\\\\\\n      \\\\\\\\\\\\\\\"current_message_count\\\\\\\\\\\\\\\": 42\\\\\\\\n    }\\\\\\\\n  },\\\\\\\\n  \\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\": [\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé≠ Welcome to AI Jubilee Debate!\\\\\\\\\\\\\\\\nüìù Topic: Remote work is the future of employment\\\\\\\\\\\\\\\\nüë• Participants: Socrates, Advocate, Mediator, Human_1\\\\\\\\\\\\\\\\n‚è±Ô∏è Total time: 30 minutes\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815828.371039,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 1,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Opening Statements Phase\\\\\\\\\\\\\\\\nEach participant has 120 seconds for their opening statement.\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815831.3736022,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 2,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Socrates's turn for opening statement (120s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815831.375623,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 3,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815839.0529852,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 4,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Indeed, this is a topic worthy of our contemplation. The concept of remote work, or telecommuting, has been thrust into the spotlight due to current global circumstances. As we partake in this discourse, let us remember that the future is not a fixed point, but a journey shaped by our choices and actions. Remote work has shown potential to increase productivity and provide flexibility, yet it also introduces challenges in maintaining work-life boundaries and effective communication. Therefore, i...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815839.055337,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 5,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Advocate's turn for opening statement (120s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815839.055578,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 6,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815845.0692759,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 7,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate: Thank you, moderator. I would like to open by stating that remote work is undoubtedly the future of employment. This is not just a speculative assertion, but a fact supported by an increasing body of evidence. Remote work offers unprecedented flexibility, leading to increased productivity, employee satisfaction, and a reduction in overhead costs for companies. According to a survey by Global Workplace Analytics, businesses can save up to $11,000 per year for every employee who works re...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815845.0708978,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 8,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Mediator's turn for opening statement (120s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815845.070956,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 9,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815847.077504,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 10,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"As we delve into the discourse surrounding remote work as the future of employment, it's vital to recognize the multifaceted nature of this topic. Remote work undeniably presents a host of advantages, such as flexibility, potential cost savings, and increased productivity for many individuals. However, it's crucial to acknowledge the challenges that come hand in hand with remote work, like maintaining work-life balance, fostering effective communication, and combating feelings of isolation. Stri...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815847.078847,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 11,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Human_1's turn for opening statement (120s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815847.0788858,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 12,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"hei finaly my turn\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815855.599628,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 13,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üí¨ Discussion Phase Begin\\\\\\\\\\\\\\\\nOpen discussion for 30 minutes. Maintain respectful dialogue!\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815855.599648,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 14,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815855.5999942,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 15,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Socrates: 60 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815855.600161,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 16,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Socrates: I am quite intrigued by the notion of remote work. Yet, I wonder, are we not assuming that all types of work can be performed remotely? A farmer, for instance, cannot till his land from his living room. Moreover, does the isolation associated with remote work not contradict the social nature of human beings? Is it possible that the increase in productivity is only a short-term effect, and in the long run, the lack of human interaction might lead to decreased motivation and engagement?\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815861.113106,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 17,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815861.113177,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 18,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815861.1147661,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 19,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815868.633038,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 20,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate: Indeed, Socrates, your points are valid. However, it's crucial to acknowledge that remote work may not apply to every profession, such as farming. Yet, it fits many industries, notably the ever-growing tech, finance, and creative sectors. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAs for the social aspect, while physical interaction is limited, remote work doesn't necessarily mean isolation. Virtual technologies facilitate team collaboration and social interaction effectively. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nLastly, evidence shows the productivity increas...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815868.6344562,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 21,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Mediator's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815868.634491,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 22,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Mediator: 59 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815868.635563,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 23,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815871.141592,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 24,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate, your points are well taken. It's essential to recognize that while remote work may not be universally applicable, its compatibility with various fields like technology and finance indicates a flexible future for employment. The evolution of virtual technologies indeed enables effective collaboration and social engagement, mitigating the potential isolation concerns often associated with remote work. \\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWhen considering the productivity aspect, studies have shown mixed results, indicatin...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815871.142476,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 25,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815871.142514,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 26,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Human_1: 59 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815871.143828,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 27,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Human_1 exceeded time limit. Warning 1/3\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815931.2812438,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 28,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815931.283378,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 29,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Socrates: 59 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815931.284396,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 30,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815938.301232,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 31,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Indeed, the Mediator presents a nuanced perspective. However, I am intrigued by the notion of this 'flexible future for employment'. Does this flexibility extend to the equilibrium between professional and personal lives? How do we ensure that the boundaries between work and home do not blur, leading to overwork and stress? Are there effective measures in place to deal with such possible outcomes of a remote work environment? Furthermore, does the potential for isolation only refer to physical i...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815938.3026502,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 32,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815938.302691,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 33,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815938.303506,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 34,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815944.81759,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 35,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate: Socrates, your concerns are valid. However, remote work actually enhances the work-life balance when managed properly. Buffer‚Äôs 2019 State of Remote Work report shows that 40% of remote workers consider a flexible schedule as the biggest benefit. As for blurring boundaries, companies are employing digital tools to ensure structured work hours, avoiding overwork. In terms of isolation, while physical isolation is one aspect, remote work fosters a global community, breaking geographical ...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815944.81867,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 36,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Mediator's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815944.818702,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 37,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Mediator: 60 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815944.819515,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 38,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚ö†Ô∏è Mediator's response was truncated due to length\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815947.324934,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 39,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"Advocate, your point about remote work enhancing work-life balance is well-supported by the Buffer report you referenced. It's crucial to acknowledge that remote work can indeed offer flexibility and autonomy, positively impacting employees' well-being. However, Socrates raised a valid concern about the potential for blurred boundaries and isolation, which are essential aspects to consider. It's important for companies to implement clear communication strategies and boundaries to address these c...\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815947.325867,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 40,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815947.325891,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 41,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    },\\\\\\\\n    {\\\\\\\\n      \\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"‚è∞ Human_1: 59 seconds remaining\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\": 1749815947.3266392,\\\\\\\\n      \\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\": 42,\\\\\\\\n      \\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {}\\\\\\\\n    }\\\\\\\\n  ]\\\\\\\\n}\\\\\\\"\\\\n    },\\\\n    \\\\\\\"extract.py\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"extract.py\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 13812,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nExtract script to read all project files and create a JSON structure.\\\\\\\\nReads all .py, .md, .yml, .yaml files and organizes them in a nested directory structure.\\\\\\\\nRespects .gitignore patterns and skips virtual environments.\\\\\\\\n\\\\\\\\n python extract.py --preview\\\\\\\\n\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport os\\\\\\\\nimport json\\\\\\\\nimport datetime\\\\\\\\nimport fnmatch\\\\\\\\nfrom pathlib import Path\\\\\\\\nfrom typing import Dict, Any, Set, List\\\\\\\\n\\\\\\\\n\\\\\\\\ndef parse_gitignore(gitignore_path: Path) -> List[str]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Parse .gitignore file and return list of patterns.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    patterns = []\\\\\\\\n    try:\\\\\\\\n        if gitignore_path.exists():\\\\\\\\n            with open(gitignore_path, 'r', encoding='utf-8') as f:\\\\\\\\n                for line in f:\\\\\\\\n                    line = line.strip()\\\\\\\\n                    # Skip empty lines and comments\\\\\\\\n                    if line and not line.startswith('#'):\\\\\\\\n                        patterns.append(line)\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Warning: Could not read .gitignore: {e}\\\\\\\\\\\\\\\")\\\\\\\\n    return patterns\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_ignored_by_gitignore(file_path: Path, root_path: Path, gitignore_patterns: List[str]) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if file is ignored by .gitignore patterns.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        # Get relative path from root\\\\\\\\n        relative_path = file_path.relative_to(root_path)\\\\\\\\n        path_str = str(relative_path)\\\\\\\\n        path_parts = relative_path.parts\\\\\\\\n\\\\\\\\n        for pattern in gitignore_patterns:\\\\\\\\n            # Handle different gitignore pattern types\\\\\\\\n            if pattern.endswith('/'):\\\\\\\\n                # Directory pattern\\\\\\\\n                pattern = pattern.rstrip('/')\\\\\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\\\\\n                    return True\\\\\\\\n            elif '/' in pattern:\\\\\\\\n                # Path pattern\\\\\\\\n                if fnmatch.fnmatch(path_str, pattern):\\\\\\\\n                    return True\\\\\\\\n            else:\\\\\\\\n                # Filename pattern\\\\\\\\n                if fnmatch.fnmatch(file_path.name, pattern):\\\\\\\\n                    return True\\\\\\\\n                # Also check if any parent directory matches\\\\\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\\\\\n                    return True\\\\\\\\n    except ValueError:\\\\\\\\n        # Path is not relative to root\\\\\\\\n        pass\\\\\\\\n    except Exception:\\\\\\\\n        # Any other error, don't ignore\\\\\\\\n        pass\\\\\\\\n\\\\\\\\n    return False\\\\\\\\n\\\\\\\\n\\\\\\\\ndef should_include_file(file_path: Path) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if file should be included based on extension.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    allowed_extensions = {'.py', '.md', '.yml', '.yaml', '.txt', '.json', '.toml', '.cfg', '.ini'}\\\\\\\\n    return file_path.suffix.lower() in allowed_extensions\\\\\\\\n\\\\\\\\n\\\\\\\\ndef should_skip_directory(dir_name: str) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if directory should be skipped (common build/cache directories).\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    skip_dirs = {\\\\\\\\n        '__pycache__',\\\\\\\\n        '.git',\\\\\\\\n        '.pytest_cache',\\\\\\\\n        'node_modules',\\\\\\\\n        '.venv',\\\\\\\\n        'venv',\\\\\\\\n        'env',\\\\\\\\n        '.env',\\\\\\\\n        'ENV',\\\\\\\\n        'env.bak',\\\\\\\\n        'venv.bak',\\\\\\\\n        'dist',\\\\\\\\n        'build',\\\\\\\\n        '.idea',\\\\\\\\n        '.vscode',\\\\\\\\n        'htmlcov',\\\\\\\\n        '.coverage',\\\\\\\\n        '.mypy_cache',\\\\\\\\n        '.tox',\\\\\\\\n        '.cache',\\\\\\\\n        'eggs',\\\\\\\\n        '*.egg-info',\\\\\\\\n        '.eggs',\\\\\\\\n        'lib',\\\\\\\\n        'lib64',\\\\\\\\n        'parts',\\\\\\\\n        'sdist',\\\\\\\\n        'var',\\\\\\\\n        'wheels',\\\\\\\\n        'share/python-wheels',\\\\\\\\n        '*.egg-info/',\\\\\\\\n        '.installed.cfg',\\\\\\\\n        '*.egg',\\\\\\\\n        'MANIFEST',\\\\\\\\n        '.DS_Store',\\\\\\\\n        'Thumbs.db'\\\\\\\\n    }\\\\\\\\n    return dir_name in skip_dirs\\\\\\\\n\\\\\\\\n\\\\\\\\ndef is_virtual_environment(dir_path: Path) -> bool:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if directory is a virtual environment.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    venv_indicators = [\\\\\\\\n        'pyvenv.cfg',\\\\\\\\n        'Scripts/activate',\\\\\\\\n        'bin/activate',\\\\\\\\n        'Scripts/python.exe',\\\\\\\\n        'bin/python'\\\\\\\\n    ]\\\\\\\\n\\\\\\\\n    for indicator in venv_indicators:\\\\\\\\n        if (dir_path / indicator).exists():\\\\\\\\n            return True\\\\\\\\n\\\\\\\\n    # Check for common venv directory names\\\\\\\\n    venv_names = {'venv', '.venv', 'env', '.env', 'ENV', 'virtualenv'}\\\\\\\\n    if dir_path.name in venv_names:\\\\\\\\n        return True\\\\\\\\n\\\\\\\\n    return False\\\\\\\\n\\\\\\\\n\\\\\\\\ndef read_file_content(file_path: Path) -> str:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Read file content safely.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\\n            return f.read()\\\\\\\\n    except UnicodeDecodeError:\\\\\\\\n        try:\\\\\\\\n            with open(file_path, 'r', encoding='latin-1') as f:\\\\\\\\n                return f.read()\\\\\\\\n        except Exception as e:\\\\\\\\n            return f\\\\\\\\\\\\\\\"[Error reading file: {e}]\\\\\\\\\\\\\\\"\\\\\\\\n    except Exception as e:\\\\\\\\n        return f\\\\\\\\\\\\\\\"[Error reading file: {e}]\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n\\\\\\\\ndef extract_directory_structure(root_path: Path, base_path: Path = None, gitignore_patterns: List[str] = None) -> Dict[\\\\\\\\n    str, Any]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    Recursively extract directory structure and file contents.\\\\\\\\n\\\\\\\\n    Args:\\\\\\\\n        root_path: Path to extract from\\\\\\\\n        base_path: Base path for relative calculations (optional)\\\\\\\\n        gitignore_patterns: List of gitignore patterns to respect\\\\\\\\n\\\\\\\\n    Returns:\\\\\\\\n        Dictionary with nested structure representing directories and files\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    if base_path is None:\\\\\\\\n        base_path = root_path\\\\\\\\n\\\\\\\\n    if gitignore_patterns is None:\\\\\\\\n        gitignore_patterns = []\\\\\\\\n\\\\\\\\n    structure = {}\\\\\\\\n\\\\\\\\n    try:\\\\\\\\n        # Ensure we have a Path object\\\\\\\\n        if not isinstance(root_path, Path):\\\\\\\\n            root_path = Path(root_path)\\\\\\\\n\\\\\\\\n        if not isinstance(base_path, Path):\\\\\\\\n            base_path = Path(base_path)\\\\\\\\n\\\\\\\\n        # Check if path exists and is directory\\\\\\\\n        if not root_path.exists():\\\\\\\\n            return {\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\"Path does not exist: {root_path}\\\\\\\\\\\\\\\"}\\\\\\\\n\\\\\\\\n        if not root_path.is_dir():\\\\\\\\n            return {\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\"Path is not a directory: {root_path}\\\\\\\\\\\\\\\"}\\\\\\\\n\\\\\\\\n        # Get all items in directory\\\\\\\\n        items = list(root_path.iterdir())\\\\\\\\n        items.sort(key=lambda x: (x.is_file(), x.name.lower()))\\\\\\\\n\\\\\\\\n        for item in items:\\\\\\\\n            try:\\\\\\\\n                # Check if item is ignored by gitignore\\\\\\\\n                if is_ignored_by_gitignore(item, base_path, gitignore_patterns):\\\\\\\\n                    continue\\\\\\\\n\\\\\\\\n                # Skip hidden files except specific ones\\\\\\\\n                if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore', '.gitattributes'}:\\\\\\\\n                    continue\\\\\\\\n\\\\\\\\n                if item.is_dir():\\\\\\\\n                    # Skip certain directories\\\\\\\\n                    if should_skip_directory(item.name):\\\\\\\\n                        continue\\\\\\\\n\\\\\\\\n                    # Skip virtual environments\\\\\\\\n                    if is_virtual_environment(item):\\\\\\\\n                        continue\\\\\\\\n\\\\\\\\n                    # Recursively process subdirectories\\\\\\\\n                    substructure = extract_directory_structure(item, base_path, gitignore_patterns)\\\\\\\\n                    if substructure:  # Only add if not empty\\\\\\\\n                        structure[item.name] = {\\\\\\\\n                            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n                            \\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\": substructure\\\\\\\\n                        }\\\\\\\\n\\\\\\\\n                elif item.is_file():\\\\\\\\n                    # Only include certain file types\\\\\\\\n                    if should_include_file(item):\\\\\\\\n                        file_content = read_file_content(item)\\\\\\\\n                        try:\\\\\\\\n                            relative_path = str(item.relative_to(base_path))\\\\\\\\n                        except ValueError:\\\\\\\\n                            relative_path = str(item)\\\\\\\\n\\\\\\\\n                        structure[item.name] = {\\\\\\\\n                            \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n                            \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": relative_path,\\\\\\\\n                            \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": item.suffix,\\\\\\\\n                            \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": len(file_content),\\\\\\\\n                            \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": file_content\\\\\\\\n                        }\\\\\\\\n\\\\\\\\n            except PermissionError:\\\\\\\\n                structure[f\\\\\\\\\\\\\\\"_error_{item.name}\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\"Permission denied accessing: {item.name}\\\\\\\\\\\\\\\"\\\\\\\\n                continue\\\\\\\\n            except Exception as e:\\\\\\\\n                structure[f\\\\\\\\\\\\\\\"_error_{item.name}\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\"Error processing {item.name}: {e}\\\\\\\\\\\\\\\"\\\\\\\\n                continue\\\\\\\\n\\\\\\\\n    except PermissionError as e:\\\\\\\\n        structure[\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\"Permission denied: {e}\\\\\\\\\\\\\\\"\\\\\\\\n    except Exception as e:\\\\\\\\n        structure[\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\"Error processing directory: {e}\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    return structure\\\\\\\\n\\\\\\\\n\\\\\\\\ndef count_items_recursive(structure: Dict[str, Any]) -> Dict[str, int]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Count files and directories recursively.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    counts = {\\\\\\\\n        \\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\": 0,\\\\\\\\n        \\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\": 0,\\\\\\\\n        \\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\": 0,\\\\\\\\n        \\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\": {}\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    for name, item in structure.items():\\\\\\\\n        if name.startswith(\\\\\\\\\\\\\\\"_\\\\\\\\\\\\\\\"):\\\\\\\\n            continue\\\\\\\\n\\\\\\\\n        if isinstance(item, dict):\\\\\\\\n            if item.get(\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\":\\\\\\\\n                counts[\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\"] += 1\\\\\\\\n                sub_counts = count_items_recursive(item.get(\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\", {}))\\\\\\\\n                counts[\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\"]\\\\\\\\n                counts[\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\"]\\\\\\\\n                counts[\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n                # Merge file types\\\\\\\\n                for ext, count in sub_counts[\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\"].items():\\\\\\\\n                    counts[\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\"][ext] = counts[\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\"].get(ext, 0) + count\\\\\\\\n\\\\\\\\n            elif item.get(\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\":\\\\\\\\n                counts[\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\"] += 1\\\\\\\\n                ext = item.get(\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n                counts[\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\"][ext] = counts[\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\"].get(ext, 0) + 1\\\\\\\\n                counts[\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\"] += item.get(\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\", 0)\\\\\\\\n\\\\\\\\n    return counts\\\\\\\\n\\\\\\\\n\\\\\\\\ndef create_project_metadata(root_path: Path, structure: Dict[str, Any]) -> Dict[str, Any]:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Create metadata about the project.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    counts = count_items_recursive(structure)\\\\\\\\n\\\\\\\\n    metadata = {\\\\\\\\n        \\\\\\\\\\\\\\\"project_name\\\\\\\\\\\\\\\": root_path.name,\\\\\\\\n        \\\\\\\\\\\\\\\"extraction_timestamp\\\\\\\\\\\\\\\": datetime.datetime.now().isoformat(),\\\\\\\\n        \\\\\\\\\\\\\\\"root_path\\\\\\\\\\\\\\\": str(root_path.absolute()),\\\\\\\\n        \\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\"],\\\\\\\\n        \\\\\\\\\\\\\\\"total_directories\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\"],\\\\\\\\n        \\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\"],\\\\\\\\n        \\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\"],\\\\\\\\n        \\\\\\\\\\\\\\\"respects_gitignore\\\\\\\\\\\\\\\": True,\\\\\\\\n        \\\\\\\\\\\\\\\"skips_virtual_environments\\\\\\\\\\\\\\\": True\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    return metadata\\\\\\\\n\\\\\\\\n\\\\\\\\ndef preview_structure(structure: Dict[str, Any], indent: int = 0) -> None:\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Preview the extracted structure.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    prefix = \\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\" * indent\\\\\\\\n\\\\\\\\n    for name, item in structure.items():\\\\\\\\n        if name.startswith(\\\\\\\\\\\\\\\"_\\\\\\\\\\\\\\\"):\\\\\\\\n            continue\\\\\\\\n\\\\\\\\n        if isinstance(item, dict):\\\\\\\\n            if item.get(\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\":\\\\\\\\n                print(f\\\\\\\\\\\\\\\"{prefix}üìÅ {name}/\\\\\\\\\\\\\\\")\\\\\\\\n                preview_structure(item.get(\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\", {}), indent + 1)\\\\\\\\n            elif item.get(\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\":\\\\\\\\n                size = item.get(\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\", 0)\\\\\\\\n                ext = item.get(\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\")\\\\\\\\n                print(f\\\\\\\\\\\\\\\"{prefix}üìÑ {name} ({size:,} chars, {ext})\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main extraction function.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    # Get current directory or specified directory\\\\\\\\n    import sys\\\\\\\\n\\\\\\\\n    if len(sys.argv) > 1:\\\\\\\\n        root_dir = Path(sys.argv[1])\\\\\\\\n    else:\\\\\\\\n        root_dir = Path.cwd()\\\\\\\\n\\\\\\\\n    # Ensure we have a Path object\\\\\\\\n    if not isinstance(root_dir, Path):\\\\\\\\n        root_dir = Path(root_dir)\\\\\\\\n\\\\\\\\n    if not root_dir.exists():\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error: Directory {root_dir} does not exist\\\\\\\\\\\\\\\")\\\\\\\\n        return\\\\\\\\n\\\\\\\\n    if not root_dir.is_dir():\\\\\\\\n        print(f\\\\\\\\\\\\\\\"Error: {root_dir} is not a directory\\\\\\\\\\\\\\\")\\\\\\\\n        return\\\\\\\\n\\\\\\\\n    print(f\\\\\\\\\\\\\\\"üîç Extracting project structure from: {root_dir.absolute()}\\\\\\\\\\\\\\\")\\\\\\\\n    print(\\\\\\\\\\\\\\\"üìÅ Reading all .py, .md, .yml, .yaml, .txt, .json files...\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Parse .gitignore if it exists\\\\\\\\n    gitignore_path = root_dir / '.gitignore'\\\\\\\\n    gitignore_patterns = parse_gitignore(gitignore_path)\\\\\\\\n\\\\\\\\n    if gitignore_patterns:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìã Found .gitignore with {len(gitignore_patterns)} patterns\\\\\\\\\\\\\\\")\\\\\\\\n    else:\\\\\\\\n        print(\\\\\\\\\\\\\\\"üìã No .gitignore found or empty\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    print(\\\\\\\\\\\\\\\"üö´ Skipping virtual environments and build directories\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Extract the directory structure\\\\\\\\n    try:\\\\\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\\\\\n\\\\\\\\n        # Create metadata\\\\\\\\n        metadata = create_project_metadata(root_dir, structure)\\\\\\\\n\\\\\\\\n        # Create project data\\\\\\\\n        project_data = {\\\\\\\\n            \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": metadata,\\\\\\\\n            \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": structure\\\\\\\\n        }\\\\\\\\n\\\\\\\\n        # Output filename\\\\\\\\n        output_file = root_dir / \\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        # Write JSON file\\\\\\\\n        with open(output_file, 'w', encoding='utf-8') as f:\\\\\\\\n            json.dump(project_data, f, indent=2, ensure_ascii=False)\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"‚úÖ Extraction complete!\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìä Statistics:\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   ‚Ä¢ Total files: {metadata['total_files']}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   ‚Ä¢ Total directories: {metadata['total_directories']}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   ‚Ä¢ Total size: {metadata['total_size']:,} characters\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üìÑ Output saved to: {output_file}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Show file type breakdown\\\\\\\\n        if metadata['file_types']:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüìã File type breakdown:\\\\\\\\\\\\\\\")\\\\\\\\n            for ext, count in sorted(metadata['file_types'].items()):\\\\\\\\n                ext_name = ext if ext else \\\\\\\\\\\\\\\"(no extension)\\\\\\\\\\\\\\\"\\\\\\\\n                print(f\\\\\\\\\\\\\\\"   ‚Ä¢ {ext_name}: {count} files\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"‚ùå Error during extraction: {e}\\\\\\\\\\\\\\\")\\\\\\\\n        import traceback\\\\\\\\n        traceback.print_exc()\\\\\\\\n\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    # Add preview option\\\\\\\\n    import sys\\\\\\\\n\\\\\\\\n    if \\\\\\\\\\\\\\\"--preview\\\\\\\\\\\\\\\" in sys.argv:\\\\\\\\n        sys.argv.remove(\\\\\\\\\\\\\\\"--preview\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Get directory\\\\\\\\n        if len(sys.argv) > 1:\\\\\\\\n            root_dir = Path(sys.argv[1])\\\\\\\\n        else:\\\\\\\\n            root_dir = Path.cwd()\\\\\\\\n\\\\\\\\n        # Parse .gitignore\\\\\\\\n        gitignore_path = root_dir / '.gitignore'\\\\\\\\n        gitignore_patterns = parse_gitignore(gitignore_path)\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üîç Preview of project structure: {root_dir.name}\\\\\\\\\\\\\\\")\\\\\\\\n        if gitignore_patterns:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"üìã Respecting .gitignore with {len(gitignore_patterns)} patterns\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\" * 50)\\\\\\\\n\\\\\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\\\\\n        preview_structure(structure)\\\\\\\\n\\\\\\\\n    else:\\\\\\\\n        main()\\\\\\\\n\\\\\\\"\\\\n    },\\\\n    \\\\\\\"project.json\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"project.json\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".json\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 598208,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"{\\\\\\\\n  \\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"project_name\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"AIMafia\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"extraction_timestamp\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"2025-06-13T13:53:46.952758\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"root_path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"/Users/voicutomut/Documents/GitHub/AIMafia\\\\\\\\\\\\\\\",\\\\\\\\n    \\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\": 23,\\\\\\\\n    \\\\\\\\\\\\\\\"total_directories\\\\\\\\\\\\\\\": 3,\\\\\\\\n    \\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\": 15,\\\\\\\\n      \\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\": 4,\\\\\\\\n      \\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\": 1,\\\\\\\\n      \\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\": 2,\\\\\\\\n      \\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\": 1\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\": 558527,\\\\\\\\n    \\\\\\\\\\\\\\\"respects_gitignore\\\\\\\\\\\\\\\": true,\\\\\\\\n    \\\\\\\\\\\\\\\"skips_virtual_environments\\\\\\\\\\\\\\\": true\\\\\\\\n  },\\\\\\\\n  \\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\": {\\\\\\\\n    \\\\\\\\\\\\\\\"app\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\\\"__init__.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/__init__.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 489,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nAI  Debate System\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nA platform for structured debates between AI bots and human participants.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n__version__ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n__author__ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AndreiVoicuT\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .main import start_debate_session\\\\\\\\\\\\\\\\nfrom .moderator import Moderator\\\\\\\\\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\\\\\\\\\nfrom .human_client import HumanClient\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n__all__ = [\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_debate_session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ChatLog\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n]\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"bot_client.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/bot_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 12395,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nAI Bot client for interacting with various language models in debates.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\nfrom abc import ABC, abstractmethod\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .chat_log import Message\\\\\\\\\\\\\\\\nfrom .utils import truncate_text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass BotConfig:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration for AI bot behavior.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    name: str\\\\\\\\\\\\\\\\n    model: str\\\\\\\\\\\\\\\\n    provider: str\\\\\\\\\\\\\\\\n    personality: str\\\\\\\\\\\\\\\\n    stance: str\\\\\\\\\\\\\\\\n    temperature: float = 0.7\\\\\\\\\\\\\\\\n    max_tokens: int = 300\\\\\\\\\\\\\\\\n    timeout: int = 30\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass AIProvider(ABC):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Abstract base class for AI providers.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @abstractmethod\\\\\\\\\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response from the AI model.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass OpenAIProvider(AIProvider):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OpenAI API provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, api_key: str):\\\\\\\\\\\\\\\\n        self.api_key = api_key\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response using OpenAI API.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            import openai\\\\\\\\\\\\\\\\n            client = openai.AsyncOpenAI(api_key=self.api_key)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            response = await client.chat.completions.create(\\\\\\\\\\\\\\\\n                model=config.model,\\\\\\\\\\\\\\\\n                messages=messages,\\\\\\\\\\\\\\\\n                max_tokens=config.max_tokens,\\\\\\\\\\\\\\\\n                temperature=config.temperature,\\\\\\\\\\\\\\\\n                timeout=config.timeout\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            return response.choices[0].message.content.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            raise Exception(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OpenAI API error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass AnthropicProvider(AIProvider):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Anthropic API provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, api_key: str):\\\\\\\\\\\\\\\\n        self.api_key = api_key\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response using Anthropic API.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            import anthropic\\\\\\\\\\\\\\\\n            client = anthropic.AsyncAnthropic(api_key=self.api_key)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Convert messages format for Anthropic\\\\\\\\\\\\\\\\n            system_message = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            user_messages = [msg for msg in messages if msg['role'] != 'system']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            response = await client.messages.create(\\\\\\\\\\\\\\\\n                model=config.model,\\\\\\\\\\\\\\\\n                max_tokens=config.max_tokens,\\\\\\\\\\\\\\\\n                temperature=config.temperature,\\\\\\\\\\\\\\\\n                system=system_message,\\\\\\\\\\\\\\\\n                messages=user_messages\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            return response.content[0].text.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            raise Exception(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Anthropic API error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass BotClient:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    AI Bot client that participates in debates using various language models.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, name: str, model: str, provider: str,\\\\\\\\\\\\\\\\n                 personality: str, stance: str, api_key: str,\\\\\\\\\\\\\\\\n                 temperature: float = 0.7, max_tokens: int = 300):\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.config = BotConfig(\\\\\\\\\\\\\\\\n            name=name,\\\\\\\\\\\\\\\\n            model=model,\\\\\\\\\\\\\\\\n            provider=provider,\\\\\\\\\\\\\\\\n            personality=personality,\\\\\\\\\\\\\\\\n            stance=stance,\\\\\\\\\\\\\\\\n            temperature=temperature,\\\\\\\\\\\\\\\\n            max_tokens=max_tokens\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Initialize AI provider\\\\\\\\\\\\\\\\n        if provider.lower() == 'openai':\\\\\\\\\\\\\\\\n            self.ai_provider = OpenAIProvider(api_key)\\\\\\\\\\\\\\\\n        elif provider.lower() == 'anthropic':\\\\\\\\\\\\\\\\n            self.ai_provider = AnthropicProvider(api_key)\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported AI provider: {provider}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Bot state\\\\\\\\\\\\\\\\n        self.conversation_history: List[Dict[str, str]] = []\\\\\\\\\\\\\\\\n        self.debate_context = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.message_queue = asyncio.Queue()\\\\\\\\\\\\\\\\n        self.response_count = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Performance tracking\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\n            'responses_generated': 0,\\\\\\\\\\\\\\\\n            'average_response_time': 0,\\\\\\\\\\\\\\\\n            'total_response_time': 0,\\\\\\\\\\\\\\\\n            'errors': 0\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\n    def name(self) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get bot name.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return self.config.name\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def get_response(self, topic: str, recent_messages: List[Message]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Generate a response to the current debate context.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            topic: Current debate topic\\\\\\\\\\\\\\\\n            recent_messages: Recent messages from the debate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            Generated response string\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Prepare conversation context\\\\\\\\\\\\\\\\n            messages = self._prepare_messages(topic, recent_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Generate response\\\\\\\\\\\\\\\\n            response = await self.ai_provider.generate_response(messages, self.config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Update statistics\\\\\\\\\\\\\\\\n            response_time = time.time() - start_time\\\\\\\\\\\\\\\\n            self._update_stats(response_time, success=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Store in conversation history\\\\\\\\\\\\\\\\n            self.conversation_history.append({\\\\\\\\\\\\\\\\n                'role': 'assistant',\\\\\\\\\\\\\\\\n                'content': response\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            self.response_count += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            return response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            self._update_stats(time.time() - start_time, success=False)\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot {self.name} error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return self._generate_fallback_response(topic)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _prepare_messages(self, topic: str, recent_messages: List[Message]) -> List[Dict[str, str]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Prepare message context for AI model.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        messages = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # System message with bot personality and instructions\\\\\\\\\\\\\\\\n        system_prompt = self._create_system_prompt(topic)\\\\\\\\\\\\\\\\n        messages.append({\\\\\\\\\\\\\\\\n            'role': 'system',\\\\\\\\\\\\\\\\n            'content': system_prompt\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add recent conversation context\\\\\\\\\\\\\\\\n        for msg in recent_messages[-5:]:  # Last 5 messages for context\\\\\\\\\\\\\\\\n            role = 'assistant' if msg.sender == self.name else 'user'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            content = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{msg.sender}: {msg.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            messages.append({\\\\\\\\\\\\\\\\n                'role': role,\\\\\\\\\\\\\\\\n                'content': content\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return messages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _create_system_prompt(self, topic: str) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create system prompt based on bot configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are {self.config.name}, participating in an AUTONOMOUS structured debate.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDEBATE TOPIC: {topic}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nYOUR ROLE AND PERSONALITY:\\\\\\\\\\\\\\\\n- Personality: {self.config.personality}\\\\\\\\\\\\\\\\n- Stance: {self.config.stance}\\\\\\\\\\\\\\\\n- Debate Style: Professional yet engaging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAUTONOMOUS DEBATE RULES:\\\\\\\\\\\\\\\\n1. You are monitoring the conversation and will be asked IF you want to respond\\\\\\\\\\\\\\\\n2. Only respond when you feel compelled to contribute meaningfully\\\\\\\\\\\\\\\\n3. You have access to the FULL conversation history for context\\\\\\\\\\\\\\\\n4. Focus on the topic and respond to specific points made by others\\\\\\\\\\\\\\\\n5. Keep responses concise but impactful (under 300 words)\\\\\\\\\\\\\\\\n6. Be respectful but persuasive\\\\\\\\\\\\\\\\n7. Use evidence and examples when possible\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWHEN TO RESPOND:\\\\\\\\\\\\\\\\n- When someone directly challenges your position\\\\\\\\\\\\\\\\n- When you can add important evidence or perspective\\\\\\\\\\\\\\\\n- When you disagree strongly with a point made\\\\\\\\\\\\\\\\n- When you can clarify misconceptions\\\\\\\\\\\\\\\\n- When the conversation lacks your viewpoint\\\\\\\\\\\\\\\\n- When you have a compelling counterargument\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRESPONSE FORMAT:\\\\\\\\\\\\\\\\n- Provide direct, substantive responses\\\\\\\\\\\\\\\\n- Reference specific points made by others when relevant\\\\\\\\\\\\\\\\n- Don't repeat previous arguments verbatim\\\\\\\\\\\\\\\\n- Engage with the actual conversation flow\\\\\\\\\\\\\\\\n- Show you've been listening to the full discussion\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nYour goal is to effectively argue your position while contributing to a dynamic, organic debate conversation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add stance-specific instructions\\\\\\\\\\\\\\\\n        if self.config.stance.lower() == 'pro':\\\\\\\\\\\\\\\\n            prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue IN FAVOR of the topic. Respond when the topic is attacked or when you can strengthen the pro position.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        elif self.config.stance.lower() == 'con':\\\\\\\\\\\\\\\\n            prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue AGAINST the topic. Respond when the topic is supported or when you can weaken the pro arguments.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        elif self.config.stance.lower() == 'neutral':\\\\\\\\\\\\\\\\n            prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should present balanced perspectives and ask probing questions. Respond when the debate needs deeper analysis or alternative viewpoints.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return prompt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _generate_fallback_response(self, topic: str) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate a fallback response when AI fails.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        fallback_responses = [\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I'd like to share another perspective on {topic}. Let me gather my thoughts and respond shortly.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"That's an interesting point. I need a moment to formulate a proper response to that argument.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"There are several important aspects of {topic} we should consider here.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I appreciate the previous arguments. Let me offer a different viewpoint on this matter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        import random\\\\\\\\\\\\\\\\n        return random.choice(fallback_responses)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def receive_message(self, message: Message) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Receive a message from the debate (for awareness/context).\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            message: Message object from the chat log\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add to message queue for processing\\\\\\\\\\\\\\\\n        await self.message_queue.put(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Update conversation history if it's not from this bot\\\\\\\\\\\\\\\\n        if message.sender != self.name:\\\\\\\\\\\\\\\\n            self.conversation_history.append({\\\\\\\\\\\\\\\\n                'role': 'user',\\\\\\\\\\\\\\\\n                'content': f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Keep history manageable\\\\\\\\\\\\\\\\n            if len(self.conversation_history) > 20:\\\\\\\\\\\\\\\\n                self.conversation_history = self.conversation_history[-15:]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _update_stats(self, response_time: float, success: bool = True):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update performance statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if success:\\\\\\\\\\\\\\\\n            self.stats['responses_generated'] += 1\\\\\\\\\\\\\\\\n            self.stats['total_response_time'] += response_time\\\\\\\\\\\\\\\\n            self.stats['average_response_time'] = (\\\\\\\\\\\\\\\\n                self.stats['total_response_time'] / self.stats['responses_generated']\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            self.stats['errors'] += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get bot performance statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'name': self.name,\\\\\\\\\\\\\\\\n            'model': self.config.model,\\\\\\\\\\\\\\\\n            'provider': self.config.provider,\\\\\\\\\\\\\\\\n            'responses_generated': self.stats['responses_generated'],\\\\\\\\\\\\\\\\n            'average_response_time': round(self.stats['average_response_time'], 2),\\\\\\\\\\\\\\\\n            'total_errors': self.stats['errors'],\\\\\\\\\\\\\\\\n            'success_rate': (\\\\\\\\\\\\\\\\n                self.stats['responses_generated'] /\\\\\\\\\\\\\\\\n                (self.stats['responses_generated'] + self.stats['errors'])\\\\\\\\\\\\\\\\n                if (self.stats['responses_generated'] + self.stats['errors']) > 0 else 0\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def update_personality(self, personality: str, stance: str = None):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update bot personality and stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.config.personality = personality\\\\\\\\\\\\\\\\n        if stance:\\\\\\\\\\\\\\\\n            self.config.stance = stance\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def reset_conversation(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reset conversation history.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.conversation_history = []\\\\\\\\\\\\\\\\n        self.response_count = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def warmup(self) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Warm up the bot by testing API connection.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            True if warmup successful, False otherwise\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            test_messages = [{\\\\\\\\\\\\\\\\n                'role': 'system',\\\\\\\\\\\\\\\\n                'content': 'You are a debate participant. Respond with just \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" to confirm you are working.'\\\\\\\\\\\\\\\\n            }, {\\\\\\\\\\\\\\\\n                'role': 'user',\\\\\\\\\\\\\\\\n                'content': 'Are you ready to participate in a debate?'\\\\\\\\\\\\\\\\n            }]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            response = await self.ai_provider.generate_response(test_messages, self.config)\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ready\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in response.lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot {self.name} warmup failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __str__(self) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"String representation of the bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient({self.name}, {self.config.model}, {self.config.stance})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __repr__(self) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Detailed string representation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return (f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient(name='{self.name}', model='{self.config.model}', \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"provider='{self.config.provider}', stance='{self.config.stance}')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"chat_log.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/chat_log.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 11211,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nShared chat log system for managing debate messages with timestamps and ordering.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom collections import deque\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass Message:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Represents a single chat message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    sender: str\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\n    timestamp: float\\\\\\\\\\\\\\\\n    message_id: int\\\\\\\\\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # chat, system, moderator, vote\\\\\\\\\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\n        if self.metadata is None:\\\\\\\\\\\\\\\\n            self.metadata = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\n    def formatted_timestamp(self) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get human-readable timestamp.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.localtime(self.timestamp))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def to_dict(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Convert message to dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return asdict(self)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @classmethod\\\\\\\\\\\\\\\\n    def from_dict(cls, data: Dict[str, Any]) -> 'Message':\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create message from dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return cls(**data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass ChatLog:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Manages the shared chat log with thread-safe message handling.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, max_messages: int = 1000):\\\\\\\\\\\\\\\\n        self.messages: deque = deque(maxlen=max_messages)\\\\\\\\\\\\\\\\n        self.message_counter = 0\\\\\\\\\\\\\\\\n        self.subscribers: List[asyncio.Queue] = []\\\\\\\\\\\\\\\\n        self._lock = asyncio.Lock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Statistics\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\n            'total_messages': 0,\\\\\\\\\\\\\\\\n            'messages_by_sender': {},\\\\\\\\\\\\\\\\n            'start_time': time.time()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def add_message(self, sender: str, content: str,\\\\\\\\\\\\\\\\n                          message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                          metadata: Optional[Dict[str, Any]] = None) -> Message:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Add a new message to the chat log.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            sender: Name of the message sender\\\\\\\\\\\\\\\\n            content: Message content\\\\\\\\\\\\\\\\n            message_type: Type of message (chat, system, moderator, vote)\\\\\\\\\\\\\\\\n            metadata: Additional message metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            The created Message object\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        async with self._lock:\\\\\\\\\\\\\\\\n            self.message_counter += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            message = Message(\\\\\\\\\\\\\\\\n                sender=sender,\\\\\\\\\\\\\\\\n                content=content,\\\\\\\\\\\\\\\\n                timestamp=time.time(),\\\\\\\\\\\\\\\\n                message_id=self.message_counter,\\\\\\\\\\\\\\\\n                message_type=message_type,\\\\\\\\\\\\\\\\n                metadata=metadata or {}\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            self.messages.append(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Update statistics\\\\\\\\\\\\\\\\n            self.stats['total_messages'] += 1\\\\\\\\\\\\\\\\n            self.stats['messages_by_sender'][sender] = (\\\\\\\\\\\\\\\\n                    self.stats['messages_by_sender'].get(sender, 0) + 1\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Notify subscribers\\\\\\\\\\\\\\\\n            await self._notify_subscribers(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            return message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _notify_subscribers(self, message: Message):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Notify all subscribers of new message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Remove closed queues\\\\\\\\\\\\\\\\n        self.subscribers = [q for q in self.subscribers if not q._closed]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Send to all active subscribers\\\\\\\\\\\\\\\\n        for queue in self.subscribers:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                await queue.put(message)\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to notify subscriber: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def subscribe(self) -> asyncio.Queue:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Subscribe to receive new messages.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            Queue that will receive new Message objects\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        queue = asyncio.Queue()\\\\\\\\\\\\\\\\n        self.subscribers.append(queue)\\\\\\\\\\\\\\\\n        return queue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def unsubscribe(self, queue: asyncio.Queue):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove a subscriber queue.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if queue in self.subscribers:\\\\\\\\\\\\\\\\n            self.subscribers.remove(queue)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_messages(self, limit: Optional[int] = None,\\\\\\\\\\\\\\\\n                     sender: Optional[str] = None,\\\\\\\\\\\\\\\\n                     message_type: Optional[str] = None,\\\\\\\\\\\\\\\\n                     since_timestamp: Optional[float] = None) -> List[Message]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Get messages with optional filtering.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            limit: Maximum number of messages to return\\\\\\\\\\\\\\\\n            sender: Filter by sender name\\\\\\\\\\\\\\\\n            message_type: Filter by message type\\\\\\\\\\\\\\\\n            since_timestamp: Only return messages after this timestamp\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            List of matching messages\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        messages = list(self.messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Apply filters\\\\\\\\\\\\\\\\n        if sender:\\\\\\\\\\\\\\\\n            messages = [m for m in messages if m.sender == sender]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if message_type:\\\\\\\\\\\\\\\\n            messages = [m for m in messages if m.message_type == message_type]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if since_timestamp:\\\\\\\\\\\\\\\\n            messages = [m for m in messages if m.timestamp > since_timestamp]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Apply limit\\\\\\\\\\\\\\\\n        if limit:\\\\\\\\\\\\\\\\n            messages = messages[-limit:]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return messages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get the most recent messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return list(self.messages)[-count:]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_conversation_context(self, participant: str,\\\\\\\\\\\\\\\\n                                 context_length: int = 5) -> List[Message]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Get conversation context for a participant.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            participant: Participant name\\\\\\\\\\\\\\\\n            context_length: Number of recent messages to include\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            Recent messages for context\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        recent = self.get_recent_messages(context_length * 2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Include messages to/from the participant and moderator messages\\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\n        for msg in recent:\\\\\\\\\\\\\\\\n            if (msg.sender == participant or\\\\\\\\\\\\\\\\n                    msg.message_type in ['moderator', 'system'] or\\\\\\\\\\\\\\\\n                    participant in msg.content):\\\\\\\\\\\\\\\\n                context.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return context[-context_length:]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def search_messages(self, query: str, case_sensitive: bool = False) -> List[Message]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Search messages by content.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            query: Search query\\\\\\\\\\\\\\\\n            case_sensitive: Whether search should be case sensitive\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            List of messages containing the query\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not case_sensitive:\\\\\\\\\\\\\\\\n            query = query.lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = []\\\\\\\\\\\\\\\\n        for message in self.messages:\\\\\\\\\\\\\\\\n            content = message.content if case_sensitive else message.content.lower()\\\\\\\\\\\\\\\\n            if query in content:\\\\\\\\\\\\\\\\n                results.append(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_statistics(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get chat log statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        duration = time.time() - self.stats['start_time']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'total_messages': self.stats['total_messages'],\\\\\\\\\\\\\\\\n            'unique_senders': len(self.stats['messages_by_sender']),\\\\\\\\\\\\\\\\n            'messages_by_sender': dict(self.stats['messages_by_sender']),\\\\\\\\\\\\\\\\n            'messages_per_minute': (self.stats['total_messages'] / (duration / 60)\\\\\\\\\\\\\\\\n                                    if duration > 0 else 0),\\\\\\\\\\\\\\\\n            'session_duration_minutes': duration / 60,\\\\\\\\\\\\\\\\n            'current_message_count': len(self.messages)\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def save_transcript(self, filename: str,\\\\\\\\\\\\\\\\n                              format_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Save chat transcript to file.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            filename: Output filename\\\\\\\\\\\\\\\\n            format_type: Format (json, txt, html)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        filepath = Path(filename)\\\\\\\\\\\\\\\\n        filepath.parent.mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        messages = list(self.messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n            data = {\\\\\\\\\\\\\\\\n                'metadata': {\\\\\\\\\\\\\\\\n                    'export_timestamp': time.time(),\\\\\\\\\\\\\\\\n                    'total_messages': len(messages),\\\\\\\\\\\\\\\\n                    'statistics': self.get_statistics()\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\n                'messages': [msg.to_dict() for msg in messages]\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                json.dump(data, f, indent=2, ensure_ascii=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                f.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=== DEBATE TRANSCRIPT ===\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                for msg in messages:\\\\\\\\\\\\\\\\n                    f.write(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{msg.formatted_timestamp}] {msg.sender}: {msg.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n            html_content = self._generate_html_transcript(messages)\\\\\\\\\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                f.write(html_content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format: {format_type}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _generate_html_transcript(self, messages: List[Message]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate HTML transcript.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        html = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        <!DOCTYPE html>\\\\\\\\\\\\\\\\n        <html>\\\\\\\\\\\\\\\\n        <head>\\\\\\\\\\\\\\\\n            <title>Debate Transcript</title>\\\\\\\\\\\\\\\\n            <style>\\\\\\\\\\\\\\\\n                body { font-family: Arial, sans-serif; margin: 20px; }\\\\\\\\\\\\\\\\n                .message { margin: 10px 0; padding: 10px; border-left: 3px solid #ccc; }\\\\\\\\\\\\\\\\n                .moderator { border-left-color: #007bff; background: #f8f9fa; }\\\\\\\\\\\\\\\\n                .system { border-left-color: #6c757d; background: #e9ecef; }\\\\\\\\\\\\\\\\n                .timestamp { color: #6c757d; font-size: 0.9em; }\\\\\\\\\\\\\\\\n                .sender { font-weight: bold; }\\\\\\\\\\\\\\\\n            </style>\\\\\\\\\\\\\\\\n        </head>\\\\\\\\\\\\\\\\n        <body>\\\\\\\\\\\\\\\\n            <h1>AI Jubilee Debate Transcript</h1>\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for msg in messages:\\\\\\\\\\\\\\\\n            css_class = msg.message_type if msg.message_type != 'chat' else ''\\\\\\\\\\\\\\\\n            html += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message {css_class}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\n                <span class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">[{msg.formatted_timestamp}]</span>\\\\\\\\\\\\\\\\n                <span class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{msg.sender}:</span>\\\\\\\\\\\\\\\\n                <div>{msg.content}</div>\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        html += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        </body>\\\\\\\\\\\\\\\\n        </html>\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return html\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def load_transcript(self, filename: str) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Load transcript from JSON file.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            filename: Input filename\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        filepath = Path(filename)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if not filepath.exists():\\\\\\\\\\\\\\\\n            raise FileNotFoundError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Transcript file not found: {filename}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with open(filepath, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            data = json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Clear current messages\\\\\\\\\\\\\\\\n        async with self._lock:\\\\\\\\\\\\\\\\n            self.messages.clear()\\\\\\\\\\\\\\\\n            self.message_counter = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Load messages\\\\\\\\\\\\\\\\n            for msg_data in data.get('messages', []):\\\\\\\\\\\\\\\\n                message = Message.from_dict(msg_data)\\\\\\\\\\\\\\\\n                self.messages.append(message)\\\\\\\\\\\\\\\\n                self.message_counter = max(self.message_counter, message.message_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def clear(self) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Clear all messages from the chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.messages.clear()\\\\\\\\\\\\\\\\n        self.message_counter = 0\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\n            'total_messages': 0,\\\\\\\\\\\\\\\\n            'messages_by_sender': {},\\\\\\\\\\\\\\\\n            'start_time': time.time()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __len__(self) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Return number of messages in the log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return len(self.messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __iter__(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iterate over messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return iter(self.messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __getitem__(self, index) -> Message:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get message by index.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return list(self.messages)[index]\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"human_client.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/human_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 20019,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nHuman client implementation for debate participation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .chat_log import Message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass InterfaceConfig:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration for human interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    mode: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    enable_rich_formatting: bool = True\\\\\\\\\\\\\\\\n    show_typing_indicators: bool = True\\\\\\\\\\\\\\\\n    enable_reactions: bool = True\\\\\\\\\\\\\\\\n    input_timeout: int = 120\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass CLIInterface:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Command line interface for human participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, config: InterfaceConfig):\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\n        self.rich_console = None\\\\\\\\\\\\\\\\n        self.input_task = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if config.enable_rich_formatting:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                from rich.console import Console\\\\\\\\\\\\\\\\n                self.rich_console = Console()\\\\\\\\\\\\\\\\n            except ImportError:\\\\\\\\\\\\\\\\n                print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Rich not available, using basic formatting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def display_message(self, message: Message):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Display a message to the user.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        timestamp = time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.localtime(message.timestamp))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if self.rich_console:\\\\\\\\\\\\\\\\n            if message.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                self.rich_console.print(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bold yellow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                self.rich_console.print(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"white\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            if message.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get input from user with timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if self.rich_console:\\\\\\\\\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé§ {prompt}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bold green\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ You have {timeout} seconds to respond...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dim\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé§ {prompt}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ You have {timeout} seconds to respond...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Start input task\\\\\\\\\\\\\\\\n        self.input_task = asyncio.create_task(self._get_user_input())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Wait for input or timeout\\\\\\\\\\\\\\\\n            response = await asyncio.wait_for(self.input_task, timeout=timeout)\\\\\\\\\\\\\\\\n            return response.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\\\\\\\\\n                self.input_task.cancel()\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n                    await self.input_task\\\\\\\\\\\\\\\\n                except asyncio.CancelledError:\\\\\\\\\\\\\\\\n                    pass  # Expected when we cancel\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Return empty string on timeout\\\\\\\\\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\\\\\\\\\n            # Handle external cancellation\\\\\\\\\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\\\\\\\\\n                self.input_task.cancel()\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Input error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\\\\\\\\\n                self.input_task.cancel()\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _get_user_input(self) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get user input asynchronously.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        loop = asyncio.get_event_loop()\\\\\\\\\\\\\\\\n        return await loop.run_in_executor(None, input, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Your response: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show a notification to the user.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        icons = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        icon = icons.get(level, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if self.rich_console:\\\\\\\\\\\\\\\\n            colors = {\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"blue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yellow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"red\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"green\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n            color = colors.get(level, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"blue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{icon} {message}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", style=color)\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{icon} {message}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass WebInterface:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Web interface for human participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, config: InterfaceConfig):\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\n        self.websocket = None\\\\\\\\\\\\\\\\n        self.pending_responses = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def display_message(self, message: Message):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Display message via websocket.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if self.websocket:\\\\\\\\\\\\\\\\n            await self.websocket.send_json({\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": message.to_dict()\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get input via websocket.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.websocket:\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        request_id = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_{time.time()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await self.websocket.send_json({\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_request\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": request_id,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": prompt,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": timeout\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Wait for response\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            response = await asyncio.wait_for(\\\\\\\\\\\\\\\\n                self._wait_for_response(request_id),\\\\\\\\\\\\\\\\n                timeout=timeout\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            return response\\\\\\\\\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _wait_for_response(self, request_id: str) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Wait for websocket response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        while request_id not in self.pending_responses:\\\\\\\\\\\\\\\\n            await asyncio.sleep(0.1)\\\\\\\\\\\\\\\\n        return self.pending_responses.pop(request_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show notification via websocket.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if self.websocket:\\\\\\\\\\\\\\\\n            await self.websocket.send_json({\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": message,\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"level\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": level\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass HumanClient:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Human participant in the debate system.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, name: str, config: Dict[str, Any]):\\\\\\\\\\\\\\\\n        self.name = name\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\n        self.is_active = True\\\\\\\\\\\\\\\\n        self.conversation_history: List[Message] = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Initialize appropriate interface\\\\\\\\\\\\\\\\n        interface_config = InterfaceConfig(\\\\\\\\\\\\\\\\n            mode=config.get('mode', 'cli'),\\\\\\\\\\\\\\\\n            enable_rich_formatting=config.get('enable_rich_formatting', True),\\\\\\\\\\\\\\\\n            show_typing_indicators=config.get('show_typing_indicators', True),\\\\\\\\\\\\\\\\n            enable_reactions=config.get('enable_reactions', True),\\\\\\\\\\\\\\\\n            input_timeout=config.get('input_timeout', 120)\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if interface_config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n            self.interface = CLIInterface(interface_config)\\\\\\\\\\\\\\\\n        elif interface_config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n            self.interface = WebInterface(interface_config)\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported interface mode: {interface_config.mode}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Statistics tracking\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\n            'responses_given': 0,\\\\\\\\\\\\\\\\n            'timeouts': 0,\\\\\\\\\\\\\\\\n            'total_response_time': 0.0,\\\\\\\\\\\\\\\\n            'average_response_time': 0.0\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def get_response(self, topic: str, messages: List[Message]) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get response from human participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Show context in autonomous mode\\\\\\\\\\\\\\\\n            if len(messages) > 0:\\\\\\\\\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìú Recent messages in conversation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n                # Show last 3 messages for context\\\\\\\\\\\\\\\\n                recent = messages[-3:] if len(messages) >= 3 else messages\\\\\\\\\\\\\\\\n                for msg in recent:\\\\\\\\\\\\\\\\n                    await self.interface.display_message(msg)\\\\\\\\\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚îÄ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 50, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Get response with timeout\\\\\\\\\\\\\\\\n            response = await self.interface.get_input(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Your response to: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                timeout=self.config.get('input_timeout', 120)\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Validate and process response\\\\\\\\\\\\\\\\n            if response:\\\\\\\\\\\\\\\\n                validated_response = self._validate_response(response)\\\\\\\\\\\\\\\\n                if validated_response:\\\\\\\\\\\\\\\\n                    # Add to conversation history\\\\\\\\\\\\\\\\n                    response_msg = Message(\\\\\\\\\\\\\\\\n                        sender=self.name,\\\\\\\\\\\\\\\\n                        content=validated_response,\\\\\\\\\\\\\\\\n                        timestamp=time.time(),\\\\\\\\\\\\\\\\n                        message_id=len(self.conversation_history) + 1\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n                    self.conversation_history.append(response_msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Update stats\\\\\\\\\\\\\\\\n                    response_time = time.time() - start_time\\\\\\\\\\\\\\\\n                    self._update_stats(response_time, success=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    return validated_response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Handle timeout/empty response\\\\\\\\\\\\\\\\n            response_time = time.time() - start_time\\\\\\\\\\\\\\\\n            self._update_stats(response_time, success=False)\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            await self.interface.show_notification(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Error getting response: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def autonomous_participation_loop(self, moderator_chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main loop for autonomous participation - human can speak anytime.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéØ AUTONOMOUS DEBATE MODE ACTIVE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó£Ô∏è  You can speak at ANY TIME during the discussion!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úèÔ∏è  Just type your response and press Enter to join the conversation!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        last_message_count = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        while self.is_active:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                # Check for new messages to display\\\\\\\\\\\\\\\\n                current_count = len(moderator_chat_log.messages)\\\\\\\\\\\\\\\\n                if current_count > last_message_count:\\\\\\\\\\\\\\\\n                    # Show new messages\\\\\\\\\\\\\\\\n                    new_messages = moderator_chat_log.messages[last_message_count:]\\\\\\\\\\\\\\\\n                    for msg in new_messages:\\\\\\\\\\\\\\\\n                        if msg.sender != self.name:  # Don't show own messages\\\\\\\\\\\\\\\\n                            await self.interface.display_message(msg)\\\\\\\\\\\\\\\\n                    last_message_count = current_count\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Get input with reasonable timeout\\\\\\\\\\\\\\\\n                response = await self.interface.get_input(\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Type your response (or command):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    timeout=30  # 30 second timeout, then check for new messages\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if not response:\\\\\\\\\\\\\\\\n                    continue  # Timeout, check for new messages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                response = response.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Handle commands\\\\\\\\\\\\\\\\n                if response.lower() == 'quit':\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üëã Leaving the debate. Thanks for participating!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n                    self.is_active = False\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                elif response.lower() == 'help':\\\\\\\\\\\\\\\\n                    await self.show_help()\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                elif response.lower() == 'status':\\\\\\\\\\\\\\\\n                    stats = self.get_stats()\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Your participation: {stats['responses_given']} responses, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{stats['participation_rate']:.1%} participation rate, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"avg response time: {stats['average_response_time']:.1f}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                elif response.lower() == 'history':\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìú Recent conversation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                    recent = moderator_chat_log.get_recent_messages(5)\\\\\\\\\\\\\\\\n                    for msg in recent:\\\\\\\\\\\\\\\\n                        await self.interface.display_message(msg)\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                elif len(response) < 3:\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Please provide a more substantial response (at least 3 characters).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Process actual debate response\\\\\\\\\\\\\\\\n                validated_response = self._validate_response(response)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if validated_response:\\\\\\\\\\\\\\\\n                    # Add to moderator's chat log directly\\\\\\\\\\\\\\\\n                    await moderator_chat_log.add_message(self.name, validated_response)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Update our stats\\\\\\\\\\\\\\\\n                    self.stats['responses_given'] += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Error in autonomous loop: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n                await asyncio.sleep(2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üõë Autonomous participation ended.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def receive_message(self, message: Message):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Receive and display a message from the debate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Don't show our own messages back to us\\\\\\\\\\\\\\\\n        if message.sender == self.name:\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add to conversation history\\\\\\\\\\\\\\\\n        self.conversation_history.append(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Limit history size\\\\\\\\\\\\\\\\n        if len(self.conversation_history) > 30:\\\\\\\\\\\\\\\\n            self.conversation_history = self.conversation_history[-30:]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Display the message\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            await self.interface.display_message(message)\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error displaying message: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def handle_voting(self, candidates: List[str], time_limit: int) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle voting process for human participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó≥Ô∏è Voting phase! You have {time_limit} seconds to vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Show candidates\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã Candidates:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        for i, candidate in enumerate(candidates, 1):\\\\\\\\\\\\\\\\n            await self.interface.show_notification(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  {i}. {candidate}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Get vote choice\\\\\\\\\\\\\\\\n            choice_input = await self.interface.get_input(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter your choice (1-{len(candidates)}):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                timeout=time_limit\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            if not choice_input:\\\\\\\\\\\\\\\\n                return {'voted': False, 'reason': 'timeout'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                choice = int(choice_input.strip())\\\\\\\\\\\\\\\\n                if 1 <= choice <= len(candidates):\\\\\\\\\\\\\\\\n                    selected_candidate = candidates[choice - 1]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Get justification if using CLI\\\\\\\\\\\\\\\\n                    justification = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    if isinstance(self.interface, CLIInterface):\\\\\\\\\\\\\\\\n                        justification = await self.interface.get_input(\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Optional: Why did you choose this candidate?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                            timeout=30\\\\\\\\\\\\\\\\n                        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    return {\\\\\\\\\\\\\\\\n                        'voted': True,\\\\\\\\\\\\\\\\n                        'candidate': selected_candidate,\\\\\\\\\\\\\\\\n                        'justification': justification or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\n                else:\\\\\\\\\\\\\\\\n                    return {'voted': False, 'reason': 'invalid_choice'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            except ValueError:\\\\\\\\\\\\\\\\n                return {'voted': False, 'reason': 'invalid_format'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            await self.interface.show_notification(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Voting error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            return {'voted': False, 'reason': 'error'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def show_help(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show help information for autonomous mode.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        help_text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüéØ AI JUBILEE DEBATE - AUTONOMOUS MODE HELP\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCOMMANDS:\\\\\\\\\\\\\\\\n‚Ä¢ Just type your response and press Enter to join the debate\\\\\\\\\\\\\\\\n‚Ä¢ 'help' - Show this help message\\\\\\\\\\\\\\\\n‚Ä¢ 'status' - Show your participation statistics  \\\\\\\\\\\\\\\\n‚Ä¢ 'history' - Show recent conversation messages\\\\\\\\\\\\\\\\n‚Ä¢ 'quit' - Leave the debate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAUTONOMOUS MODE:\\\\\\\\\\\\\\\\n‚Ä¢ You can speak at ANY TIME during the discussion phase\\\\\\\\\\\\\\\\n‚Ä¢ Bots are monitoring and will respond when they feel compelled\\\\\\\\\\\\\\\\n‚Ä¢ No turn-taking - completely organic conversation flow\\\\\\\\\\\\\\\\n‚Ä¢ Your responses are immediately added to the debate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nTIPS:\\\\\\\\\\\\\\\\n‚Ä¢ Keep responses focused and substantial (3+ characters)\\\\\\\\\\\\\\\\n‚Ä¢ Reference specific points made by others\\\\\\\\\\\\\\\\n‚Ä¢ Feel free to jump in whenever you have something to add!\\\\\\\\\\\\\\\\n‚Ä¢ The debate flows naturally - speak when inspired!\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDEBATE PHASES:\\\\\\\\\\\\\\\\n1. Introduction & Opening Statements (structured)\\\\\\\\\\\\\\\\n2. Autonomous Discussion (free-flowing - you can speak anytime!)\\\\\\\\\\\\\\\\n3. Closing Statements (structured)  \\\\\\\\\\\\\\\\n4. Voting Phase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nEnjoy the organic debate experience! üé≠\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self.interface.show_notification(help_text, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _validate_response(self, response: str) -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Validate and clean up human response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not response or not response.strip():\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Clean up the response\\\\\\\\\\\\\\\\n        response = response.strip()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check length limits\\\\\\\\\\\\\\\\n        max_length = self.config.get('max_message_length', 500)\\\\\\\\\\\\\\\\n        if len(response) > max_length:\\\\\\\\\\\\\\\\n            response = response[:max_length - 3] + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add note for very short responses\\\\\\\\\\\\\\\\n        if len(response) < 10:\\\\\\\\\\\\\\\\n            response += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" [Note: Very short response]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _update_stats(self, response_time: float, success: bool):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update response statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if success:\\\\\\\\\\\\\\\\n            self.stats['responses_given'] += 1\\\\\\\\\\\\\\\\n            self.stats['total_response_time'] += response_time\\\\\\\\\\\\\\\\n            if self.stats['responses_given'] > 0:\\\\\\\\\\\\\\\\n                self.stats['average_response_time'] = (\\\\\\\\\\\\\\\\n                        self.stats['total_response_time'] / self.stats['responses_given']\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            self.stats['timeouts'] += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get comprehensive human client statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        total_attempts = self.stats['responses_given'] + self.stats['timeouts']\\\\\\\\\\\\\\\\n        participation_rate = (\\\\\\\\\\\\\\\\n            self.stats['responses_given'] / total_attempts\\\\\\\\\\\\\\\\n            if total_attempts > 0 else 0\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'name': self.name,\\\\\\\\\\\\\\\\n            'interface_mode': self.interface.config.mode,\\\\\\\\\\\\\\\\n            'responses_given': self.stats['responses_given'],\\\\\\\\\\\\\\\\n            'timeouts': self.stats['timeouts'],\\\\\\\\\\\\\\\\n            'total_attempts': total_attempts,\\\\\\\\\\\\\\\\n            'participation_rate': participation_rate,\\\\\\\\\\\\\\\\n            'average_response_time': self.stats.get('average_response_time', 0),\\\\\\\\\\\\\\\\n            'is_active': self.is_active,\\\\\\\\\\\\\\\\n            'conversation_length': len(self.conversation_history)\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def set_active(self, active: bool):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Set the active status of the human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.is_active = active\\\\\\\\\\\\\\\\n        status = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if active else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"deactivated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîÑ {self.name} has been {status}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __str__(self) -> str:\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human({self.name}, {self.interface.config.mode}, active={self.is_active})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __repr__(self) -> str:\\\\\\\\\\\\\\\\n        return (f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HumanClient(name='{self.name}', mode='{self.interface.config.mode}', \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"active={self.is_active}, responses={self.stats['responses_given']})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"main.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/main.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 4550,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nMain entry point for the AI Jubilee Debate System.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport yaml\\\\\\\\\\\\\\\\nimport click\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nfrom typing import List, Optional\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom dotenv import load_dotenv\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .moderator import Moderator\\\\\\\\\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\\\\\\\\\nfrom .human_client import HumanClient\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\nfrom .streaming import StreamingServer\\\\\\\\\\\\\\\\nfrom .utils import setup_logging, load_config\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nasync def start_debate_session(\\\\\\\\\\\\\\\\n    topic: Optional[str] = None,\\\\\\\\\\\\\\\\n    ai_bots: int = 2,\\\\\\\\\\\\\\\\n    human_participants: int = 1,\\\\\\\\\\\\\\\\n    config_path: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n) -> None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Start a debate session with specified participants.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        topic: Debate topic (if None, uses random from config)\\\\\\\\\\\\\\\\n        ai_bots: Number of AI bot participants\\\\\\\\\\\\\\\\n        human_participants: Number of human participants\\\\\\\\\\\\\\\\n        config_path: Path to configuration file\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Load environment variables from .env file\\\\\\\\\\\\\\\\n    load_dotenv()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Load configuration\\\\\\\\\\\\\\\\n    config = load_config(config_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Setup logging\\\\\\\\\\\\\\\\n    setup_logging(config.get('chat', {}).get('log_level', 'INFO'))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Initialize chat log\\\\\\\\\\\\\\\\n    chat_log = ChatLog()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Initialize voting system\\\\\\\\\\\\\\\\n    voting_system = VotingSystem(config.get('voting', {}))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Select topic\\\\\\\\\\\\\\\\n    if not topic:\\\\\\\\\\\\\\\\n        import random\\\\\\\\\\\\\\\\n        topic = random.choice(config.get('topics', [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Create bot clients\\\\\\\\\\\\\\\\n    bot_clients = []\\\\\\\\\\\\\\\\n    bot_configs = config.get('bots', [])[:ai_bots]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for i, bot_config in enumerate(bot_configs):\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\n            name=bot_config['name'],\\\\\\\\\\\\\\\\n            model=bot_config['model'],\\\\\\\\\\\\\\\\n            provider=bot_config['provider'],\\\\\\\\\\\\\\\\n            personality=bot_config['personality'],\\\\\\\\\\\\\\\\n            stance=bot_config['stance'],\\\\\\\\\\\\\\\\n            api_key=config['api_keys'].get(bot_config['provider'])\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        bot_clients.append(bot)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Create human clients\\\\\\\\\\\\\\\\n    human_clients = []\\\\\\\\\\\\\\\\n    for i in range(human_participants):\\\\\\\\\\\\\\\\n        human = HumanClient(\\\\\\\\\\\\\\\\n            name=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_{i+1}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            interface_config=config.get('interface', {})\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        human_clients.append(human)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Initialize moderator based on debate mode\\\\\\\\\\\\\\\\n    debate_mode = config.get('debate', {}).get('mode', 'sequential')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    moderator = Moderator(\\\\\\\\\\\\\\\\n        topic=topic,\\\\\\\\\\\\\\\\n        participants=bot_clients + human_clients,\\\\\\\\\\\\\\\\n        chat_log=chat_log,\\\\\\\\\\\\\\\\n        voting_system=voting_system,\\\\\\\\\\\\\\\\n        config=config.get('debate', {})\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if debate_mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ Running in AUTONOMOUS mode - bots will decide when to speak!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìù Topic: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Discussion time: {config.get('debate', {}).get('time_limit_minutes', 30)} minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéØ Bots will monitor conversation and jump in when they feel compelled to respond!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìù Running in SEQUENTIAL mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Participants take turns in order\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Initialize streaming server if enabled\\\\\\\\\\\\\\\\n    streaming_server = None\\\\\\\\\\\\\\\\n    if config.get('streaming', {}).get('enabled', False):\\\\\\\\\\\\\\\\n        streaming_server = StreamingServer(\\\\\\\\\\\\\\\\n            chat_log=chat_log,\\\\\\\\\\\\\\\\n            voting_system=voting_system,\\\\\\\\\\\\\\\\n            config=config.get('streaming', {})\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n        await streaming_server.start()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        # Start the debate\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé≠ Starting AI Jubilee Debate: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await moderator.run_debate()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    except KeyboardInterrupt:\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚èπÔ∏è  Debate interrupted by user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    finally:\\\\\\\\\\\\\\\\n        # Cleanup\\\\\\\\\\\\\\\\n        if streaming_server:\\\\\\\\\\\\\\\\n            await streaming_server.stop()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Save transcript\\\\\\\\\\\\\\\\n        if config.get('chat', {}).get('save_transcripts', True):\\\\\\\\\\\\\\\\n            await chat_log.save_transcript(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_{topic[:20]}.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@click.command()\\\\\\\\\\\\\\\\n@click.option('--topic', '-t', help='Debate topic')\\\\\\\\\\\\\\\\n@click.option('--bots', '-b', default=2, help='Number of AI bots')\\\\\\\\\\\\\\\\n@click.option('--humans', '-h', default=1, help='Number of human participants')\\\\\\\\\\\\\\\\n@click.option('--config', '-c', default='config.yaml', help='Configuration file path')\\\\\\\\\\\\\\\\ndef cli(topic: str, bots: int, humans: int, config: str):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Launch the AI Jubilee Debate System.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    asyncio.run(start_debate_session(topic, bots, humans, config))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n    cli()\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"moderator.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/moderator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 27164,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nModerator class for managing debate flow, rules, and coordination.\\\\\\\\\\\\\\\\nSupports both structured and autonomous debate modes.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nimport random\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\nfrom enum import Enum\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog, Message\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\nfrom .utils import format_time_remaining\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass DebatePhase(Enum):\\\\\\\\\\\\\\\\n    INTRODUCTION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"introduction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    OPENING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    DISCUSSION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    CLOSING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    VOTING = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    RESULTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    FINISHED = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"finished\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass DebateState:\\\\\\\\\\\\\\\\n    phase: DebatePhase\\\\\\\\\\\\\\\\n    current_speaker: Optional[str] = None\\\\\\\\\\\\\\\\n    time_remaining: int = 0\\\\\\\\\\\\\\\\n    turn_order: List[str] = None\\\\\\\\\\\\\\\\n    warnings_issued: Dict[str, int] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\n        if self.turn_order is None:\\\\\\\\\\\\\\\\n            self.turn_order = []\\\\\\\\\\\\\\\\n        if self.warnings_issued is None:\\\\\\\\\\\\\\\\n            self.warnings_issued = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass BotState:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Track individual bot state in autonomous mode.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    name: str\\\\\\\\\\\\\\\\n    last_spoke_time: float = 0\\\\\\\\\\\\\\\\n    last_checked_messages: int = 0\\\\\\\\\\\\\\\\n    cooldown_until: float = 0\\\\\\\\\\\\\\\\n    speaking_probability: float = 0.7\\\\\\\\\\\\\\\\n    is_thinking: bool = False\\\\\\\\\\\\\\\\n    consecutive_passes: int = 0\\\\\\\\\\\\\\\\n    total_responses: int = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass Moderator:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Manages debate flow, enforces rules, and coordinates between participants.\\\\\\\\\\\\\\\\n    Supports both structured (sequential) and autonomous debate modes.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, topic: str, participants: List, chat_log: ChatLog,\\\\\\\\\\\\\\\\n                 voting_system: VotingSystem, config: Dict[str, Any]):\\\\\\\\\\\\\\\\n        self.topic = topic\\\\\\\\\\\\\\\\n        self.participants = {p.name: p for p in participants}\\\\\\\\\\\\\\\\n        self.chat_log = chat_log\\\\\\\\\\\\\\\\n        self.voting_system = voting_system\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.state = DebateState(\\\\\\\\\\\\\\\\n            phase=DebatePhase.INTRODUCTION,\\\\\\\\\\\\\\\\n            turn_order=list(self.participants.keys())\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.phase_times = {\\\\\\\\\\\\\\\\n            DebatePhase.OPENING_STATEMENTS: config.get('opening_statement_time', 120),\\\\\\\\\\\\\\\\n            DebatePhase.DISCUSSION: config.get('time_limit_minutes', 30) * 60,\\\\\\\\\\\\\\\\n            DebatePhase.CLOSING_STATEMENTS: config.get('closing_statement_time', 90),\\\\\\\\\\\\\\\\n            DebatePhase.VOTING: config.get('voting_duration', 300)\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.max_response_time = config.get('max_response_time', 120)\\\\\\\\\\\\\\\\n        self.warning_time = config.get('warning_time', 90)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Autonomous mode settings\\\\\\\\\\\\\\\\n        self.autonomous_mode = config.get('mode', 'sequential') == 'autonomous'\\\\\\\\\\\\\\\\n        self.bot_states: Dict[str, BotState] = {}\\\\\\\\\\\\\\\\n        self.bot_tasks: List[asyncio.Task] = []\\\\\\\\\\\\\\\\n        self.phase_task: Optional[asyncio.Task] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Timing controls for autonomous mode\\\\\\\\\\\\\\\\n        self.min_bot_cooldown = config.get('min_bot_cooldown', 15)\\\\\\\\\\\\\\\\n        self.max_bot_cooldown = config.get('max_bot_cooldown', 45)\\\\\\\\\\\\\\\\n        self.message_check_interval = config.get('message_check_interval', 5)\\\\\\\\\\\\\\\\n        self.silence_timeout = config.get('silence_timeout', 60)\\\\\\\\\\\\\\\\n        self.last_activity_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Initialize bot states for autonomous mode\\\\\\\\\\\\\\\\n        if self.autonomous_mode:\\\\\\\\\\\\\\\\n            for participant in self.participants.values():\\\\\\\\\\\\\\\\n                if hasattr(participant, 'config'):  # It's a bot\\\\\\\\\\\\\\\\n                    self.bot_states[participant.name] = BotState(name=participant.name)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def run_debate(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run the complete debate session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        results = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            await self._introduction_phase()\\\\\\\\\\\\\\\\n            await self._opening_statements_phase()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            if self.autonomous_mode:\\\\\\\\\\\\\\\\n                await self._autonomous_discussion_phase()\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                await self._discussion_phase()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            await self._closing_statements_phase()\\\\\\\\\\\\\\\\n            results = await self._voting_phase()\\\\\\\\\\\\\\\\n            await self._results_phase(results)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\n            if self.autonomous_mode:\\\\\\\\\\\\\\\\n                await self._cleanup_autonomous_tasks()\\\\\\\\\\\\\\\\n            self.state.phase = DebatePhase.FINISHED\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _autonomous_discussion_phase(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Autonomous discussion where bots decide when to speak.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\\\\\\\\\\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Autonomous Discussion Phase Begin!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ Bots will monitor the conversation and speak when they feel compelled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Humans can speak at any time.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Total time: {total_time // 60} minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Let the organic debate begin!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.last_activity_time = time.time()\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Start bot monitoring tasks\\\\\\\\\\\\\\\\n        await self._start_bot_monitoring()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Start phase management task\\\\\\\\\\\\\\\\n        self.phase_task = asyncio.create_task(\\\\\\\\\\\\\\\\n            self._manage_autonomous_phase(start_time, total_time)\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            await self.phase_task\\\\\\\\\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\\\\\\\\\n            pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚èπÔ∏è Autonomous discussion phase complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _start_bot_monitoring(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Start monitoring tasks for all bots.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for bot_name, participant in self.participants.items():\\\\\\\\\\\\\\\\n            if hasattr(participant, 'config'):  # It's a bot\\\\\\\\\\\\\\\\n                task = asyncio.create_task(\\\\\\\\\\\\\\\\n                    self._bot_monitoring_loop(bot_name, participant)\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n                self.bot_tasks.append(task)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ {bot_name} is now monitoring the conversation...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _bot_monitoring_loop(self, bot_name: str, bot):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main monitoring loop for each bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_state = self.bot_states[bot_name]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        while self.state.phase == DebatePhase.DISCUSSION:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                await asyncio.sleep(self.message_check_interval)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Check if bot is in cooldown\\\\\\\\\\\\\\\\n                if time.time() < bot_state.cooldown_until:\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Check if there are new messages to consider\\\\\\\\\\\\\\\\n                current_msg_count = len(self.chat_log.messages)\\\\\\\\\\\\\\\\n                if current_msg_count <= bot_state.last_checked_messages:\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Update last checked\\\\\\\\\\\\\\\\n                bot_state.last_checked_messages = current_msg_count\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Get recent conversation context\\\\\\\\\\\\\\\\n                recent_messages = self.chat_log.get_recent_messages(10)\\\\\\\\\\\\\\\\n                full_history = list(self.chat_log.messages)  # Full conversation history\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Decide if bot should speak\\\\\\\\\\\\\\\\n                should_speak = await self._bot_should_speak(bot_name, bot, recent_messages, full_history)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if should_speak:\\\\\\\\\\\\\\\\n                    bot_state.is_thinking = True\\\\\\\\\\\\\\\\n                    await self._broadcast_message(\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí≠ {bot_name} is thinking about responding...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Generate and post response\\\\\\\\\\\\\\\\n                    await self._bot_autonomous_response(bot_name, bot, full_history)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Update bot state\\\\\\\\\\\\\\\\n                    bot_state.last_spoke_time = time.time()\\\\\\\\\\\\\\\\n                    bot_state.total_responses += 1\\\\\\\\\\\\\\\\n                    bot_state.is_thinking = False\\\\\\\\\\\\\\\\n                    bot_state.consecutive_passes = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Set cooldown (longer if bot is very active)\\\\\\\\\\\\\\\\n                    cooldown = self.min_bot_cooldown\\\\\\\\\\\\\\\\n                    if bot_state.total_responses > 3:\\\\\\\\\\\\\\\\n                        cooldown += min(bot_state.total_responses * 5, self.max_bot_cooldown)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    bot_state.cooldown_until = time.time() + cooldown\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Update activity time\\\\\\\\\\\\\\\\n                    self.last_activity_time = time.time()\\\\\\\\\\\\\\\\n                else:\\\\\\\\\\\\\\\\n                    bot_state.consecutive_passes += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\\\\\\\\\n                break\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è {bot_name} monitoring error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n                await asyncio.sleep(5)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _bot_should_speak(self, bot_name: str, bot, recent_messages: List[Message],\\\\\\\\\\\\\\\\n                               full_history: List[Message]) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Determine if bot should speak based on conversation context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_state = self.bot_states[bot_name]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Don't speak if recently spoke\\\\\\\\\\\\\\\\n        if time.time() - bot_state.last_spoke_time < self.min_bot_cooldown:\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Don't speak if currently thinking\\\\\\\\\\\\\\\\n        if bot_state.is_thinking:\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check if bot was mentioned\\\\\\\\\\\\\\\\n        recent_text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join([msg.content for msg in recent_messages[-3:]])\\\\\\\\\\\\\\\\n        if bot_name.lower() in recent_text.lower():\\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check for stance-based triggers\\\\\\\\\\\\\\\\n        triggers_found = self._check_stance_triggers(bot, recent_text)\\\\\\\\\\\\\\\\n        if triggers_found:\\\\\\\\\\\\\\\\n            return random.random() < 0.8  # 80% chance if triggered\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check conversation flow (encourage participation if quiet)\\\\\\\\\\\\\\\\n        bot_recent_count = sum(1 for msg in recent_messages[-5:] if msg.sender == bot_name)\\\\\\\\\\\\\\\\n        if bot_recent_count == 0 and len(recent_messages) >= 3:\\\\\\\\\\\\\\\\n            return random.random() < 0.4  # 40% chance to join if not participated recently\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Random chance to speak (small)\\\\\\\\\\\\\\\\n        base_probability = 0.15\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Increase probability based on time since last participation\\\\\\\\\\\\\\\\n        time_factor = min((time.time() - bot_state.last_spoke_time) / 120, 1.0)  # 2 minutes max\\\\\\\\\\\\\\\\n        adjusted_probability = base_probability + (time_factor * 0.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return random.random() < adjusted_probability\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _check_stance_triggers(self, bot, recent_text: str) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if recent text contains triggers based on bot's stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        recent_lower = recent_text.lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if hasattr(bot, 'config') and hasattr(bot.config, 'stance'):\\\\\\\\\\\\\\\\n            stance = bot.config.stance.lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            if stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                triggers = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"disagree\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"wrong\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"against\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oppose\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bad idea\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"won't work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n                return any(trigger in recent_lower for trigger in triggers)\\\\\\\\\\\\\\\\n            elif stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                triggers = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"agree\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"support\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"favor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"benefit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"good idea\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"will work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n                return any(trigger in recent_lower for trigger in triggers)\\\\\\\\\\\\\\\\n            elif stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                triggers = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"clarify\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"explain\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"evidence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"example\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"what about\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"consider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n                return any(trigger in recent_lower for trigger in triggers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _bot_autonomous_response(self, bot_name: str, bot, full_history: List[Message]):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get autonomous response from bot with full conversation history.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Provide full conversation history for context\\\\\\\\\\\\\\\\n            response = await asyncio.wait_for(\\\\\\\\\\\\\\\\n                bot.get_response(self.topic, full_history),\\\\\\\\\\\\\\\\n                timeout=self.max_response_time\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            if response and response.strip():\\\\\\\\\\\\\\\\n                await self._process_response(bot_name, response)\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ {bot_name} has spoken\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí≠ {bot_name} decided not to respond after all\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {bot_name} took too long to respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è {bot_name} error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _manage_autonomous_phase(self, start_time: float, total_time: int):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Manage the autonomous phase - handle silence and provide incentives.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        incentives_given = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        while time.time() - start_time < total_time:\\\\\\\\\\\\\\\\n            await asyncio.sleep(10)  # Check every 10 seconds\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Check for prolonged silence\\\\\\\\\\\\\\\\n            silence_duration = time.time() - self.last_activity_time\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            if silence_duration > self.silence_timeout:\\\\\\\\\\\\\\\\n                await self._provide_debate_incentive(incentives_given)\\\\\\\\\\\\\\\\n                incentives_given += 1\\\\\\\\\\\\\\\\n                self.last_activity_time = time.time()  # Reset timer\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Give time updates\\\\\\\\\\\\\\\\n            remaining = total_time - (time.time() - start_time)\\\\\\\\\\\\\\\\n            if remaining <= 300 and remaining > 295:  # 5 minutes warning\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ 5 minutes remaining in discussion phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n            elif remaining <= 60 and remaining > 55:  # 1 minute warning\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ 1 minute remaining! Final thoughts?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _provide_debate_incentive(self, incentive_count: int):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provide incentives to encourage participation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        incentives = [\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéØ The conversation seems to have paused. What are your thoughts on the key arguments made so far?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§î Does anyone have evidence or examples to support their position?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí° Are there any important aspects of this topic we haven't explored yet?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚öñÔ∏è How do the benefits and drawbacks compare? What's your perspective?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîç Can someone clarify or expand on the previous points made?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üåü What would be the real-world implications of the positions discussed?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùì Are there any questions or counterarguments you'd like to raise?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé™ Let's keep this lively debate going! Who wants to jump in?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if incentive_count < len(incentives):\\\\\\\\\\\\\\\\n            message = incentives[incentive_count]\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            message = random.choice(incentives)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(message, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Also provide topic-specific prompts\\\\\\\\\\\\\\\\n        topic_lower = self.topic.lower()\\\\\\\\\\\\\\\\n        if \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"remote work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in topic_lower:\\\\\\\\\\\\\\\\n            specific_prompts = [\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üíº What about productivity - does remote work increase or decrease it?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üè† How does remote work affect work-life balance?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üåç What are the environmental implications of remote work?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí∞ What about the economic impact on cities and office spaces?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            ]\\\\\\\\\\\\\\\\n        elif \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in topic_lower:\\\\\\\\\\\\\\\\n            specific_prompts = [\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ What specific jobs might AI create vs eliminate?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Do we have data on AI's employment impact so far?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéì How should education adapt to AI changes?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚öñÔ∏è What role should government play in AI employment policy?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            ]\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            specific_prompts = [\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìà What evidence supports your view on {self.topic}?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîÑ How might {self.topic} evolve in the next 5-10 years?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üåç What are the global implications of {self.topic}?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Who benefits most from your proposed approach to {self.topic}?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if random.random() < 0.3:  # 30% chance for specific prompt\\\\\\\\\\\\\\\\n            specific_message = random.choice(specific_prompts)\\\\\\\\\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\\\\\\\\\n            await self._broadcast_message(specific_message, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _cleanup_autonomous_tasks(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Clean up all autonomous monitoring tasks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Cancel all bot monitoring tasks\\\\\\\\\\\\\\\\n        for task in self.bot_tasks:\\\\\\\\\\\\\\\\n            if not task.done():\\\\\\\\\\\\\\\\n                task.cancel()\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n                    await task\\\\\\\\\\\\\\\\n                except asyncio.CancelledError:\\\\\\\\\\\\\\\\n                    pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Cancel phase management task\\\\\\\\\\\\\\\\n        if self.phase_task and not self.phase_task.done():\\\\\\\\\\\\\\\\n            self.phase_task.cancel()\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                await self.phase_task\\\\\\\\\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\\\\\\\\\n                pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.bot_tasks.clear()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ All autonomous monitoring tasks stopped\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def run_debate(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run the complete debate session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        results = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            await self._introduction_phase()\\\\\\\\\\\\\\\\n            await self._opening_statements_phase()\\\\\\\\\\\\\\\\n            await self._discussion_phase()\\\\\\\\\\\\\\\\n            await self._closing_statements_phase()\\\\\\\\\\\\\\\\n            results = await self._voting_phase()\\\\\\\\\\\\\\\\n            await self._results_phase(results)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\n            self.state.phase = DebatePhase.FINISHED\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _introduction_phase(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Introduce the debate topic and participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠ Welcome to AI Jubilee Debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìù Topic: {self.topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Participants: {', '.join(self.participants.keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è±Ô∏è Total time: {self.config.get('time_limit_minutes', 30)} minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Brief pause for participants to prepare\\\\\\\\\\\\\\\\n        await asyncio.sleep(3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _opening_statements_phase(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle opening statements from each participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.OPENING_STATEMENTS\\\\\\\\\\\\\\\\n        statement_time = self.phase_times[DebatePhase.OPENING_STATEMENTS]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Opening Statements Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Each participant has {statement_time} seconds for their opening statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for participant_name in self.state.turn_order:\\\\\\\\\\\\\\\\n            await self._give_turn(participant_name, statement_time, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening statement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _discussion_phase(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Manage the main discussion phase.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\\\\\\\\\\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Discussion Phase Begin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Open discussion for {total_time // 60} minutes. Maintain respectful dialogue!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\n        response_time = self.config.get('response_time', 60)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        while time.time() - start_time < total_time:\\\\\\\\\\\\\\\\n            # Rotate through participants\\\\\\\\\\\\\\\\n            for participant_name in self.state.turn_order:\\\\\\\\\\\\\\\\n                if time.time() - start_time >= total_time:\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                remaining = total_time - (time.time() - start_time)\\\\\\\\\\\\\\\\n                if remaining < response_time:\\\\\\\\\\\\\\\\n                    response_time = int(remaining)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                await self._give_turn(participant_name, response_time, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Check for time warnings\\\\\\\\\\\\\\\\n                if remaining <= 300:  # 5 minutes\\\\\\\\\\\\\\\\n                    await self._broadcast_message(\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {format_time_remaining(remaining)} remaining in discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚èπÔ∏è Discussion phase complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _closing_statements_phase(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle closing statements.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.CLOSING_STATEMENTS\\\\\\\\\\\\\\\\n        statement_time = self.phase_times[DebatePhase.CLOSING_STATEMENTS]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üèÅ Closing Statements Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Each participant has {statement_time} seconds for final remarks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Reverse order for closing statements\\\\\\\\\\\\\\\\n        for participant_name in reversed(self.state.turn_order):\\\\\\\\\\\\\\\\n            await self._give_turn(participant_name, statement_time, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing statement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _voting_phase(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Conduct voting on debate performance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.VOTING\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if not self.voting_system.enabled:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting disabled. Debate complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó≥Ô∏è Voting Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote for the most persuasive participant. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting closes in {self.phase_times[DebatePhase.VOTING]} seconds.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Enable voting\\\\\\\\\\\\\\\\n        await self.voting_system.start_voting(\\\\\\\\\\\\\\\\n            list(self.participants.keys()),\\\\\\\\\\\\\\\\n            self.phase_times[DebatePhase.VOTING]\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Wait for voting period\\\\\\\\\\\\\\\\n        await asyncio.sleep(self.phase_times[DebatePhase.VOTING])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = await self.voting_system.end_voting()\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _results_phase(self, voting_results: Dict[str, Any]):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Announce final results.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.RESULTS\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if voting_results:\\\\\\\\\\\\\\\\n            winner = voting_results.get('winner')\\\\\\\\\\\\\\\\n            vote_counts = voting_results.get('vote_counts', {})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            results_msg = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üèÜ DEBATE RESULTS üèÜ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            results_msg += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            results_msg += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote Breakdown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            for participant, votes in sorted(vote_counts.items(),\\\\\\\\\\\\\\\\n                                           key=lambda x: x[1], reverse=True):\\\\\\\\\\\\\\\\n                results_msg += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  {participant}: {votes} votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            results_msg = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ù Debate concluded without voting. Great discussion everyone!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(results_msg, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thank you for participating in AI Jubilee Debate! üé≠\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _give_turn(self, participant_name: str, time_limit: int, turn_type: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Give speaking turn to a participant with time management.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.current_speaker = participant_name\\\\\\\\\\\\\\\\n        self.state.time_remaining = time_limit\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        participant = self.participants[participant_name]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ {participant_name}'s turn for {turn_type} ({time_limit}s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Start response task\\\\\\\\\\\\\\\\n            response_task = asyncio.create_task(\\\\\\\\\\\\\\\\n                participant.get_response(self.topic, self.chat_log.get_recent_messages())\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Start timer\\\\\\\\\\\\\\\\n            start_time = time.time()\\\\\\\\\\\\\\\\n            warning_sent = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            while not response_task.done():\\\\\\\\\\\\\\\\n                elapsed = time.time() - start_time\\\\\\\\\\\\\\\\n                remaining = time_limit - elapsed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if remaining <= 0:\\\\\\\\\\\\\\\\n                    # Cancel the task and handle timeout\\\\\\\\\\\\\\\\n                    response_task.cancel()\\\\\\\\\\\\\\\\n                    try:\\\\\\\\\\\\\\\\n                        await response_task\\\\\\\\\\\\\\\\n                    except asyncio.CancelledError:\\\\\\\\\\\\\\\\n                        pass  # Expected when we cancel\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    await self._handle_timeout(participant_name)\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if not warning_sent and remaining <= self.warning_time:\\\\\\\\\\\\\\\\n                    await self._send_warning(participant_name, remaining)\\\\\\\\\\\\\\\\n                    warning_sent = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                await asyncio.sleep(0.5)  # Check every 500ms\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Process response if task completed successfully\\\\\\\\\\\\\\\\n            if response_task.done() and not response_task.cancelled():\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n                    response = await response_task\\\\\\\\\\\\\\\\n                    if response:  # Only process non-empty responses\\\\\\\\\\\\\\\\n                        await self._process_response(participant_name, response)\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\n                    await self._broadcast_message(\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Error getting response from {participant_name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Error during {participant_name}'s turn: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\n            self.state.current_speaker = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _process_response(self, participant_name: str, response: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Process and validate participant response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Basic validation\\\\\\\\\\\\\\\\n        if len(response) > self.config.get('max_message_length', 500):\\\\\\\\\\\\\\\\n            response = response[:self.config.get('max_message_length', 500)] + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è {participant_name}'s response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Log the response\\\\\\\\\\\\\\\\n        await self.chat_log.add_message(participant_name, response)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _handle_timeout(self, participant_name: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle participant timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.state.warnings_issued[participant_name] = (\\\\\\\\\\\\\\\\n            self.state.warnings_issued.get(participant_name, 0) + 1\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {participant_name} exceeded time limit. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning {self.state.warnings_issued[participant_name]}/3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if self.state.warnings_issued[participant_name] >= 3:\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîá {participant_name} muted for repeated violations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _send_warning(self, participant_name: str, time_remaining: float):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send time warning to participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {participant_name}: {int(time_remaining)} seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _broadcast_message(self, content: str, sender: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message to all participants and log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = await self.chat_log.add_message(sender, content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Send to all participants\\\\\\\\\\\\\\\\n        for participant in self.participants.values():\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                await participant.receive_message(message)\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to send message to {participant.name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_state(self) -> DebateState:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get current debate state.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return self.state\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"streaming.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/streaming.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 15845,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nLive streaming and WebSocket server for real-time debate broadcasting.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nimport logging\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Set, Any, Optional\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\\\\\\\\\nimport websockets\\\\\\\\\\\\\\\\nfrom websockets.server import WebSocketServerProtocol\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog, Message\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\nfrom .utils import format_time_remaining\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass StreamingClient:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Information about a connected streaming client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    websocket: WebSocketServerProtocol\\\\\\\\\\\\\\\\n    client_id: str\\\\\\\\\\\\\\\\n    connected_at: float\\\\\\\\\\\\\\\\n    client_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"viewer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # viewer, participant, moderator\\\\\\\\\\\\\\\\n    metadata: Dict[str, Any] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\n        if self.metadata is None:\\\\\\\\\\\\\\\\n            self.metadata = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass StreamingServer:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    WebSocket server for live streaming debate sessions.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, chat_log: ChatLog, voting_system: VotingSystem,\\\\\\\\\\\\\\\\n                 config: Dict[str, Any]):\\\\\\\\\\\\\\\\n        self.chat_log = chat_log\\\\\\\\\\\\\\\\n        self.voting_system = voting_system\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.host = config.get('host', 'localhost')\\\\\\\\\\\\\\\\n        self.port = config.get('websocket_port', 8080)\\\\\\\\\\\\\\\\n        self.max_connections = config.get('max_connections', 100)\\\\\\\\\\\\\\\\n        self.broadcast_votes = config.get('broadcast_votes', True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Server state\\\\\\\\\\\\\\\\n        self.server = None\\\\\\\\\\\\\\\\n        self.clients: Dict[str, StreamingClient] = {}\\\\\\\\\\\\\\\\n        self.is_running = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Message subscription\\\\\\\\\\\\\\\\n        self.message_queue = None\\\\\\\\\\\\\\\\n        self.broadcast_task = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Statistics\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\n            'total_connections': 0,\\\\\\\\\\\\\\\\n            'messages_sent': 0,\\\\\\\\\\\\\\\\n            'votes_broadcast': 0,\\\\\\\\\\\\\\\\n            'start_time': time.time()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.logger = logging.getLogger(__name__)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def start(self) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Start the streaming server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if self.is_running:\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Subscribe to chat log messages\\\\\\\\\\\\\\\\n            self.message_queue = self.chat_log.subscribe()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Start WebSocket server\\\\\\\\\\\\\\\\n            self.server = await websockets.serve(\\\\\\\\\\\\\\\\n                self._handle_client,\\\\\\\\\\\\\\\\n                self.host,\\\\\\\\\\\\\\\\n                self.port,\\\\\\\\\\\\\\\\n                max_size=1024 * 1024,  # 1MB max message size\\\\\\\\\\\\\\\\n                ping_interval=20,\\\\\\\\\\\\\\\\n                ping_timeout=10\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Start broadcast task\\\\\\\\\\\\\\\\n            self.broadcast_task = asyncio.create_task(self._broadcast_loop())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            self.is_running = True\\\\\\\\\\\\\\\\n            self.logger.info(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Streaming server started on {self.host}:{self.port}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to start streaming server: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def stop(self) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stop the streaming server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.is_running:\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.is_running = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Stop broadcast task\\\\\\\\\\\\\\\\n        if self.broadcast_task:\\\\\\\\\\\\\\\\n            self.broadcast_task.cancel()\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                await self.broadcast_task\\\\\\\\\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\\\\\\\\\n                pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Close all client connections\\\\\\\\\\\\\\\\n        if self.clients:\\\\\\\\\\\\\\\\n            await asyncio.gather(\\\\\\\\\\\\\\\\n                *[client.websocket.close() for client in self.clients.values()],\\\\\\\\\\\\\\\\n                return_exceptions=True\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Stop WebSocket server\\\\\\\\\\\\\\\\n        if self.server:\\\\\\\\\\\\\\\\n            self.server.close()\\\\\\\\\\\\\\\\n            await self.server.wait_closed()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Unsubscribe from chat log\\\\\\\\\\\\\\\\n        if self.message_queue:\\\\\\\\\\\\\\\\n            self.chat_log.unsubscribe(self.message_queue)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.logger.info(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Streaming server stopped\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _handle_client(self, websocket: WebSocketServerProtocol, path: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle new client connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if len(self.clients) >= self.max_connections:\\\\\\\\\\\\\\\\n            await websocket.close(code=1013, reason=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Server full\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        client_id = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"client_{int(time.time() * 1000)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        client = StreamingClient(\\\\\\\\\\\\\\\\n            websocket=websocket,\\\\\\\\\\\\\\\\n            client_id=client_id,\\\\\\\\\\\\\\\\n            connected_at=time.time()\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.clients[client_id] = client\\\\\\\\\\\\\\\\n        self.stats['total_connections'] += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.logger.info(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client {client_id} connected from {websocket.remote_address}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            # Send welcome message\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\\\\\\\\\n                'type': 'welcome',\\\\\\\\\\\\\\\\n                'client_id': client_id,\\\\\\\\\\\\\\\\n                'server_info': {\\\\\\\\\\\\\\\\n                    'version': '1.0.0',\\\\\\\\\\\\\\\\n                    'features': ['chat', 'voting', 'real_time']\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Send recent messages\\\\\\\\\\\\\\\\n            recent_messages = self.chat_log.get_recent_messages(10)\\\\\\\\\\\\\\\\n            for msg in recent_messages:\\\\\\\\\\\\\\\\n                await self._send_to_client(client, {\\\\\\\\\\\\\\\\n                    'type': 'message',\\\\\\\\\\\\\\\\n                    'data': msg.to_dict()\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Handle client messages\\\\\\\\\\\\\\\\n            async for message in websocket:\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n                    await self._process_client_message(client, json.loads(message))\\\\\\\\\\\\\\\\n                except json.JSONDecodeError:\\\\\\\\\\\\\\\\n                    await self._send_error(client, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid JSON message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\n                    self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing client message: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                    await self._send_error(client, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Internal server error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except websockets.exceptions.ConnectionClosed:\\\\\\\\\\\\\\\\n            self.logger.info(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client {client_id} disconnected\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client {client_id} error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\n            # Clean up client\\\\\\\\\\\\\\\\n            if client_id in self.clients:\\\\\\\\\\\\\\\\n                del self.clients[client_id]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _process_client_message(self, client: StreamingClient, data: Dict[str, Any]):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Process message from client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message_type = data.get('type')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if message_type == 'ping':\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {'type': 'pong'})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif message_type == 'subscribe':\\\\\\\\\\\\\\\\n            # Update client subscription preferences\\\\\\\\\\\\\\\\n            client.metadata['subscriptions'] = data.get('channels', [])\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\\\\\\\\\n                'type': 'subscribed',\\\\\\\\\\\\\\\\n                'channels': client.metadata.get('subscriptions', [])\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif message_type == 'get_stats':\\\\\\\\\\\\\\\\n            # Send server statistics\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\\\\\\\\\n                'type': 'stats',\\\\\\\\\\\\\\\\n                'data': self._get_server_stats()\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif message_type == 'vote' and self.voting_system.is_active:\\\\\\\\\\\\\\\\n            # Handle vote from client\\\\\\\\\\\\\\\\n            voter_id = data.get('voter_id', client.client_id)\\\\\\\\\\\\\\\\n            candidate = data.get('candidate')\\\\\\\\\\\\\\\\n            justification = data.get('justification')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                success = await self.voting_system.cast_vote(\\\\\\\\\\\\\\\\n                    voter_id, candidate, justification\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                await self._send_to_client(client, {\\\\\\\\\\\\\\\\n                    'type': 'vote_result',\\\\\\\\\\\\\\\\n                    'success': success,\\\\\\\\\\\\\\\\n                    'candidate': candidate\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if success and self.broadcast_votes:\\\\\\\\\\\\\\\\n                    await self._broadcast_vote_update()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                await self._send_error(client, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            await self._send_error(client, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unknown message type: {message_type}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _broadcast_loop(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main broadcast loop for new messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            while self.is_running:\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n                    # Wait for new message from chat log\\\\\\\\\\\\\\\\n                    message = await asyncio.wait_for(\\\\\\\\\\\\\\\\n                        self.message_queue.get(),\\\\\\\\\\\\\\\\n                        timeout=1.0\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Broadcast to all clients\\\\\\\\\\\\\\\\n                    await self._broadcast_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                except asyncio.TimeoutError:\\\\\\\\\\\\\\\\n                    # Timeout is expected, continue loop\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\n                    self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast loop error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                    await asyncio.sleep(1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\\\\\\\\\n            self.logger.info(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast loop cancelled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _broadcast_message(self, message: Message):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message to all connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.clients:\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        broadcast_data = {\\\\\\\\\\\\\\\\n            'type': 'message',\\\\\\\\\\\\\\\\n            'data': message.to_dict()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Send to all clients\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\\\\\\\\\n            if self._should_send_to_client(client, message):\\\\\\\\\\\\\\\\n                tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\n            self.stats['messages_sent'] += len(tasks)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _should_send_to_client(self, client: StreamingClient, message: Message) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Determine if message should be sent to client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Check client subscriptions\\\\\\\\\\\\\\\\n        subscriptions = client.metadata.get('subscriptions', [])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if subscriptions:\\\\\\\\\\\\\\\\n            # If client has specific subscriptions, check them\\\\\\\\\\\\\\\\n            if message.message_type not in subscriptions:\\\\\\\\\\\\\\\\n                return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _broadcast_vote_update(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast voting update to clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.voting_system.is_active:\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        vote_summary = self.voting_system.get_vote_summary()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        broadcast_data = {\\\\\\\\\\\\\\\\n            'type': 'vote_update',\\\\\\\\\\\\\\\\n            'data': vote_summary\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\\\\\\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\n            self.stats['votes_broadcast'] += 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _send_to_client(self, client: StreamingClient, data: Dict[str, Any]):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send data to specific client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            await client.websocket.send(json.dumps(data))\\\\\\\\\\\\\\\\n        except websockets.exceptions.ConnectionClosed:\\\\\\\\\\\\\\\\n            # Client disconnected, will be cleaned up\\\\\\\\\\\\\\\\n            pass\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to send to client {client.client_id}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def _send_error(self, client: StreamingClient, error_message: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send error message to client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await self._send_to_client(client, {\\\\\\\\\\\\\\\\n            'type': 'error',\\\\\\\\\\\\\\\\n            'message': error_message\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _get_server_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get server statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        uptime = time.time() - self.stats['start_time']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'connected_clients': len(self.clients),\\\\\\\\\\\\\\\\n            'total_connections': self.stats['total_connections'],\\\\\\\\\\\\\\\\n            'messages_sent': self.stats['messages_sent'],\\\\\\\\\\\\\\\\n            'votes_broadcast': self.stats['votes_broadcast'],\\\\\\\\\\\\\\\\n            'uptime_seconds': uptime,\\\\\\\\\\\\\\\\n            'uptime_formatted': format_time_remaining(uptime),\\\\\\\\\\\\\\\\n            'is_voting_active': self.voting_system.is_active if self.voting_system else False\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def broadcast_custom_message(self, message_type: str, data: Any):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast custom message to all clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        broadcast_data = {\\\\\\\\\\\\\\\\n            'type': message_type,\\\\\\\\\\\\\\\\n            'data': data,\\\\\\\\\\\\\\\\n            'timestamp': time.time()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\\\\\\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def send_to_specific_clients(self, client_ids: List[str],\\\\\\\\\\\\\\\\n                                       message_type: str, data: Any):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send message to specific clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = {\\\\\\\\\\\\\\\\n            'type': message_type,\\\\\\\\\\\\\\\\n            'data': data,\\\\\\\\\\\\\\\\n            'timestamp': time.time()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\n        for client_id in client_ids:\\\\\\\\\\\\\\\\n            if client_id in self.clients:\\\\\\\\\\\\\\\\n                client = self.clients[client_id]\\\\\\\\\\\\\\\\n                tasks.append(self._send_to_client(client, message))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_connected_clients(self) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get information about connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return [\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\n                'client_id': client.client_id,\\\\\\\\\\\\\\\\n                'connected_at': client.connected_at,\\\\\\\\\\\\\\\\n                'client_type': client.client_type,\\\\\\\\\\\\\\\\n                'connection_duration': time.time() - client.connected_at\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n            for client in self.clients.values()\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\n    def is_active(self) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if server is running.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return self.is_running\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\n    def client_count(self) -> int:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get number of connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return len(self.clients)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass StreamingManager:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    High-level manager for streaming functionality.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self):\\\\\\\\\\\\\\\\n        self.servers: Dict[str, StreamingServer] = {}\\\\\\\\\\\\\\\\n        self.is_initialized = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def create_streaming_session(self, session_id: str, chat_log: ChatLog,\\\\\\\\\\\\\\\\n                                       voting_system: VotingSystem,\\\\\\\\\\\\\\\\n                                       config: Dict[str, Any]) -> StreamingServer:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Create a new streaming session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            session_id: Unique session identifier\\\\\\\\\\\\\\\\n            chat_log: Chat log to stream\\\\\\\\\\\\\\\\n            voting_system: Voting system to integrate\\\\\\\\\\\\\\\\n            config: Streaming configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            StreamingServer instance\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if session_id in self.servers:\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Streaming session {session_id} already exists\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Create unique port for this session\\\\\\\\\\\\\\\\n        base_port = config.get('websocket_port', 8080)\\\\\\\\\\\\\\\\n        port = base_port + len(self.servers)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        session_config = config.copy()\\\\\\\\\\\\\\\\n        session_config['websocket_port'] = port\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        server = StreamingServer(chat_log, voting_system, session_config)\\\\\\\\\\\\\\\\n        self.servers[session_id] = server\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await server.start()\\\\\\\\\\\\\\\\n        return server\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def stop_streaming_session(self, session_id: str):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stop a streaming session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if session_id in self.servers:\\\\\\\\\\\\\\\\n            server = self.servers[session_id]\\\\\\\\\\\\\\\\n            await server.stop()\\\\\\\\\\\\\\\\n            del self.servers[session_id]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def stop_all_sessions(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stop all streaming sessions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\n        for session_id in list(self.servers.keys()):\\\\\\\\\\\\\\\\n            tasks.append(self.stop_streaming_session(session_id))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get information about a streaming session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if session_id not in self.servers:\\\\\\\\\\\\\\\\n            return None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        server = self.servers[session_id]\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'session_id': session_id,\\\\\\\\\\\\\\\\n            'is_active': server.is_active,\\\\\\\\\\\\\\\\n            'client_count': server.client_count,\\\\\\\\\\\\\\\\n            'host': server.host,\\\\\\\\\\\\\\\\n            'port': server.port,\\\\\\\\\\\\\\\\n            'stats': server._get_server_stats()\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def list_active_sessions(self) -> List[str]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get list of active session IDs.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return [\\\\\\\\\\\\\\\\n            session_id for session_id, server in self.servers.items()\\\\\\\\\\\\\\\\n            if server.is_active\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"utils.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/utils.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 10954,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nUtility functions for the AI Jubilee Debate System.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport yaml\\\\\\\\\\\\\\\\nimport logging\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nimport re\\\\\\\\\\\\\\\\nfrom typing import Dict, Any, List, Optional\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom datetime import datetime, timedelta\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef load_config(config_path: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> Dict[str, Any]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Load configuration from YAML file with environment variable substitution.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        config_path: Path to configuration file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Configuration dictionary\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    config_file = Path(config_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not config_file.exists():\\\\\\\\\\\\\\\\n        raise FileNotFoundError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration file not found: {config_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    with open(config_file, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n        config_content = f.read()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Substitute environment variables\\\\\\\\\\\\\\\\n    config_content = substitute_env_vars(config_content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        config = yaml.safe_load(config_content)\\\\\\\\\\\\\\\\n        return config\\\\\\\\\\\\\\\\n    except yaml.YAMLError as e:\\\\\\\\\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid YAML configuration: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef substitute_env_vars(text: str) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Substitute environment variables in text using ${VAR_NAME} syntax.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        text: Text containing environment variable references\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Text with environment variables substituted\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    def replace_env_var(match):\\\\\\\\\\\\\\\\n        var_name = match.group(1)\\\\\\\\\\\\\\\\n        env_value = os.getenv(var_name)\\\\\\\\\\\\\\\\n        if env_value is None:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning: Environment variable {var_name} not found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"${{{var_name}}}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Keep original if not found\\\\\\\\\\\\\\\\n        return env_value\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return re.sub(r'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\$\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\{([^}]+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}', replace_env_var, text)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef setup_logging(level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", log_file: Optional[str] = None) -> None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Setup logging configuration.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        level: Logging level (DEBUG, INFO, WARNING, ERROR)\\\\\\\\\\\\\\\\n        log_file: Optional log file path\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Create formatter\\\\\\\\\\\\\\\\n    formatter = logging.Formatter(\\\\\\\\\\\\\\\\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Setup root logger\\\\\\\\\\\\\\\\n    root_logger = logging.getLogger()\\\\\\\\\\\\\\\\n    root_logger.setLevel(numeric_level)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Clear existing handlers\\\\\\\\\\\\\\\\n    root_logger.handlers.clear()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Console handler\\\\\\\\\\\\\\\\n    console_handler = logging.StreamHandler()\\\\\\\\\\\\\\\\n    console_handler.setFormatter(formatter)\\\\\\\\\\\\\\\\n    root_logger.addHandler(console_handler)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # File handler if specified\\\\\\\\\\\\\\\\n    if log_file:\\\\\\\\\\\\\\\\n        file_handler = logging.FileHandler(log_file)\\\\\\\\\\\\\\\\n        file_handler.setFormatter(formatter)\\\\\\\\\\\\\\\\n        root_logger.addHandler(file_handler)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef format_time_remaining(seconds: float) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Format remaining time in human-readable format.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        seconds: Time remaining in seconds\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Formatted time string\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if seconds <= 0:\\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Time's up!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if seconds < 60:\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{int(seconds)} seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    elif seconds < 3600:\\\\\\\\\\\\\\\\n        minutes = int(seconds // 60)\\\\\\\\\\\\\\\\n        secs = int(seconds % 60)\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{minutes}m {secs}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n        hours = int(seconds // 3600)\\\\\\\\\\\\\\\\n        minutes = int((seconds % 3600) // 60)\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{hours}h {minutes}m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Truncate text to maximum length with suffix.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        text: Text to truncate\\\\\\\\\\\\\\\\n        max_length: Maximum length\\\\\\\\\\\\\\\\n        suffix: Suffix to add when truncating\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Truncated text\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if len(text) <= max_length:\\\\\\\\\\\\\\\\n        return text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return text[:max_length - len(suffix)] + suffix\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef generate_debate_prompt(topic: str, role: str, personality: str) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Generate a debate prompt for AI participants.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        topic: Debate topic\\\\\\\\\\\\\\\\n        role: Participant role (pro, con, neutral)\\\\\\\\\\\\\\\\n        personality: Personality description\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Generated prompt\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    base_prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are participating in a structured debate on the topic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nYour role: {role}\\\\\\\\\\\\\\\\nYour personality: {personality}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nInstructions:\\\\\\\\\\\\\\\\n1. Present clear, logical arguments\\\\\\\\\\\\\\\\n2. Respond to other participants' points\\\\\\\\\\\\\\\\n3. Stay focused on the topic\\\\\\\\\\\\\\\\n4. Be respectful but persuasive\\\\\\\\\\\\\\\\n5. Keep responses concise and engaging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCurrent debate topic: {topic}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if role.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue IN FAVOR of the topic.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    elif role.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue AGAINST the topic.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    elif role.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should present balanced perspectives and ask probing questions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return base_prompt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef validate_participant_name(name: str) -> bool:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Validate participant name.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        name: Participant name to validate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        True if valid, False otherwise\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if not name or len(name.strip()) == 0:\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Check length\\\\\\\\\\\\\\\\n    if len(name) > 50:\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Check for valid characters (alphanumeric, spaces, underscores, hyphens)\\\\\\\\\\\\\\\\n    if not re.match(r'^[a-zA-Z0-9\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s_-]+$', name):\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef sanitize_filename(filename: str) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Sanitize filename for safe file operations.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        filename: Original filename\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Sanitized filename\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Remove or replace invalid characters\\\\\\\\\\\\\\\\n    sanitized = re.sub(r'[<>:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|?*]', '_', filename)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Remove leading/trailing spaces and dots\\\\\\\\\\\\\\\\n    sanitized = sanitized.strip(' .')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Limit length\\\\\\\\\\\\\\\\n    if len(sanitized) > 255:\\\\\\\\\\\\\\\\n        sanitized = sanitized[:255]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return sanitized\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef parse_duration(duration_str: str) -> int:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Parse duration string into seconds.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        duration_str: Duration string (e.g., \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"30s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1h30m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Duration in seconds\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if duration_str.isdigit():\\\\\\\\\\\\\\\\n        return int(duration_str)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    total_seconds = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Parse hours\\\\\\\\\\\\\\\\n    hours_match = re.search(r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d+)h', duration_str.lower())\\\\\\\\\\\\\\\\n    if hours_match:\\\\\\\\\\\\\\\\n        total_seconds += int(hours_match.group(1)) * 3600\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Parse minutes\\\\\\\\\\\\\\\\n    minutes_match = re.search(r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d+)m', duration_str.lower())\\\\\\\\\\\\\\\\n    if minutes_match:\\\\\\\\\\\\\\\\n        total_seconds += int(minutes_match.group(1)) * 60\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Parse seconds\\\\\\\\\\\\\\\\n    seconds_match = re.search(r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d+)s', duration_str.lower())\\\\\\\\\\\\\\\\n    if seconds_match:\\\\\\\\\\\\\\\\n        total_seconds += int(seconds_match.group(1))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return total_seconds if total_seconds > 0 else 60  # Default to 60 seconds\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef create_timestamp() -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Create ISO format timestamp.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        ISO formatted timestamp string\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return datetime.now().isoformat()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef format_participant_list(participants: List[str], max_display: int = 5) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Format participant list for display.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        participants: List of participant names\\\\\\\\\\\\\\\\n        max_display: Maximum participants to display before truncating\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Formatted participant string\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if len(participants) <= max_display:\\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(participants)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    displayed = participants[:max_display]\\\\\\\\\\\\\\\\n    remaining = len(participants) - max_display\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{', '.join(displayed)} (+{remaining} more)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef calculate_word_count(text: str) -> int:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Calculate word count in text.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        text: Text to count words in\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Number of words\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return len(text.split())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef extract_key_phrases(text: str, max_phrases: int = 5) -> List[str]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Extract key phrases from text (simple implementation).\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        text: Text to extract phrases from\\\\\\\\\\\\\\\\n        max_phrases: Maximum number of phrases to return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        List of key phrases\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Simple implementation - could be enhanced with NLP\\\\\\\\\\\\\\\\n    sentences = text.split('.')\\\\\\\\\\\\\\\\n    phrases = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for sentence in sentences[:max_phrases]:\\\\\\\\\\\\\\\\n        sentence = sentence.strip()\\\\\\\\\\\\\\\\n        if len(sentence) > 10:  # Minimum length\\\\\\\\\\\\\\\\n            phrases.append(sentence)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return phrases[:max_phrases]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef generate_session_id() -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Generate unique session ID.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Unique session identifier\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    import uuid\\\\\\\\\\\\\\\\n    return str(uuid.uuid4())[:8]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef ensure_directory(path: str) -> Path:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Ensure directory exists, create if necessary.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        path: Directory path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Path object\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    dir_path = Path(path)\\\\\\\\\\\\\\\\n    dir_path.mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\n    return dir_path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef load_debate_topics(topics_file: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"topics.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> List[str]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Load debate topics from file.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        topics_file: Path to topics file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        List of debate topics\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    topics_path = Path(topics_file)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not topics_path.exists():\\\\\\\\\\\\\\\\n        # Return default topics\\\\\\\\\\\\\\\\n        return [\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Artificial intelligence will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Social media has a net positive impact on society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    with open(topics_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n        topics = [line.strip() for line in f if line.strip() and not line.startswith('#')]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return topics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass PerformanceTimer:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Context manager for timing operations.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, operation_name: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Operation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n        self.operation_name = operation_name\\\\\\\\\\\\\\\\n        self.start_time = None\\\\\\\\\\\\\\\\n        self.end_time = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __enter__(self):\\\\\\\\\\\\\\\\n        self.start_time = time.time()\\\\\\\\\\\\\\\\n        return self\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\\\\\\\\\\\\\\\n        self.end_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\n    def duration(self) -> float:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get operation duration in seconds.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if self.start_time and self.end_time:\\\\\\\\\\\\\\\\n            return self.end_time - self.start_time\\\\\\\\\\\\\\\\n        return 0.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __str__(self) -> str:\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.operation_name}: {self.duration:.3f}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Decorator for retrying operations with exponential backoff.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        max_retries: Maximum number of retry attempts\\\\\\\\\\\\\\\\n        base_delay: Base delay between retries\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    def decorator(func):\\\\\\\\\\\\\\\\n        async def wrapper(*args, **kwargs):\\\\\\\\\\\\\\\\n            last_exception = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            for attempt in range(max_retries + 1):\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\n                    return await func(*args, **kwargs)\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\n                    last_exception = e\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    if attempt < max_retries:\\\\\\\\\\\\\\\\n                        delay = base_delay * (2 ** attempt)\\\\\\\\\\\\\\\\n                        await asyncio.sleep(delay)\\\\\\\\\\\\\\\\n                    else:\\\\\\\\\\\\\\\\n                        raise last_exception\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            raise last_exception\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return wrapper\\\\\\\\\\\\\\\\n    return decorator\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"voting.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"app/voting.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 11436,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nVoting system for debate evaluation and winner determination.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Optional, Any\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, field\\\\\\\\\\\\\\\\nfrom collections import defaultdict, Counter\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass Vote:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Represents a single vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    voter_id: str\\\\\\\\\\\\\\\\n    candidate: str\\\\\\\\\\\\\\\\n    justification: Optional[str] = None\\\\\\\\\\\\\\\\n    timestamp: float = field(default_factory=time.time)\\\\\\\\\\\\\\\\n    anonymous: bool = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass VotingResults:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Results of a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    winner: Optional[str]\\\\\\\\\\\\\\\\n    vote_counts: Dict[str, int]\\\\\\\\\\\\\\\\n    total_votes: int\\\\\\\\\\\\\\\\n    votes_by_voter: Dict[str, Vote]\\\\\\\\\\\\\\\\n    voting_duration: float\\\\\\\\\\\\\\\\n    participation_rate: float\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass VotingSystem:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Manages voting process, vote collection, and result calculation.\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def __init__(self, config: Dict[str, Any]):\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\n        self.enabled = config.get('enabled', True)\\\\\\\\\\\\\\\\n        self.voting_duration = config.get('voting_duration', 300)\\\\\\\\\\\\\\\\n        self.allow_participant_voting = config.get('allow_participant_voting', True)\\\\\\\\\\\\\\\\n        self.require_justification = config.get('require_justification', True)\\\\\\\\\\\\\\\\n        self.anonymous_votes = config.get('anonymous_votes', False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Voting state\\\\\\\\\\\\\\\\n        self.is_active = False\\\\\\\\\\\\\\\\n        self.candidates: List[str] = []\\\\\\\\\\\\\\\\n        self.eligible_voters: List[str] = []\\\\\\\\\\\\\\\\n        self.votes: Dict[str, Vote] = {}\\\\\\\\\\\\\\\\n        self.start_time: Optional[float] = None\\\\\\\\\\\\\\\\n        self.end_time: Optional[float] = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Vote validation\\\\\\\\\\\\\\\\n        self.vote_history: List[Dict[str, Any]] = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def start_voting(self, candidates: List[str], duration: Optional[int] = None) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Start a voting session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            candidates: List of debate participants to vote for\\\\\\\\\\\\\\\\n            duration: Voting duration in seconds (uses config default if None)\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.enabled:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting system is disabled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if self.is_active:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting session already active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.candidates = candidates.copy()\\\\\\\\\\\\\\\\n        self.eligible_voters = candidates.copy() if self.allow_participant_voting else []\\\\\\\\\\\\\\\\n        self.votes = {}\\\\\\\\\\\\\\\\n        self.start_time = time.time()\\\\\\\\\\\\\\\\n        self.end_time = self.start_time + (duration or self.voting_duration)\\\\\\\\\\\\\\\\n        self.is_active = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó≥Ô∏è Voting started for {len(candidates)} candidates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Voting closes in {duration or self.voting_duration} seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def cast_vote(self, voter_id: str, candidate: str,\\\\\\\\\\\\\\\\n                        justification: Optional[str] = None) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Cast a vote for a candidate.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            voter_id: ID of the voter\\\\\\\\\\\\\\\\n            candidate: Candidate being voted for\\\\\\\\\\\\\\\\n            justification: Optional reasoning for the vote\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            True if vote was successfully cast, False otherwise\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if time.time() > self.end_time:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting period has ended\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Validate voter eligibility\\\\\\\\\\\\\\\\n        if not self._is_eligible_voter(voter_id):\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voter {voter_id} is not eligible to vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Validate candidate\\\\\\\\\\\\\\\\n        if candidate not in self.candidates:\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid candidate: {candidate}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check for self-voting\\\\\\\\\\\\\\\\n        if voter_id == candidate and not self.allow_participant_voting:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Self-voting is not allowed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Validate justification requirement\\\\\\\\\\\\\\\\n        if self.require_justification and not justification:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote justification is required\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Record the vote (overwrites previous vote from same voter)\\\\\\\\\\\\\\\\n        vote = Vote(\\\\\\\\\\\\\\\\n            voter_id=voter_id,\\\\\\\\\\\\\\\\n            candidate=candidate,\\\\\\\\\\\\\\\\n            justification=justification,\\\\\\\\\\\\\\\\n            anonymous=self.anonymous_votes\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.votes[voter_id] = vote\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Vote recorded: {voter_id} -> {candidate}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def end_voting(self) -> VotingResults:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        End the voting session and calculate results.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            VotingResults object with winner and vote breakdown\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        self.is_active = False\\\\\\\\\\\\\\\\n        actual_end_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Calculate vote counts\\\\\\\\\\\\\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\\\\\\\\\\\\\n        total_votes = len(self.votes)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Determine winner\\\\\\\\\\\\\\\\n        winner = None\\\\\\\\\\\\\\\\n        if vote_counts:\\\\\\\\\\\\\\\\n            max_votes = max(vote_counts.values())\\\\\\\\\\\\\\\\n            winners = [candidate for candidate, count in vote_counts.items()\\\\\\\\\\\\\\\\n                       if count == max_votes]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            if len(winners) == 1:\\\\\\\\\\\\\\\\n                winner = winners[0]\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                # Handle tie - could implement tiebreaker logic here\\\\\\\\\\\\\\\\n                winner = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TIE: {', '.join(winners)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Calculate participation rate\\\\\\\\\\\\\\\\n        participation_rate = (total_votes / len(self.eligible_voters)\\\\\\\\\\\\\\\\n                              if self.eligible_voters else 0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Create results\\\\\\\\\\\\\\\\n        results = VotingResults(\\\\\\\\\\\\\\\\n            winner=winner,\\\\\\\\\\\\\\\\n            vote_counts=dict(vote_counts),\\\\\\\\\\\\\\\\n            total_votes=total_votes,\\\\\\\\\\\\\\\\n            votes_by_voter=self.votes.copy(),\\\\\\\\\\\\\\\\n            voting_duration=actual_end_time - self.start_time,\\\\\\\\\\\\\\\\n            participation_rate=participation_rate\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Store in history\\\\\\\\\\\\\\\\n        self.vote_history.append({\\\\\\\\\\\\\\\\n            'timestamp': actual_end_time,\\\\\\\\\\\\\\\\n            'candidates': self.candidates.copy(),\\\\\\\\\\\\\\\\n            'results': results\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üèÜ Voting ended. Winner: {winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Total votes: {total_votes}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìà Participation: {participation_rate:.1%}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def _is_eligible_voter(self, voter_id: str) -> bool:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if a voter is eligible to vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.eligible_voters:\\\\\\\\\\\\\\\\n            return True  # Open voting\\\\\\\\\\\\\\\\n        return voter_id in self.eligible_voters\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def add_eligible_voter(self, voter_id: str) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Add a voter to the eligible voters list.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if voter_id not in self.eligible_voters:\\\\\\\\\\\\\\\\n            self.eligible_voters.append(voter_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def remove_eligible_voter(self, voter_id: str) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove a voter from the eligible voters list.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if voter_id in self.eligible_voters:\\\\\\\\\\\\\\\\n            self.eligible_voters.remove(voter_id)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_vote_summary(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get current voting summary without ending the session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\n            return {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\\\\\\\\\\\\\n        time_remaining = max(0, self.end_time - time.time())\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'candidates': self.candidates,\\\\\\\\\\\\\\\\n            'vote_counts': dict(vote_counts),\\\\\\\\\\\\\\\\n            'total_votes': len(self.votes),\\\\\\\\\\\\\\\\n            'time_remaining': time_remaining,\\\\\\\\\\\\\\\\n            'is_active': self.is_active\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_voter_history(self, voter_id: str) -> List[Vote]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get voting history for a specific voter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        history = []\\\\\\\\\\\\\\\\n        for session in self.vote_history:\\\\\\\\\\\\\\\\n            votes = session.get('results', {}).votes_by_voter\\\\\\\\\\\\\\\\n            if voter_id in votes:\\\\\\\\\\\\\\\\n                history.append(votes[voter_id])\\\\\\\\\\\\\\\\n        return history\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def get_candidate_performance(self, candidate: str) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get performance statistics for a candidate across all sessions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        wins = 0\\\\\\\\\\\\\\\\n        total_votes = 0\\\\\\\\\\\\\\\\n        participations = 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for session in self.vote_history:\\\\\\\\\\\\\\\\n            results = session.get('results', {})\\\\\\\\\\\\\\\\n            if candidate in session.get('candidates', []):\\\\\\\\\\\\\\\\n                participations += 1\\\\\\\\\\\\\\\\n                if results.winner == candidate:\\\\\\\\\\\\\\\\n                    wins += 1\\\\\\\\\\\\\\\\n                total_votes += results.vote_counts.get(candidate, 0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'candidate': candidate,\\\\\\\\\\\\\\\\n            'wins': wins,\\\\\\\\\\\\\\\\n            'total_votes': total_votes,\\\\\\\\\\\\\\\\n            'participations': participations,\\\\\\\\\\\\\\\\n            'win_rate': wins / participations if participations > 0 else 0,\\\\\\\\\\\\\\\\n            'avg_votes': total_votes / participations if participations > 0 else 0\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    async def export_results(self, format_type: str = 'json') -> str:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        Export voting results in specified format.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\n            format_type: Export format ('json', 'csv', 'txt')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\n            Formatted results string\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        if not self.vote_history:\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No voting history available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if format_type == 'json':\\\\\\\\\\\\\\\\n            import json\\\\\\\\\\\\\\\\n            return json.dumps(self.vote_history, indent=2, default=str)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif format_type == 'csv':\\\\\\\\\\\\\\\\n            import csv\\\\\\\\\\\\\\\\n            import io\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            output = io.StringIO()\\\\\\\\\\\\\\\\n            writer = csv.writer(output)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Header\\\\\\\\\\\\\\\\n            writer.writerow(['Session', 'Timestamp', 'Candidate', 'Votes', 'Winner'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Data\\\\\\\\\\\\\\\\n            for i, session in enumerate(self.vote_history):\\\\\\\\\\\\\\\\n                results = session.get('results', {})\\\\\\\\\\\\\\\\n                timestamp = session.get('timestamp', '')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                for candidate, votes in results.vote_counts.items():\\\\\\\\\\\\\\\\n                    writer.writerow([\\\\\\\\\\\\\\\\n                        i + 1,\\\\\\\\\\\\\\\\n                        timestamp,\\\\\\\\\\\\\\\\n                        candidate,\\\\\\\\\\\\\\\\n                        votes,\\\\\\\\\\\\\\\\n                        results.winner == candidate\\\\\\\\\\\\\\\\n                    ])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            return output.getvalue()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        elif format_type == 'txt':\\\\\\\\\\\\\\\\n            output = []\\\\\\\\\\\\\\\\n            output.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=== VOTING HISTORY REPORT ===\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            for i, session in enumerate(self.vote_history):\\\\\\\\\\\\\\\\n                results = session.get('results', {})\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Session {i + 1}:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  Winner: {results.winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  Total Votes: {results.total_votes}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  Vote Breakdown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                for candidate, votes in sorted(results.vote_counts.items(),\\\\\\\\\\\\\\\\n                                               key=lambda x: x[1], reverse=True):\\\\\\\\\\\\\\\\n                    output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    {candidate}: {votes}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                output.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(output)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format: {format_type}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def reset(self) -> None:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reset the voting system to initial state.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        self.is_active = False\\\\\\\\\\\\\\\\n        self.candidates = []\\\\\\\\\\\\\\\\n        self.eligible_voters = []\\\\\\\\\\\\\\\\n        self.votes = {}\\\\\\\\\\\\\\\\n        self.start_time = None\\\\\\\\\\\\\\\\n        self.end_time = None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\n    def status(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get current status of the voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\n            'enabled': self.enabled,\\\\\\\\\\\\\\\\n            'is_active': self.is_active,\\\\\\\\\\\\\\\\n            'candidates': self.candidates,\\\\\\\\\\\\\\\\n            'eligible_voters': len(self.eligible_voters),\\\\\\\\\\\\\\\\n            'votes_cast': len(self.votes),\\\\\\\\\\\\\\\\n            'time_remaining': (self.end_time - time.time()\\\\\\\\\\\\\\\\n                               if self.is_active and self.end_time else 0),\\\\\\\\\\\\\\\\n            'sessions_completed': len(self.vote_history)\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\"\\\\\\\\n        }\\\\\\\\n      }\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"docs\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\\\"api_reference.md\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"docs/api_reference.md\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 15639,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# AI Jubilee Debate System API Reference\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Core Classes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Moderator\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe central coordinator for debate sessions.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nModerator(\\\\\\\\\\\\\\\\n    topic: str,\\\\\\\\\\\\\\\\n    participants: List[Union[BotClient, HumanClient]],\\\\\\\\\\\\\\\\n    chat_log: ChatLog,\\\\\\\\\\\\\\\\n    voting_system: VotingSystem,\\\\\\\\\\\\\\\\n    config: Dict[str, Any]\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `topic`: The debate topic string\\\\\\\\\\\\\\\\n- `participants`: List of bot and human participants\\\\\\\\\\\\\\\\n- `chat_log`: ChatLog instance for message management\\\\\\\\\\\\\\\\n- `voting_system`: VotingSystem instance for handling votes\\\\\\\\\\\\\\\\n- `config`: Configuration dictionary with timing and rule settings\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async run_debate() -> Dict[str, Any]`\\\\\\\\\\\\\\\\nRuns the complete debate session through all phases.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Dictionary containing voting results and session statistics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nmoderator = Moderator(topic, participants, chat_log, voting_system, config)\\\\\\\\\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {results.get('winner', 'No winner')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `get_state() -> DebateState`\\\\\\\\\\\\\\\\nReturns current debate state information.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** DebateState object with phase, speaker, and timing info\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async _give_turn(participant_name: str, time_limit: int, turn_type: str) -> None`\\\\\\\\\\\\\\\\nGives speaking turn to a specific participant.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `participant_name`: Name of participant to give turn to\\\\\\\\\\\\\\\\n- `time_limit`: Maximum time in seconds for response\\\\\\\\\\\\\\\\n- `turn_type`: Type of turn (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### ChatLog\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThread-safe message management system.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nChatLog(max_messages: int = 1000)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `max_messages`: Maximum number of messages to retain in memory\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async add_message(sender: str, content: str, message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", metadata: Optional[Dict] = None) -> Message`\\\\\\\\\\\\\\\\nAdds a new message to the chat log.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `sender`: Name of message sender\\\\\\\\\\\\\\\\n- `content`: Message content text\\\\\\\\\\\\\\\\n- `message_type`: Type of message (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n- `metadata`: Optional additional data\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Created Message object\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nmessage = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I think AI will help humanity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message ID: {message.message_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `get_messages(limit: Optional[int] = None, sender: Optional[str] = None, message_type: Optional[str] = None, since_timestamp: Optional[float] = None) -> List[Message]`\\\\\\\\\\\\\\\\nRetrieves messages with optional filtering.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `limit`: Maximum number of messages to return\\\\\\\\\\\\\\\\n- `sender`: Filter by sender name\\\\\\\\\\\\\\\\n- `message_type`: Filter by message type\\\\\\\\\\\\\\\\n- `since_timestamp`: Only messages after this timestamp\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** List of Message objects\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `subscribe() -> asyncio.Queue`\\\\\\\\\\\\\\\\nCreates subscription for real-time message updates.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Queue that receives new Message objects\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async save_transcript(filename: str, format_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> None`\\\\\\\\\\\\\\\\nSaves chat transcript to file.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `filename`: Output file path\\\\\\\\\\\\\\\\n- `format_type`: Export format (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `search_messages(query: str, case_sensitive: bool = False) -> List[Message]`\\\\\\\\\\\\\\\\nSearches messages by content.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `query`: Search string\\\\\\\\\\\\\\\\n- `case_sensitive`: Whether search is case sensitive\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** List of matching Message objects\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### VotingSystem\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nManages voting sessions and result calculation.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nVotingSystem(config: Dict[str, Any])\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `config`: Voting configuration dictionary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async start_voting(candidates: List[str], duration: Optional[int] = None) -> None`\\\\\\\\\\\\\\\\nStarts a new voting session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `candidates`: List of participant names to vote for\\\\\\\\\\\\\\\\n- `duration`: Voting duration in seconds (uses config default if None)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nawait voting_system.start_voting([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], 300)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async cast_vote(voter_id: str, candidate: str, justification: Optional[str] = None) -> bool`\\\\\\\\\\\\\\\\nCasts a vote for a candidate.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `voter_id`: ID of the voter\\\\\\\\\\\\\\\\n- `candidate`: Name of candidate being voted for\\\\\\\\\\\\\\\\n- `justification`: Optional reasoning for the vote\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** True if vote was successfully cast\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async end_voting() -> VotingResults`\\\\\\\\\\\\\\\\nEnds voting session and calculates results.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** VotingResults object with winner and vote breakdown\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `get_vote_summary() -> Dict[str, Any]`\\\\\\\\\\\\\\\\nGets current voting status without ending session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Dictionary with vote counts and time remaining\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async export_results(format_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str`\\\\\\\\\\\\\\\\nExports voting results in specified format.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `format_type`: Export format (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Formatted results string\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### BotClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAI-powered debate participant.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nBotClient(\\\\\\\\\\\\\\\\n    name: str,\\\\\\\\\\\\\\\\n    model: str,\\\\\\\\\\\\\\\\n    provider: str,\\\\\\\\\\\\\\\\n    personality: str,\\\\\\\\\\\\\\\\n    stance: str,\\\\\\\\\\\\\\\\n    api_key: str,\\\\\\\\\\\\\\\\n    temperature: float = 0.7,\\\\\\\\\\\\\\\\n    max_tokens: int = 300\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `name`: Bot display name\\\\\\\\\\\\\\\\n- `model`: AI model identifier\\\\\\\\\\\\\\\\n- `provider`: AI provider (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n- `personality`: Personality description for prompt\\\\\\\\\\\\\\\\n- `stance`: Debate stance (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n- `api_key`: API key for AI provider\\\\\\\\\\\\\\\\n- `temperature`: Response creativity (0.0-1.0)\\\\\\\\\\\\\\\\n- `max_tokens`: Maximum response length\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\\\\\\\\\\\\\nGenerates AI response to current debate context.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `topic`: Current debate topic\\\\\\\\\\\\\\\\n- `recent_messages`: Recent conversation messages for context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Generated response string\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyst\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", api_key)\\\\\\\\\\\\\\\\nresponse = await bot.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in healthcare\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", recent_messages)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async receive_message(message: Message) -> None`\\\\\\\\\\\\\\\\nReceives message from debate for context awareness.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `get_stats() -> Dict[str, Any]`\\\\\\\\\\\\\\\\nReturns bot performance statistics.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Dictionary with response counts, timing, and success rates\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async warmup() -> bool`\\\\\\\\\\\\\\\\nTests bot connectivity and readiness.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** True if bot is ready for debate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `update_personality(personality: str, stance: str = None) -> None`\\\\\\\\\\\\\\\\nUpdates bot personality and stance during session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### HumanClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nHuman participant interface.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nHumanClient(name: str, interface_config: Dict[str, Any])\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `name`: Human participant display name\\\\\\\\\\\\\\\\n- `interface_config`: Interface configuration dictionary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\\\\\\\\\\\\\nGets response from human participant.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `topic`: Current debate topic\\\\\\\\\\\\\\\\n- `recent_messages`: Recent messages for context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Human's response string\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async handle_voting(candidates: List[str], voting_time: int) -> Dict[str, Any]`\\\\\\\\\\\\\\\\nHandles voting interface for human.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `candidates`: List of candidates to vote for\\\\\\\\\\\\\\\\n- `voting_time`: Time allowed for voting\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Dictionary with vote result and metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async set_active(active: bool) -> None`\\\\\\\\\\\\\\\\nSets whether human is actively participating.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `active`: Whether human should be active in debate\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### StreamingServer\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWebSocket server for live debate streaming.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nStreamingServer(\\\\\\\\\\\\\\\\n    chat_log: ChatLog,\\\\\\\\\\\\\\\\n    voting_system: VotingSystem,\\\\\\\\\\\\\\\\n    config: Dict[str, Any]\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async start() -> None`\\\\\\\\\\\\\\\\nStarts the streaming server.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async stop() -> None`\\\\\\\\\\\\\\\\nStops the streaming server and closes connections.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `async broadcast_custom_message(message_type: str, data: Any) -> None`\\\\\\\\\\\\\\\\nBroadcasts custom message to all connected clients.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `message_type`: Type identifier for the message\\\\\\\\\\\\\\\\n- `data`: Message payload\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `get_connected_clients() -> List[Dict[str, Any]]`\\\\\\\\\\\\\\\\nReturns information about all connected streaming clients.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** List of client information dictionaries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Data Classes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRepresents a single chat message.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass Message:\\\\\\\\\\\\\\\\n    sender: str\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\n    timestamp: float\\\\\\\\\\\\\\\\n    message_id: int\\\\\\\\\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Properties:**\\\\\\\\\\\\\\\\n- `formatted_timestamp`: Human-readable timestamp string\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Methods:**\\\\\\\\\\\\\\\\n- `to_dict() -> Dict[str, Any]`: Convert to dictionary\\\\\\\\\\\\\\\\n- `from_dict(data: Dict[str, Any]) -> Message`: Create from dictionary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Vote\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRepresents a single vote in the voting system.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass Vote:\\\\\\\\\\\\\\\\n    voter_id: str\\\\\\\\\\\\\\\\n    candidate: str\\\\\\\\\\\\\\\\n    justification: Optional[str] = None\\\\\\\\\\\\\\\\n    timestamp: float = field(default_factory=time.time)\\\\\\\\\\\\\\\\n    anonymous: bool = False\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### VotingResults\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nContains results from a voting session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass VotingResults:\\\\\\\\\\\\\\\\n    winner: Optional[str]\\\\\\\\\\\\\\\\n    vote_counts: Dict[str, int]\\\\\\\\\\\\\\\\n    total_votes: int\\\\\\\\\\\\\\\\n    votes_by_voter: Dict[str, Vote]\\\\\\\\\\\\\\\\n    voting_duration: float\\\\\\\\\\\\\\\\n    participation_rate: float\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### DebateState\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nTracks current debate session state.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass DebateState:\\\\\\\\\\\\\\\\n    phase: DebatePhase\\\\\\\\\\\\\\\\n    current_speaker: Optional[str] = None\\\\\\\\\\\\\\\\n    time_remaining: int = 0\\\\\\\\\\\\\\\\n    turn_order: List[str] = None\\\\\\\\\\\\\\\\n    warnings_issued: Dict[str, int] = None\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Enums\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### DebatePhase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDefines the phases of a debate session.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nclass DebatePhase(Enum):\\\\\\\\\\\\\\\\n    INTRODUCTION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"introduction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    OPENING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    DISCUSSION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    CLOSING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    VOTING = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    RESULTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    FINISHED = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"finished\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Utility Functions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Configuration (`app/utils.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `load_config(config_path: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> Dict[str, Any]`\\\\\\\\\\\\\\\\nLoads configuration from YAML file with environment variable substitution.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `config_path`: Path to configuration file\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Configuration dictionary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nconfig = load_config(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"custom_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `setup_logging(level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", log_file: Optional[str] = None) -> None`\\\\\\\\\\\\\\\\nSets up logging configuration.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `level`: Logging level (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WARNING\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ERROR\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n- `log_file`: Optional log file path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `format_time_remaining(seconds: float) -> str`\\\\\\\\\\\\\\\\nFormats time remaining in human-readable format.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `seconds`: Time in seconds\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Formatted time string (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5m 30s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2h 15m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", etc.)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### `truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str`\\\\\\\\\\\\\\\\nTruncates text to maximum length.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\n- `text`: Text to truncate\\\\\\\\\\\\\\\\n- `max_length`: Maximum length\\\\\\\\\\\\\\\\n- `suffix`: Suffix to add when truncating\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Returns:** Truncated text\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Error Handling\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Custom Exceptions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe system uses standard Python exceptions with descriptive messages:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- `ValueError`: Invalid configuration or parameters\\\\\\\\\\\\\\\\n- `FileNotFoundError`: Missing configuration files\\\\\\\\\\\\\\\\n- `ConnectionError`: API or network failures\\\\\\\\\\\\\\\\n- `TimeoutError`: Response timeouts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Error Recovery\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAll async methods include proper error handling and will not crash the session:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\ntry:\\\\\\\\\\\\\\\\n    response = await bot.get_response(topic, messages)\\\\\\\\\\\\\\\\nexcept Exception as e:\\\\\\\\\\\\\\\\n    # Fallback response is automatically generated\\\\\\\\\\\\\\\\n    response = bot._generate_fallback_response(topic)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Configuration Schema\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Main Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\n# Debate settings\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  default_topic: str\\\\\\\\\\\\\\\\n  max_participants: int\\\\\\\\\\\\\\\\n  time_limit_minutes: int\\\\\\\\\\\\\\\\n  opening_statement_time: int  # seconds\\\\\\\\\\\\\\\\n  response_time: int\\\\\\\\\\\\\\\\n  closing_statement_time: int\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Bot configurations\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\n  - name: str\\\\\\\\\\\\\\\\n    model: str\\\\\\\\\\\\\\\\n    provider: str  # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: str\\\\\\\\\\\\\\\\n    stance: str  # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    temperature: float  # 0.0-1.0\\\\\\\\\\\\\\\\n    max_tokens: int\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# API credentials\\\\\\\\\\\\\\\\napi_keys:\\\\\\\\\\\\\\\\n  openai: str\\\\\\\\\\\\\\\\n  anthropic: str\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Voting settings\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\n  enabled: bool\\\\\\\\\\\\\\\\n  voting_duration: int  # seconds\\\\\\\\\\\\\\\\n  allow_participant_voting: bool\\\\\\\\\\\\\\\\n  require_justification: bool\\\\\\\\\\\\\\\\n  anonymous_votes: bool\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Chat settings\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\n  max_message_length: int\\\\\\\\\\\\\\\\n  enable_timestamps: bool\\\\\\\\\\\\\\\\n  log_level: str\\\\\\\\\\\\\\\\n  save_transcripts: bool\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Streaming settings\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\n  enabled: bool\\\\\\\\\\\\\\\\n  websocket_port: int\\\\\\\\\\\\\\\\n  max_connections: int\\\\\\\\\\\\\\\\n  broadcast_votes: bool\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Interface settings\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\n  mode: str  # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  enable_rich_formatting: bool\\\\\\\\\\\\\\\\n  show_typing_indicators: bool\\\\\\\\\\\\\\\\n  input_timeout: int\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## WebSocket API\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Client Connection\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nConnect to the streaming server:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```javascript\\\\\\\\\\\\\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Message Types\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Incoming Messages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### Welcome Message\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"welcome\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"client_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"client_123456789\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"server_info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"real_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### Chat Message\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I believe AI will benefit society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1640995200.0,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 42,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### Vote Update\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote_update\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"candidates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote_counts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 5, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3},\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 8,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"time_remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 120,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": true\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Outgoing Messages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### Subscribe to Channels\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"subscribe\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"channels\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### Cast Vote\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voter_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"viewer_123\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"justification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Most persuasive arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n##### Ping/Pong\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ping\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Performance Considerations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### API Rate Limits\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- OpenAI: Respect rate limits based on your plan\\\\\\\\\\\\\\\\n- Anthropic: Monitor request quotas\\\\\\\\\\\\\\\\n- Implement exponential backoff for retries\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Memory Management\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- Chat log automatically limits message history\\\\\\\\\\\\\\\\n- Conversation history is pruned in bot clients\\\\\\\\\\\\\\\\n- Streaming connections are cleaned up automatically\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Async Best Practices\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAll I/O operations are async:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Correct - awaits async operations\\\\\\\\\\\\\\\\nresponse = await bot.get_response(topic, messages)\\\\\\\\\\\\\\\\nawait chat_log.add_message(sender, content)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Incorrect - would block the event loop\\\\\\\\\\\\\\\\n# response = bot.get_response(topic, messages).result()\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Testing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Unit Tests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRun the test suite:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\npython -m pytest tests/ -v\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Integration Tests\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nTest with real APIs:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Set test API keys\\\\\\\\\\\\\\\\nexport OPENAI_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nexport ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Run integration tests\\\\\\\\\\\\\\\\npython -m pytest tests/integration/ -v\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Mock Testing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nfrom unittest.mock import AsyncMock\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Mock bot responses\\\\\\\\\\\\\\\\nbot.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nresponse = await bot.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\nassert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Deployment\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Docker\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```dockerfile\\\\\\\\\\\\\\\\nFROM python:3.9-slim\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nWORKDIR /app\\\\\\\\\\\\\\\\nCOPY requirements.txt .\\\\\\\\\\\\\\\\nRUN pip install -r requirements.txt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCOPY . .\\\\\\\\\\\\\\\\nCMD [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app.main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Environment Variables\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nRequired for production:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\nOPENAI_API_KEY=sk-...\\\\\\\\\\\\\\\\nANTHROPIC_API_KEY=sk-ant-...\\\\\\\\\\\\\\\\nLOG_LEVEL=INFO\\\\\\\\\\\\\\\\nCONFIG_PATH=/app/production_config.yaml\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Health Checks\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Check system health\\\\\\\\\\\\\\\\nasync def health_check():\\\\\\\\\\\\\\\\n    # Test bot connectivity\\\\\\\\\\\\\\\\n    for bot in bots:\\\\\\\\\\\\\\\\n        if not await bot.warmup():\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    # Test streaming server\\\\\\\\\\\\\\\\n    if streaming_server and not streaming_server.is_active:\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    return True\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis API reference provides comprehensive documentation for integrating with and extending the AI Jubilee Debate System.\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"architecture.md\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"docs/architecture.md\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 7424,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# AI Jubilee Debate System Architecture\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe AI Jubilee Debate System is a modular, event-driven platform that facilitates structured debates between AI bots and human participants. The system emphasizes real-time interaction, fair moderation, and comprehensive result tracking.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Core Components\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 1. Moderator (`app/moderator.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe central orchestrator of the debate system.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Responsibilities:**\\\\\\\\\\\\\\\\n- Manage debate phases (introduction, opening statements, discussion, closing statements, voting, results)\\\\\\\\\\\\\\\\n- Enforce time limits and speaking order\\\\\\\\\\\\\\\\n- Handle participant timeouts and warnings\\\\\\\\\\\\\\\\n- Coordinate with voting system\\\\\\\\\\\\\\\\n- Broadcast messages to all participants\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Key Classes:**\\\\\\\\\\\\\\\\n- `Moderator`: Main orchestration class\\\\\\\\\\\\\\\\n- `DebatePhase`: Enum defining debate stages\\\\\\\\\\\\\\\\n- `DebateState`: Current state tracking\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Flow Diagram:**\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\n‚îÇIntroduction ‚îÇ -> ‚îÇOpening Stmts ‚îÇ -> ‚îÇ Discussion  ‚îÇ\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\n                                              ‚îÇ\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\n‚îÇ   Results   ‚îÇ <- ‚îÇ    Voting    ‚îÇ <- ‚îÇClosing Stmts‚îÇ\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 2. Chat Log (`app/chat_log.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThread-safe message management system.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Features:**\\\\\\\\\\\\\\\\n- Chronological message ordering\\\\\\\\\\\\\\\\n- Pub/sub message distribution\\\\\\\\\\\\\\\\n- Message filtering and search\\\\\\\\\\\\\\\\n- Transcript export (JSON, TXT, HTML)\\\\\\\\\\\\\\\\n- Statistics tracking\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Data Model:**\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\nclass Message:\\\\\\\\\\\\\\\\n    sender: str\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\n    timestamp: float\\\\\\\\\\\\\\\\n    message_id: int\\\\\\\\\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 3. Voting System (`app/voting.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nDemocratic evaluation mechanism for debate performance.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Features:**\\\\\\\\\\\\\\\\n- Time-limited voting sessions\\\\\\\\\\\\\\\\n- Multiple export formats\\\\\\\\\\\\\\\\n- Vote validation and security\\\\\\\\\\\\\\\\n- Historical tracking\\\\\\\\\\\\\\\\n- Participation analytics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Voting Flow:**\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nStart Session -> Accept Votes -> End Session -> Calculate Results\\\\\\\\\\\\\\\\n     ‚îÇ              ‚îÇ               ‚îÇ              ‚îÇ\\\\\\\\\\\\\\\\n     v              v               v              v\\\\\\\\\\\\\\\\nSet Candidates  Validate Vote   Close Voting   Determine Winner\\\\\\\\\\\\\\\\nSet Duration    Store Vote      Stop Accepting  Export Results\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 4. Participant Clients\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Bot Client (`app/bot_client.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAI-powered debate participants.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Supported Providers:**\\\\\\\\\\\\\\\\n- OpenAI (GPT-3.5, GPT-4)\\\\\\\\\\\\\\\\n- Anthropic (Claude)\\\\\\\\\\\\\\\\n- Extensible for additional providers\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Key Features:**\\\\\\\\\\\\\\\\n- Personality-driven responses\\\\\\\\\\\\\\\\n- Stance-aware argumentation\\\\\\\\\\\\\\\\n- Response time tracking\\\\\\\\\\\\\\\\n- Conversation context management\\\\\\\\\\\\\\\\n- Fallback response handling\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Human Client (`app/human_client.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nHuman participant interface.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Interface Modes:**\\\\\\\\\\\\\\\\n- CLI: Terminal-based interaction\\\\\\\\\\\\\\\\n- Web: WebSocket-based browser interface\\\\\\\\\\\\\\\\n- API: Programmatic integration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Features:**\\\\\\\\\\\\\\\\n- Response validation\\\\\\\\\\\\\\\\n- Timeout handling\\\\\\\\\\\\\\\\n- Conversation history\\\\\\\\\\\\\\\\n- Voting participation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### 5. Streaming Server (`app/streaming.py`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nReal-time broadcast system for live audience.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Capabilities:**\\\\\\\\\\\\\\\\n- WebSocket connections\\\\\\\\\\\\\\\\n- Message broadcasting\\\\\\\\\\\\\\\\n- Vote updates\\\\\\\\\\\\\\\\n- Client management\\\\\\\\\\\\\\\\n- Statistics reporting\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## System Architecture\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\n‚îÇ                    Moderator                            ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ   Phases    ‚îÇ ‚îÇ   Timing    ‚îÇ ‚îÇ   Rules     ‚îÇ       ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\n                      ‚îÇ\\\\\\\\\\\\\\\\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\\\\\\\\\\\\\n    v                 v                 v\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\n‚îÇChat Log  ‚îÇ    ‚îÇ  Voting   ‚îÇ    ‚îÇ  Streaming   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ          ‚îÇ    ‚îÇ  System   ‚îÇ    ‚îÇ   Server     ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ- Messages‚îÇ    ‚îÇ- Sessions ‚îÇ    ‚îÇ- WebSockets  ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ- History ‚îÇ    ‚îÇ- Results  ‚îÇ    ‚îÇ- Broadcast   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ- Export  ‚îÇ    ‚îÇ- Stats    ‚îÇ    ‚îÇ- Clients     ‚îÇ\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\\\\\\\\\\\\\n    v                 v                 v\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\n‚îÇ                Participants                     ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ Bot Clients ‚îÇ              ‚îÇHuman Clients‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ- OpenAI     ‚îÇ              ‚îÇ- CLI        ‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ- Anthropic  ‚îÇ              ‚îÇ- Web        ‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ- Custom     ‚îÇ              ‚îÇ- API        ‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Data Flow\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Message Flow\\\\\\\\\\\\\\\\n1. Participant generates response\\\\\\\\\\\\\\\\n2. Moderator validates and timestamps\\\\\\\\\\\\\\\\n3. Chat Log stores and distributes\\\\\\\\\\\\\\\\n4. Streaming Server broadcasts to audience\\\\\\\\\\\\\\\\n5. Other participants receive for context\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Voting Flow\\\\\\\\\\\\\\\\n1. Moderator initiates voting phase\\\\\\\\\\\\\\\\n2. Voting System opens session\\\\\\\\\\\\\\\\n3. Participants cast votes\\\\\\\\\\\\\\\\n4. System validates and stores votes\\\\\\\\\\\\\\\\n5. Results calculated and broadcast\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Configuration Flow\\\\\\\\\\\\\\\\n1. Load YAML configuration\\\\\\\\\\\\\\\\n2. Initialize components with settings\\\\\\\\\\\\\\\\n3. Create participants based on config\\\\\\\\\\\\\\\\n4. Start session with configured parameters\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Error Handling\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Graceful Degradation\\\\\\\\\\\\\\\\n- API failures trigger fallback responses\\\\\\\\\\\\\\\\n- Network issues don't crash sessions\\\\\\\\\\\\\\\\n- Participant timeouts handled smoothly\\\\\\\\\\\\\\\\n- Voting continues despite individual failures\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Monitoring and Logging\\\\\\\\\\\\\\\\n- Comprehensive error logging\\\\\\\\\\\\\\\\n- Performance metrics tracking\\\\\\\\\\\\\\\\n- Participant statistics\\\\\\\\\\\\\\\\n- System health monitoring\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Scalability Considerations\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Horizontal Scaling\\\\\\\\\\\\\\\\n- Multiple debate sessions simultaneously\\\\\\\\\\\\\\\\n- Load balancing for streaming\\\\\\\\\\\\\\\\n- Database for persistent storage\\\\\\\\\\\\\\\\n- Message queue for high throughput\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Performance Optimization\\\\\\\\\\\\\\\\n- Async/await throughout\\\\\\\\\\\\\\\\n- Connection pooling for APIs\\\\\\\\\\\\\\\\n- Message batching for efficiency\\\\\\\\\\\\\\\\n- Resource cleanup and management\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Security\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Input Validation\\\\\\\\\\\\\\\\n- Message content sanitization\\\\\\\\\\\\\\\\n- Participant authentication\\\\\\\\\\\\\\\\n- Vote integrity verification\\\\\\\\\\\\\\\\n- Rate limiting protection\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Privacy Protection\\\\\\\\\\\\\\\\n- Anonymous voting options\\\\\\\\\\\\\\\\n- Conversation encryption\\\\\\\\\\\\\\\\n- Participant data protection\\\\\\\\\\\\\\\\n- Audit trail maintenance\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Extension Points\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Adding New AI Providers\\\\\\\\\\\\\\\\n1. Implement `AIProvider` interface\\\\\\\\\\\\\\\\n2. Add configuration options\\\\\\\\\\\\\\\\n3. Update provider factory\\\\\\\\\\\\\\\\n4. Test integration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Custom Interfaces\\\\\\\\\\\\\\\\n1. Implement `HumanInterface` interface\\\\\\\\\\\\\\\\n2. Handle async message flow\\\\\\\\\\\\\\\\n3. Add configuration support\\\\\\\\\\\\\\\\n4. Test user experience\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Additional Export Formats\\\\\\\\\\\\\\\\n1. Extend export methods\\\\\\\\\\\\\\\\n2. Add format validation\\\\\\\\\\\\\\\\n3. Update documentation\\\\\\\\\\\\\\\\n4. Test output quality\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Deployment Architecture\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Development\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nLocal Machine\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Python Environment\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Configuration Files\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Test Data\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ Log Files\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Production\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nContainer Orchestration\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Moderator Service\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Bot Client Services\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Streaming Service\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Web Interface\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Database\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ Message Queue\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Configuration Management\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Environment-Specific Settings\\\\\\\\\\\\\\\\n- Development: Local APIs, debug logging\\\\\\\\\\\\\\\\n- Staging: Production APIs, info logging\\\\\\\\\\\\\\\\n- Production: Optimized settings, error logging\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Secret Management\\\\\\\\\\\\\\\\n- API keys in environment variables\\\\\\\\\\\\\\\\n- Database credentials secured\\\\\\\\\\\\\\\\n- SSL certificates managed\\\\\\\\\\\\\\\\n- Rotation policies enforced\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis architecture enables a robust, scalable, and extensible debate platform that can accommodate various use cases from small-scale experiments to large public events.\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"usage.md\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"docs/usage.md\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 21363,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# AI Jubilee Debate System - Usage Guide\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üöÄ Quick Start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Prerequisites\\\\\\\\\\\\\\\\n1. **Python 3.8+** installed\\\\\\\\\\\\\\\\n2. **API Keys** for OpenAI and/or Anthropic\\\\\\\\\\\\\\\\n3. **Dependencies** installed\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Setup Steps\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Clone or download the project**\\\\\\\\\\\\\\\\n2. **Install dependencies:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   pip install -r requirements.txt\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **Set up your API keys in `.env` file:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   # Create .env file in project root\\\\\\\\\\\\\\\\n   OPENAI_API_KEY=sk-your-openai-key-here\\\\\\\\\\\\\\\\n   ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n4. **Run the debate:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   # Recommended: Use the simple launcher\\\\\\\\\\\\\\\\n   python run_debate.py\\\\\\\\\\\\\\\\n   \\\\\\\\\\\\\\\\n   # Alternative: Use the module directly\\\\\\\\\\\\\\\\n   python -m app.main\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üé≠ Debate Modes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Autonomous Mode** (Default - Recommended!)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nIn autonomous mode, bots monitor the conversation and decide when to speak, creating a natural, organic debate flow.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### How Autonomous Mode Works:\\\\\\\\\\\\\\\\n- ü§ñ **Bots run in parallel**, continuously monitoring chat\\\\\\\\\\\\\\\\n- üß† **Intelligent decision making** - bots decide when they feel compelled to respond\\\\\\\\\\\\\\\\n- üìö **Full conversation history** available to all participants\\\\\\\\\\\\\\\\n- üéØ **Smart triggers** - bots respond to mentions, challenges, or opportunities\\\\\\\\\\\\\\\\n- ‚è∞ **Cooldown system** prevents spam (15-45 second intervals)\\\\\\\\\\\\\\\\n- üó£Ô∏è **Humans can speak anytime** during discussion phase\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Configuration:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Enable autonomous mode\\\\\\\\\\\\\\\\n  min_bot_cooldown: 15         # Minimum seconds between bot responses\\\\\\\\\\\\\\\\n  max_bot_cooldown: 45         # Maximum cooldown for active bots  \\\\\\\\\\\\\\\\n  message_check_interval: 5    # How often bots check for new messages\\\\\\\\\\\\\\\\n  silence_timeout: 60          # Moderator intervenes after silence\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Example Autonomous Flow:\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nüé≠ Moderator: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Autonomous Discussion Phase Begin!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work increases productivity by 40%...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüí≠ Skeptic is thinking about responding...\\\\\\\\\\\\\\\\nü§ñ Skeptic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"But what about the collaboration costs?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüë§ Human: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I've experienced both - here's my take...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüí≠ Socrates is thinking about responding...  \\\\\\\\\\\\\\\\nü§ñ Socrates: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What evidence supports these productivity claims?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüéØ Moderator: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What about environmental implications?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüí≠ Advocate is thinking about responding...\\\\\\\\\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Great point - remote work cuts commuting emissions...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Sequential Mode** (Traditional)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nParticipants take turns in a structured order. More predictable but less dynamic.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sequential\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Traditional turn-based mode\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üéØ Human Participation in Autonomous Mode\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **During Discussion Phase:**\\\\\\\\\\\\\\\\n- ‚úÖ **Speak anytime** - no waiting for turns!\\\\\\\\\\\\\\\\n- ‚úÖ **Type naturally** - just enter your response\\\\\\\\\\\\\\\\n- ‚úÖ **Full context** - see all previous messages\\\\\\\\\\\\\\\\n- ‚úÖ **Real-time** - immediate feedback from bots\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Available Commands:**\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nüí¨ [your message]     # Join the debate with your response\\\\\\\\\\\\\\\\nhelp                  # Show help information\\\\\\\\\\\\\\\\nstatus                # Show your participation statistics\\\\\\\\\\\\\\\\nhistory               # Show recent conversation\\\\\\\\\\\\\\\\nquit                  # Leave the debate\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Example Human Session:**\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nüéØ AUTONOMOUS DEBATE MODE ACTIVE\\\\\\\\\\\\\\\\nüó£Ô∏è You can speak at ANY TIME during the discussion!\\\\\\\\\\\\\\\\nüí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work is clearly the future because...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nü§ñ Skeptic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I disagree - here's why remote work fails...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nüí¨ Type your response: I think both perspectives miss the point about hybrid work...\\\\\\\\\\\\\\\\n‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nüí≠ Socrates is thinking about responding...\\\\\\\\\\\\\\\\nü§ñ Socrates: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Interesting point about hybrid - can you elaborate?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nüí¨ Type your response: status\\\\\\\\\\\\\\\\nüìä Your participation: 1 responses, 100.0% participation rate, avg response time: 12.3s\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nüí¨ Type your response: Sure! Hybrid work combines the best of both...\\\\\\\\\\\\\\\\n‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üìã Debate Phases\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **1. Introduction Phase**\\\\\\\\\\\\\\\\n- Moderator introduces topic and participants\\\\\\\\\\\\\\\\n- Overview of rules and format\\\\\\\\\\\\\\\\n- Duration: ~2 minutes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **2. Opening Statements Phase** \\\\\\\\\\\\\\\\n- Each participant gives structured opening statement\\\\\\\\\\\\\\\\n- **Sequential order** (even in autonomous mode)\\\\\\\\\\\\\\\\n- Time limit: 120 seconds per participant\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **3. Discussion Phase**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### **Autonomous Mode:**\\\\\\\\\\\\\\\\n- üîÑ **Free-flowing conversation**\\\\\\\\\\\\\\\\n- ü§ñ **Bots monitor and respond intelligently** \\\\\\\\\\\\\\\\n- üë• **Humans can jump in anytime**\\\\\\\\\\\\\\\\n- üéØ **Moderator provides prompts during silence**\\\\\\\\\\\\\\\\n- ‚è∞ **Total time: 30 minutes** (configurable)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### **Sequential Mode:**\\\\\\\\\\\\\\\\n- üîÑ **Round-robin turns**\\\\\\\\\\\\\\\\n- ‚è∞ **60 seconds per response**\\\\\\\\\\\\\\\\n- üìù **Structured format**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **4. Closing Statements Phase**\\\\\\\\\\\\\\\\n- Final arguments from each participant\\\\\\\\\\\\\\\\n- **Sequential order** \\\\\\\\\\\\\\\\n- Time limit: 90 seconds per participant\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **5. Voting Phase**\\\\\\\\\\\\\\\\n- Participants and audience vote for most persuasive\\\\\\\\\\\\\\\\n- Duration: 5 minutes\\\\\\\\\\\\\\\\n- Optional justification required\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **6. Results Phase**\\\\\\\\\\\\\\\\n- Vote tallies and winner announcement\\\\\\\\\\\\\\\\n- Final statistics and transcript saving\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## ‚öôÔ∏è Configuration Options\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Bot Personalities**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Passionate supporter, data-driven, persuasive. Jumps in when position is challenged.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Critical thinker, questions assumptions. Responds when claims need scrutiny.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Timing Controls**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  time_limit_minutes: 30        # Total discussion time\\\\\\\\\\\\\\\\n  opening_statement_time: 120   # Opening statement duration\\\\\\\\\\\\\\\\n  response_time: 60            # Response time in sequential mode\\\\\\\\\\\\\\\\n  closing_statement_time: 90   # Closing statement duration\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\n  # Autonomous mode specific\\\\\\\\\\\\\\\\n  min_bot_cooldown: 15         # Minimum bot response interval\\\\\\\\\\\\\\\\n  max_bot_cooldown: 45         # Maximum bot cooldown\\\\\\\\\\\\\\\\n  silence_timeout: 60          # Silence before moderator intervenes\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Interface Options**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"                  # CLI or web interface\\\\\\\\\\\\\\\\n  enable_rich_formatting: true # Colored/formatted output\\\\\\\\\\\\\\\\n  show_typing_indicators: true # Show when bots are thinking\\\\\\\\\\\\\\\\n  enable_reactions: true       # Enable emoji reactions\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üéõÔ∏è Advanced Usage\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Command Line Options**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Basic usage\\\\\\\\\\\\\\\\npython run_debate.py\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Using the module with options\\\\\\\\\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI ethics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" --bots 3 --humans 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Custom configuration\\\\\\\\\\\\\\\\npython -m app.main --config custom_config.yaml\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Web interface mode\\\\\\\\\\\\\\\\npython -m app.main --interface web\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Custom Topics**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nAdd to `config.yaml`:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ntopics:\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Your custom debate topic here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Another interesting topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nOr specify directly:\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Custom topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Bot Configuration**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nCreate custom bots in `config.yaml`:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MyBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Your custom personality description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üîß Troubleshooting\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Common Issues**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**API Key Errors:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Check your .env file format\\\\\\\\\\\\\\\\nOPENAI_API_KEY=sk-your-key  # No quotes, no export\\\\\\\\\\\\\\\\nANTHROPIC_API_KEY=sk-ant-your-key\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Import Errors:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Make sure you're in the project root directory\\\\\\\\\\\\\\\\ncd ai_jubilee_debate\\\\\\\\\\\\\\\\npython run_debate.py\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n**Timeout Issues:**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Check internet connection and API status\\\\\\\\\\\\\\\\n# Increase timeouts in config.yaml if needed\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Debug Mode**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nEnable detailed logging:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\n  log_level: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nOr set environment variable:\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\nexport LOG_LEVEL=DEBUG\\\\\\\\\\\\\\\\npython run_debate.py\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Saving Transcripts**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nTranscripts are automatically saved after each debate:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\n  save_transcripts: true\\\\\\\\\\\\\\\\n  transcript_format: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nFiles saved as: `debate_YYYY-MM-DD_HH-MM-SS.json`\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üé™ Tips for Great Debates\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **For Humans:**\\\\\\\\\\\\\\\\n- üéØ **Jump in naturally** during autonomous mode\\\\\\\\\\\\\\\\n- üìä **Reference specific points** made by others\\\\\\\\\\\\\\\\n- üí° **Provide evidence** and examples\\\\\\\\\\\\\\\\n- ü§ù **Be respectful** but persuasive\\\\\\\\\\\\\\\\n- ‚ö° **Keep responses focused** and substantial\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Bot Optimization:**\\\\\\\\\\\\\\\\n- üé≠ **Diverse personalities** create better dynamics\\\\\\\\\\\\\\\\n- ‚öñÔ∏è **Balanced stances** (pro/con/neutral mix)\\\\\\\\\\\\\\\\n- üß† **Different models** (GPT-4, Claude, etc.) for variety\\\\\\\\\\\\\\\\n- ‚è∞ **Appropriate cooldowns** prevent spam\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Moderator Settings:**\\\\\\\\\\\\\\\\n- üéØ **Topic-specific prompts** keep discussion flowing\\\\\\\\\\\\\\\\n- ‚è∞ **Reasonable timeouts** balance pace and depth\\\\\\\\\\\\\\\\n- üí¨ **Silence intervention** maintains engagement\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üìä Monitoring and Analytics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Real-time Stats**\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n# During debate, type 'status' to see:\\\\\\\\\\\\\\\\nüìä Your participation: 3 responses, 75% participation rate\\\\\\\\\\\\\\\\n‚è±Ô∏è Average response time: 15.2 seconds\\\\\\\\\\\\\\\\nüí¨ Conversation length: 24 messages\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Post-Debate Analysis**\\\\\\\\\\\\\\\\n- üìà Participation rates per participant\\\\\\\\\\\\\\\\n- ‚è∞ Response time analytics  \\\\\\\\\\\\\\\\n- üó≥Ô∏è Voting results and justifications\\\\\\\\\\\\\\\\n- üìù Full transcript with timestamps\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üöÄ Performance Tips\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **For Better Performance:**\\\\\\\\\\\\\\\\n- Use **GPT-3.5** for faster, cheaper responses\\\\\\\\\\\\\\\\n- Set **reasonable cooldowns** (15-30 seconds)\\\\\\\\\\\\\\\\n- Limit **conversation history** for speed\\\\\\\\\\\\\\\\n- Use **async mode** for responsiveness\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **For Higher Quality:**\\\\\\\\\\\\\\\\n- Use **GPT-4** or **Claude** for better reasoning\\\\\\\\\\\\\\\\n- Increase **response time limits**\\\\\\\\\\\\\\\\n- Enable **detailed logging** for analysis\\\\\\\\\\\\\\\\n- Create **specific bot personalities**\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üåü Advanced Features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Real-time Streaming**\\\\\\\\\\\\\\\\nEnable WebSocket streaming for live audiences:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\n  max_connections: 100\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Voting System**\\\\\\\\\\\\\\\\nComprehensive voting with justifications:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\n  voting_duration: 300\\\\\\\\\\\\\\\\n  require_justification: true\\\\\\\\\\\\\\\\n  anonymous_votes: false\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Web Interface**\\\\\\\\\\\\\\\\nFor browser-based participation:\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üìÅ File Structure\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\nai_jubilee_debate/\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ .env                    # Your API keys (never commit!)\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ .env.example           # Example environment file\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ config.yaml            # Main configuration\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ run_debate.py          # Simple launcher script\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ app/                   # Core application\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package initialization\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Main entry point\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ moderator.py      # Debate moderation logic\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ bot_client.py     # AI bot participants\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ human_client.py   # Human participants\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ chat_log.py       # Message management\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ voting.py         # Voting system\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions\\\\\\\\\\\\\\\\n‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # WebSocket streaming\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ tests/                 # Test suite\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_moderator.py\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_voting.py\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_chat_log.py\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_bot_client.py\\\\\\\\\\\\\\\\n‚îÇ   ‚îî‚îÄ‚îÄ test_human_client.py\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ docs/                  # Documentation\\\\\\\\\\\\\\\\n    ‚îú‚îÄ‚îÄ architecture.md    # System architecture\\\\\\\\\\\\\\\\n    ‚îú‚îÄ‚îÄ usage.md          # This file\\\\\\\\\\\\\\\\n    ‚îî‚îÄ‚îÄ api_reference.md  # API documentation\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## üÜò Getting Help\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Built-in Help**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# During debate\\\\\\\\\\\\\\\\nhelp                    # Show autonomous mode help\\\\\\\\\\\\\\\\nstatus                  # Show participation stats\\\\\\\\\\\\\\\\nhistory                 # Show recent messages\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Command line\\\\\\\\\\\\\\\\npython -m app.main --help   # Show CLI options\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### **Common Commands**\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Run with debug logging\\\\\\\\\\\\\\\\nLOG_LEVEL=DEBUG python run_debate.py\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Run tests\\\\\\\\\\\\\\\\npython -m pytest tests/ -v\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Check configuration\\\\\\\\\\\\\\\\npython -c \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"from app.utils import load_config; print(load_config())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis autonomous debate system creates truly organic, intelligent conversations between AI participants while allowing humans to jump in naturally whenever they feel inspired to contribute! üé≠ü§ñ# AI Jubilee Debate System Usage Guide\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Quick Start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Installation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Clone the repository:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   git clone <repository-url>\\\\\\\\\\\\\\\\n   cd ai_jubilee_debate\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n2. **Install dependencies:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   pip install -r requirements.txt\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **Set up environment variables:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   export OPENAI_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"your-openai-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n   export ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"your-anthropic-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n4. **Run your first debate:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   python -m app.main\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Basic Configuration (`config.yaml`)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  default_topic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  max_participants: 4\\\\\\\\\\\\\\\\n  time_limit_minutes: 20\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\n  voting_duration: 180\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Advanced Configuration Options\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Timing Settings\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  opening_statement_time: 120  # seconds\\\\\\\\\\\\\\\\n  response_time: 60\\\\\\\\\\\\\\\\n  closing_statement_time: 90\\\\\\\\\\\\\\\\n  warning_time: 45  # warning before timeout\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Bot Personalities\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosopher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thoughtful, asks probing questions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"socratic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    temperature: 0.8\\\\\\\\\\\\\\\\n    max_tokens: 250\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Human Interface\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  enable_rich_formatting: true\\\\\\\\\\\\\\\\n  show_typing_indicators: true\\\\\\\\\\\\\\\\n  input_timeout: 120\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Running Debates\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Command Line Interface\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Basic Usage\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Run with default settings\\\\\\\\\\\\\\\\npython -m app.main\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Specify topic\\\\\\\\\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Set participant counts\\\\\\\\\\\\\\\\npython -m app.main --bots 3 --humans 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Use custom config\\\\\\\\\\\\\\\\npython -m app.main --config custom_config.yaml\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Advanced Options\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Full command with all options\\\\\\\\\\\\\\\\npython -m app.main \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --bots 2 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --humans 1 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --config production_config.yaml\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Programmatic Usage\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Simple Session\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nfrom app.main import start_debate_session\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Start a basic debate\\\\\\\\\\\\\\\\nawait start_debate_session(\\\\\\\\\\\\\\\\n    topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The future of remote work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    ai_bots=2,\\\\\\\\\\\\\\\\n    human_participants=1\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Custom Session\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nfrom app import Moderator, BotClient, HumanClient, ChatLog, VotingSystem\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Create components\\\\\\\\\\\\\\\\nchat_log = ChatLog()\\\\\\\\\\\\\\\\nvoting_system = VotingSystem({'enabled': True})\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Create participants\\\\\\\\\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyst\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Data-driven and analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"your-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nhuman = HumanClient(\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Participant1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    interface_config={'mode': 'cli'}\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Create moderator and run\\\\\\\\\\\\\\\\nmoderator = Moderator(\\\\\\\\\\\\\\\\n    topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI Ethics in Healthcare\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    participants=[bot, human],\\\\\\\\\\\\\\\\n    chat_log=chat_log,\\\\\\\\\\\\\\\\n    voting_system=voting_system,\\\\\\\\\\\\\\\\n    config={'time_limit_minutes': 15}\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Participant Management\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### AI Bot Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Creating Custom Bots\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Argumentative bot\\\\\\\\\\\\\\\\naggressive_bot = BotClient(\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debater\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Aggressive, uses strong rhetoric\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    temperature=0.9,  # More creative\\\\\\\\\\\\\\\\n    api_key=api_key\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Analytical bot\\\\\\\\\\\\\\\\nanalytical_bot = BotClient(\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Researcher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Fact-focused, cites evidence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    temperature=0.3,  # More conservative\\\\\\\\\\\\\\\\n    api_key=api_key\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Bot Personality Examples\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\npersonalities:\\\\\\\\\\\\\\\\n  socratic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Asks probing questions, seeks deeper understanding\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Passionate, uses emotional appeals and personal stories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\n  scientist: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Data-driven, cites studies and statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  philosopher: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Abstract thinking, explores ethical implications\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  pragmatist: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Focuses on practical implementation and real-world effects\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  skeptic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Questions assumptions, plays devil's advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Human Interface Options\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### CLI Mode (Default)\\\\\\\\\\\\\\\\n- Terminal-based interaction\\\\\\\\\\\\\\\\n- Rich formatting with colors\\\\\\\\\\\\\\\\n- Real-time message display\\\\\\\\\\\\\\\\n- Keyboard input for responses\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Web Mode \\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nhuman = HumanClient(\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WebUser\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    interface_config={\\\\\\\\\\\\\\\\n        'mode': 'web',\\\\\\\\\\\\\\\\n        'enable_reactions': True,\\\\\\\\\\\\\\\\n        'show_typing_indicators': True\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Debate Topics\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Predefined Topics\\\\\\\\\\\\\\\\nThe system includes several built-in topics:\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Social media has a net positive impact on democracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Custom Topics\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Define your own topics\\\\\\\\\\\\\\\\ncustom_topics = [\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Cryptocurrency will replace traditional banking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Space exploration should be publicly funded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Genetic engineering should be available to all\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Automation will eliminate the need for human work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Use in configuration\\\\\\\\\\\\\\\\nconfig['topics'] = custom_topics\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Topic Guidelines\\\\\\\\\\\\\\\\n- Keep topics debatable (not factual statements)\\\\\\\\\\\\\\\\n- Ensure both sides can be reasonably argued\\\\\\\\\\\\\\\\n- Make them relevant to your audience\\\\\\\\\\\\\\\\n- Consider current events and trends\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Voting and Results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Voting Configuration\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\n  voting_duration: 300  # 5 minutes\\\\\\\\\\\\\\\\n  allow_participant_voting: true\\\\\\\\\\\\\\\\n  require_justification: true\\\\\\\\\\\\\\\\n  anonymous_votes: false\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Accessing Results\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# After debate completion\\\\\\\\\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {results['winner']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote breakdown: {results['vote_counts']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Export detailed results\\\\\\\\\\\\\\\\nawait voting_system.export_results('json')\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Results Analysis\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Get participant performance\\\\\\\\\\\\\\\\nfor participant in participants:\\\\\\\\\\\\\\\\n    performance = voting_system.get_candidate_performance(participant.name)\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{participant.name}: {performance['win_rate']:.1%} win rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Live Streaming\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Enable Streaming\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\n  max_connections: 100\\\\\\\\\\\\\\\\n  broadcast_votes: true\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Streaming Server\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nfrom app.streaming import StreamingServer\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Create streaming server\\\\\\\\\\\\\\\\nstreaming = StreamingServer(\\\\\\\\\\\\\\\\n    chat_log=chat_log,\\\\\\\\\\\\\\\\n    voting_system=voting_system,\\\\\\\\\\\\\\\\n    config=streaming_config\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nawait streaming.start()\\\\\\\\\\\\\\\\n# Server runs on localhost:8080\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Client Connection\\\\\\\\\\\\\\\\n```javascript\\\\\\\\\\\\\\\\n// Connect to stream\\\\\\\\\\\\\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nws.onmessage = function(event) {\\\\\\\\\\\\\\\\n    const data = JSON.parse(event.data);\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\n    if (data.type === 'message') {\\\\\\\\\\\\\\\\n        displayMessage(data.data);\\\\\\\\\\\\\\\\n    } else if (data.type === 'vote_update') {\\\\\\\\\\\\\\\\n        updateVoteDisplay(data.data);\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n};\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Data Export and Analysis\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Transcript Export\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Save debate transcript\\\\\\\\\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_2024.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_2024.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") \\\\\\\\\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_2024.html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Statistics and Analytics\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Chat statistics\\\\\\\\\\\\\\\\nstats = chat_log.get_statistics()\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total messages: {stats['total_messages']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Average per minute: {stats['messages_per_minute']:.1f}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Participant statistics  \\\\\\\\\\\\\\\\nfor participant in participants:\\\\\\\\\\\\\\\\n    stats = participant.get_stats()\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{participant.name}: {stats}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Voting Analysis\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Export voting data\\\\\\\\\\\\\\\\ncsv_data = await voting_system.export_results('csv')\\\\\\\\\\\\\\\\ntxt_report = await voting_system.export_results('txt')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Historical analysis\\\\\\\\\\\\\\\\nhistory = voting_system.vote_history\\\\\\\\\\\\\\\\nfor session in history:\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Session: {session['timestamp']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {session['results'].winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Troubleshooting\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Common Issues\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### API Key Problems\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Check environment variables\\\\\\\\\\\\\\\\necho $OPENAI_API_KEY\\\\\\\\\\\\\\\\necho $ANTHROPIC_API_KEY\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Set them if missing\\\\\\\\\\\\\\\\nexport OPENAI_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sk-...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nexport ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sk-ant-...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Connection Issues\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Test bot connectivity\\\\\\\\\\\\\\\\nbot = BotClient(...)\\\\\\\\\\\\\\\\nsuccess = await bot.warmup()\\\\\\\\\\\\\\\\nif not success:\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot connection failed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n#### Performance Issues\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\n# Reduce timeouts for faster sessions\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  opening_statement_time: 60\\\\\\\\\\\\\\\\n  response_time: 30\\\\\\\\\\\\\\\\n  closing_statement_time: 45\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Limit message history\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\n  max_message_length: 300\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Debug Mode\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\n# Enable debug logging\\\\\\\\\\\\\\\\npython -m app.main --config debug_config.yaml\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\n# debug_config.yaml\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\n  log_level: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  save_transcripts: true\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Error Recovery\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\n# Handle errors gracefully\\\\\\\\\\\\\\\\ntry:\\\\\\\\\\\\\\\\n    results = await moderator.run_debate()\\\\\\\\\\\\\\\\nexcept Exception as e:\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debate error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    # Save partial transcript\\\\\\\\\\\\\\\\n    await chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error_recovery.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Best Practices\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Bot Configuration\\\\\\\\\\\\\\\\n- Use different personalities for variety\\\\\\\\\\\\\\\\n- Balance pro/con/neutral stances\\\\\\\\\\\\\\\\n- Test API connections before debates\\\\\\\\\\\\\\\\n- Monitor response times and adjust timeouts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Topic Selection\\\\\\\\\\\\\\\\n- Choose engaging, relevant topics\\\\\\\\\\\\\\\\n- Ensure balanced argumentation potential\\\\\\\\\\\\\\\\n- Test topics with different participant mixes\\\\\\\\\\\\\\\\n- Update topics regularly for freshness\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Session Management\\\\\\\\\\\\\\\\n- Start with shorter sessions for testing\\\\\\\\\\\\\\\\n- Monitor participant engagement\\\\\\\\\\\\\\\\n- Save transcripts for analysis\\\\\\\\\\\\\\\\n- Review voting patterns for improvements\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Performance Optimization\\\\\\\\\\\\\\\\n- Use appropriate API models for your needs\\\\\\\\\\\\\\\\n- Set reasonable timeouts\\\\\\\\\\\\\\\\n- Limit concurrent API calls\\\\\\\\\\\\\\\\n- Monitor system resources\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThis guide covers the core functionality of the AI Jubilee Debate System. For detailed API documentation, see [api_reference.md](api_reference.md).\\\\\\\\\\\\\\\"\\\\\\\\n        }\\\\\\\\n      }\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"tests\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\": {\\\\\\\\n        \\\\\\\\\\\\\\\"test_bot_client.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"tests/test_bot_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 15291,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTests for the BotClient class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\\\\\\\\\nfrom app.bot_client import BotClient, BotConfig, OpenAIProvider, AnthropicProvider\\\\\\\\\\\\\\\\nfrom app.chat_log import Message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef bot_config():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test bot configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\n        'name': 'TestBot',\\\\\\\\\\\\\\\\n        'model': 'gpt-3.5-turbo',\\\\\\\\\\\\\\\\n        'provider': 'openai',\\\\\\\\\\\\\\\\n        'personality': 'Analytical and thoughtful',\\\\\\\\\\\\\\\\n        'stance': 'pro',\\\\\\\\\\\\\\\\n        'api_key': 'test-api-key'\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef bot_client(bot_config):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test bot client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return BotClient(**bot_config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef sample_messages():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return [\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What do you think about AI?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1),\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995210.0, 2, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestBotConfig:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for BotConfig dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_bot_config_creation(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating bot configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert config.name == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.model == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.provider == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.personality == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.temperature == 0.7  # Default value\\\\\\\\\\\\\\\\n        assert config.max_tokens == 300  # Default value\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestBotClient:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for BotClient class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_bot_client_initialization(self, bot_config):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test bot client initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot = BotClient(**bot_config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert bot.name == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert bot.config.model == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert bot.config.provider == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert isinstance(bot.ai_provider, OpenAIProvider)\\\\\\\\\\\\\\\\n        assert bot.response_count == 0\\\\\\\\\\\\\\\\n        assert bot.conversation_history == []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_bot_client_with_anthropic(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test bot client with Anthropic provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AnthropicBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Balanced\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(bot.ai_provider, AnthropicProvider)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_bot_client_unsupported_provider(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test bot client with unsupported provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported AI provider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            BotClient(\\\\\\\\\\\\\\\\n                name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"unsupported\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_response_success(self, bot_client, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Mock the AI provider\\\\\\\\\\\\\\\\n        mock_response = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I think AI has great potential for society.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=mock_response)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await bot_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert response == mock_response\\\\\\\\\\\\\\\\n        assert bot_client.response_count == 1\\\\\\\\\\\\\\\\n        assert len(bot_client.conversation_history) == 1\\\\\\\\\\\\\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_response_with_error(self, bot_client, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response generation with API error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Mock the AI provider to raise an exception\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\\\\\\\\\\\\\n            side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await bot_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should return fallback response\\\\\\\\\\\\\\\\n        assert isinstance(response, str)\\\\\\\\\\\\\\\\n        assert len(response) > 0\\\\\\\\\\\\\\\\n        assert bot_client.stats['errors'] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_prepare_messages(self, bot_client, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message preparation for AI model.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        messages = bot_client._prepare_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(messages) >= 1  # At least system message\\\\\\\\\\\\\\\\n        assert messages[0]['role'] == 'system'\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[0]['content']\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[0]['content']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_create_system_prompt_pro_stance(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test system prompt creation for pro stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        prompt = bot_client._create_system_prompt(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI is beneficial\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI is beneficial\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical and thoughtful\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"IN FAVOR\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_create_system_prompt_con_stance(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test system prompt creation for con stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ConBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Critical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        prompt = bot._create_system_prompt(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AGAINST\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_create_system_prompt_neutral_stance(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test system prompt creation for neutral stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"NeutralBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Balanced\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        prompt = bot._create_system_prompt(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"balanced perspectives\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_generate_fallback_response(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test fallback response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        response = bot_client._generate_fallback_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(response, str)\\\\\\\\\\\\\\\\n        assert len(response) > 0\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in response or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"perspective\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in response.lower()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_receive_message(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should be added to conversation history\\\\\\\\\\\\\\\\n        assert len(bot_client.conversation_history) == 1\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice: Hello bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in bot_client.conversation_history[0]['content']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Message queue should have the message\\\\\\\\\\\\\\\\n        queued_message = await bot_client.message_queue.get()\\\\\\\\\\\\\\\\n        assert queued_message == message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_receive_own_message(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving own message (should not be added to history).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My own message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should not be added to conversation history\\\\\\\\\\\\\\\\n        assert len(bot_client.conversation_history) == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_update_stats_success(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on success.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_client._update_stats(1.5, success=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\\\\\\\\\\\\\n        assert bot_client.stats['average_response_time'] == 1.5\\\\\\\\\\\\\\\\n        assert bot_client.stats['total_response_time'] == 1.5\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_update_stats_error(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_client._update_stats(2.0, success=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert bot_client.stats['errors'] == 1\\\\\\\\\\\\\\\\n        assert bot_client.stats['responses_generated'] == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_stats(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting bot statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add some test data\\\\\\\\\\\\\\\\n        bot_client.stats['responses_generated'] = 5\\\\\\\\\\\\\\\\n        bot_client.stats['total_response_time'] = 10.0\\\\\\\\\\\\\\\\n        bot_client.stats['errors'] = 1\\\\\\\\\\\\\\\\n        bot_client._update_stats(0, success=True)  # Recalculate average\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        stats = bot_client.get_stats()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert stats['name'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert stats['model'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert stats['provider'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert stats['responses_generated'] == 5\\\\\\\\\\\\\\\\n        assert stats['total_errors'] == 1\\\\\\\\\\\\\\\\n        assert 'success_rate' in stats\\\\\\\\\\\\\\\\n        assert 'average_response_time' in stats\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_update_personality(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating bot personality.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_client.update_personality(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New personality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert bot_client.config.personality == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New personality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert bot_client.config.stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_reset_conversation(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test resetting conversation history.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add some conversation history\\\\\\\\\\\\\\\\n        bot_client.conversation_history = [\\\\\\\\\\\\\\\\n            {'role': 'user', 'content': 'Test message'}\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n        bot_client.response_count = 3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        bot_client.reset_conversation()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert bot_client.conversation_history == []\\\\\\\\\\\\\\\\n        assert bot_client.response_count == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_warmup_success(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful bot warmup.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await bot_client.warmup()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_warmup_failure(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test failed bot warmup.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\\\\\\\\\\\\\n            side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Connection failed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await bot_client.warmup()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result == False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_str_representation(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test string representation of bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        string_repr = str(bot_client)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_repr_representation(self, bot_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test detailed string representation of bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repr_str = repr(bot_client)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name='TestBot'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model='gpt-3.5-turbo'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestOpenAIProvider:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for OpenAIProvider class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_openai_provider_initialization(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test OpenAI provider initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert provider.api_key == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_generate_response_success(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Mock OpenAI client\\\\\\\\\\\\\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\n            mock_openai.return_value = mock_client\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Mock response\\\\\\\\\\\\\\\\n            mock_response = Mock()\\\\\\\\\\\\\\\\n            mock_response.choices = [Mock()]\\\\\\\\\\\\\\\\n            mock_response.choices[0].message.content = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I help?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            mock_client.chat.completions.create = AsyncMock(return_value=mock_response)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            response = await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I help?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            mock_client.chat.completions.create.assert_called_once()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_generate_response_error(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response generation with error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\n            mock_openai.return_value = mock_client\\\\\\\\\\\\\\\\n            mock_client.chat.completions.create = AsyncMock(\\\\\\\\\\\\\\\\n                side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            with pytest.raises(Exception, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OpenAI API error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n                await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestAnthropicProvider:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for AnthropicProvider class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_anthropic_provider_initialization(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test Anthropic provider initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert provider.api_key == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_generate_response_success(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        messages = [\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are a helpful assistant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\n            mock_anthropic.return_value = mock_client\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            # Mock response\\\\\\\\\\\\\\\\n            mock_response = Mock()\\\\\\\\\\\\\\\\n            mock_response.content = [Mock()]\\\\\\\\\\\\\\\\n            mock_response.content[0].text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I assist you?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            mock_client.messages.create = AsyncMock(return_value=mock_response)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            response = await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I assist you?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n            mock_client.messages.create.assert_called_once()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_generate_response_error(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response generation with error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\n            mock_anthropic.return_value = mock_client\\\\\\\\\\\\\\\\n            mock_client.messages.create = AsyncMock(\\\\\\\\\\\\\\\\n                side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            with pytest.raises(Exception, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Anthropic API error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n                await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_conversation_history_management(bot_client):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test conversation history management.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Add messages beyond the limit\\\\\\\\\\\\\\\\n    for i in range(25):\\\\\\\\\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should be limited to avoid memory issues\\\\\\\\\\\\\\\\n    assert len(bot_client.conversation_history) <= 20\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_bot_response_timing(bot_client, sample_messages):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test that response timing is tracked.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Simulate some delay\\\\\\\\\\\\\\\\n    async def delayed_response(*args):\\\\\\\\\\\\\\\\n        await asyncio.sleep(0.1)\\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Delayed response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    bot_client.ai_provider.generate_response = delayed_response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    await bot_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    assert bot_client.stats['average_response_time'] > 0\\\\\\\\\\\\\\\\n    assert bot_client.stats['total_response_time'] > 0\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"test_chat_log.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"tests/test_chat_log.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 15406,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTests for the ChatLog class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom unittest.mock import patch, mock_open\\\\\\\\\\\\\\\\nfrom app.chat_log import ChatLog, Message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef chat_log():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return ChatLog(max_messages=100)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef sample_messages():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return [\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello everyone!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 1),\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi Alice!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 2),\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome to the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 3, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestMessage:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for Message dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_message_creation(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        timestamp = time.time()\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timestamp, 1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert msg.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg.timestamp == timestamp\\\\\\\\\\\\\\\\n        assert msg.message_id == 1\\\\\\\\\\\\\\\\n        assert msg.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg.metadata == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_message_with_metadata(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message with metadata.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        metadata = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"urgency\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"high\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Important point\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 2,\\\\\\\\\\\\\\\\n                      message_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", metadata=metadata)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert msg.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg.metadata == metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_formatted_timestamp(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test formatted timestamp property.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        timestamp = 1640995200.0  # Known timestamp\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timestamp, 1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        formatted = msg.formatted_timestamp\\\\\\\\\\\\\\\\n        assert isinstance(formatted, str)\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in formatted  # Should contain time separator\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_to_dict(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test converting message to dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 1)\\\\\\\\\\\\\\\\n        msg_dict = msg.to_dict()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(msg_dict, dict)\\\\\\\\\\\\\\\\n        assert msg_dict[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg_dict[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in msg_dict\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in msg_dict\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_from_dict(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating message from dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        data = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": time.time(),\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 5,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        msg = Message.from_dict(data)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert msg.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert msg.message_id == 5\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestChatLog:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for ChatLog class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_chat_log_initialization(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test chat log initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        chat_log = ChatLog(max_messages=50)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\\\\\\\\\n        assert chat_log.message_counter == 0\\\\\\\\\\\\\\\\n        assert chat_log.subscribers == []\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_add_message(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test adding a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(message, Message)\\\\\\\\\\\\\\\\n        assert message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert message.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert message.message_id == 1\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 1\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 1\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_add_multiple_messages(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test adding multiple messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"First message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Second message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Third message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 3\\\\\\\\\\\\\\\\n        assert chat_log.message_counter == 3\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 2\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_message_ordering(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test that messages maintain chronological order.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        msg1 = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"First\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        await asyncio.sleep(0.01)  # Small delay\\\\\\\\\\\\\\\\n        msg2 = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Second\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        messages = list(chat_log.messages)\\\\\\\\\\\\\\\\n        assert messages[0].message_id == 1\\\\\\\\\\\\\\\\n        assert messages[1].message_id == 2\\\\\\\\\\\\\\\\n        assert messages[0].timestamp < messages[1].timestamp\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_max_messages_limit(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message limit enforcement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        chat_log = ChatLog(max_messages=3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add more messages than the limit\\\\\\\\\\\\\\\\n        for i in range(5):\\\\\\\\\\\\\\\\n            await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 3  # Should be limited\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check that oldest messages were removed\\\\\\\\\\\\\\\\n        messages = list(chat_log.messages)\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[0].content\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message 4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[2].content\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_subscription_system(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message subscription system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        queue = chat_log.subscribe()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add a message\\\\\\\\\\\\\\\\n        message = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check that subscriber received the message\\\\\\\\\\\\\\\\n        received_message = await asyncio.wait_for(queue.get(), timeout=1.0)\\\\\\\\\\\\\\\\n        assert received_message.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert received_message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_multiple_subscribers(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test multiple subscribers.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        queue1 = chat_log.subscribe()\\\\\\\\\\\\\\\\n        queue2 = chat_log.subscribe()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Both subscribers should receive the message\\\\\\\\\\\\\\\\n        msg1 = await asyncio.wait_for(queue1.get(), timeout=1.0)\\\\\\\\\\\\\\\\n        msg2 = await asyncio.wait_for(queue2.get(), timeout=1.0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert msg1.content == msg2.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_unsubscribe(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test unsubscribing from messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        queue = chat_log.subscribe()\\\\\\\\\\\\\\\\n        assert queue in chat_log.subscribers\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        chat_log.unsubscribe(queue)\\\\\\\\\\\\\\\\n        assert queue not in chat_log.subscribers\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_messages_no_filter(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting all messages without filters.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Manually add messages to chat log\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\\\\\\\\\n        assert len(messages) == 3\\\\\\\\\\\\\\\\n        assert messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_messages_with_limit(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting messages with limit.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages(limit=2)\\\\\\\\\\\\\\\\n        assert len(messages) == 2\\\\\\\\\\\\\\\\n        # Should get the last 2 messages\\\\\\\\\\\\\\\\n        assert messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert messages[1].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_messages_by_sender(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test filtering messages by sender.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        alice_messages = chat_log.get_messages(sender=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert len(alice_messages) == 1\\\\\\\\\\\\\\\\n        assert alice_messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_messages_by_type(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test filtering messages by type.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        moderator_messages = chat_log.get_messages(message_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert len(moderator_messages) == 1\\\\\\\\\\\\\\\\n        assert moderator_messages[0].message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_messages_since_timestamp(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test filtering messages by timestamp.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add messages with known timestamps\\\\\\\\\\\\\\\\n        old_time = time.time() - 100\\\\\\\\\\\\\\\\n        new_time = time.time()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        chat_log.messages.append(Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Old\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", old_time, 1))\\\\\\\\\\\\\\\\n        chat_log.messages.append(Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", new_time, 2))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        cutoff = time.time() - 50\\\\\\\\\\\\\\\\n        recent_messages = chat_log.get_messages(since_timestamp=cutoff)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(recent_messages) == 1\\\\\\\\\\\\\\\\n        assert recent_messages[0].content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_recent_messages(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting recent messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        recent = chat_log.get_recent_messages(2)\\\\\\\\\\\\\\\\n        assert len(recent) == 2\\\\\\\\\\\\\\\\n        assert recent[-1].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Most recent\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_conversation_context(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting conversation context for a participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add various messages\\\\\\\\\\\\\\\\n        messages = [\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 1),\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 2),\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome everyone\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 3, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thanks!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 4),\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Good luck\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 5)\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for msg in messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        context = chat_log.get_conversation_context(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", context_length=3)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should include Alice's messages and moderator messages\\\\\\\\\\\\\\\\n        assert len(context) <= 3\\\\\\\\\\\\\\\\n        assert any(msg.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for msg in context)\\\\\\\\\\\\\\\\n        assert any(msg.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for msg in context)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_search_messages(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test searching messages by content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Case insensitive search\\\\\\\\\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert len(results) == 1\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results[0].content\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Case sensitive search\\\\\\\\\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", case_sensitive=True)\\\\\\\\\\\\\\\\n        assert len(results) == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", case_sensitive=True)\\\\\\\\\\\\\\\\n        assert len(results) == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_statistics(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting chat log statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n            chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += 1\\\\\\\\\\\\\\\\n            sender = msg.sender\\\\\\\\\\\\\\\\n            chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][sender] = (\\\\\\\\\\\\\\\\n                    chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(sender, 0) + 1\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        stats = chat_log.get_statistics()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 3\\\\\\\\\\\\\\\\n        assert stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"unique_senders\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 2  # Alice, Bob, moderator\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in stats\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_per_minute\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in stats\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"session_duration_minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in stats\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_save_transcript_json(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript in JSON format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert output_file.exists()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with open(output_file, 'r') as f:\\\\\\\\\\\\\\\\n            data = json.load(f)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in data\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in data\\\\\\\\\\\\\\\\n        assert len(data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]) == 1\\\\\\\\\\\\\\\\n        assert data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_save_transcript_txt(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript in TXT format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert output_file.exists()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        content = output_file.read_text()\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBATE TRANSCRIPT\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice: Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_save_transcript_html(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript in HTML format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"System message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                                   message_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert output_file.exists()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        content = output_file.read_text()\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"<!DOCTYPE html>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_save_transcript_invalid_format(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript with invalid format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test.xml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_load_transcript(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test loading transcript from file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Save a transcript first\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Original message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Clear chat log and reload\\\\\\\\\\\\\\\\n        chat_log.clear()\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await chat_log.load_transcript(str(output_file))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 1\\\\\\\\\\\\\\\\n        assert list(chat_log.messages)[0].content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Original message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_load_transcript_file_not_found(self, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test loading transcript from non-existent file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with pytest.raises(FileNotFoundError):\\\\\\\\\\\\\\\\n            await chat_log.load_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"nonexistent.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_clear_chat_log(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test clearing the chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        chat_log.message_counter = 5\\\\\\\\\\\\\\\\n        chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = 3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        chat_log.clear()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\\\\\\\\\n        assert chat_log.message_counter == 0\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 0\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_chat_log_len(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test chat log length.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert len(chat_log) == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(chat_log) == 3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_chat_log_iteration(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test iterating over chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        iterated_messages = list(chat_log)\\\\\\\\\\\\\\\\n        assert len(iterated_messages) == 3\\\\\\\\\\\\\\\\n        assert iterated_messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_chat_log_indexing(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test indexing chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        first_message = chat_log[0]\\\\\\\\\\\\\\\\n        assert first_message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        last_message = chat_log[-1]\\\\\\\\\\\\\\\\n        assert last_message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"test_human_client.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"tests/test_human_client.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 20297,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTests for the HumanClient class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\\\\\\\\\nfrom app.human_client import HumanClient, CLIInterface, WebInterface, InterfaceConfig\\\\\\\\\\\\\\\\nfrom app.chat_log import Message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef interface_config():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test interface configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\n        'mode': 'cli',\\\\\\\\\\\\\\\\n        'enable_rich_formatting': False,  # Disable for testing\\\\\\\\\\\\\\\\n        'show_typing_indicators': True,\\\\\\\\\\\\\\\\n        'enable_reactions': True,\\\\\\\\\\\\\\\\n        'input_timeout': 60\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef human_client(interface_config):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", interface_config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef sample_messages():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return [\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What's your opinion?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1),\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I think...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995210.0, 2),\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995220.0, 3, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestInterfaceConfig:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for InterfaceConfig dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_interface_config_defaults(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test interface config with default values.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.enable_rich_formatting == True\\\\\\\\\\\\\\\\n        assert config.show_typing_indicators == True\\\\\\\\\\\\\\\\n        assert config.enable_reactions == True\\\\\\\\\\\\\\\\n        assert config.input_timeout == 120\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_interface_config_custom(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test interface config with custom values.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(\\\\\\\\\\\\\\\\n            mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            enable_rich_formatting=False,\\\\\\\\\\\\\\\\n            input_timeout=90\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert config.enable_rich_formatting == False\\\\\\\\\\\\\\\\n        assert config.input_timeout == 90\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestCLIInterface:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for CLIInterface class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_cli_interface_initialization(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test CLI interface initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert interface.config == config\\\\\\\\\\\\\\\\n        assert interface.rich_console is None  # Rich disabled\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_display_basic_message(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test displaying message with basic formatting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\\\\\\\\\n            await interface.display_message(message)\\\\\\\\\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_display_moderator_message(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test displaying moderator message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\\\\\\\\\n            await interface.display_message(message)\\\\\\\\\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\\\\\\\\\n            # Should have moderator prefix\\\\\\\\\\\\\\\\n            args = mock_print.call_args[0]\\\\\\\\\\\\\\\\n            assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_input_success(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful input retrieval.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('builtins.input', return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            response = await interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timeout=1)\\\\\\\\\\\\\\\\n            assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_input_timeout(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test input timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Mock input to simulate hanging\\\\\\\\\\\\\\\\n        async def slow_input():\\\\\\\\\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Too late\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        interface._get_user_input = slow_input\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timeout=0.1)\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Should return empty string on timeout\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_show_notification(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test showing notifications.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\\\\\\\\\n            await interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\\\\\\\\\n            args = mock_print.call_args[0]\\\\\\\\\\\\\\\\n            assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\n            assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestWebInterface:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for WebInterface class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_web_interface_initialization(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test web interface initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        interface = WebInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert interface.config == config\\\\\\\\\\\\\\\\n        assert interface.websocket is None\\\\\\\\\\\\\\\\n        assert interface.pending_responses == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_display_message_no_websocket(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test displaying message without websocket connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        interface = WebInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should not raise an error even without websocket\\\\\\\\\\\\\\\\n        await interface.display_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_input_no_websocket(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting input without websocket connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        interface = WebInterface(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Should return empty string\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestHumanClient:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for HumanClient class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_human_client_initialization(self, interface_config):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", interface_config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert client.name == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert isinstance(client.interface, CLIInterface)\\\\\\\\\\\\\\\\n        assert client.is_active == True\\\\\\\\\\\\\\\\n        assert client.conversation_history == []\\\\\\\\\\\\\\\\n        assert client.stats['responses_given'] == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_human_client_web_mode(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client with web interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = {'mode': 'web'}\\\\\\\\\\\\\\\\n        client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WebHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(client.interface, WebInterface)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_human_client_unsupported_mode(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client with unsupported interface mode.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = {'mode': 'unsupported'}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported interface mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_response_success(self, human_client, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response retrieval.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Mock the interface get_input method\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert human_client.stats['responses_given'] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_response_timeout(self, human_client, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Mock timeout scenario\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert human_client.stats['timeouts'] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_get_response_inactive(self, human_client, sample_messages):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response when client is inactive.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        human_client.is_active = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_validate_response(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response validation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Normal response\\\\\\\\\\\\\\\\n        response = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This is a good response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This is a good response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Very long response\\\\\\\\\\\\\\\\n        long_response = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"x\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 600\\\\\\\\\\\\\\\\n        response = human_client._validate_response(long_response)\\\\\\\\\\\\\\\\n        assert len(response) <= 503  # 500 + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert response.endswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Very short response\\\\\\\\\\\\\\\\n        short_response = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Yes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Note: Very short response]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in short_response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_receive_message(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello human\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await human_client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should be added to conversation history\\\\\\\\\\\\\\\\n        assert len(human_client.conversation_history) == 1\\\\\\\\\\\\\\\\n        assert human_client.conversation_history[0] == message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should display the message\\\\\\\\\\\\\\\\n        human_client.interface.display_message.assert_called_once_with(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_receive_own_message(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving own message (should be ignored).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My own message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await human_client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should not be added to history or displayed\\\\\\\\\\\\\\\\n        assert len(human_client.conversation_history) == 0\\\\\\\\\\\\\\\\n        human_client.interface.display_message.assert_not_called()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_conversation_history_limit(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test conversation history length limit.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Add many messages\\\\\\\\\\\\\\\\n        for i in range(60):\\\\\\\\\\\\\\\\n            message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\n            await human_client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should be limited to 30 (as per implementation)\\\\\\\\\\\\\\\\n        assert len(human_client.conversation_history) == 30\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_handle_voting_success(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful voting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Mock interface methods\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(side_effect=[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Good arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 60)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result['voted'] == True\\\\\\\\\\\\\\\\n        assert result['candidate'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Index 2-1 = 1 -> \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert result['justification'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Good arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_handle_voting_timeout(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Timeout\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result['voted'] == False\\\\\\\\\\\\\\\\n        assert result['reason'] == 'timeout'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_handle_voting_invalid_choice(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting with invalid choice.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Out of range\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result['voted'] == False\\\\\\\\\\\\\\\\n        assert result['reason'] == 'invalid_choice'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_handle_voting_invalid_format(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting with invalid input format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"not_a_number\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result['voted'] == False\\\\\\\\\\\\\\\\n        assert result['reason'] == 'invalid_format'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_update_stats_success(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on successful response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        human_client._update_stats(2.5, success=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert human_client.stats['responses_given'] == 1\\\\\\\\\\\\\\\\n        assert human_client.stats['average_response_time'] == 2.5\\\\\\\\\\\\\\\\n        assert human_client.stats['total_response_time'] == 2.5\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_update_stats_timeout(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        human_client._update_stats(5.0, success=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert human_client.stats['timeouts'] == 1\\\\\\\\\\\\\\\\n        assert human_client.stats['responses_given'] == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_stats(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting human client statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add some test data\\\\\\\\\\\\\\\\n        human_client.stats['responses_given'] = 3\\\\\\\\\\\\\\\\n        human_client.stats['timeouts'] = 1\\\\\\\\\\\\\\\\n        human_client.stats['total_response_time'] = 15.0\\\\\\\\\\\\\\\\n        human_client._update_stats(0, success=True)  # Recalculate average\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        stats = human_client.get_stats()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert stats['name'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert stats['interface_mode'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert stats['responses_given'] == 3\\\\\\\\\\\\\\\\n        assert stats['timeouts'] == 1\\\\\\\\\\\\\\\\n        assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\\\\\\\\\\\\\n        assert 'average_response_time' in stats\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_set_active(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test setting client active/inactive status.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Set inactive\\\\\\\\\\\\\\\\n        await human_client.set_active(False)\\\\\\\\\\\\\\\\n        assert human_client.is_active == False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Set active\\\\\\\\\\\\\\\\n        await human_client.set_active(True)\\\\\\\\\\\\\\\\n        assert human_client.is_active == True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should have called show_notification twice\\\\\\\\\\\\\\\\n        assert human_client.interface.show_notification.call_count == 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_show_help(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test showing help information.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await human_client.show_help()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        human_client.interface.show_notification.assert_called_once()\\\\\\\\\\\\\\\\n        args = human_client.interface.show_notification.call_args[0]\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI Jubilee Debate Help\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"COMMANDS:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_str_representation(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test string representation of human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        string_repr = str(human_client)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_repr_representation(self, human_client):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test detailed string representation of human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        repr_str = repr(human_client)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name='TestHuman'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mode='cli'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"active=True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_show_context_integration(human_client, sample_messages):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test showing context to human before response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n    human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should show context notification\\\\\\\\\\\\\\\\n    notification_calls = human_client.interface.show_notification.call_args_list\\\\\\\\\\\\\\\\n    assert any(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Recent messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in str(call) for call in notification_calls)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should display recent messages\\\\\\\\\\\\\\\\n    assert human_client.interface.display_message.call_count >= 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_human_response_validation_edge_cases(human_client):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test edge cases in response validation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Empty response\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    assert result == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Whitespace only\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\t   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    assert result == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Response with just newlines\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    assert result == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Very short meaningful response\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Note: Very short response]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in result\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_human_client_error_resilience(human_client, sample_messages):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client resilience to interface errors.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Mock interface to raise errors\\\\\\\\\\\\\\\\n    human_client.interface.display_message = AsyncMock(side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Interface error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\n    human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should not crash despite interface errors\\\\\\\\\\\\\\\\n    response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\n    assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_human_client_concurrent_operations(human_client):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test concurrent operations on human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Simulate concurrent message receiving\\\\\\\\\\\\\\\\n    tasks = []\\\\\\\\\\\\\\\\n    for i in range(10):\\\\\\\\\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\n        tasks.append(human_client.receive_message(message))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    await asyncio.gather(*tasks)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # All messages should be processed\\\\\\\\\\\\\\\\n    assert len(human_client.conversation_history) == 10\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef test_human_client_stats_calculation(human_client):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test statistics calculation accuracy.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Simulate various response scenarios\\\\\\\\\\\\\\\\n    human_client._update_stats(2.0, success=True)\\\\\\\\\\\\\\\\n    human_client._update_stats(3.0, success=True)\\\\\\\\\\\\\\\\n    human_client._update_stats(1.5, success=False)  # Timeout\\\\\\\\\\\\\\\\n    human_client._update_stats(2.5, success=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    stats = human_client.get_stats()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    assert stats['responses_given'] == 3\\\\\\\\\\\\\\\\n    assert stats['timeouts'] == 1\\\\\\\\\\\\\\\\n    assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\\\\\\\\\\\\\n    assert abs(stats['average_response_time'] - 2.5) < 0.1  # (2.0+3.0+2.5)/3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_voting_with_web_interface():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting behavior with web interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    config = {'mode': 'web'}\\\\\\\\\\\\\\\\n    client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WebUser\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\n    candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Web interface should handle justification differently\\\\\\\\\\\\\\\\n    client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    result = await client.handle_voting(candidates, 60)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    assert result['voted'] == True\\\\\\\\\\\\\\\\n    assert result['candidate'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    assert result['justification'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # No justification prompt for web\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_human_client_lifecycle():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test complete human client lifecycle.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    config = {'mode': 'cli', 'enable_rich_formatting': False}\\\\\\\\\\\\\\\\n    client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"LifecycleTest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Initial state\\\\\\\\\\\\\\\\n    assert client.is_active == True\\\\\\\\\\\\\\\\n    assert len(client.conversation_history) == 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Mock interface for testing\\\\\\\\\\\\\\\\n    client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\n    client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Receive some messages\\\\\\\\\\\\\\\\n    for i in range(3):\\\\\\\\\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\n        await client.receive_message(message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    assert len(client.conversation_history) == 3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Participate in debate\\\\\\\\\\\\\\\\n    response = await client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\n    assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    assert client.stats['responses_given'] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Deactivate\\\\\\\\\\\\\\\\n    await client.set_active(False)\\\\\\\\\\\\\\\\n    assert client.is_active == False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should not respond when inactive\\\\\\\\\\\\\\\\n    response = await client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Another topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\n    assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"test_moderator.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"tests/test_moderator.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 9146,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTests for the Moderator class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\\\\\\\\\nfrom app.moderator import Moderator, DebatePhase, DebateState\\\\\\\\\\\\\\\\nfrom app.chat_log import ChatLog\\\\\\\\\\\\\\\\nfrom app.voting import VotingSystem\\\\\\\\\\\\\\\\nfrom app.bot_client import BotClient\\\\\\\\\\\\\\\\nfrom app.human_client import HumanClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef chat_log():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return ChatLog()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef voting_system():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    config = {'enabled': True, 'voting_duration': 60}\\\\\\\\\\\\\\\\n    return VotingSystem(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef mock_participants():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create mock participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    bot = Mock(spec=BotClient)\\\\\\\\\\\\\\\\n    bot.name = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    bot.get_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    bot.receive_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    human = Mock(spec=HumanClient)\\\\\\\\\\\\\\\\n    human.name = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    human.get_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    human.receive_message = AsyncMock()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return [bot, human]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef moderator(chat_log, voting_system, mock_participants):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test moderator.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    config = {\\\\\\\\\\\\\\\\n        'opening_statement_time': 30,\\\\\\\\\\\\\\\\n        'discussion_time': 60,\\\\\\\\\\\\\\\\n        'closing_statement_time': 30,\\\\\\\\\\\\\\\\n        'response_time': 20,\\\\\\\\\\\\\\\\n        'max_response_time': 60,\\\\\\\\\\\\\\\\n        'warning_time': 45\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return Moderator(\\\\\\\\\\\\\\\\n        topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n        participants=mock_participants,\\\\\\\\\\\\\\\\n        chat_log=chat_log,\\\\\\\\\\\\\\\\n        voting_system=voting_system,\\\\\\\\\\\\\\\\n        config=config\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestModerator:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for Moderator class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_moderator_initialization(self, moderator):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test moderator initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert moderator.topic == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert len(moderator.participants) == 2\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in moderator.participants\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in moderator.participants\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_introduction_phase(self, moderator, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test introduction phase.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await moderator._introduction_phase()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check that introduction message was logged\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\\\\\\\\\n        assert any(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome to AI Jubilee Debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in msg.content for msg in messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_opening_statements_phase(self, moderator, mock_participants):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test opening statements phase.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await moderator._opening_statements_phase()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.OPENING_STATEMENTS\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Verify each participant was asked for response\\\\\\\\\\\\\\\\n        for participant in mock_participants:\\\\\\\\\\\\\\\\n            participant.get_response.assert_called()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_give_turn_success(self, moderator, mock_participants):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful turn giving.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        participant = mock_participants[0]\\\\\\\\\\\\\\\\n        participant.get_response.return_value = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await moderator._give_turn(participant.name, 30, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        participant.get_response.assert_called_once()\\\\\\\\\\\\\\\\n        assert moderator.state.current_speaker is None  # Reset after turn\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_give_turn_timeout(self, moderator, mock_participants):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test turn timeout handling.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        participant = mock_participants[0]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Simulate timeout by making get_response take too long\\\\\\\\\\\\\\\\n        async def slow_response(*args):\\\\\\\\\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Too late\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        participant.get_response = slow_response\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Use very short timeout for testing\\\\\\\\\\\\\\\\n        await moderator._give_turn(participant.name, 0.1, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should have issued a warning\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued.get(participant.name, 0) >= 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_voting_phase_enabled(self, moderator):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting phase when voting is enabled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        moderator.voting_system.enabled = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with patch.object(moderator.voting_system, 'start_voting') as mock_start:\\\\\\\\\\\\\\\\n            with patch.object(moderator.voting_system, 'end_voting') as mock_end:\\\\\\\\\\\\\\\\n                mock_end.return_value = {\\\\\\\\\\\\\\\\n                    'winner': 'TestBot',\\\\\\\\\\\\\\\\n                    'vote_counts': {'TestBot': 2, 'TestHuman': 1}\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                results = await moderator._voting_phase()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                mock_start.assert_called_once()\\\\\\\\\\\\\\\\n                mock_end.assert_called_once()\\\\\\\\\\\\\\\\n                assert results['winner'] == 'TestBot'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_voting_phase_disabled(self, moderator):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting phase when voting is disabled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        moderator.voting_system.enabled = False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = await moderator._voting_phase()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert results == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_broadcast_message(self, moderator, mock_participants, chat_log):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message broadcasting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await moderator._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check message was logged\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\\\\\\\\\n        assert any(msg.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for msg in messages)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check all participants received message\\\\\\\\\\\\\\\\n        for participant in mock_participants:\\\\\\\\\\\\\\\\n            participant.receive_message.assert_called()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_handle_timeout_warnings(self, moderator):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test timeout warning system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        participant_name = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # First timeout\\\\\\\\\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Second timeout\\\\\\\\\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Third timeout (should trigger mute)\\\\\\\\\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_state(self, moderator):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test state retrieval.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        state = moderator.get_state()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(state, DebateState)\\\\\\\\\\\\\\\\n        assert state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\n        assert state.current_speaker is None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_full_debate_flow(self, moderator, mock_participants):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test complete debate flow.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Mock voting system methods\\\\\\\\\\\\\\\\n        moderator.voting_system.start_voting = AsyncMock()\\\\\\\\\\\\\\\\n        moderator.voting_system.end_voting = AsyncMock(return_value={\\\\\\\\\\\\\\\\n            'winner': 'TestBot',\\\\\\\\\\\\\\\\n            'vote_counts': {'TestBot': 1, 'TestHuman': 0}\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Run complete debate with short timeouts for testing\\\\\\\\\\\\\\\\n        moderator.phase_times[DebatePhase.DISCUSSION] = 1  # 1 second\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = await moderator.run_debate()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Verify all phases completed\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.FINISHED\\\\\\\\\\\\\\\\n        assert 'winner' in results\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Verify participants were called\\\\\\\\\\\\\\\\n        for participant in mock_participants:\\\\\\\\\\\\\\\\n            assert participant.get_response.call_count > 0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestDebateState:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for DebateState dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_debate_state_initialization(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test DebateState initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        state = DebateState(DebatePhase.DISCUSSION)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert state.phase == DebatePhase.DISCUSSION\\\\\\\\\\\\\\\\n        assert state.current_speaker is None\\\\\\\\\\\\\\\\n        assert state.time_remaining == 0\\\\\\\\\\\\\\\\n        assert state.turn_order == []\\\\\\\\\\\\\\\\n        assert state.warnings_issued == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_debate_state_with_values(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test DebateState with custom values.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        turn_order = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n        warnings = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        state = DebateState(\\\\\\\\\\\\\\\\n            phase=DebatePhase.VOTING,\\\\\\\\\\\\\\\\n            current_speaker=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            time_remaining=120,\\\\\\\\\\\\\\\\n            turn_order=turn_order,\\\\\\\\\\\\\\\\n            warnings_issued=warnings\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert state.phase == DebatePhase.VOTING\\\\\\\\\\\\\\\\n        assert state.current_speaker == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        assert state.time_remaining == 120\\\\\\\\\\\\\\\\n        assert state.turn_order == turn_order\\\\\\\\\\\\\\\\n        assert state.warnings_issued == warnings\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_moderator_error_handling(moderator, mock_participants):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test moderator error handling.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Make participant raise an error\\\\\\\\\\\\\\\\n    mock_participants[0].get_response.side_effect = Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should not crash the debate\\\\\\\\\\\\\\\\n    await moderator._give_turn(mock_participants[0].name, 30, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Moderator should continue functioning\\\\\\\\\\\\\\\\n    assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\nasync def test_moderator_message_validation(moderator):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message content validation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    long_message = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"x\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 1000  # Very long message\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    await moderator._process_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", long_message)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Should have been truncated\\\\\\\\\\\\\\\\n    messages = moderator.chat_log.get_messages()\\\\\\\\\\\\\\\\n    last_message = messages[-1]\\\\\\\\\\\\\\\\n    assert len(last_message.content) <= 503  # 500 + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n        },\\\\\\\\n        \\\\\\\\\\\\\\\"test_voting.py\\\\\\\\\\\\\\\": {\\\\\\\\n          \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"tests/test_voting.py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n          \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 16340,\\\\\\\\n          \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nTests for the VotingSystem class.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\nfrom app.voting import VotingSystem, Vote, VotingResults\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef voting_config():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test voting configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\n        'enabled': True,\\\\\\\\\\\\\\\\n        'voting_duration': 60,\\\\\\\\\\\\\\\\n        'allow_participant_voting': True,\\\\\\\\\\\\\\\\n        'require_justification': False,\\\\\\\\\\\\\\\\n        'anonymous_votes': False\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef voting_system(voting_config):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    return VotingSystem(voting_config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\ndef active_voting_system(voting_system):\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create and start a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    asyncio.create_task(voting_system.start_voting(['Alice', 'Bob', 'Charlie'], 30))\\\\\\\\\\\\\\\\n    return voting_system\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestVotingSystem:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for VotingSystem class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_voting_system_initialization(self, voting_config):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting system initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        vs = VotingSystem(voting_config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert vs.enabled == True\\\\\\\\\\\\\\\\n        assert vs.voting_duration == 60\\\\\\\\\\\\\\\\n        assert vs.allow_participant_voting == True\\\\\\\\\\\\\\\\n        assert vs.require_justification == False\\\\\\\\\\\\\\\\n        assert vs.anonymous_votes == False\\\\\\\\\\\\\\\\n        assert vs.is_active == False\\\\\\\\\\\\\\\\n        assert vs.candidates == []\\\\\\\\\\\\\\\\n        assert vs.votes == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_disabled_voting_system(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test disabled voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = {'enabled': False}\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert vs.enabled == False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_start_voting_session(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test starting a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        candidates = ['Alice', 'Bob', 'Charlie']\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await voting_system.start_voting(candidates, 30)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert voting_system.is_active == True\\\\\\\\\\\\\\\\n        assert voting_system.candidates == candidates\\\\\\\\\\\\\\\\n        assert voting_system.eligible_voters == candidates  # allow_participant_voting=True\\\\\\\\\\\\\\\\n        assert voting_system.start_time is not None\\\\\\\\\\\\\\\\n        assert voting_system.end_time is not None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_start_voting_disabled_system(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test starting voting on disabled system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = {'enabled': False}\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting system is disabled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await vs.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_start_voting_already_active(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test starting voting when already active.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting session already active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await voting_system.start_voting(['Charlie', 'Dave'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_cast_valid_vote(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting a valid vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        result = await voting_system.cast_vote('voter1', 'Alice', 'Great arguments')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\n        assert 'voter1' in voting_system.votes\\\\\\\\\\\\\\\\n        assert voting_system.votes['voter1'].candidate == 'Alice'\\\\\\\\\\\\\\\\n        assert voting_system.votes['voter1'].justification == 'Great arguments'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_cast_vote_no_active_session(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting vote with no active session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_cast_vote_invalid_candidate(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting vote for invalid candidate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await voting_system.cast_vote('voter1', 'Charlie')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_cast_vote_requires_justification(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting system that requires justification.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = {\\\\\\\\\\\\\\\\n            'enabled': True,\\\\\\\\\\\\\\\\n            'require_justification': True,\\\\\\\\\\\\\\\\n            'allow_participant_voting': True\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Vote without justification should fail\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote justification is required\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await vs.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Vote with justification should succeed\\\\\\\\\\\\\\\\n        result = await vs.cast_vote('voter1', 'Alice', 'Good points')\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_cast_vote_overwrite(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test that new vote overwrites previous vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Bob')  # Change vote\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert voting_system.votes['voter1'].candidate == 'Bob'\\\\\\\\\\\\\\\\n        assert len(voting_system.votes) == 1  # Only one vote per voter\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test self-voting when allowed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test self-voting when allowed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Should allow participant to vote for themselves\\\\\\\\\\\\\\\\n        result = await voting_system.cast_vote('Alice', 'Alice')\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_self_voting_disallowed(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test self-voting when disallowed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        config = {\\\\\\\\\\\\\\\\n            'enabled': True,\\\\\\\\\\\\\\\\n            'allow_participant_voting': False\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Self-voting is not allowed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await vs.cast_vote('Alice', 'Alice')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_end_voting_session(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Cast some votes\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter2', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter3', 'Bob')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(results, VotingResults)\\\\\\\\\\\\\\\\n        assert results.winner == 'Alice'  # Most votes\\\\\\\\\\\\\\\\n        assert results.vote_counts['Alice'] == 2\\\\\\\\\\\\\\\\n        assert results.vote_counts['Bob'] == 1\\\\\\\\\\\\\\\\n        assert results.total_votes == 3\\\\\\\\\\\\\\\\n        assert voting_system.is_active == False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_end_voting_tie(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending voting with a tie.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter2', 'Bob')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TIE:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results.winner\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results.winner\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results.winner\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_end_voting_no_votes(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending voting with no votes cast.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert results.winner is None\\\\\\\\\\\\\\\\n        assert results.total_votes == 0\\\\\\\\\\\\\\\\n        assert results.vote_counts == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_end_voting_not_active(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending voting when not active.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_get_vote_summary(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting vote summary during active session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # No active session\\\\\\\\\\\\\\\\n        summary = voting_system.get_vote_summary()\\\\\\\\\\\\\\\\n        assert summary == {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # With active session\\\\\\\\\\\\\\\\n        asyncio.create_task(voting_system.start_voting(['Alice', 'Bob'], 60))\\\\\\\\\\\\\\\\n        summary = voting_system.get_vote_summary()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert 'candidates' in summary\\\\\\\\\\\\\\\\n        assert 'vote_counts' in summary\\\\\\\\\\\\\\\\n        assert 'total_votes' in summary\\\\\\\\\\\\\\\\n        assert 'time_remaining' in summary\\\\\\\\\\\\\\\\n        assert 'is_active' in summary\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_add_remove_eligible_voters(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test adding and removing eligible voters.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        voting_system.add_eligible_voter('voter1')\\\\\\\\\\\\\\\\n        assert 'voter1' in voting_system.eligible_voters\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        voting_system.add_eligible_voter('voter2')\\\\\\\\\\\\\\\\n        assert len(voting_system.eligible_voters) == 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        voting_system.remove_eligible_voter('voter1')\\\\\\\\\\\\\\\\n        assert 'voter1' not in voting_system.eligible_voters\\\\\\\\\\\\\\\\n        assert len(voting_system.eligible_voters) == 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_is_eligible_voter(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voter eligibility checking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Empty eligible voters list means open voting\\\\\\\\\\\\\\\\n        assert voting_system._is_eligible_voter('anyone') == True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # With specific eligible voters\\\\\\\\\\\\\\\\n        voting_system.add_eligible_voter('voter1')\\\\\\\\\\\\\\\\n        assert voting_system._is_eligible_voter('voter1') == True\\\\\\\\\\\\\\\\n        assert voting_system._is_eligible_voter('voter2') == False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_vote_history(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test vote history tracking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # First session\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Second session\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Charlie', 'Dave'])\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Charlie')\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert len(voting_system.vote_history) == 2\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Test voter history\\\\\\\\\\\\\\\\n        voter_history = voting_system.get_voter_history('voter1')\\\\\\\\\\\\\\\\n        assert len(voter_history) == 2\\\\\\\\\\\\\\\\n        assert voter_history[0].candidate == 'Alice'\\\\\\\\\\\\\\\\n        assert voter_history[1].candidate == 'Charlie'\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_candidate_performance(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test candidate performance tracking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Add some mock history\\\\\\\\\\\\\\\\n        voting_system.vote_history = [\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\n                'candidates': ['Alice', 'Bob'],\\\\\\\\\\\\\\\\n                'results': VotingResults(\\\\\\\\\\\\\\\\n                    winner='Alice',\\\\\\\\\\\\\\\\n                    vote_counts={'Alice': 2, 'Bob': 1},\\\\\\\\\\\\\\\\n                    total_votes=3,\\\\\\\\\\\\\\\\n                    votes_by_voter={},\\\\\\\\\\\\\\\\n                    voting_duration=60,\\\\\\\\\\\\\\\\n                    participation_rate=1.0\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n            },\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\n                'candidates': ['Alice', 'Charlie'],\\\\\\\\\\\\\\\\n                'results': VotingResults(\\\\\\\\\\\\\\\\n                    winner='Charlie',\\\\\\\\\\\\\\\\n                    vote_counts={'Alice': 1, 'Charlie': 2},\\\\\\\\\\\\\\\\n                    total_votes=3,\\\\\\\\\\\\\\\\n                    votes_by_voter={},\\\\\\\\\\\\\\\\n                    voting_duration=60,\\\\\\\\\\\\\\\\n                    participation_rate=1.0\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        performance = voting_system.get_candidate_performance('Alice')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert performance['wins'] == 1\\\\\\\\\\\\\\\\n        assert performance['participations'] == 2\\\\\\\\\\\\\\\\n        assert performance['total_votes'] == 3\\\\\\\\\\\\\\\\n        assert performance['win_rate'] == 0.5\\\\\\\\\\\\\\\\n        assert performance['avg_votes'] == 1.5\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_export_results_json(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting results in JSON format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Create some history\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        json_output = await voting_system.export_results('json')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(json_output, str)\\\\\\\\\\\\\\\\n        assert 'Alice' in json_output\\\\\\\\\\\\\\\\n        assert 'vote_counts' in json_output\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_export_results_csv(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting results in CSV format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        csv_output = await voting_system.export_results('csv')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(csv_output, str)\\\\\\\\\\\\\\\\n        assert 'Session,Timestamp,Candidate,Votes,Winner' in csv_output\\\\\\\\\\\\\\\\n        assert 'Alice' in csv_output\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_export_results_txt(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting results in TXT format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        txt_output = await voting_system.export_results('txt')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert isinstance(txt_output, str)\\\\\\\\\\\\\\\\n        assert 'VOTING HISTORY REPORT' in txt_output\\\\\\\\\\\\\\\\n        assert 'Alice' in txt_output\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_export_unsupported_format(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting with unsupported format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await voting_system.export_results('xml')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_reset_voting_system(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test resetting the voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Set up some state\\\\\\\\\\\\\\\\n        voting_system.candidates = ['Alice', 'Bob']\\\\\\\\\\\\\\\\n        voting_system.votes = {'voter1': Vote('voter1', 'Alice')}\\\\\\\\\\\\\\\\n        voting_system.is_active = True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        voting_system.reset()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert voting_system.is_active == False\\\\\\\\\\\\\\\\n        assert voting_system.candidates == []\\\\\\\\\\\\\\\\n        assert voting_system.votes == {}\\\\\\\\\\\\\\\\n        assert voting_system.start_time is None\\\\\\\\\\\\\\\\n        assert voting_system.end_time is None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_voting_system_status(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting system status property.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        status = voting_system.status\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert 'enabled' in status\\\\\\\\\\\\\\\\n        assert 'is_active' in status\\\\\\\\\\\\\\\\n        assert 'candidates' in status\\\\\\\\\\\\\\\\n        assert 'eligible_voters' in status\\\\\\\\\\\\\\\\n        assert 'votes_cast' in status\\\\\\\\\\\\\\\\n        assert 'time_remaining' in status\\\\\\\\\\\\\\\\n        assert 'sessions_completed' in status\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\n    async def test_vote_after_time_expires(self, voting_system):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting vote after voting time expires.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        # Start voting with very short duration\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'], 0.1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Wait for voting to expire\\\\\\\\\\\\\\\\n        await asyncio.sleep(0.2)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting period has ended\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestVote:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for Vote dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_vote_creation(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating a vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        vote = Vote('voter1', 'Alice', 'Great arguments')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert vote.voter_id == 'voter1'\\\\\\\\\\\\\\\\n        assert vote.candidate == 'Alice'\\\\\\\\\\\\\\\\n        assert vote.justification == 'Great arguments'\\\\\\\\\\\\\\\\n        assert vote.anonymous == False\\\\\\\\\\\\\\\\n        assert isinstance(vote.timestamp, float)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_vote_anonymous(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating anonymous vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        vote = Vote('voter1', 'Alice', anonymous=True)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert vote.anonymous == True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_vote_no_justification(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test vote without justification.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        vote = Vote('voter1', 'Alice')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert vote.justification is None\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nclass TestVotingResults:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for VotingResults dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    def test_voting_results_creation(self):\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating voting results.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        vote_counts = {'Alice': 2, 'Bob': 1}\\\\\\\\\\\\\\\\n        votes_by_voter = {\\\\\\\\\\\\\\\\n            'voter1': Vote('voter1', 'Alice'),\\\\\\\\\\\\\\\\n            'voter2': Vote('voter2', 'Alice'),\\\\\\\\\\\\\\\\n            'voter3': Vote('voter3', 'Bob')\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        results = VotingResults(\\\\\\\\\\\\\\\\n            winner='Alice',\\\\\\\\\\\\\\\\n            vote_counts=vote_counts,\\\\\\\\\\\\\\\\n            total_votes=3,\\\\\\\\\\\\\\\\n            votes_by_voter=votes_by_voter,\\\\\\\\\\\\\\\\n            voting_duration=60.0,\\\\\\\\\\\\\\\\n            participation_rate=1.0\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        assert results.winner == 'Alice'\\\\\\\\\\\\\\\\n        assert results.vote_counts == vote_counts\\\\\\\\\\\\\\\\n        assert results.total_votes == 3\\\\\\\\\\\\\\\\n        assert len(results.votes_by_voter) == 3\\\\\\\\\\\\\\\\n        assert results.voting_duration == 60.0\\\\\\\\\\\\\\\\n        assert results.participation_rate == 1.0\\\\\\\\\\\\\\\"\\\\\\\\n        }\\\\\\\\n      }\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 2896,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# AI Jubilee Debate Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Debate Settings\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\n  default_topic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The role of artificial intelligence in modern society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  max_participants: 5\\\\\\\\\\\\\\\\n  time_limit_minutes: 30\\\\\\\\\\\\\\\\n  opening_statement_time: 120  # seconds\\\\\\\\\\\\\\\\n  response_time: 60  # seconds\\\\\\\\\\\\\\\\n  closing_statement_time: 90  # seconds\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n  # Debate mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sequential\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # AUTONOMOUS MODE: Bots monitor and decide when to speak!\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n  # Autonomous mode settings\\\\\\\\\\\\\\\\n  min_bot_cooldown: 15          # Minimum seconds between bot responses\\\\\\\\\\\\\\\\n  max_bot_cooldown: 45          # Maximum cooldown for very active bots\\\\\\\\\\\\\\\\n  message_check_interval: 5     # How often bots check for new messages\\\\\\\\\\\\\\\\n  silence_timeout: 60           # Seconds of silence before moderator intervenes\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Available debate topics\\\\\\\\\\\\\\\\ntopics:\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Social media has a net positive impact on democracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work is the future of employment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# AI Bot Configurations\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"socratic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Passionate supporter, data-driven, persuasive speaker. Jumps in when position is challenged.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"assertive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Balanced, seeks common ground, diplomatic. Speaks to bridge disagreements and find synthesis.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"collaborative\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# API Keys (use environment variables in production)\\\\\\\\\\\\\\\\napi_keys:\\\\\\\\\\\\\\\\n  openai: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"${OPENAI_API_KEY}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  anthropic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"${ANTHROPIC_API_KEY}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Voting System\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\n  voting_duration: 300  # seconds\\\\\\\\\\\\\\\\n  allow_participant_voting: true\\\\\\\\\\\\\\\\n  require_justification: true\\\\\\\\\\\\\\\\n  anonymous_votes: false\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Chat and Logging\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\n  max_message_length: 500\\\\\\\\\\\\\\\\n  enable_timestamps: true\\\\\\\\\\\\\\\\n  log_level: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n  save_transcripts: true\\\\\\\\\\\\\\\\n  transcript_format: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Streaming Configuration\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\n  enabled: false\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\n  max_connections: 100\\\\\\\\\\\\\\\\n  broadcast_votes: true\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Timeouts and Limits\\\\\\\\\\\\\\\\nlimits:\\\\\\\\\\\\\\\\n  max_response_time: 120  # seconds\\\\\\\\\\\\\\\\n  warning_time: 90  # seconds\\\\\\\\\\\\\\\\n  max_retries: 3\\\\\\\\\\\\\\\\n  rate_limit_per_minute: 10\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Moderation Rules\\\\\\\\\\\\\\\\nmoderation:\\\\\\\\\\\\\\\\n  enable_profanity_filter: true\\\\\\\\\\\\\\\\n  max_interruptions: 3\\\\\\\\\\\\\\\\n  enforce_turn_order: false  # No turn order in autonomous mode\\\\\\\\\\\\\\\\n  auto_mute_violations: true\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Human Interface\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # options: cli, web, api\\\\\\\\\\\\\\\\n  enable_rich_formatting: true\\\\\\\\\\\\\\\\n  show_typing_indicators: true\\\\\\\\\\\\\\\\n  enable_reactions: true\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"debate_Remote work is the f.json\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"debate_Remote work is the f.json\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 13661,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"export_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812154.74717,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"unique_senders\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 33,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3\\\\\\\\\\\\\\\\n      },\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_per_minute\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 12.37544767478349,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"session_duration_minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3.5554269353548684,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"current_message_count\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n  },\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠ Welcome to AI  Debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüìù Topic: Remote work is the future of employment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüë• Participants: Socrates, Advocate, Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚è±Ô∏è Total time: 30 minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811941.5010219,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Opening Statements Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEach participant has 120 seconds for their opening statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811944.502393,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 2,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for opening statement (120s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811944.502721,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811954.512209,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thank you, dear moderator. As we embark on this discourse, let us consider not just the nature of remote work, but also the essence of employment itself. What are the fundamental elements of work? One might posit that they include collaboration, productivity, and satisfaction, among other things.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRemote work, undeniably, has altered the landscape of employment. It transcends geographical boundaries, allows for flexibility, and can, in some cases, increase productivity. Yet, it also brings forth...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811954.5130692,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 5,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for opening statement (120s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811954.5131688,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 6,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811965.525105,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 7,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Thank you, moderator. I firmly believe that remote work represents the future of employment. The digital age has brought about unprecedented technological advancements, enabling us to work from anywhere, at any time. This is not just a passing trend, but a fundamental shift in how we approach work.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nData from a study by Stanford University shows that remote workers are 13% more productive than their in-office counterparts. It also reduces costs for businesses by eliminating the need fo...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811965.5253692,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 8,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for opening statement (120s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811965.5253801,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 9,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 89 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811995.5549319,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 10,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hei i don¬¥t belive you\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.5676649,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 11,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Discussion Phase Begin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOpen discussion for 30 minutes. Maintain respectful dialogue!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.567806,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 12,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.569291,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 13,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Socrates: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.569945,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 14,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates: It appears there may be some confusion, my friend. We are here to debate the future of remote work, not to question our trust in one another. I would like to ask you, do you believe that the rise in remote work we have seen in recent years, especially during the pandemic, is a temporary phenomenon, or do you think it hints at a more permanent shift in the way we approach work?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812011.574508,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812011.574569,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 16,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812011.5753531,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 17,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.583849,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 18,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Thank you, Socrates, for your question. I firmly believe that the rise in remote work is not just a temporary phenomenon but a reflection of a more significant, more permanent shift in work arrangements. A study from Upwork's \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Future Workforce Report\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" suggests that 22% of the American workforce will be remote by 2025, a staggering 87% increase from pre-pandemic levels. This is not just a response to the pandemic, but a result of businesses realizing the benefits of remote work, includi...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.584952,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.585004,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.5856278,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 21,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tell me that you love me\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812027.595841,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 22,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812027.595914,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 23,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Socrates: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812027.597049,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 24,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.60398,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 25,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates: Indeed, the Upwork report is an insightful piece of evidence. However, might we not question whether this shift is wholly beneficial for both employers and employees? For instance, remote work may lead to a blurring of boundaries between work and home life, potentially leading to stress and burnout. Moreover, does this shift not potentially exacerbate inequalities, since not all jobs can be performed remotely ‚Äì a privilege often reserved for certain types of jobs and sectors? Lastly, o...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.605064,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 26,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.6051142,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 27,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.605727,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 28,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616073,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 29,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Valid points, Socrates. However, let's tackle them one by one. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFirstly, the challenge of work-life balance is indeed present in remote work. But it's not unique to it. Many traditionally structured jobs also struggle with it. The key here is proper management and the setting of boundaries, which can be learned and improved. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nIn terms of exacerbating inequalities, it's true that not all jobs can be performed remotely. Yet, the move towards remote work can potentially reduce inequalit...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616268,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 30,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616277,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 31,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 60 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616369,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 32,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"eliminate me\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812072.650063,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 33,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812072.650076,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 34,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Socrates: 60 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812072.650274,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 35,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.6638489,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 36,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates: I agree, dear advocate, that work-life balance is a challenge that transcends the confines of remote work. However, might it be that the boundary between work and life becomes especially blurred when both occur within the same physical space? \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAs for the potential of remote work to reduce inequalities, this is indeed a tantalizing prospect. Yet, we must ask ourselves: does the shift to remote work not risk creating a new form of inequality? Those with access to technology, stable inte...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.664929,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 37,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.664972,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 38,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.6655931,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 39,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679034,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 40,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Socrates, I appreciate your thoughtful concerns about blurring boundaries and potential inequalities. However, I would argue that these are challenges to be managed, not insurmountable barriers.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nIn terms of blurred boundaries, it's crucial to set up remote work policies that respect employees' personal time and create a distinction between work and home life. Companies like Buffer have already demonstrated that this is possible by implementing 'no-work weekends' and mandatory vacation...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679281,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 41,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679292,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 42,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 60 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679415,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 43,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1 exceeded time limit. Warning 1/3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812154.746779,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n  ]\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"extract.py\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"extract.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 13812,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nExtract script to read all project files and create a JSON structure.\\\\\\\\\\\\\\\\nReads all .py, .md, .yml, .yaml files and organizes them in a nested directory structure.\\\\\\\\\\\\\\\\nRespects .gitignore patterns and skips virtual environments.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n python extract.py --preview\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\nimport datetime\\\\\\\\\\\\\\\\nimport fnmatch\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\nfrom typing import Dict, Any, Set, List\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef parse_gitignore(gitignore_path: Path) -> List[str]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Parse .gitignore file and return list of patterns.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    patterns = []\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        if gitignore_path.exists():\\\\\\\\\\\\\\\\n            with open(gitignore_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n                for line in f:\\\\\\\\\\\\\\\\n                    line = line.strip()\\\\\\\\\\\\\\\\n                    # Skip empty lines and comments\\\\\\\\\\\\\\\\n                    if line and not line.startswith('#'):\\\\\\\\\\\\\\\\n                        patterns.append(line)\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning: Could not read .gitignore: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    return patterns\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef is_ignored_by_gitignore(file_path: Path, root_path: Path, gitignore_patterns: List[str]) -> bool:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if file is ignored by .gitignore patterns.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        # Get relative path from root\\\\\\\\\\\\\\\\n        relative_path = file_path.relative_to(root_path)\\\\\\\\\\\\\\\\n        path_str = str(relative_path)\\\\\\\\\\\\\\\\n        path_parts = relative_path.parts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for pattern in gitignore_patterns:\\\\\\\\\\\\\\\\n            # Handle different gitignore pattern types\\\\\\\\\\\\\\\\n            if pattern.endswith('/'):\\\\\\\\\\\\\\\\n                # Directory pattern\\\\\\\\\\\\\\\\n                pattern = pattern.rstrip('/')\\\\\\\\\\\\\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\n            elif '/' in pattern:\\\\\\\\\\\\\\\\n                # Path pattern\\\\\\\\\\\\\\\\n                if fnmatch.fnmatch(path_str, pattern):\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\n                # Filename pattern\\\\\\\\\\\\\\\\n                if fnmatch.fnmatch(file_path.name, pattern):\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\n                # Also check if any parent directory matches\\\\\\\\\\\\\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\n    except ValueError:\\\\\\\\\\\\\\\\n        # Path is not relative to root\\\\\\\\\\\\\\\\n        pass\\\\\\\\\\\\\\\\n    except Exception:\\\\\\\\\\\\\\\\n        # Any other error, don't ignore\\\\\\\\\\\\\\\\n        pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef should_include_file(file_path: Path) -> bool:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if file should be included based on extension.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    allowed_extensions = {'.py', '.md', '.yml', '.yaml', '.txt', '.json', '.toml', '.cfg', '.ini'}\\\\\\\\\\\\\\\\n    return file_path.suffix.lower() in allowed_extensions\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef should_skip_directory(dir_name: str) -> bool:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if directory should be skipped (common build/cache directories).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    skip_dirs = {\\\\\\\\\\\\\\\\n        '__pycache__',\\\\\\\\\\\\\\\\n        '.git',\\\\\\\\\\\\\\\\n        '.pytest_cache',\\\\\\\\\\\\\\\\n        'node_modules',\\\\\\\\\\\\\\\\n        '.venv',\\\\\\\\\\\\\\\\n        'venv',\\\\\\\\\\\\\\\\n        'env',\\\\\\\\\\\\\\\\n        '.env',\\\\\\\\\\\\\\\\n        'ENV',\\\\\\\\\\\\\\\\n        'env.bak',\\\\\\\\\\\\\\\\n        'venv.bak',\\\\\\\\\\\\\\\\n        'dist',\\\\\\\\\\\\\\\\n        'build',\\\\\\\\\\\\\\\\n        '.idea',\\\\\\\\\\\\\\\\n        '.vscode',\\\\\\\\\\\\\\\\n        'htmlcov',\\\\\\\\\\\\\\\\n        '.coverage',\\\\\\\\\\\\\\\\n        '.mypy_cache',\\\\\\\\\\\\\\\\n        '.tox',\\\\\\\\\\\\\\\\n        '.cache',\\\\\\\\\\\\\\\\n        'eggs',\\\\\\\\\\\\\\\\n        '*.egg-info',\\\\\\\\\\\\\\\\n        '.eggs',\\\\\\\\\\\\\\\\n        'lib',\\\\\\\\\\\\\\\\n        'lib64',\\\\\\\\\\\\\\\\n        'parts',\\\\\\\\\\\\\\\\n        'sdist',\\\\\\\\\\\\\\\\n        'var',\\\\\\\\\\\\\\\\n        'wheels',\\\\\\\\\\\\\\\\n        'share/python-wheels',\\\\\\\\\\\\\\\\n        '*.egg-info/',\\\\\\\\\\\\\\\\n        '.installed.cfg',\\\\\\\\\\\\\\\\n        '*.egg',\\\\\\\\\\\\\\\\n        'MANIFEST',\\\\\\\\\\\\\\\\n        '.DS_Store',\\\\\\\\\\\\\\\\n        'Thumbs.db'\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n    return dir_name in skip_dirs\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef is_virtual_environment(dir_path: Path) -> bool:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if directory is a virtual environment.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    venv_indicators = [\\\\\\\\\\\\\\\\n        'pyvenv.cfg',\\\\\\\\\\\\\\\\n        'Scripts/activate',\\\\\\\\\\\\\\\\n        'bin/activate',\\\\\\\\\\\\\\\\n        'Scripts/python.exe',\\\\\\\\\\\\\\\\n        'bin/python'\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for indicator in venv_indicators:\\\\\\\\\\\\\\\\n        if (dir_path / indicator).exists():\\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Check for common venv directory names\\\\\\\\\\\\\\\\n    venv_names = {'venv', '.venv', 'env', '.env', 'ENV', 'virtualenv'}\\\\\\\\\\\\\\\\n    if dir_path.name in venv_names:\\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef read_file_content(file_path: Path) -> str:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Read file content safely.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            return f.read()\\\\\\\\\\\\\\\\n    except UnicodeDecodeError:\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            with open(file_path, 'r', encoding='latin-1') as f:\\\\\\\\\\\\\\\\n                return f.read()\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Error reading file: {e}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Error reading file: {e}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef extract_directory_structure(root_path: Path, base_path: Path = None, gitignore_patterns: List[str] = None) -> Dict[\\\\\\\\\\\\\\\\n    str, Any]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    Recursively extract directory structure and file contents.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\n        root_path: Path to extract from\\\\\\\\\\\\\\\\n        base_path: Base path for relative calculations (optional)\\\\\\\\\\\\\\\\n        gitignore_patterns: List of gitignore patterns to respect\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\n        Dictionary with nested structure representing directories and files\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    if base_path is None:\\\\\\\\\\\\\\\\n        base_path = root_path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if gitignore_patterns is None:\\\\\\\\\\\\\\\\n        gitignore_patterns = []\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    structure = {}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        # Ensure we have a Path object\\\\\\\\\\\\\\\\n        if not isinstance(root_path, Path):\\\\\\\\\\\\\\\\n            root_path = Path(root_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if not isinstance(base_path, Path):\\\\\\\\\\\\\\\\n            base_path = Path(base_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Check if path exists and is directory\\\\\\\\\\\\\\\\n        if not root_path.exists():\\\\\\\\\\\\\\\\n            return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Path does not exist: {root_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if not root_path.is_dir():\\\\\\\\\\\\\\\\n            return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Path is not a directory: {root_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Get all items in directory\\\\\\\\\\\\\\\\n        items = list(root_path.iterdir())\\\\\\\\\\\\\\\\n        items.sort(key=lambda x: (x.is_file(), x.name.lower()))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        for item in items:\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\n                # Check if item is ignored by gitignore\\\\\\\\\\\\\\\\n                if is_ignored_by_gitignore(item, base_path, gitignore_patterns):\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Skip hidden files except specific ones\\\\\\\\\\\\\\\\n                if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore', '.gitattributes'}:\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                if item.is_dir():\\\\\\\\\\\\\\\\n                    # Skip certain directories\\\\\\\\\\\\\\\\n                    if should_skip_directory(item.name):\\\\\\\\\\\\\\\\n                        continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Skip virtual environments\\\\\\\\\\\\\\\\n                    if is_virtual_environment(item):\\\\\\\\\\\\\\\\n                        continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                    # Recursively process subdirectories\\\\\\\\\\\\\\\\n                    substructure = extract_directory_structure(item, base_path, gitignore_patterns)\\\\\\\\\\\\\\\\n                    if substructure:  # Only add if not empty\\\\\\\\\\\\\\\\n                        structure[item.name] = {\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": substructure\\\\\\\\\\\\\\\\n                        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                elif item.is_file():\\\\\\\\\\\\\\\\n                    # Only include certain file types\\\\\\\\\\\\\\\\n                    if should_include_file(item):\\\\\\\\\\\\\\\\n                        file_content = read_file_content(item)\\\\\\\\\\\\\\\\n                        try:\\\\\\\\\\\\\\\\n                            relative_path = str(item.relative_to(base_path))\\\\\\\\\\\\\\\\n                        except ValueError:\\\\\\\\\\\\\\\\n                            relative_path = str(item)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                        structure[item.name] = {\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": relative_path,\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": item.suffix,\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": len(file_content),\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_content\\\\\\\\\\\\\\\\n                        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            except PermissionError:\\\\\\\\\\\\\\\\n                structure[f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error_{item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Permission denied accessing: {item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                continue\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\n                structure[f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error_{item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing {item.name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    except PermissionError as e:\\\\\\\\\\\\\\\\n        structure[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Permission denied: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        structure[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing directory: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return structure\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef count_items_recursive(structure: Dict[str, Any]) -> Dict[str, int]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Count files and directories recursively.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    counts = {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for name, item in structure.items():\\\\\\\\\\\\\\\\n        if name.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if isinstance(item, dict):\\\\\\\\\\\\\\\\n            if item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += 1\\\\\\\\\\\\\\\\n                sub_counts = count_items_recursive(item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}))\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n                # Merge file types\\\\\\\\\\\\\\\\n                for ext, count in sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].items():\\\\\\\\\\\\\\\\n                    counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][ext] = counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(ext, 0) + count\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n            elif item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += 1\\\\\\\\\\\\\\\\n                ext = item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][ext] = counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(ext, 0) + 1\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return counts\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef create_project_metadata(root_path: Path, structure: Dict[str, Any]) -> Dict[str, Any]:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create metadata about the project.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    counts = count_items_recursive(structure)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    metadata = {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": root_path.name,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extraction_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": datetime.datetime.now().isoformat(),\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"root_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": str(root_path.absolute()),\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"respects_gitignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": True,\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"skips_virtual_environments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": True\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    return metadata\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef preview_structure(structure: Dict[str, Any], indent: int = 0) -> None:\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Preview the extracted structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    prefix = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * indent\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    for name, item in structure.items():\\\\\\\\\\\\\\\\n        if name.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\n            continue\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        if isinstance(item, dict):\\\\\\\\\\\\\\\\n            if item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{prefix}üìÅ {name}/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                preview_structure(item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}), indent + 1)\\\\\\\\\\\\\\\\n            elif item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n                size = item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0)\\\\\\\\\\\\\\\\n                ext = item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{prefix}üìÑ {name} ({size:,} chars, {ext})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef main():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main extraction function.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Get current directory or specified directory\\\\\\\\\\\\\\\\n    import sys\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if len(sys.argv) > 1:\\\\\\\\\\\\\\\\n        root_dir = Path(sys.argv[1])\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n        root_dir = Path.cwd()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Ensure we have a Path object\\\\\\\\\\\\\\\\n    if not isinstance(root_dir, Path):\\\\\\\\\\\\\\\\n        root_dir = Path(root_dir)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not root_dir.exists():\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: Directory {root_dir} does not exist\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not root_dir.is_dir():\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: {root_dir} is not a directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîç Extracting project structure from: {root_dir.absolute()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìÅ Reading all .py, .md, .yml, .yaml, .txt, .json files...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Parse .gitignore if it exists\\\\\\\\\\\\\\\\n    gitignore_path = root_dir / '.gitignore'\\\\\\\\\\\\\\\\n    gitignore_patterns = parse_gitignore(gitignore_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if gitignore_patterns:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã Found .gitignore with {len(gitignore_patterns)} patterns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã No .gitignore found or empty\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üö´ Skipping virtual environments and build directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Extract the directory structure\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Create metadata\\\\\\\\\\\\\\\\n        metadata = create_project_metadata(root_dir, structure)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Create project data\\\\\\\\\\\\\\\\n        project_data = {\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata,\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": structure\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Output filename\\\\\\\\\\\\\\\\n        output_file = root_dir / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Write JSON file\\\\\\\\\\\\\\\\n        with open(output_file, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\n            json.dump(project_data, f, indent=2, ensure_ascii=False)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Extraction complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Statistics:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Total files: {metadata['total_files']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Total directories: {metadata['total_directories']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Total size: {metadata['total_size']:,} characters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìÑ Output saved to: {output_file}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Show file type breakdown\\\\\\\\\\\\\\\\n        if metadata['file_types']:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüìã File type breakdown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            for ext, count in sorted(metadata['file_types'].items()):\\\\\\\\\\\\\\\\n                ext_name = ext if ext else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"(no extension)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ {ext_name}: {count} files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Error during extraction: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        import traceback\\\\\\\\\\\\\\\\n        traceback.print_exc()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n    # Add preview option\\\\\\\\\\\\\\\\n    import sys\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--preview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in sys.argv:\\\\\\\\\\\\\\\\n        sys.argv.remove(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--preview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Get directory\\\\\\\\\\\\\\\\n        if len(sys.argv) > 1:\\\\\\\\\\\\\\\\n            root_dir = Path(sys.argv[1])\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\n            root_dir = Path.cwd()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Parse .gitignore\\\\\\\\\\\\\\\\n        gitignore_path = root_dir / '.gitignore'\\\\\\\\\\\\\\\\n        gitignore_patterns = parse_gitignore(gitignore_path)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîç Preview of project structure: {root_dir.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        if gitignore_patterns:\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã Respecting .gitignore with {len(gitignore_patterns)} patterns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 50)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\\\\\\\\\\\\\n        preview_structure(structure)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\n        main()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 287502,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AIMafia\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extraction_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-06-13T13:47:28.958343\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"root_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/Users/voicutomut/Documents/GitHub/AIMafia\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 23,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 2,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 268209,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"respects_gitignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": true,\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"skips_virtual_environments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": true\\\\\\\\\\\\\\\\n  },\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__init__.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/__init__.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 489,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAI  Debate System\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nA platform for structured debates between AI bots and human participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n__version__ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n__author__ = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AndreiVoicuT\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .main import start_debate_session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .moderator import Moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .human_client import HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n__all__ = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"start_debate_session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ChatLog\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bot_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/bot_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 12395,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAI Bot client for interacting with various language models in debates.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom abc import ABC, abstractmethod\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .chat_log import Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .utils import truncate_text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass BotConfig:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration for AI bot behavior.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    temperature: float = 0.7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    max_tokens: int = 300\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    timeout: int = 30\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass AIProvider(ABC):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Abstract base class for AI providers.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @abstractmethod\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response from the AI model.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass OpenAIProvider(AIProvider):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OpenAI API provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, api_key: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.api_key = api_key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response using OpenAI API.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            import openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            client = openai.AsyncOpenAI(api_key=self.api_key)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await client.chat.completions.create(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                model=config.model,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                messages=messages,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                max_tokens=config.max_tokens,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                temperature=config.temperature,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timeout=config.timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return response.choices[0].message.content.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise Exception(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OpenAI API error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass AnthropicProvider(AIProvider):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Anthropic API provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, api_key: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.api_key = api_key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def generate_response(self, messages: List[Dict[str, str]],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                              config: BotConfig) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate response using Anthropic API.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            import anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            client = anthropic.AsyncAnthropic(api_key=self.api_key)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Convert messages format for Anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            system_message = messages[0]['content'] if messages and messages[0]['role'] == 'system' else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            user_messages = [msg for msg in messages if msg['role'] != 'system']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await client.messages.create(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                model=config.model,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                max_tokens=config.max_tokens,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                temperature=config.temperature,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                system=system_message,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                messages=user_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return response.content[0].text.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise Exception(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Anthropic API error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass BotClient:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    AI Bot client that participates in debates using various language models.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, name: str, model: str, provider: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                 personality: str, stance: str, api_key: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                 temperature: float = 0.7, max_tokens: int = 300):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=name,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            model=model,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            provider=provider,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            personality=personality,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance=stance,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            temperature=temperature,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            max_tokens=max_tokens\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Initialize AI provider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if provider.lower() == 'openai':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.ai_provider = OpenAIProvider(api_key)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif provider.lower() == 'anthropic':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.ai_provider = AnthropicProvider(api_key)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported AI provider: {provider}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Bot state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.conversation_history: List[Dict[str, str]] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.debate_context = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.message_queue = asyncio.Queue()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.response_count = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Performance tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'responses_generated': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'average_response_time': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_response_time': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'errors': 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def name(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get bot name.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return self.config.name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def get_response(self, topic: str, recent_messages: List[Message]) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Generate a response to the current debate context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            topic: Current debate topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            recent_messages: Recent messages from the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Generated response string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Prepare conversation context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            messages = self._prepare_messages(topic, recent_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Generate response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await self.ai_provider.generate_response(messages, self.config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Update statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response_time = time.time() - start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self._update_stats(response_time, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Store in conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.conversation_history.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'role': 'assistant',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'content': response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.response_count += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self._update_stats(time.time() - start_time, success=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot {self.name} error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return self._generate_fallback_response(topic)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _prepare_messages(self, topic: str, recent_messages: List[Message]) -> List[Dict[str, str]]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Prepare message context for AI model.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # System message with bot personality and instructions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        system_prompt = self._create_system_prompt(topic)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'role': 'system',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'content': system_prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add recent conversation context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in recent_messages[-5:]:  # Last 5 messages for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            role = 'assistant' if msg.sender == self.name else 'user'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            content = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{msg.sender}: {msg.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            messages.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'role': role,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'content': content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _create_system_prompt(self, topic: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create system prompt based on bot configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are {self.config.name}, participating in an AUTONOMOUS structured debate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nDEBATE TOPIC: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYOUR ROLE AND PERSONALITY:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Personality: {self.config.personality}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Stance: {self.config.stance}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Debate Style: Professional yet engaging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAUTONOMOUS DEBATE RULES:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. You are monitoring the conversation and will be asked IF you want to respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Only respond when you feel compelled to contribute meaningfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. You have access to the FULL conversation history for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Focus on the topic and respond to specific points made by others\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n5. Keep responses concise but impactful (under 300 words)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n6. Be respectful but persuasive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n7. Use evidence and examples when possible\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nWHEN TO RESPOND:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- When someone directly challenges your position\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- When you can add important evidence or perspective\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- When you disagree strongly with a point made\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- When you can clarify misconceptions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- When the conversation lacks your viewpoint\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- When you have a compelling counterargument\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRESPONSE FORMAT:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Provide direct, substantive responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Reference specific points made by others when relevant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Don't repeat previous arguments verbatim\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Engage with the actual conversation flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Show you've been listening to the full discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYour goal is to effectively argue your position while contributing to a dynamic, organic debate conversation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add stance-specific instructions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.config.stance.lower() == 'pro':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue IN FAVOR of the topic. Respond when the topic is attacked or when you can strengthen the pro position.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif self.config.stance.lower() == 'con':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue AGAINST the topic. Respond when the topic is supported or when you can weaken the pro arguments.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif self.config.stance.lower() == 'neutral':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should present balanced perspectives and ask probing questions. Respond when the debate needs deeper analysis or alternative viewpoints.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _generate_fallback_response(self, topic: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate a fallback response when AI fails.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        fallback_responses = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I'd like to share another perspective on {topic}. Let me gather my thoughts and respond shortly.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"That's an interesting point. I need a moment to formulate a proper response to that argument.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"There are several important aspects of {topic} we should consider here.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I appreciate the previous arguments. Let me offer a different viewpoint on this matter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        import random\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return random.choice(fallback_responses)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def receive_message(self, message: Message) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Receive a message from the debate (for awareness/context).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message: Message object from the chat log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add to message queue for processing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.message_queue.put(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Update conversation history if it's not from this bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if message.sender != self.name:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.conversation_history.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'role': 'user',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'content': f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Keep history manageable\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if len(self.conversation_history) > 20:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.conversation_history = self.conversation_history[-15:]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _update_stats(self, response_time: float, success: bool = True):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update performance statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if success:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['responses_generated'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['total_response_time'] += response_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['average_response_time'] = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.stats['total_response_time'] / self.stats['responses_generated']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['errors'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get bot performance statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'name': self.name,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'model': self.config.model,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'provider': self.config.provider,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'responses_generated': self.stats['responses_generated'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'average_response_time': round(self.stats['average_response_time'], 2),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_errors': self.stats['errors'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'success_rate': (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.stats['responses_generated'] /\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                (self.stats['responses_generated'] + self.stats['errors'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if (self.stats['responses_generated'] + self.stats['errors']) > 0 else 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def update_personality(self, personality: str, stance: str = None):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update bot personality and stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config.personality = personality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if stance:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.config.stance = stance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def reset_conversation(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reset conversation history.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.conversation_history = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.response_count = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def warmup(self) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Warm up the bot by testing API connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            True if warmup successful, False otherwise\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            test_messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'role': 'system',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'content': 'You are a debate participant. Respond with just \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" to confirm you are working.'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            }, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'role': 'user',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'content': 'Are you ready to participate in a debate?'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            }]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await self.ai_provider.generate_response(test_messages, self.config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ready\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in response.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot {self.name} warmup failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __str__(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"String representation of the bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient({self.name}, {self.config.model}, {self.config.stance})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __repr__(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Detailed string representation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return (f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient(name='{self.name}', model='{self.config.model}', \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"provider='{self.config.provider}', stance='{self.config.stance}')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat_log.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/chat_log.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 11211,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nShared chat log system for managing debate messages with timestamps and ordering.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom collections import deque\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass Message:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Represents a single chat message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    sender: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    timestamp: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    message_id: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # chat, system, moderator, vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.metadata is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.metadata = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def formatted_timestamp(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get human-readable timestamp.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.localtime(self.timestamp))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def to_dict(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Convert message to dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return asdict(self)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @classmethod\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def from_dict(cls, data: Dict[str, Any]) -> 'Message':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create message from dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return cls(**data)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass ChatLog:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Manages the shared chat log with thread-safe message handling.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, max_messages: int = 1000):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.messages: deque = deque(maxlen=max_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.message_counter = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.subscribers: List[asyncio.Queue] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self._lock = asyncio.Lock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_messages': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'messages_by_sender': {},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'start_time': time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def add_message(self, sender: str, content: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                          message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                          metadata: Optional[Dict[str, Any]] = None) -> Message:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Add a new message to the chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            sender: Name of the message sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            content: Message content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message_type: Type of message (chat, system, moderator, vote)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            metadata: Additional message metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            The created Message object\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        async with self._lock:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.message_counter += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                sender=sender,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                content=content,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timestamp=time.time(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                message_id=self.message_counter,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                message_type=message_type,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                metadata=metadata or {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.messages.append(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Update statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['total_messages'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['messages_by_sender'][sender] = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.stats['messages_by_sender'].get(sender, 0) + 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Notify subscribers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._notify_subscribers(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _notify_subscribers(self, message: Message):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Notify all subscribers of new message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Remove closed queues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.subscribers = [q for q in self.subscribers if not q._closed]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Send to all active subscribers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for queue in self.subscribers:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await queue.put(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to notify subscriber: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def subscribe(self) -> asyncio.Queue:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Subscribe to receive new messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Queue that will receive new Message objects\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        queue = asyncio.Queue()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.subscribers.append(queue)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return queue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def unsubscribe(self, queue: asyncio.Queue):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove a subscriber queue.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if queue in self.subscribers:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.subscribers.remove(queue)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_messages(self, limit: Optional[int] = None,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                     sender: Optional[str] = None,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                     message_type: Optional[str] = None,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                     since_timestamp: Optional[float] = None) -> List[Message]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Get messages with optional filtering.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            limit: Maximum number of messages to return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            sender: Filter by sender name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message_type: Filter by message type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            since_timestamp: Only return messages after this timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            List of matching messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = list(self.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Apply filters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if sender:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            messages = [m for m in messages if m.sender == sender]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if message_type:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            messages = [m for m in messages if m.message_type == message_type]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if since_timestamp:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            messages = [m for m in messages if m.timestamp > since_timestamp]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Apply limit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if limit:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            messages = messages[-limit:]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_recent_messages(self, count: int = 10) -> List[Message]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get the most recent messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return list(self.messages)[-count:]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_conversation_context(self, participant: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                 context_length: int = 5) -> List[Message]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Get conversation context for a participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            participant: Participant name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            context_length: Number of recent messages to include\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Recent messages for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        recent = self.get_recent_messages(context_length * 2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Include messages to/from the participant and moderator messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        context = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in recent:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if (msg.sender == participant or\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    msg.message_type in ['moderator', 'system'] or\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    participant in msg.content):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                context.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return context[-context_length:]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def search_messages(self, query: str, case_sensitive: bool = False) -> List[Message]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Search messages by content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            query: Search query\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            case_sensitive: Whether search should be case sensitive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            List of messages containing the query\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not case_sensitive:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            query = query.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for message in self.messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            content = message.content if case_sensitive else message.content.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if query in content:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                results.append(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_statistics(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get chat log statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        duration = time.time() - self.stats['start_time']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_messages': self.stats['total_messages'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'unique_senders': len(self.stats['messages_by_sender']),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'messages_by_sender': dict(self.stats['messages_by_sender']),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'messages_per_minute': (self.stats['total_messages'] / (duration / 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                    if duration > 0 else 0),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'session_duration_minutes': duration / 60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'current_message_count': len(self.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def save_transcript(self, filename: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                              format_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Save chat transcript to file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            filename: Output filename\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            format_type: Format (json, txt, html)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        filepath = Path(filename)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        filepath.parent.mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = list(self.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            data = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'metadata': {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'export_timestamp': time.time(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'total_messages': len(messages),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'statistics': self.get_statistics()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'messages': [msg.to_dict() for msg in messages]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                json.dump(data, f, indent=2, ensure_ascii=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f.write(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=== DEBATE TRANSCRIPT ===\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                for msg in messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f.write(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{msg.formatted_timestamp}] {msg.sender}: {msg.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif format_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            html_content = self._generate_html_transcript(messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with open(filepath, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f.write(html_content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format: {format_type}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _generate_html_transcript(self, messages: List[Message]) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Generate HTML transcript.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        html = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        <!DOCTYPE html>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        <html>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        <head>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            <title>Debate Transcript</title>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            <style>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                body { font-family: Arial, sans-serif; margin: 20px; }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                .message { margin: 10px 0; padding: 10px; border-left: 3px solid #ccc; }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                .moderator { border-left-color: #007bff; background: #f8f9fa; }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                .system { border-left-color: #6c757d; background: #e9ecef; }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                .timestamp { color: #6c757d; font-size: 0.9em; }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                .sender { font-weight: bold; }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            </style>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        </head>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        <body>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            <h1>AI Jubilee Debate Transcript</h1>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            css_class = msg.message_type if msg.message_type != 'chat' else ''\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            html += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            <div class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message {css_class}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                <span class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">[{msg.formatted_timestamp}]</span>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                <span class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\">{msg.sender}:</span>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                <div>{msg.content}</div>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            </div>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        html += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        </body>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        </html>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def load_transcript(self, filename: str) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Load transcript from JSON file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            filename: Input filename\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        filepath = Path(filename)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not filepath.exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise FileNotFoundError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Transcript file not found: {filename}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with open(filepath, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            data = json.load(f)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Clear current messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        async with self._lock:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.messages.clear()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.message_counter = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Load messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for msg_data in data.get('messages', []):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                message = Message.from_dict(msg_data)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.messages.append(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.message_counter = max(self.message_counter, message.message_id)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def clear(self) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Clear all messages from the chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.messages.clear()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.message_counter = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_messages': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'messages_by_sender': {},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'start_time': time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __len__(self) -> int:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Return number of messages in the log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return len(self.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __iter__(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Iterate over messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return iter(self.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __getitem__(self, index) -> Message:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get message by index.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return list(self.messages)[index]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"human_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/human_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20019,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nHuman client implementation for debate participation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .chat_log import Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass InterfaceConfig:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration for human interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    mode: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    enable_rich_formatting: bool = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    show_typing_indicators: bool = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    enable_reactions: bool = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    input_timeout: int = 120\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass CLIInterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Command line interface for human participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, config: InterfaceConfig):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.rich_console = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.input_task = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if config.enable_rich_formatting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                from rich.console import Console\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.rich_console = Console()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except ImportError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Rich not available, using basic formatting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def display_message(self, message: Message):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Display a message to the user.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        timestamp = time.strftime(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"%H:%M:%S\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.localtime(message.timestamp))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.rich_console:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if message.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.rich_console.print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bold yellow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.rich_console.print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"white\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if message.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] üé≠ {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[{timestamp}] {message.sender}: {message.content}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get input from user with timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.rich_console:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé§ {prompt}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bold green\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ You have {timeout} seconds to respond...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", style=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"dim\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé§ {prompt}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ You have {timeout} seconds to respond...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Start input task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.input_task = asyncio.create_task(self._get_user_input())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Wait for input or timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await asyncio.wait_for(self.input_task, timeout=timeout)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return response.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.input_task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.input_task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    pass  # Expected when we cancel\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Return empty string on timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Handle external cancellation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.input_task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Input error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self.input_task and not self.input_task.done():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.input_task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _get_user_input(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get user input asynchronously.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        loop = asyncio.get_event_loop()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return await loop.run_in_executor(None, input, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Your response: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show a notification to the user.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        icons = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        icon = icons.get(level, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.rich_console:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            colors = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"blue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"yellow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"red\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"green\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            color = colors.get(level, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"blue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.rich_console.print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{icon} {message}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", style=color)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{icon} {message}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass WebInterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Web interface for human participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, config: InterfaceConfig):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.websocket = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.pending_responses = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def display_message(self, message: Message):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Display message via websocket.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.websocket:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.websocket.send_json({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": message.to_dict()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def get_input(self, prompt: str, timeout: int = 120) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get input via websocket.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.websocket:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        request_id = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_{time.time()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.websocket.send_json({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"input_request\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": request_id,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": prompt,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Wait for response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await asyncio.wait_for(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self._wait_for_response(request_id),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timeout=timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _wait_for_response(self, request_id: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Wait for websocket response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        while request_id not in self.pending_responses:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.sleep(0.1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return self.pending_responses.pop(request_id)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def show_notification(self, message: str, level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show notification via websocket.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.websocket:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.websocket.send_json({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": message,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"level\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": level\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass HumanClient:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Human participant in the debate system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, name: str, config: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.name = name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_active = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.conversation_history: List[Message] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Initialize appropriate interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface_config = InterfaceConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mode=config.get('mode', 'cli'),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            enable_rich_formatting=config.get('enable_rich_formatting', True),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            show_typing_indicators=config.get('show_typing_indicators', True),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            enable_reactions=config.get('enable_reactions', True),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            input_timeout=config.get('input_timeout', 120)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if interface_config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.interface = CLIInterface(interface_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif interface_config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.interface = WebInterface(interface_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported interface mode: {interface_config.mode}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Statistics tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'responses_given': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'timeouts': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_response_time': 0.0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'average_response_time': 0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def get_response(self, topic: str, messages: List[Message]) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get response from human participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Show context in autonomous mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if len(messages) > 0:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìú Recent messages in conversation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Show last 3 messages for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                recent = messages[-3:] if len(messages) >= 3 else messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                for msg in recent:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.interface.display_message(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚îÄ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 50, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Get response with timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await self.interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Your response to: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timeout=self.config.get('input_timeout', 120)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Validate and process response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                validated_response = self._validate_response(response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if validated_response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Add to conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    response_msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        sender=self.name,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        content=validated_response,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        timestamp=time.time(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        message_id=len(self.conversation_history) + 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.conversation_history.append(response_msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Update stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    response_time = time.time() - start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self._update_stats(response_time, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return validated_response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Handle timeout/empty response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response_time = time.time() - start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self._update_stats(response_time, success=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Error getting response: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def autonomous_participation_loop(self, moderator_chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main loop for autonomous participation - human can speak anytime.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéØ AUTONOMOUS DEBATE MODE ACTIVE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó£Ô∏è  You can speak at ANY TIME during the discussion!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úèÔ∏è  Just type your response and press Enter to join the conversation!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        last_message_count = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        while self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Check for new messages to display\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                current_count = len(moderator_chat_log.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if current_count > last_message_count:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Show new messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    new_messages = moderator_chat_log.messages[last_message_count:]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    for msg in new_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        if msg.sender != self.name:  # Don't show own messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            await self.interface.display_message(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    last_message_count = current_count\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Get input with reasonable timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                response = await self.interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Type your response (or command):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    timeout=30  # 30 second timeout, then check for new messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if not response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue  # Timeout, check for new messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                response = response.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Handle commands\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if response.lower() == 'quit':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üëã Leaving the debate. Thanks for participating!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.is_active = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                elif response.lower() == 'help':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.show_help()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                elif response.lower() == 'status':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    stats = self.get_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Your participation: {stats['responses_given']} responses, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{stats['participation_rate']:.1%} participation rate, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"avg response time: {stats['average_response_time']:.1f}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                elif response.lower() == 'history':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìú Recent conversation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    recent = moderator_chat_log.get_recent_messages(5)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    for msg in recent:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        await self.interface.display_message(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                elif len(response) < 3:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Please provide a more substantial response (at least 3 characters).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Process actual debate response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                validated_response = self._validate_response(response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if validated_response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Add to moderator's chat log directly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await moderator_chat_log.add_message(self.name, validated_response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Update our stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.stats['responses_given'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"success\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Error in autonomous loop: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await asyncio.sleep(2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üõë Autonomous participation ended.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def receive_message(self, message: Message):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Receive and display a message from the debate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Don't show our own messages back to us\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if message.sender == self.name:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add to conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.conversation_history.append(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Limit history size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(self.conversation_history) > 30:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.conversation_history = self.conversation_history[-30:]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Display the message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.interface.display_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error displaying message: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def handle_voting(self, candidates: List[str], time_limit: int) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle voting process for human participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó≥Ô∏è Voting phase! You have {time_limit} seconds to vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Show candidates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã Candidates:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for i, candidate in enumerate(candidates, 1):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  {i}. {candidate}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Get vote choice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            choice_input = await self.interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter your choice (1-{len(candidates)}):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timeout=time_limit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if not choice_input:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return {'voted': False, 'reason': 'timeout'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                choice = int(choice_input.strip())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if 1 <= choice <= len(candidates):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    selected_candidate = candidates[choice - 1]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Get justification if using CLI\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    justification = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if isinstance(self.interface, CLIInterface):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        justification = await self.interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Optional: Why did you choose this candidate?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            timeout=30\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        'voted': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        'candidate': selected_candidate,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        'justification': justification or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return {'voted': False, 'reason': 'invalid_choice'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except ValueError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return {'voted': False, 'reason': 'invalid_format'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Voting error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return {'voted': False, 'reason': 'error'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def show_help(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Show help information for autonomous mode.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        help_text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüéØ AI JUBILEE DEBATE - AUTONOMOUS MODE HELP\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCOMMANDS:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ Just type your response and press Enter to join the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ 'help' - Show this help message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ 'status' - Show your participation statistics  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ 'history' - Show recent conversation messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ 'quit' - Leave the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAUTONOMOUS MODE:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ You can speak at ANY TIME during the discussion phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ Bots are monitoring and will respond when they feel compelled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ No turn-taking - completely organic conversation flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ Your responses are immediately added to the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTIPS:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ Keep responses focused and substantial (3+ characters)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ Reference specific points made by others\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ Feel free to jump in whenever you have something to add!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚Ä¢ The debate flows naturally - speak when inspired!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nDEBATE PHASES:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Introduction & Opening Statements (structured)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Autonomous Discussion (free-flowing - you can speak anytime!)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Closing Statements (structured)  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Voting Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEnjoy the organic debate experience! üé≠\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(help_text, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _validate_response(self, response: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Validate and clean up human response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not response or not response.strip():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Clean up the response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = response.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check length limits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        max_length = self.config.get('max_message_length', 500)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(response) > max_length:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = response[:max_length - 3] + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add note for very short responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(response) < 10:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" [Note: Very short response]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _update_stats(self, response_time: float, success: bool):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Update response statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if success:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['responses_given'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['total_response_time'] += response_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self.stats['responses_given'] > 0:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.stats['average_response_time'] = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        self.stats['total_response_time'] / self.stats['responses_given']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['timeouts'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get comprehensive human client statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_attempts = self.stats['responses_given'] + self.stats['timeouts']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participation_rate = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['responses_given'] / total_attempts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if total_attempts > 0 else 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'name': self.name,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'interface_mode': self.interface.config.mode,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'responses_given': self.stats['responses_given'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'timeouts': self.stats['timeouts'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_attempts': total_attempts,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'participation_rate': participation_rate,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'average_response_time': self.stats.get('average_response_time', 0),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'is_active': self.is_active,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'conversation_length': len(self.conversation_history)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def set_active(self, active: bool):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Set the active status of the human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_active = active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        status = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"activated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" if active else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"deactivated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîÑ {self.name} has been {status}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __str__(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human({self.name}, {self.interface.config.mode}, active={self.is_active})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __repr__(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return (f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HumanClient(name='{self.name}', mode='{self.interface.config.mode}', \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"active={self.is_active}, responses={self.stats['responses_given']})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"main.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/main.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4550,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMain entry point for the AI Jubilee Debate System.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport click\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import List, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dotenv import load_dotenv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .moderator import Moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .bot_client import BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .human_client import HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .streaming import StreamingServer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .utils import setup_logging, load_config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def start_debate_session(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    topic: Optional[str] = None,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ai_bots: int = 2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_participants: int = 1,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config_path: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Start a debate session with specified participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topic: Debate topic (if None, uses random from config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ai_bots: Number of AI bot participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_participants: Number of human participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config_path: Path to configuration file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Load environment variables from .env file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    load_dotenv()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Load configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config = load_config(config_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Setup logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    setup_logging(config.get('chat', {}).get('log_level', 'INFO'))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Initialize chat log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    chat_log = ChatLog()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Initialize voting system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_system = VotingSystem(config.get('voting', {}))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Select topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not topic:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        import random\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topic = random.choice(config.get('topics', [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Create bot clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot_clients = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot_configs = config.get('bots', [])[:ai_bots]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for i, bot_config in enumerate(bot_configs):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=bot_config['name'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            model=bot_config['model'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            provider=bot_config['provider'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            personality=bot_config['personality'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance=bot_config['stance'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            api_key=config['api_keys'].get(bot_config['provider'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_clients.append(bot)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Create human clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_clients = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for i in range(human_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_{i+1}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            interface_config=config.get('interface', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_clients.append(human)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Initialize moderator based on debate mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    debate_mode = config.get('debate', {}).get('mode', 'sequential')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    moderator = Moderator(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topic=topic,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participants=bot_clients + human_clients,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log=chat_log,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system=voting_system,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config=config.get('debate', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if debate_mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ Running in AUTONOMOUS mode - bots will decide when to speak!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìù Topic: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Discussion time: {config.get('debate', {}).get('time_limit_minutes', 30)} minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéØ Bots will monitor conversation and jump in when they feel compelled to respond!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìù Running in SEQUENTIAL mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Participants take turns in order\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Initialize streaming server if enabled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    streaming_server = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if config.get('streaming', {}).get('enabled', False):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        streaming_server = StreamingServer(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log=chat_log,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voting_system=voting_system,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            config=config.get('streaming', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await streaming_server.start()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Start the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé≠ Starting AI Jubilee Debate: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator.run_debate()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except KeyboardInterrupt:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚èπÔ∏è  Debate interrupted by user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    finally:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Cleanup\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if streaming_server:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await streaming_server.stop()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Save transcript\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if config.get('chat', {}).get('save_transcripts', True):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await chat_log.save_transcript(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_{topic[:20]}.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@click.command()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@click.option('--topic', '-t', help='Debate topic')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@click.option('--bots', '-b', default=2, help='Number of AI bots')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@click.option('--humans', '-h', default=1, help='Number of human participants')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@click.option('--config', '-c', default='config.yaml', help='Configuration file path')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef cli(topic: str, bots: int, humans: int, config: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Launch the AI Jubilee Debate System.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    asyncio.run(start_debate_session(topic, bots, humans, config))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    cli()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/moderator.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 27164,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nModerator class for managing debate flow, rules, and coordination.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSupports both structured and autonomous debate modes.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport random\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import List, Dict, Any, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom enum import Enum\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog, Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .utils import format_time_remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass DebatePhase(Enum):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    INTRODUCTION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"introduction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    OPENING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    DISCUSSION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    CLOSING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    VOTING = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    RESULTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    FINISHED = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"finished\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass DebateState:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    phase: DebatePhase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    current_speaker: Optional[str] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    time_remaining: int = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    turn_order: List[str] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    warnings_issued: Dict[str, int] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.turn_order is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.turn_order = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.warnings_issued is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.warnings_issued = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass BotState:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Track individual bot state in autonomous mode.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    last_spoke_time: float = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    last_checked_messages: int = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    cooldown_until: float = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    speaking_probability: float = 0.7\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    is_thinking: bool = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    consecutive_passes: int = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    total_responses: int = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass Moderator:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Manages debate flow, enforces rules, and coordinates between participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Supports both structured (sequential) and autonomous debate modes.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, topic: str, participants: List, chat_log: ChatLog,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                 voting_system: VotingSystem, config: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.topic = topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.participants = {p.name: p for p in participants}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.chat_log = chat_log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.voting_system = voting_system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state = DebateState(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            phase=DebatePhase.INTRODUCTION,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            turn_order=list(self.participants.keys())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.phase_times = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            DebatePhase.OPENING_STATEMENTS: config.get('opening_statement_time', 120),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            DebatePhase.DISCUSSION: config.get('time_limit_minutes', 30) * 60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            DebatePhase.CLOSING_STATEMENTS: config.get('closing_statement_time', 90),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            DebatePhase.VOTING: config.get('voting_duration', 300)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.max_response_time = config.get('max_response_time', 120)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.warning_time = config.get('warning_time', 90)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Autonomous mode settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.autonomous_mode = config.get('mode', 'sequential') == 'autonomous'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.bot_states: Dict[str, BotState] = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.bot_tasks: List[asyncio.Task] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.phase_task: Optional[asyncio.Task] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Timing controls for autonomous mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.min_bot_cooldown = config.get('min_bot_cooldown', 15)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.max_bot_cooldown = config.get('max_bot_cooldown', 45)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.message_check_interval = config.get('message_check_interval', 5)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.silence_timeout = config.get('silence_timeout', 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.last_activity_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Initialize bot states for autonomous mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.autonomous_mode:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for participant in self.participants.values():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if hasattr(participant, 'config'):  # It's a bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.bot_states[participant.name] = BotState(name=participant.name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def run_debate(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run the complete debate session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._introduction_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._opening_statements_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self.autonomous_mode:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._autonomous_discussion_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._discussion_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._closing_statements_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results = await self._voting_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._results_phase(results)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self.autonomous_mode:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._cleanup_autonomous_tasks()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.state.phase = DebatePhase.FINISHED\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _autonomous_discussion_phase(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Autonomous discussion where bots decide when to speak.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Autonomous Discussion Phase Begin!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ Bots will monitor the conversation and speak when they feel compelled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Humans can speak at any time.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Total time: {total_time // 60} minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Let the organic debate begin!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.last_activity_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Start bot monitoring tasks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._start_bot_monitoring()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Start phase management task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.phase_task = asyncio.create_task(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self._manage_autonomous_phase(start_time, total_time)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.phase_task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚èπÔ∏è Autonomous discussion phase complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _start_bot_monitoring(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Start monitoring tasks for all bots.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for bot_name, participant in self.participants.items():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if hasattr(participant, 'config'):  # It's a bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                task = asyncio.create_task(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self._bot_monitoring_loop(bot_name, participant)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.bot_tasks.append(task)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ {bot_name} is now monitoring the conversation...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _bot_monitoring_loop(self, bot_name: str, bot):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main monitoring loop for each bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_state = self.bot_states[bot_name]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        while self.state.phase == DebatePhase.DISCUSSION:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await asyncio.sleep(self.message_check_interval)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Check if bot is in cooldown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if time.time() < bot_state.cooldown_until:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Check if there are new messages to consider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                current_msg_count = len(self.chat_log.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if current_msg_count <= bot_state.last_checked_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Update last checked\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                bot_state.last_checked_messages = current_msg_count\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Get recent conversation context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                recent_messages = self.chat_log.get_recent_messages(10)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                full_history = list(self.chat_log.messages)  # Full conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Decide if bot should speak\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                should_speak = await self._bot_should_speak(bot_name, bot, recent_messages, full_history)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if should_speak:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.is_thinking = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí≠ {bot_name} is thinking about responding...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Generate and post response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._bot_autonomous_response(bot_name, bot, full_history)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Update bot state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.last_spoke_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.total_responses += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.is_thinking = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.consecutive_passes = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Set cooldown (longer if bot is very active)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    cooldown = self.min_bot_cooldown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if bot_state.total_responses > 3:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        cooldown += min(bot_state.total_responses * 5, self.max_bot_cooldown)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.cooldown_until = time.time() + cooldown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Update activity time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.last_activity_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    bot_state.consecutive_passes += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                break\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è {bot_name} monitoring error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await asyncio.sleep(5)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _bot_should_speak(self, bot_name: str, bot, recent_messages: List[Message],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                               full_history: List[Message]) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Determine if bot should speak based on conversation context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_state = self.bot_states[bot_name]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Don't speak if recently spoke\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if time.time() - bot_state.last_spoke_time < self.min_bot_cooldown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Don't speak if currently thinking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if bot_state.is_thinking:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check if bot was mentioned\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        recent_text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join([msg.content for msg in recent_messages[-3:]])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if bot_name.lower() in recent_text.lower():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check for stance-based triggers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        triggers_found = self._check_stance_triggers(bot, recent_text)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if triggers_found:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return random.random() < 0.8  # 80% chance if triggered\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check conversation flow (encourage participation if quiet)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_recent_count = sum(1 for msg in recent_messages[-5:] if msg.sender == bot_name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if bot_recent_count == 0 and len(recent_messages) >= 3:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return random.random() < 0.4  # 40% chance to join if not participated recently\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Random chance to speak (small)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_probability = 0.15\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Increase probability based on time since last participation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        time_factor = min((time.time() - bot_state.last_spoke_time) / 120, 1.0)  # 2 minutes max\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        adjusted_probability = base_probability + (time_factor * 0.2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return random.random() < adjusted_probability\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _check_stance_triggers(self, bot, recent_text: str) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if recent text contains triggers based on bot's stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        recent_lower = recent_text.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if hasattr(bot, 'config') and hasattr(bot.config, 'stance'):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance = bot.config.stance.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                triggers = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"disagree\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"wrong\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"against\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"oppose\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"bad idea\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"won't work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return any(trigger in recent_lower for trigger in triggers)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            elif stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                triggers = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"agree\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"support\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"favor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"benefit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"good idea\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"will work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return any(trigger in recent_lower for trigger in triggers)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            elif stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                triggers = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"clarify\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"explain\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"evidence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"example\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"what about\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"consider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return any(trigger in recent_lower for trigger in triggers)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _bot_autonomous_response(self, bot_name: str, bot, full_history: List[Message]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get autonomous response from bot with full conversation history.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Provide full conversation history for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await asyncio.wait_for(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                bot.get_response(self.topic, full_history),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timeout=self.max_response_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if response and response.strip():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._process_response(bot_name, response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ {bot_name} has spoken\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí≠ {bot_name} decided not to respond after all\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except asyncio.TimeoutError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {bot_name} took too long to respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è {bot_name} error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _manage_autonomous_phase(self, start_time: float, total_time: int):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Manage the autonomous phase - handle silence and provide incentives.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        incentives_given = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        while time.time() - start_time < total_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.sleep(10)  # Check every 10 seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Check for prolonged silence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            silence_duration = time.time() - self.last_activity_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if silence_duration > self.silence_timeout:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._provide_debate_incentive(incentives_given)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                incentives_given += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.last_activity_time = time.time()  # Reset timer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Give time updates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            remaining = total_time - (time.time() - start_time)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if remaining <= 300 and remaining > 295:  # 5 minutes warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ 5 minutes remaining in discussion phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            elif remaining <= 60 and remaining > 55:  # 1 minute warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ 1 minute remaining! Final thoughts?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _provide_debate_incentive(self, incentive_count: int):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Provide incentives to encourage participation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        incentives = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéØ The conversation seems to have paused. What are your thoughts on the key arguments made so far?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§î Does anyone have evidence or examples to support their position?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí° Are there any important aspects of this topic we haven't explored yet?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚öñÔ∏è How do the benefits and drawbacks compare? What's your perspective?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîç Can someone clarify or expand on the previous points made?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üåü What would be the real-world implications of the positions discussed?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùì Are there any questions or counterarguments you'd like to raise?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé™ Let's keep this lively debate going! Who wants to jump in?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if incentive_count < len(incentives):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message = incentives[incentive_count]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message = random.choice(incentives)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(message, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Also provide topic-specific prompts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topic_lower = self.topic.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"remote work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in topic_lower:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            specific_prompts = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üíº What about productivity - does remote work increase or decrease it?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üè† How does remote work affect work-life balance?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üåç What are the environmental implications of remote work?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí∞ What about the economic impact on cities and office spaces?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in topic_lower:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            specific_prompts = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ What specific jobs might AI create vs eliminate?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Do we have data on AI's employment impact so far?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üéì How should education adapt to AI changes?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚öñÔ∏è What role should government play in AI employment policy?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            specific_prompts = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìà What evidence supports your view on {self.topic}?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîÑ How might {self.topic} evolve in the next 5-10 years?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üåç What are the global implications of {self.topic}?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Who benefits most from your proposed approach to {self.topic}?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if random.random() < 0.3:  # 30% chance for specific prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            specific_message = random.choice(specific_prompts)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(specific_message, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _cleanup_autonomous_tasks(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Clean up all autonomous monitoring tasks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Cancel all bot monitoring tasks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for task in self.bot_tasks:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if not task.done():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Cancel phase management task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.phase_task and not self.phase_task.done():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.phase_task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self.phase_task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.bot_tasks.clear()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ All autonomous monitoring tasks stopped\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def run_debate(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run the complete debate session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._introduction_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._opening_statements_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._discussion_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._closing_statements_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results = await self._voting_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._results_phase(results)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Debate error: {e}. Ending session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.state.phase = DebatePhase.FINISHED\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _introduction_phase(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Introduce the debate topic and participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠ Welcome to AI Jubilee Debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìù Topic: {self.topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üë• Participants: {', '.join(self.participants.keys())}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è±Ô∏è Total time: {self.config.get('time_limit_minutes', 30)} minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Brief pause for participants to prepare\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await asyncio.sleep(3)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _opening_statements_phase(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle opening statements from each participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.OPENING_STATEMENTS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        statement_time = self.phase_times[DebatePhase.OPENING_STATEMENTS]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Opening Statements Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Each participant has {statement_time} seconds for their opening statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for participant_name in self.state.turn_order:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._give_turn(participant_name, statement_time, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening statement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _discussion_phase(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Manage the main discussion phase.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.DISCUSSION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_time = self.phase_times[DebatePhase.DISCUSSION]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Discussion Phase Begin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Open discussion for {total_time // 60} minutes. Maintain respectful dialogue!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response_time = self.config.get('response_time', 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        while time.time() - start_time < total_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Rotate through participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for participant_name in self.state.turn_order:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if time.time() - start_time >= total_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                remaining = total_time - (time.time() - start_time)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if remaining < response_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    response_time = int(remaining)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._give_turn(participant_name, response_time, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Check for time warnings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if remaining <= 300:  # 5 minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {format_time_remaining(remaining)} remaining in discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚èπÔ∏è Discussion phase complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _closing_statements_phase(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle closing statements.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.CLOSING_STATEMENTS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        statement_time = self.phase_times[DebatePhase.CLOSING_STATEMENTS]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üèÅ Closing Statements Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Each participant has {statement_time} seconds for final remarks.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Reverse order for closing statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for participant_name in reversed(self.state.turn_order):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._give_turn(participant_name, statement_time, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing statement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _voting_phase(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Conduct voting on debate performance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.VOTING\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.voting_system.enabled:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting disabled. Debate complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó≥Ô∏è Voting Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote for the most persuasive participant. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting closes in {self.phase_times[DebatePhase.VOTING]} seconds.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Enable voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.voting_system.start_voting(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            list(self.participants.keys()),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.phase_times[DebatePhase.VOTING]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Wait for voting period\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await asyncio.sleep(self.phase_times[DebatePhase.VOTING])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = await self.voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _results_phase(self, voting_results: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Announce final results.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.phase = DebatePhase.RESULTS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if voting_results:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            winner = voting_results.get('winner')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            vote_counts = voting_results.get('vote_counts', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results_msg = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üèÜ DEBATE RESULTS üèÜ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results_msg += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results_msg += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote Breakdown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for participant, votes in sorted(vote_counts.items(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                           key=lambda x: x[1], reverse=True):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                results_msg += f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  {participant}: {votes} votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results_msg = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ù Debate concluded without voting. Great discussion everyone!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(results_msg, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thank you for participating in AI Jubilee Debate! üé≠\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _give_turn(self, participant_name: str, time_limit: int, turn_type: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Give speaking turn to a participant with time management.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.current_speaker = participant_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.time_remaining = time_limit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant = self.participants[participant_name]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ {participant_name}'s turn for {turn_type} ({time_limit}s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Start response task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response_task = asyncio.create_task(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                participant.get_response(self.topic, self.chat_log.get_recent_messages())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Start timer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            warning_sent = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            while not response_task.done():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                elapsed = time.time() - start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                remaining = time_limit - elapsed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if remaining <= 0:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Cancel the task and handle timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    response_task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        await response_task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        pass  # Expected when we cancel\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._handle_timeout(participant_name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    break\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if not warning_sent and remaining <= self.warning_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._send_warning(participant_name, remaining)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    warning_sent = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await asyncio.sleep(0.5)  # Check every 500ms\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Process response if task completed successfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if response_task.done() and not response_task.cancelled():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    response = await response_task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if response:  # Only process non-empty responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        await self._process_response(participant_name, response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Error getting response from {participant_name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Error during {participant_name}'s turn: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.state.current_speaker = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _process_response(self, participant_name: str, response: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Process and validate participant response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Basic validation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(response) > self.config.get('max_message_length', 500):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = response[:self.config.get('max_message_length', 500)] + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è {participant_name}'s response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Log the response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self.chat_log.add_message(participant_name, response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _handle_timeout(self, participant_name: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle participant timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.state.warnings_issued[participant_name] = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.state.warnings_issued.get(participant_name, 0) + 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {participant_name} exceeded time limit. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning {self.state.warnings_issued[participant_name]}/3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.state.warnings_issued[participant_name] >= 3:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîá {participant_name} muted for repeated violations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _send_warning(self, participant_name: str, time_remaining: float):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send time warning to participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ {participant_name}: {int(time_remaining)} seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _broadcast_message(self, content: str, sender: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message to all participants and log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = await self.chat_log.add_message(sender, content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Send to all participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for participant in self.participants.values():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await participant.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to send message to {participant.name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_state(self) -> DebateState:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get current debate state.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return self.state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"streaming.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/streaming.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15845,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nLive streaming and WebSocket server for real-time debate broadcasting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Set, Any, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, asdict\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport websockets\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom websockets.server import WebSocketServerProtocol\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .chat_log import ChatLog, Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .voting import VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom .utils import format_time_remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass StreamingClient:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Information about a connected streaming client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    websocket: WebSocketServerProtocol\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client_id: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    connected_at: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"viewer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # viewer, participant, moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    metadata: Dict[str, Any] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __post_init__(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.metadata is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.metadata = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass StreamingServer:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    WebSocket server for live streaming debate sessions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, chat_log: ChatLog, voting_system: VotingSystem,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                 config: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.chat_log = chat_log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.voting_system = voting_system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.host = config.get('host', 'localhost')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.port = config.get('websocket_port', 8080)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.max_connections = config.get('max_connections', 100)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.broadcast_votes = config.get('broadcast_votes', True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Server state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.server = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.clients: Dict[str, StreamingClient] = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_running = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Message subscription\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.message_queue = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.broadcast_task = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.stats = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_connections': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'messages_sent': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'votes_broadcast': 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'start_time': time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.logger = logging.getLogger(__name__)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def start(self) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Start the streaming server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.is_running:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Subscribe to chat log messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.message_queue = self.chat_log.subscribe()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Start WebSocket server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.server = await websockets.serve(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self._handle_client,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.host,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                self.port,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                max_size=1024 * 1024,  # 1MB max message size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                ping_interval=20,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                ping_timeout=10\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Start broadcast task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.broadcast_task = asyncio.create_task(self._broadcast_loop())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.is_running = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.logger.info(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Streaming server started on {self.host}:{self.port}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to start streaming server: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def stop(self) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stop the streaming server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.is_running:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_running = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Stop broadcast task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.broadcast_task:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.broadcast_task.cancel()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self.broadcast_task\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Close all client connections\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.clients:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.gather(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                *[client.websocket.close() for client in self.clients.values()],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return_exceptions=True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Stop WebSocket server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.server:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.server.close()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self.server.wait_closed()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Unsubscribe from chat log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.message_queue:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.chat_log.unsubscribe(self.message_queue)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.logger.info(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Streaming server stopped\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _handle_client(self, websocket: WebSocketServerProtocol, path: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Handle new client connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(self.clients) >= self.max_connections:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await websocket.close(code=1013, reason=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Server full\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        client_id = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"client_{int(time.time() * 1000)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        client = StreamingClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            websocket=websocket,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            client_id=client_id,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            connected_at=time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.clients[client_id] = client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.stats['total_connections'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.logger.info(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client {client_id} connected from {websocket.remote_address}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Send welcome message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'type': 'welcome',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'client_id': client_id,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'server_info': {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'version': '1.0.0',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'features': ['chat', 'voting', 'real_time']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Send recent messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            recent_messages = self.chat_log.get_recent_messages(10)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for msg in recent_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._send_to_client(client, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'type': 'message',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'data': msg.to_dict()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Handle client messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            async for message in websocket:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._process_client_message(client, json.loads(message))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except json.JSONDecodeError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._send_error(client, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid JSON message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing client message: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._send_error(client, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Internal server error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except websockets.exceptions.ConnectionClosed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.logger.info(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client {client_id} disconnected\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Client {client_id} error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        finally:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Clean up client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if client_id in self.clients:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                del self.clients[client_id]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _process_client_message(self, client: StreamingClient, data: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Process message from client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message_type = data.get('type')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if message_type == 'ping':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {'type': 'pong'})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif message_type == 'subscribe':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Update client subscription preferences\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            client.metadata['subscriptions'] = data.get('channels', [])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'type': 'subscribed',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'channels': client.metadata.get('subscriptions', [])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif message_type == 'get_stats':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Send server statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._send_to_client(client, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'type': 'stats',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'data': self._get_server_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif message_type == 'vote' and self.voting_system.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Handle vote from client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voter_id = data.get('voter_id', client.client_id)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            candidate = data.get('candidate')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            justification = data.get('justification')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                success = await self.voting_system.cast_vote(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    voter_id, candidate, justification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._send_to_client(client, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'type': 'vote_result',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'success': success,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'candidate': candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if success and self.broadcast_votes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._broadcast_vote_update()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await self._send_error(client, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote failed: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await self._send_error(client, f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unknown message type: {message_type}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _broadcast_loop(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main broadcast loop for new messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            while self.is_running:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Wait for new message from chat log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    message = await asyncio.wait_for(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        self.message_queue.get(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        timeout=1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Broadcast to all clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await self._broadcast_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except asyncio.TimeoutError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Timeout is expected, continue loop\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast loop error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    await asyncio.sleep(1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except asyncio.CancelledError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.logger.info(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast loop cancelled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _broadcast_message(self, message: Message):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message to all connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.clients:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        broadcast_data = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'type': 'message',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'data': message.to_dict()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Send to all clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if self._should_send_to_client(client, message):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['messages_sent'] += len(tasks)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _should_send_to_client(self, client: StreamingClient, message: Message) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Determine if message should be sent to client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check client subscriptions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        subscriptions = client.metadata.get('subscriptions', [])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if subscriptions:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # If client has specific subscriptions, check them\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if message.message_type not in subscriptions:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _broadcast_vote_update(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast voting update to clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.voting_system.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote_summary = self.voting_system.get_vote_summary()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        broadcast_data = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'type': 'vote_update',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'data': vote_summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.stats['votes_broadcast'] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _send_to_client(self, client: StreamingClient, data: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send data to specific client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await client.websocket.send(json.dumps(data))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except websockets.exceptions.ConnectionClosed:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Client disconnected, will be cleaned up\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.logger.error(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Failed to send to client {client.client_id}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def _send_error(self, client: StreamingClient, error_message: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send error message to client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await self._send_to_client(client, {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'type': 'error',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'message': error_message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _get_server_stats(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get server statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        uptime = time.time() - self.stats['start_time']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'connected_clients': len(self.clients),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_connections': self.stats['total_connections'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'messages_sent': self.stats['messages_sent'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'votes_broadcast': self.stats['votes_broadcast'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'uptime_seconds': uptime,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'uptime_formatted': format_time_remaining(uptime),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'is_voting_active': self.voting_system.is_active if self.voting_system else False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def broadcast_custom_message(self, message_type: str, data: Any):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast custom message to all clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        broadcast_data = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'type': message_type,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'data': data,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'timestamp': time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for client in list(self.clients.values()):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            tasks.append(self._send_to_client(client, broadcast_data))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def send_to_specific_clients(self, client_ids: List[str],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                       message_type: str, data: Any):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Send message to specific clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'type': message_type,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'data': data,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'timestamp': time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for client_id in client_ids:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if client_id in self.clients:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                client = self.clients[client_id]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                tasks.append(self._send_to_client(client, message))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_connected_clients(self) -> List[Dict[str, Any]]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get information about connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'client_id': client.client_id,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'connected_at': client.connected_at,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'client_type': client.client_type,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'connection_duration': time.time() - client.connected_at\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for client in self.clients.values()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def is_active(self) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if server is running.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return self.is_running\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def client_count(self) -> int:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get number of connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return len(self.clients)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass StreamingManager:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    High-level manager for streaming functionality.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.servers: Dict[str, StreamingServer] = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_initialized = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def create_streaming_session(self, session_id: str, chat_log: ChatLog,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                       voting_system: VotingSystem,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                       config: Dict[str, Any]) -> StreamingServer:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Create a new streaming session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            session_id: Unique session identifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log: Chat log to stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voting_system: Voting system to integrate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            config: Streaming configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            StreamingServer instance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if session_id in self.servers:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Streaming session {session_id} already exists\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Create unique port for this session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_port = config.get('websocket_port', 8080)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        port = base_port + len(self.servers)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        session_config = config.copy()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        session_config['websocket_port'] = port\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        server = StreamingServer(chat_log, voting_system, session_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.servers[session_id] = server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await server.start()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def stop_streaming_session(self, session_id: str):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stop a streaming session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if session_id in self.servers:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            server = self.servers[session_id]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await server.stop()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            del self.servers[session_id]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def stop_all_sessions(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Stop all streaming sessions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        tasks = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for session_id in list(self.servers.keys()):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            tasks.append(self.stop_streaming_session(session_id))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if tasks:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.gather(*tasks, return_exceptions=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get information about a streaming session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if session_id not in self.servers:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        server = self.servers[session_id]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'session_id': session_id,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'is_active': server.is_active,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'client_count': server.client_count,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'host': server.host,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'port': server.port,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'stats': server._get_server_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def list_active_sessions(self) -> List[str]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get list of active session IDs.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            session_id for session_id, server in self.servers.items()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if server.is_active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"utils.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/utils.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 10954,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nUtility functions for the AI Jubilee Debate System.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport re\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import Dict, Any, List, Optional\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom datetime import datetime, timedelta\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef load_config(config_path: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Load configuration from YAML file with environment variable substitution.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config_path: Path to configuration file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Configuration dictionary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config_file = Path(config_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not config_file.exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        raise FileNotFoundError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Configuration file not found: {config_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with open(config_file, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config_content = f.read()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Substitute environment variables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config_content = substitute_env_vars(config_content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = yaml.safe_load(config_content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except yaml.YAMLError as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid YAML configuration: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef substitute_env_vars(text: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Substitute environment variables in text using ${VAR_NAME} syntax.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        text: Text containing environment variable references\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Text with environment variables substituted\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def replace_env_var(match):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        var_name = match.group(1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        env_value = os.getenv(var_name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if env_value is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning: Environment variable {var_name} not found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"${{{var_name}}}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Keep original if not found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return env_value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return re.sub(r'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\$\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\{([^}]+)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}', replace_env_var, text)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef setup_logging(level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", log_file: Optional[str] = None) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Setup logging configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        level: Logging level (DEBUG, INFO, WARNING, ERROR)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        log_file: Optional log file path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    numeric_level = getattr(logging, level.upper(), logging.INFO)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Create formatter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    formatter = logging.Formatter(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Setup root logger\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    root_logger = logging.getLogger()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    root_logger.setLevel(numeric_level)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Clear existing handlers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    root_logger.handlers.clear()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Console handler\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    console_handler = logging.StreamHandler()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    console_handler.setFormatter(formatter)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    root_logger.addHandler(console_handler)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # File handler if specified\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if log_file:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        file_handler = logging.FileHandler(log_file)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        file_handler.setFormatter(formatter)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        root_logger.addHandler(file_handler)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef format_time_remaining(seconds: float) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Format remaining time in human-readable format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        seconds: Time remaining in seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Formatted time string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if seconds <= 0:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Time's up!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if seconds < 60:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{int(seconds)} seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    elif seconds < 3600:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        minutes = int(seconds // 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        secs = int(seconds % 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{minutes}m {secs}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        hours = int(seconds // 3600)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        minutes = int((seconds % 3600) // 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{hours}h {minutes}m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Truncate text to maximum length with suffix.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        text: Text to truncate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        max_length: Maximum length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        suffix: Suffix to add when truncating\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Truncated text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if len(text) <= max_length:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return text[:max_length - len(suffix)] + suffix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef generate_debate_prompt(topic: str, role: str, personality: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Generate a debate prompt for AI participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topic: Debate topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        role: Participant role (pro, con, neutral)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        personality: Personality description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Generated prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    base_prompt = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are participating in a structured debate on the topic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYour role: {role}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYour personality: {personality}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nInstructions:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Present clear, logical arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Respond to other participants' points\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Stay focused on the topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Be respectful but persuasive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n5. Keep responses concise and engaging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCurrent debate topic: {topic}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if role.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue IN FAVOR of the topic.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    elif role.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should argue AGAINST the topic.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    elif role.lower() == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_prompt += \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nYou should present balanced perspectives and ask probing questions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return base_prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef validate_participant_name(name: str) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Validate participant name.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        name: Participant name to validate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        True if valid, False otherwise\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not name or len(name.strip()) == 0:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Check length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if len(name) > 50:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Check for valid characters (alphanumeric, spaces, underscores, hyphens)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not re.match(r'^[a-zA-Z0-9\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\s_-]+$', name):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef sanitize_filename(filename: str) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Sanitize filename for safe file operations.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        filename: Original filename\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Sanitized filename\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Remove or replace invalid characters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    sanitized = re.sub(r'[<>:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\|?*]', '_', filename)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Remove leading/trailing spaces and dots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    sanitized = sanitized.strip(' .')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Limit length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if len(sanitized) > 255:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        sanitized = sanitized[:255]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return sanitized\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef parse_duration(duration_str: str) -> int:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Parse duration string into seconds.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        duration_str: Duration string (e.g., \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"30s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1h30m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Duration in seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if duration_str.isdigit():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return int(duration_str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    total_seconds = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Parse hours\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    hours_match = re.search(r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d+)h', duration_str.lower())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if hours_match:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_seconds += int(hours_match.group(1)) * 3600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Parse minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    minutes_match = re.search(r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d+)m', duration_str.lower())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if minutes_match:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_seconds += int(minutes_match.group(1)) * 60\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Parse seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    seconds_match = re.search(r'(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\d+)s', duration_str.lower())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if seconds_match:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_seconds += int(seconds_match.group(1))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return total_seconds if total_seconds > 0 else 60  # Default to 60 seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef create_timestamp() -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Create ISO format timestamp.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ISO formatted timestamp string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return datetime.now().isoformat()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef format_participant_list(participants: List[str], max_display: int = 5) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Format participant list for display.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participants: List of participant names\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        max_display: Maximum participants to display before truncating\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Formatted participant string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if len(participants) <= max_display:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(participants)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    displayed = participants[:max_display]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    remaining = len(participants) - max_display\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{', '.join(displayed)} (+{remaining} more)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef calculate_word_count(text: str) -> int:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Calculate word count in text.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        text: Text to count words in\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Number of words\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return len(text.split())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef extract_key_phrases(text: str, max_phrases: int = 5) -> List[str]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Extract key phrases from text (simple implementation).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        text: Text to extract phrases from\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        max_phrases: Maximum number of phrases to return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        List of key phrases\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Simple implementation - could be enhanced with NLP\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    sentences = text.split('.')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    phrases = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for sentence in sentences[:max_phrases]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        sentence = sentence.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(sentence) > 10:  # Minimum length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            phrases.append(sentence)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return phrases[:max_phrases]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef generate_session_id() -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Generate unique session ID.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Unique session identifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    import uuid\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return str(uuid.uuid4())[:8]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef ensure_directory(path: str) -> Path:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Ensure directory exists, create if necessary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        path: Directory path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Path object\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    dir_path = Path(path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    dir_path.mkdir(parents=True, exist_ok=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return dir_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef load_debate_topics(topics_file: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"topics.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> List[str]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Load debate topics from file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topics_file: Path to topics file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        List of debate topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    topics_path = Path(topics_file)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not topics_path.exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Return default topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Artificial intelligence will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Social media has a net positive impact on society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    with open(topics_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topics = [line.strip() for line in f if line.strip() and not line.startswith('#')]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass PerformanceTimer:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Context manager for timing operations.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, operation_name: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Operation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.operation_name = operation_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.start_time = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.end_time = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __enter__(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return self\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __exit__(self, exc_type, exc_val, exc_tb):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.end_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def duration(self) -> float:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get operation duration in seconds.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.start_time and self.end_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return self.end_time - self.start_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return 0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __str__(self) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{self.operation_name}: {self.duration:.3f}s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef retry_with_backoff(max_retries: int = 3, base_delay: float = 1.0):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Decorator for retrying operations with exponential backoff.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        max_retries: Maximum number of retry attempts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_delay: Base delay between retries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def decorator(func):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        async def wrapper(*args, **kwargs):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            last_exception = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for attempt in range(max_retries + 1):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return await func(*args, **kwargs)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    last_exception = e\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if attempt < max_retries:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        delay = base_delay * (2 ** attempt)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        await asyncio.sleep(delay)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        raise last_exception\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise last_exception\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return wrapper\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return decorator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app/voting.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 11436,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nVoting system for debate evaluation and winner determination.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import Dict, List, Optional, Any\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom dataclasses import dataclass, field\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom collections import defaultdict, Counter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass Vote:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Represents a single vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voter_id: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    candidate: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    justification: Optional[str] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    timestamp: float = field(default_factory=time.time)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    anonymous: bool = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass VotingResults:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Results of a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    winner: Optional[str]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    vote_counts: Dict[str, int]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    total_votes: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    votes_by_voter: Dict[str, Vote]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_duration: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    participation_rate: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass VotingSystem:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Manages voting process, vote collection, and result calculation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def __init__(self, config: Dict[str, Any]):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.config = config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.enabled = config.get('enabled', True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.voting_duration = config.get('voting_duration', 300)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.allow_participant_voting = config.get('allow_participant_voting', True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.require_justification = config.get('require_justification', True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.anonymous_votes = config.get('anonymous_votes', False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Voting state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_active = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.candidates: List[str] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.eligible_voters: List[str] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.votes: Dict[str, Vote] = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.start_time: Optional[float] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.end_time: Optional[float] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Vote validation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.vote_history: List[Dict[str, Any]] = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def start_voting(self, candidates: List[str], duration: Optional[int] = None) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Start a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            candidates: List of debate participants to vote for\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            duration: Voting duration in seconds (uses config default if None)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.enabled:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting system is disabled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting session already active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.candidates = candidates.copy()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.eligible_voters = candidates.copy() if self.allow_participant_voting else []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.votes = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.start_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.end_time = self.start_time + (duration or self.voting_duration)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_active = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üó≥Ô∏è Voting started for {len(candidates)} candidates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Voting closes in {duration or self.voting_duration} seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def cast_vote(self, voter_id: str, candidate: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        justification: Optional[str] = None) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Cast a vote for a candidate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voter_id: ID of the voter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            candidate: Candidate being voted for\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            justification: Optional reasoning for the vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            True if vote was successfully cast, False otherwise\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if time.time() > self.end_time:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting period has ended\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Validate voter eligibility\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self._is_eligible_voter(voter_id):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voter {voter_id} is not eligible to vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Validate candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if candidate not in self.candidates:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid candidate: {candidate}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check for self-voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if voter_id == candidate and not self.allow_participant_voting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Self-voting is not allowed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Validate justification requirement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if self.require_justification and not justification:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote justification is required\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Record the vote (overwrites previous vote from same voter)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote = Vote(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voter_id=voter_id,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            candidate=candidate,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            justification=justification,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            anonymous=self.anonymous_votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.votes[voter_id] = vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Vote recorded: {voter_id} -> {candidate}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def end_voting(self) -> VotingResults:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        End the voting session and calculate results.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            VotingResults object with winner and vote breakdown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_active = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        actual_end_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Calculate vote counts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_votes = len(self.votes)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Determine winner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        winner = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if vote_counts:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            max_votes = max(vote_counts.values())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            winners = [candidate for candidate, count in vote_counts.items()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                       if count == max_votes]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if len(winners) == 1:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                winner = winners[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Handle tie - could implement tiebreaker logic here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                winner = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TIE: {', '.join(winners)}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Calculate participation rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participation_rate = (total_votes / len(self.eligible_voters)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                              if self.eligible_voters else 0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Create results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = VotingResults(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            winner=winner,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            vote_counts=dict(vote_counts),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            total_votes=total_votes,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            votes_by_voter=self.votes.copy(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voting_duration=actual_end_time - self.start_time,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            participation_rate=participation_rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Store in history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.vote_history.append({\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'timestamp': actual_end_time,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'candidates': self.candidates.copy(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'results': results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üèÜ Voting ended. Winner: {winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Total votes: {total_votes}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìà Participation: {participation_rate:.1%}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def _is_eligible_voter(self, voter_id: str) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if a voter is eligible to vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.eligible_voters:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return True  # Open voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return voter_id in self.eligible_voters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def add_eligible_voter(self, voter_id: str) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Add a voter to the eligible voters list.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if voter_id not in self.eligible_voters:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.eligible_voters.append(voter_id)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def remove_eligible_voter(self, voter_id: str) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remove a voter from the eligible voters list.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if voter_id in self.eligible_voters:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            self.eligible_voters.remove(voter_id)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_vote_summary(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get current voting summary without ending the session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote_counts = Counter(vote.candidate for vote in self.votes.values())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        time_remaining = max(0, self.end_time - time.time())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'candidates': self.candidates,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'vote_counts': dict(vote_counts),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_votes': len(self.votes),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'time_remaining': time_remaining,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'is_active': self.is_active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_voter_history(self, voter_id: str) -> List[Vote]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get voting history for a specific voter.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        history = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for session in self.vote_history:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            votes = session.get('results', {}).votes_by_voter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if voter_id in votes:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                history.append(votes[voter_id])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def get_candidate_performance(self, candidate: str) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get performance statistics for a candidate across all sessions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        wins = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        total_votes = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participations = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for session in self.vote_history:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            results = session.get('results', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if candidate in session.get('candidates', []):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                participations += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if results.winner == candidate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    wins += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                total_votes += results.vote_counts.get(candidate, 0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'candidate': candidate,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'wins': wins,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'total_votes': total_votes,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'participations': participations,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'win_rate': wins / participations if participations > 0 else 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'avg_votes': total_votes / participations if participations > 0 else 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def export_results(self, format_type: str = 'json') -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Export voting results in specified format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            format_type: Export format ('json', 'csv', 'txt')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Formatted results string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not self.vote_history:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No voting history available\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if format_type == 'json':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            import json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return json.dumps(self.vote_history, indent=2, default=str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif format_type == 'csv':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            import csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            import io\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            output = io.StringIO()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            writer = csv.writer(output)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Header\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            writer.writerow(['Session', 'Timestamp', 'Candidate', 'Votes', 'Winner'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for i, session in enumerate(self.vote_history):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                results = session.get('results', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                timestamp = session.get('timestamp', '')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                for candidate, votes in results.vote_counts.items():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    writer.writerow([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        i + 1,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        timestamp,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        candidate,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        votes,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        results.winner == candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    ])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return output.getvalue()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        elif format_type == 'txt':\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            output = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            output.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=== VOTING HISTORY REPORT ===\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for i, session in enumerate(self.vote_history):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                results = session.get('results', {})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Session {i + 1}:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  Winner: {results.winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  Total Votes: {results.total_votes}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  Vote Breakdown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                for candidate, votes in sorted(results.vote_counts.items(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                               key=lambda x: x[1], reverse=True):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    output.append(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"    {candidate}: {votes}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                output.append(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".join(output)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            raise ValueError(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format: {format_type}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def reset(self) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Reset the voting system to initial state.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.is_active = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.candidates = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.eligible_voters = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.votes = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.start_time = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        self.end_time = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @property\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def status(self) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Get current status of the voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'enabled': self.enabled,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'is_active': self.is_active,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'candidates': self.candidates,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'eligible_voters': len(self.eligible_voters),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'votes_cast': len(self.votes),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'time_remaining': (self.end_time - time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                               if self.is_active and self.end_time else 0),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'sessions_completed': len(self.vote_history)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n      }\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"docs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"api_reference.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"docs/api_reference.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15639,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# AI Jubilee Debate System API Reference\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Core Classes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe central coordinator for debate sessions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nModerator(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    topic: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    participants: List[Union[BotClient, HumanClient]],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    chat_log: ChatLog,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_system: VotingSystem,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config: Dict[str, Any]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `topic`: The debate topic string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `participants`: List of bot and human participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `chat_log`: ChatLog instance for message management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `voting_system`: VotingSystem instance for handling votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `config`: Configuration dictionary with timing and rule settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async run_debate() -> Dict[str, Any]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRuns the complete debate session through all phases.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Dictionary containing voting results and session statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nmoderator = Moderator(topic, participants, chat_log, voting_system, config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {results.get('winner', 'No winner')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `get_state() -> DebateState`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nReturns current debate state information.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** DebateState object with phase, speaker, and timing info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async _give_turn(participant_name: str, time_limit: int, turn_type: str) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nGives speaking turn to a specific participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `participant_name`: Name of participant to give turn to\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `time_limit`: Maximum time in seconds for response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `turn_type`: Type of turn (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### ChatLog\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThread-safe message management system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nChatLog(max_messages: int = 1000)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `max_messages`: Maximum number of messages to retain in memory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async add_message(sender: str, content: str, message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", metadata: Optional[Dict] = None) -> Message`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAdds a new message to the chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `sender`: Name of message sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `content`: Message content text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `message_type`: Type of message (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `metadata`: Optional additional data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Created Message object\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nmessage = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I think AI will help humanity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message ID: {message.message_id}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `get_messages(limit: Optional[int] = None, sender: Optional[str] = None, message_type: Optional[str] = None, since_timestamp: Optional[float] = None) -> List[Message]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRetrieves messages with optional filtering.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `limit`: Maximum number of messages to return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `sender`: Filter by sender name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `message_type`: Filter by message type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `since_timestamp`: Only messages after this timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** List of Message objects\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `subscribe() -> asyncio.Queue`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCreates subscription for real-time message updates.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Queue that receives new Message objects\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async save_transcript(filename: str, format_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSaves chat transcript to file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `filename`: Output file path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `format_type`: Export format (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `search_messages(query: str, case_sensitive: bool = False) -> List[Message]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSearches messages by content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `query`: Search string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `case_sensitive`: Whether search is case sensitive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** List of matching Message objects\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nManages voting sessions and result calculation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nVotingSystem(config: Dict[str, Any])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `config`: Voting configuration dictionary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async start_voting(candidates: List[str], duration: Optional[int] = None) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nStarts a new voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `candidates`: List of participant names to vote for\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `duration`: Voting duration in seconds (uses config default if None)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait voting_system.start_voting([\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"], 300)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async cast_vote(voter_id: str, candidate: str, justification: Optional[str] = None) -> bool`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCasts a vote for a candidate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `voter_id`: ID of the voter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `candidate`: Name of candidate being voted for\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `justification`: Optional reasoning for the vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** True if vote was successfully cast\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async end_voting() -> VotingResults`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEnds voting session and calculates results.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** VotingResults object with winner and vote breakdown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `get_vote_summary() -> Dict[str, Any]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nGets current voting status without ending session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Dictionary with vote counts and time remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async export_results(format_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nExports voting results in specified format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `format_type`: Export format (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"csv\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Formatted results string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAI-powered debate participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nBotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    api_key: str,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    temperature: float = 0.7,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    max_tokens: int = 300\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `name`: Bot display name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `model`: AI model identifier\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `provider`: AI provider (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `personality`: Personality description for prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `stance`: Debate stance (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `api_key`: API key for AI provider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `temperature`: Response creativity (0.0-1.0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `max_tokens`: Maximum response length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nGenerates AI response to current debate context.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `topic`: Current debate topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `recent_messages`: Recent conversation messages for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Generated response string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyst\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", api_key)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nresponse = await bot.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in healthcare\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", recent_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async receive_message(message: Message) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nReceives message from debate for context awareness.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `get_stats() -> Dict[str, Any]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nReturns bot performance statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Dictionary with response counts, timing, and success rates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async warmup() -> bool`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTests bot connectivity and readiness.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** True if bot is ready for debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `update_personality(personality: str, stance: str = None) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nUpdates bot personality and stance during session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nHuman participant interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nHumanClient(name: str, interface_config: Dict[str, Any])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `name`: Human participant display name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `interface_config`: Interface configuration dictionary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async get_response(topic: str, recent_messages: List[Message]) -> str`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nGets response from human participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `topic`: Current debate topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `recent_messages`: Recent messages for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Human's response string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async handle_voting(candidates: List[str], voting_time: int) -> Dict[str, Any]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nHandles voting interface for human.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `candidates`: List of candidates to vote for\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `voting_time`: Time allowed for voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Dictionary with vote result and metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async set_active(active: bool) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSets whether human is actively participating.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `active`: Whether human should be active in debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### StreamingServer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nWebSocket server for live debate streaming.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Constructor\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nStreamingServer(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    chat_log: ChatLog,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_system: VotingSystem,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config: Dict[str, Any]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async start() -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nStarts the streaming server.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async stop() -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nStops the streaming server and closes connections.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `async broadcast_custom_message(message_type: str, data: Any) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nBroadcasts custom message to all connected clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `message_type`: Type identifier for the message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `data`: Message payload\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `get_connected_clients() -> List[Dict[str, Any]]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nReturns information about all connected streaming clients.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** List of client information dictionaries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Data Classes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRepresents a single chat message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass Message:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    sender: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    timestamp: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    message_id: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Properties:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `formatted_timestamp`: Human-readable timestamp string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Methods:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `to_dict() -> Dict[str, Any]`: Convert to dictionary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `from_dict(data: Dict[str, Any]) -> Message`: Create from dictionary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRepresents a single vote in the voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass Vote:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voter_id: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    candidate: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    justification: Optional[str] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    timestamp: float = field(default_factory=time.time)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    anonymous: bool = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### VotingResults\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nContains results from a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass VotingResults:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    winner: Optional[str]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    vote_counts: Dict[str, int]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    total_votes: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    votes_by_voter: Dict[str, Vote]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_duration: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    participation_rate: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### DebateState\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTracks current debate session state.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass DebateState:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    phase: DebatePhase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    current_speaker: Optional[str] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    time_remaining: int = 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    turn_order: List[str] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    warnings_issued: Dict[str, int] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Enums\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### DebatePhase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nDefines the phases of a debate session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass DebatePhase(Enum):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    INTRODUCTION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"introduction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    OPENING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"opening_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    DISCUSSION = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    CLOSING_STATEMENTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"closing_statements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    VOTING = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    RESULTS = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    FINISHED = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"finished\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Utility Functions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Configuration (`app/utils.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `load_config(config_path: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> Dict[str, Any]`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nLoads configuration from YAML file with environment variable substitution.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `config_path`: Path to configuration file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Configuration dictionary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Example:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nconfig = load_config(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"custom_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `setup_logging(level: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", log_file: Optional[str] = None) -> None`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSets up logging configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `level`: Logging level (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WARNING\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ERROR\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `log_file`: Optional log file path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `format_time_remaining(seconds: float) -> str`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFormats time remaining in human-readable format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `seconds`: Time in seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Formatted time string (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5m 30s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2h 15m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", etc.)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### `truncate_text(text: str, max_length: int = 100, suffix: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") -> str`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTruncates text to maximum length.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Parameters:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `text`: Text to truncate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `max_length`: Maximum length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `suffix`: Suffix to add when truncating\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Returns:** Truncated text\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Error Handling\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Custom Exceptions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe system uses standard Python exceptions with descriptive messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `ValueError`: Invalid configuration or parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `FileNotFoundError`: Missing configuration files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `ConnectionError`: API or network failures\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `TimeoutError`: Response timeouts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Error Recovery\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAll async methods include proper error handling and will not crash the session:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntry:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    response = await bot.get_response(topic, messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexcept Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Fallback response is automatically generated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    response = bot._generate_fallback_response(topic)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Configuration Schema\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Main Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Debate settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  default_topic: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_participants: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  time_limit_minutes: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  opening_statement_time: int  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  response_time: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  closing_statement_time: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Bot configurations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: str  # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: str  # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    temperature: float  # 0.0-1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    max_tokens: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# API credentials\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\napi_keys:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  openai: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  anthropic: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Voting settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  voting_duration: int  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  allow_participant_voting: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  require_justification: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  anonymous_votes: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Chat settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_message_length: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_timestamps: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  log_level: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  save_transcripts: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Streaming settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  websocket_port: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_connections: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  broadcast_votes: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Interface settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: str  # \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_rich_formatting: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  show_typing_indicators: bool\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  input_timeout: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## WebSocket API\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Client Connection\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nConnect to the streaming server:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```javascript\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Message Types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Incoming Messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### Welcome Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"welcome\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"client_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"client_123456789\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"server_info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"version\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"real_time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### Chat Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I believe AI will benefit society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1640995200.0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 42,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### Vote Update\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote_update\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"candidates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote_counts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 5, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 8,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"time_remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 120,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"is_active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Outgoing Messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### Subscribe to Channels\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"subscribe\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"channels\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### Cast Vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"voter_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"viewer_123\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"justification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Most persuasive arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n##### Ping/Pong\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ping\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Performance Considerations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### API Rate Limits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- OpenAI: Respect rate limits based on your plan\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Anthropic: Monitor request quotas\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Implement exponential backoff for retries\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Memory Management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Chat log automatically limits message history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Conversation history is pruned in bot clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Streaming connections are cleaned up automatically\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Async Best Practices\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAll I/O operations are async:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Correct - awaits async operations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nresponse = await bot.get_response(topic, messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait chat_log.add_message(sender, content)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Incorrect - would block the event loop\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# response = bot.get_response(topic, messages).result()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Unit Tests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRun the test suite:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m pytest tests/ -v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Integration Tests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTest with real APIs:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Set test API keys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexport OPENAI_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexport ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Run integration tests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m pytest tests/integration/ -v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Mock Testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom unittest.mock import AsyncMock\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Mock bot responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbot.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nresponse = await bot.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nassert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n---\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Deployment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Docker\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```dockerfile\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFROM python:3.9-slim\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nWORKDIR /app\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCOPY requirements.txt .\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRUN pip install -r requirements.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCOPY . .\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCMD [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"-m\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"app.main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Environment Variables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRequired for production:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOPENAI_API_KEY=sk-...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nANTHROPIC_API_KEY=sk-ant-...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nLOG_LEVEL=INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCONFIG_PATH=/app/production_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Health Checks\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Check system health\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def health_check():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Test bot connectivity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for bot in bots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not await bot.warmup():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Test streaming server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if streaming_server and not streaming_server.is_active:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis API reference provides comprehensive documentation for integrating with and extending the AI Jubilee Debate System.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"architecture.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"docs/architecture.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 7424,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# AI Jubilee Debate System Architecture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Overview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe AI Jubilee Debate System is a modular, event-driven platform that facilitates structured debates between AI bots and human participants. The system emphasizes real-time interaction, fair moderation, and comprehensive result tracking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Core Components\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### 1. Moderator (`app/moderator.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe central orchestrator of the debate system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Responsibilities:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Manage debate phases (introduction, opening statements, discussion, closing statements, voting, results)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Enforce time limits and speaking order\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Handle participant timeouts and warnings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Coordinate with voting system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Broadcast messages to all participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Key Classes:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `Moderator`: Main orchestration class\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `DebatePhase`: Enum defining debate stages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- `DebateState`: Current state tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Flow Diagram:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇIntroduction ‚îÇ -> ‚îÇOpening Stmts ‚îÇ -> ‚îÇ Discussion  ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                              ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   Results   ‚îÇ <- ‚îÇ    Voting    ‚îÇ <- ‚îÇClosing Stmts‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### 2. Chat Log (`app/chat_log.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThread-safe message management system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Features:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Chronological message ordering\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Pub/sub message distribution\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Message filtering and search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Transcript export (JSON, TXT, HTML)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Statistics tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Data Model:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@dataclass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass Message:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    sender: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    content: str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    timestamp: float\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    message_id: int\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    message_type: str = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    metadata: Optional[Dict[str, Any]] = None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### 3. Voting System (`app/voting.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nDemocratic evaluation mechanism for debate performance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Features:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Time-limited voting sessions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Multiple export formats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Vote validation and security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Historical tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Participation analytics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Voting Flow:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nStart Session -> Accept Votes -> End Session -> Calculate Results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n     ‚îÇ              ‚îÇ               ‚îÇ              ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n     v              v               v              v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSet Candidates  Validate Vote   Close Voting   Determine Winner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nSet Duration    Store Vote      Stop Accepting  Export Results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### 4. Participant Clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Bot Client (`app/bot_client.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAI-powered debate participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Supported Providers:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- OpenAI (GPT-3.5, GPT-4)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Anthropic (Claude)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Extensible for additional providers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Key Features:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Personality-driven responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Stance-aware argumentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Response time tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Conversation context management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Fallback response handling\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Human Client (`app/human_client.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nHuman participant interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Interface Modes:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- CLI: Terminal-based interaction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Web: WebSocket-based browser interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- API: Programmatic integration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Features:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Response validation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Timeout handling\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Voting participation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### 5. Streaming Server (`app/streaming.py`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nReal-time broadcast system for live audience.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Capabilities:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- WebSocket connections\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Message broadcasting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Vote updates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Client management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Statistics reporting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## System Architecture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ                    Moderator                            ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ   Phases    ‚îÇ ‚îÇ   Timing    ‚îÇ ‚îÇ   Rules     ‚îÇ       ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                      ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    v                 v                 v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇChat Log  ‚îÇ    ‚îÇ  Voting   ‚îÇ    ‚îÇ  Streaming   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ          ‚îÇ    ‚îÇ  System   ‚îÇ    ‚îÇ   Server     ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ- Messages‚îÇ    ‚îÇ- Sessions ‚îÇ    ‚îÇ- WebSockets  ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ- History ‚îÇ    ‚îÇ- Results  ‚îÇ    ‚îÇ- Broadcast   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ- Export  ‚îÇ    ‚îÇ- Stats    ‚îÇ    ‚îÇ- Clients     ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ‚îÇ                 ‚îÇ                 ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    v                 v                 v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ                Participants                     ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ Bot Clients ‚îÇ              ‚îÇHuman Clients‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ- OpenAI     ‚îÇ              ‚îÇ- CLI        ‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ- Anthropic  ‚îÇ              ‚îÇ- Web        ‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îÇ- Custom     ‚îÇ              ‚îÇ- API        ‚îÇ   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Data Flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Message Flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Participant generates response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Moderator validates and timestamps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Chat Log stores and distributes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Streaming Server broadcasts to audience\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n5. Other participants receive for context\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Voting Flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Moderator initiates voting phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Voting System opens session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Participants cast votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. System validates and stores votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n5. Results calculated and broadcast\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Configuration Flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Load YAML configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Initialize components with settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Create participants based on config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Start session with configured parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Error Handling\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Graceful Degradation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- API failures trigger fallback responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Network issues don't crash sessions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Participant timeouts handled smoothly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Voting continues despite individual failures\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Monitoring and Logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Comprehensive error logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Performance metrics tracking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Participant statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- System health monitoring\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Scalability Considerations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Horizontal Scaling\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Multiple debate sessions simultaneously\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Load balancing for streaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Database for persistent storage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Message queue for high throughput\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Performance Optimization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Async/await throughout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Connection pooling for APIs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Message batching for efficiency\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Resource cleanup and management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Input Validation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Message content sanitization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Participant authentication\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Vote integrity verification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Rate limiting protection\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Privacy Protection\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Anonymous voting options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Conversation encryption\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Participant data protection\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Audit trail maintenance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Extension Points\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Adding New AI Providers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Implement `AIProvider` interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Add configuration options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Update provider factory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Test integration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Custom Interfaces\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Implement `HumanInterface` interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Handle async message flow\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Add configuration support\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Test user experience\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Additional Export Formats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Extend export methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Add format validation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Update documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Test output quality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Deployment Architecture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Development\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nLocal Machine\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Python Environment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Configuration Files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Test Data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ Log Files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Production\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nContainer Orchestration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Moderator Service\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Bot Client Services\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Streaming Service\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Web Interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ Database\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ Message Queue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Configuration Management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Environment-Specific Settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Development: Local APIs, debug logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Staging: Production APIs, info logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Production: Optimized settings, error logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Secret Management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- API keys in environment variables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Database credentials secured\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- SSL certificates managed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Rotation policies enforced\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis architecture enables a robust, scalable, and extensible debate platform that can accommodate various use cases from small-scale experiments to large public events.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"usage.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"docs/usage.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 21363,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# AI Jubilee Debate System - Usage Guide\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üöÄ Quick Start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Prerequisites\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. **Python 3.8+** installed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. **API Keys** for OpenAI and/or Anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. **Dependencies** installed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Setup Steps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. **Clone or download the project**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. **Install dependencies:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   pip install -r requirements.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. **Set up your API keys in `.env` file:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   # Create .env file in project root\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   OPENAI_API_KEY=sk-your-openai-key-here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. **Run the debate:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   # Recommended: Use the simple launcher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   python run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   # Alternative: Use the module directly\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   python -m app.main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üé≠ Debate Modes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Autonomous Mode** (Default - Recommended!)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nIn autonomous mode, bots monitor the conversation and decide when to speak, creating a natural, organic debate flow.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### How Autonomous Mode Works:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ü§ñ **Bots run in parallel**, continuously monitoring chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üß† **Intelligent decision making** - bots decide when they feel compelled to respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üìö **Full conversation history** available to all participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üéØ **Smart triggers** - bots respond to mentions, challenges, or opportunities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚è∞ **Cooldown system** prevents spam (15-45 second intervals)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üó£Ô∏è **Humans can speak anytime** during discussion phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Configuration:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Enable autonomous mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  min_bot_cooldown: 15         # Minimum seconds between bot responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_bot_cooldown: 45         # Maximum cooldown for active bots  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  message_check_interval: 5    # How often bots check for new messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  silence_timeout: 60          # Moderator intervenes after silence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Example Autonomous Flow:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüé≠ Moderator: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Autonomous Discussion Phase Begin!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work increases productivity by 40%...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí≠ Skeptic is thinking about responding...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Skeptic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"But what about the collaboration costs?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüë§ Human: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I've experienced both - here's my take...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí≠ Socrates is thinking about responding...  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Socrates: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What evidence supports these productivity claims?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüéØ Moderator: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What about environmental implications?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí≠ Advocate is thinking about responding...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Great point - remote work cuts commuting emissions...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Sequential Mode** (Traditional)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nParticipants take turns in a structured order. More predictable but less dynamic.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sequential\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Traditional turn-based mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üéØ Human Participation in Autonomous Mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **During Discussion Phase:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚úÖ **Speak anytime** - no waiting for turns!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚úÖ **Type naturally** - just enter your response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚úÖ **Full context** - see all previous messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚úÖ **Real-time** - immediate feedback from bots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Available Commands:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí¨ [your message]     # Join the debate with your response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhelp                  # Show help information\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstatus                # Show your participation statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhistory               # Show recent conversation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nquit                  # Leave the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Example Human Session:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüéØ AUTONOMOUS DEBATE MODE ACTIVE\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüó£Ô∏è You can speak at ANY TIME during the discussion!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí° Commands: 'help', 'status', 'history', 'quit'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work is clearly the future because...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Skeptic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I disagree - here's why remote work fails...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí¨ Type your response: I think both perspectives miss the point about hybrid work...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí≠ Socrates is thinking about responding...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nü§ñ Socrates: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Interesting point about hybrid - can you elaborate?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí¨ Type your response: status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüìä Your participation: 1 responses, 100.0% participation rate, avg response time: 12.3s\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí¨ Type your response: Sure! Hybrid work combines the best of both...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚úÖ Your message has been added to the debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üìã Debate Phases\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **1. Introduction Phase**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Moderator introduces topic and participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Overview of rules and format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Duration: ~2 minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **2. Opening Statements Phase** \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Each participant gives structured opening statement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Sequential order** (even in autonomous mode)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Time limit: 120 seconds per participant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **3. Discussion Phase**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### **Autonomous Mode:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üîÑ **Free-flowing conversation**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ü§ñ **Bots monitor and respond intelligently** \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üë• **Humans can jump in anytime**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üéØ **Moderator provides prompts during silence**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚è∞ **Total time: 30 minutes** (configurable)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### **Sequential Mode:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üîÑ **Round-robin turns**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚è∞ **60 seconds per response**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üìù **Structured format**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **4. Closing Statements Phase**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Final arguments from each participant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Sequential order** \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Time limit: 90 seconds per participant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **5. Voting Phase**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Participants and audience vote for most persuasive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Duration: 5 minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Optional justification required\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **6. Results Phase**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Vote tallies and winner announcement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Final statistics and transcript saving\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## ‚öôÔ∏è Configuration Options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Bot Personalities**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Passionate supporter, data-driven, persuasive. Jumps in when position is challenged.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Critical thinker, questions assumptions. Responds when claims need scrutiny.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Timing Controls**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  time_limit_minutes: 30        # Total discussion time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  opening_statement_time: 120   # Opening statement duration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  response_time: 60            # Response time in sequential mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  closing_statement_time: 90   # Closing statement duration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  # Autonomous mode specific\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  min_bot_cooldown: 15         # Minimum bot response interval\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_bot_cooldown: 45         # Maximum bot cooldown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  silence_timeout: 60          # Silence before moderator intervenes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Interface Options**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"                  # CLI or web interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_rich_formatting: true # Colored/formatted output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  show_typing_indicators: true # Show when bots are thinking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_reactions: true       # Enable emoji reactions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üéõÔ∏è Advanced Usage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Command Line Options**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Basic usage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Using the module with options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI ethics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" --bots 3 --humans 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Custom configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --config custom_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Web interface mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --interface web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Custom Topics**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAdd to `config.yaml`:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntopics:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Your custom debate topic here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Another interesting topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOr specify directly:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Custom topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Bot Configuration**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nCreate custom bots in `config.yaml`:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"MyBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Your custom personality description\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üîß Troubleshooting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Common Issues**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**API Key Errors:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Check your .env file format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOPENAI_API_KEY=sk-your-key  # No quotes, no export\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nANTHROPIC_API_KEY=sk-ant-your-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Import Errors:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Make sure you're in the project root directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ncd ai_jubilee_debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n**Timeout Issues:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Check internet connection and API status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Increase timeouts in config.yaml if needed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Debug Mode**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEnable detailed logging:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  log_level: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOr set environment variable:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexport LOG_LEVEL=DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Saving Transcripts**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTranscripts are automatically saved after each debate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  save_transcripts: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  transcript_format: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFiles saved as: `debate_YYYY-MM-DD_HH-MM-SS.json`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üé™ Tips for Great Debates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **For Humans:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üéØ **Jump in naturally** during autonomous mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üìä **Reference specific points** made by others\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üí° **Provide evidence** and examples\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ü§ù **Be respectful** but persuasive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚ö° **Keep responses focused** and substantial\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Bot Optimization:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üé≠ **Diverse personalities** create better dynamics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚öñÔ∏è **Balanced stances** (pro/con/neutral mix)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üß† **Different models** (GPT-4, Claude, etc.) for variety\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚è∞ **Appropriate cooldowns** prevent spam\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Moderator Settings:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üéØ **Topic-specific prompts** keep discussion flowing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚è∞ **Reasonable timeouts** balance pace and depth\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üí¨ **Silence intervention** maintains engagement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üìä Monitoring and Analytics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Real-time Stats**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# During debate, type 'status' to see:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüìä Your participation: 3 responses, 75% participation rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚è±Ô∏è Average response time: 15.2 seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí¨ Conversation length: 24 messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Post-Debate Analysis**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üìà Participation rates per participant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- ‚è∞ Response time analytics  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üó≥Ô∏è Voting results and justifications\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- üìù Full transcript with timestamps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üöÄ Performance Tips\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **For Better Performance:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use **GPT-3.5** for faster, cheaper responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Set **reasonable cooldowns** (15-30 seconds)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Limit **conversation history** for speed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use **async mode** for responsiveness\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **For Higher Quality:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use **GPT-4** or **Claude** for better reasoning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Increase **response time limits**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Enable **detailed logging** for analysis\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Create **specific bot personalities**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üåü Advanced Features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Real-time Streaming**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEnable WebSocket streaming for live audiences:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_connections: 100\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Voting System**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nComprehensive voting with justifications:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  voting_duration: 300\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  require_justification: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  anonymous_votes: false\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Web Interface**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFor browser-based participation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üìÅ File Structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nai_jubilee_debate/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ .env                    # Your API keys (never commit!)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ .env.example           # Example environment file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ config.yaml            # Main configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ run_debate.py          # Simple launcher script\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ app/                   # Core application\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py       # Package initialization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Main entry point\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ moderator.py      # Debate moderation logic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ bot_client.py     # AI bot participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ human_client.py   # Human participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ chat_log.py       # Message management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ voting.py         # Voting system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ utils.py          # Utility functions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îî‚îÄ‚îÄ streaming.py      # WebSocket streaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îú‚îÄ‚îÄ tests/                 # Test suite\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_moderator.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_voting.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_chat_log.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îú‚îÄ‚îÄ test_bot_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îÇ   ‚îî‚îÄ‚îÄ test_human_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚îî‚îÄ‚îÄ docs/                  # Documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ‚îú‚îÄ‚îÄ architecture.md    # System architecture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ‚îú‚îÄ‚îÄ usage.md          # This file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ‚îî‚îÄ‚îÄ api_reference.md  # API documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## üÜò Getting Help\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Built-in Help**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# During debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhelp                    # Show autonomous mode help\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstatus                  # Show participation stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhistory                 # Show recent messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Command line\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --help   # Show CLI options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### **Common Commands**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Run with debug logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nLOG_LEVEL=DEBUG python run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Run tests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m pytest tests/ -v\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Check configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -c \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"from app.utils import load_config; print(load_config())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis autonomous debate system creates truly organic, intelligent conversations between AI participants while allowing humans to jump in naturally whenever they feel inspired to contribute! üé≠ü§ñ# AI Jubilee Debate System Usage Guide\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Quick Start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Installation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. **Clone the repository:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   git clone <repository-url>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   cd ai_jubilee_debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. **Install dependencies:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   pip install -r requirements.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. **Set up environment variables:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   export OPENAI_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"your-openai-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   export ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"your-anthropic-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. **Run your first debate:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   python -m app.main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Basic Configuration (`config.yaml`)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  default_topic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_participants: 4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  time_limit_minutes: 20\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Skeptic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  voting_duration: 180\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Advanced Configuration Options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Timing Settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  opening_statement_time: 120  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  response_time: 60\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  closing_statement_time: 90\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  warning_time: 45  # warning before timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Bot Personalities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosopher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thoughtful, asks probing questions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"socratic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    temperature: 0.8\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    max_tokens: 250\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Human Interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_rich_formatting: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  show_typing_indicators: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  input_timeout: 120\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Running Debates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Command Line Interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Basic Usage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Run with default settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Specify topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Set participant counts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --bots 3 --humans 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Use custom config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --config custom_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Advanced Options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Full command with all options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --topic \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --bots 2 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --humans 1 \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  --config production_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Programmatic Usage\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Simple Session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.main import start_debate_session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Start a basic debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait start_debate_session(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The future of remote work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ai_bots=2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_participants=1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Custom Session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app import Moderator, BotClient, HumanClient, ChatLog, VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Create components\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat_log = ChatLog()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nvoting_system = VotingSystem({'enabled': True})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Create participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analyst\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Data-driven and analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"your-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhuman = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Participant1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    interface_config={'mode': 'cli'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Create moderator and run\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nmoderator = Moderator(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI Ethics in Healthcare\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    participants=[bot, human],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    chat_log=chat_log,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_system=voting_system,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config={'time_limit_minutes': 15}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Participant Management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### AI Bot Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Creating Custom Bots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Argumentative bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\naggressive_bot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debater\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Aggressive, uses strong rhetoric\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    temperature=0.9,  # More creative\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    api_key=api_key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Analytical bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nanalytical_bot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Researcher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Fact-focused, cites evidence\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    temperature=0.3,  # More conservative\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    api_key=api_key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Bot Personality Examples\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npersonalities:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  socratic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Asks probing questions, seeks deeper understanding\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  advocate: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Passionate, uses emotional appeals and personal stories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  scientist: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Data-driven, cites studies and statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  philosopher: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Abstract thinking, explores ethical implications\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  pragmatist: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Focuses on practical implementation and real-world effects\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  skeptic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Questions assumptions, plays devil's advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Human Interface Options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### CLI Mode (Default)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Terminal-based interaction\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Rich formatting with colors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Real-time message display\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Keyboard input for responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Web Mode \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhuman = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WebUser\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    interface_config={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'mode': 'web',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'enable_reactions': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'show_typing_indicators': True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Debate Topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Predefined Topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe system includes several built-in topics:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Social media has a net positive impact on democracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Custom Topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Define your own topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ncustom_topics = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Cryptocurrency will replace traditional banking\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Space exploration should be publicly funded\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Genetic engineering should be available to all\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Automation will eliminate the need for human work\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Use in configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nconfig['topics'] = custom_topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Topic Guidelines\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Keep topics debatable (not factual statements)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Ensure both sides can be reasonably argued\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Make them relevant to your audience\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Consider current events and trends\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Voting and Results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Voting Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  voting_duration: 300  # 5 minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  allow_participant_voting: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  require_justification: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  anonymous_votes: false\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Accessing Results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# After debate completion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nresults = await moderator.run_debate()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {results['winner']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote breakdown: {results['vote_counts']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Export detailed results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait voting_system.export_results('json')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Results Analysis\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Get participant performance\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfor participant in participants:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    performance = voting_system.get_candidate_performance(participant.name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{participant.name}: {performance['win_rate']:.1%} win rate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Live Streaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Enable Streaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_connections: 100\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  broadcast_votes: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Streaming Server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.streaming import StreamingServer\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Create streaming server\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstreaming = StreamingServer(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    chat_log=chat_log,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    voting_system=voting_system,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config=streaming_config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait streaming.start()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Server runs on localhost:8080\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Client Connection\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```javascript\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n// Connect to stream\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nconst ws = new WebSocket('ws://localhost:8080');\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nws.onmessage = function(event) {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    const data = JSON.parse(event.data);\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if (data.type === 'message') {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        displayMessage(data.data);\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    } else if (data.type === 'vote_update') {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        updateVoteDisplay(data.data);\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n};\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Data Export and Analysis\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Transcript Export\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Save debate transcript\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_2024.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_2024.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nawait chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_2024.html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Statistics and Analytics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Chat statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstats = chat_log.get_statistics()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Total messages: {stats['total_messages']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nprint(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Average per minute: {stats['messages_per_minute']:.1f}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Participant statistics  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfor participant in participants:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stats = participant.get_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{participant.name}: {stats}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Voting Analysis\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Export voting data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ncsv_data = await voting_system.export_results('csv')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntxt_report = await voting_system.export_results('txt')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Historical analysis\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nhistory = voting_system.vote_history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfor session in history:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Session: {session['timestamp']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Winner: {session['results'].winner}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Troubleshooting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Common Issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### API Key Problems\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Check environment variables\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\necho $OPENAI_API_KEY\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\necho $ANTHROPIC_API_KEY\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Set them if missing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexport OPENAI_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sk-...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexport ANTHROPIC_API_KEY=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sk-ant-...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Connection Issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Test bot connectivity\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbot = BotClient(...)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsuccess = await bot.warmup()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nif not success:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot connection failed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n#### Performance Issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Reduce timeouts for faster sessions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  opening_statement_time: 60\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  response_time: 30\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  closing_statement_time: 45\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Limit message history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_message_length: 300\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Debug Mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Enable debug logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython -m app.main --config debug_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# debug_config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  log_level: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBUG\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  save_transcripts: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Error Recovery\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Handle errors gracefully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntry:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    results = await moderator.run_debate()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nexcept Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Debate error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Save partial transcript\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"error_recovery.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Best Practices\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Bot Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use different personalities for variety\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Balance pro/con/neutral stances\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Test API connections before debates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Monitor response times and adjust timeouts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Topic Selection\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Choose engaging, relevant topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Ensure balanced argumentation potential\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Test topics with different participant mixes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Update topics regularly for freshness\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Session Management\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Start with shorter sessions for testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Monitor participant engagement\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Save transcripts for analysis\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Review voting patterns for improvements\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Performance Optimization\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Use appropriate API models for your needs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Set reasonable timeouts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Limit concurrent API calls\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Monitor system resources\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThis guide covers the core functionality of the AI Jubilee Debate System. For detailed API documentation, see [api_reference.md](api_reference.md).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n      }\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tests\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test_bot_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tests/test_bot_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15291,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTests for the BotClient class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.bot_client import BotClient, BotConfig, OpenAIProvider, AnthropicProvider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.chat_log import Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef bot_config():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test bot configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'name': 'TestBot',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'model': 'gpt-3.5-turbo',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'provider': 'openai',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'personality': 'Analytical and thoughtful',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'stance': 'pro',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'api_key': 'test-api-key'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef bot_client(bot_config):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test bot client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return BotClient(**bot_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef sample_messages():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What do you think about AI?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995210.0, 2, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestBotConfig:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for BotConfig dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_bot_config_creation(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating bot configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.name == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.model == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.provider == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.personality == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.temperature == 0.7  # Default value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.max_tokens == 300  # Default value\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestBotClient:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for BotClient class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_bot_client_initialization(self, bot_config):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test bot client initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot = BotClient(**bot_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot.name == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot.config.model == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot.config.provider == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(bot.ai_provider, OpenAIProvider)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot.response_count == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot.conversation_history == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_bot_client_with_anthropic(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test bot client with Anthropic provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AnthropicBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Balanced\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(bot.ai_provider, AnthropicProvider)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_bot_client_unsupported_provider(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test bot client with unsupported provider.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported AI provider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-model\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"unsupported\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_response_success(self, bot_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock the AI provider\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        mock_response = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I think AI has great potential for society.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=mock_response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await bot_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == mock_response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.response_count == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(bot_client.conversation_history) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_response_with_error(self, bot_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response generation with API error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock the AI provider to raise an exception\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await bot_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI in society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should return fallback response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(response, str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(response) > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['errors'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_prepare_messages(self, bot_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message preparation for AI model.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = bot_client._prepare_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(messages) >= 1  # At least system message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[0]['role'] == 'system'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[0]['content']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[0]['content']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_create_system_prompt_pro_stance(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test system prompt creation for pro stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        prompt = bot_client._create_system_prompt(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI is beneficial\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI is beneficial\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Analytical and thoughtful\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"IN FAVOR\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_create_system_prompt_con_stance(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test system prompt creation for con stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ConBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Critical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        prompt = bot._create_system_prompt(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AGAINST\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_create_system_prompt_neutral_stance(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test system prompt creation for neutral stance.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"NeutralBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            provider=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Balanced\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            api_key=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        prompt = bot._create_system_prompt(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"balanced perspectives\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in prompt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_generate_fallback_response(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test fallback response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = bot_client._generate_fallback_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(response, str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(response) > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in response or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"perspective\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in response.lower()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_receive_message(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should be added to conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(bot_client.conversation_history) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice: Hello bot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in bot_client.conversation_history[0]['content']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Message queue should have the message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        queued_message = await bot_client.message_queue.get()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert queued_message == message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_receive_own_message(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving own message (should not be added to history).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My own message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should not be added to conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(bot_client.conversation_history) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_update_stats_success(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on success.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client._update_stats(1.5, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['responses_generated'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['average_response_time'] == 1.5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['total_response_time'] == 1.5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_update_stats_error(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client._update_stats(2.0, success=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['errors'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.stats['responses_generated'] == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_stats(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting bot statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add some test data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.stats['responses_generated'] = 5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.stats['total_response_time'] = 10.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.stats['errors'] = 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client._update_stats(0, success=True)  # Recalculate average\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        stats = bot_client.get_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['name'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['model'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['provider'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['responses_generated'] == 5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['total_errors'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'success_rate' in stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'average_response_time' in stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_update_personality(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating bot personality.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.update_personality(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New personality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.config.personality == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New personality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.config.stance == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"con\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_reset_conversation(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test resetting conversation history.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add some conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.conversation_history = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            {'role': 'user', 'content': 'Test message'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.response_count = 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.reset_conversation()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.conversation_history == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert bot_client.response_count == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_warmup_success(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful bot warmup.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Ready\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await bot_client.warmup()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_warmup_failure(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test failed bot warmup.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        bot_client.ai_provider.generate_response = AsyncMock(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Connection failed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await bot_client.warmup()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_str_representation(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test string representation of bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        string_repr = str(bot_client)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_repr_representation(self, bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test detailed string representation of bot.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        repr_str = repr(bot_client)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name='TestBot'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"model='gpt-3.5-turbo'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestOpenAIProvider:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for OpenAIProvider class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_openai_provider_initialization(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test OpenAI provider initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert provider.api_key == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_generate_response_success(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock OpenAI client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_openai.return_value = mock_client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Mock response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_response = Mock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_response.choices = [Mock()]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_response.choices[0].message.content = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I help?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client.chat.completions.create = AsyncMock(return_value=mock_response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I help?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client.chat.completions.create.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_generate_response_error(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response generation with error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        provider = OpenAIProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('app.bot_client.openai.AsyncOpenAI') as mock_openai:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_openai.return_value = mock_client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client.chat.completions.create = AsyncMock(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with pytest.raises(Exception, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"OpenAI API error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestAnthropicProvider:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for AnthropicProvider class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_anthropic_provider_initialization(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test Anthropic provider initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert provider.api_key == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-api-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_generate_response_success(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response generation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"You are a helpful assistant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_anthropic.return_value = mock_client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Mock response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_response = Mock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_response.content = [Mock()]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_response.content[0].text = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I assist you?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client.messages.create = AsyncMock(return_value=mock_response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello! How can I assist you?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client.messages.create.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_generate_response_error(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response generation with error.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        provider = AnthropicProvider(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test-key\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = BotConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"claude-3-sonnet\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"anthropic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = [{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"role\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"user\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('app.bot_client.anthropic.AsyncAnthropic') as mock_anthropic:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client = Mock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_anthropic.return_value = mock_client\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_client.messages.create = AsyncMock(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"API Error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with pytest.raises(Exception, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Anthropic API error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                await provider.generate_response(messages, config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_conversation_history_management(bot_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test conversation history management.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Add messages beyond the limit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for i in range(25):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await bot_client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should be limited to avoid memory issues\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert len(bot_client.conversation_history) <= 20\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_bot_response_timing(bot_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test that response timing is tracked.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot_client.ai_provider.generate_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Simulate some delay\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def delayed_response(*args):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await asyncio.sleep(0.1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Delayed response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot_client.ai_provider.generate_response = delayed_response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await bot_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert bot_client.stats['average_response_time'] > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert bot_client.stats['total_response_time'] > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test_chat_log.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tests/test_chat_log.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15406,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTests for the ChatLog class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom unittest.mock import patch, mock_open\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.chat_log import ChatLog, Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef chat_log():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return ChatLog(max_messages=100)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef sample_messages():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello everyone!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 1),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi Alice!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 2),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome to the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 3, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestMessage:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for Message dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_message_creation(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        timestamp = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timestamp, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.timestamp == timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.message_id == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.metadata == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_message_with_metadata(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message with metadata.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        metadata = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"urgency\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"high\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Important point\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                      message_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", metadata=metadata)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.metadata == metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_formatted_timestamp(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test formatted timestamp property.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        timestamp = 1640995200.0  # Known timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timestamp, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        formatted = msg.formatted_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(formatted, str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in formatted  # Should contain time separator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_to_dict(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test converting message to dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg_dict = msg.to_dict()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(msg_dict, dict)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg_dict[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg_dict[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in msg_dict\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in msg_dict\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_from_dict(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating message from dictionary.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        data = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": time.time(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 5,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg = Message.from_dict(data)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg.message_id == 5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestChatLog:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for ChatLog class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_chat_log_initialization(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test chat log initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log = ChatLog(max_messages=50)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.message_counter == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.subscribers == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_add_message(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test adding a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(message, Message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert message.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert message.message_id == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_add_multiple_messages(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test adding multiple messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"First message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Second message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Third message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.message_counter == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_message_ordering(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test that messages maintain chronological order.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg1 = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"First\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await asyncio.sleep(0.01)  # Small delay\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg2 = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Second\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = list(chat_log.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[0].message_id == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[1].message_id == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[0].timestamp < messages[1].timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_max_messages_limit(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message limit enforcement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log = ChatLog(max_messages=3)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add more messages than the limit\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for i in range(5):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 3  # Should be limited\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check that oldest messages were removed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = list(chat_log.messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[0].content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message 4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in messages[2].content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_subscription_system(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message subscription system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        queue = chat_log.subscribe()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add a message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check that subscriber received the message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        received_message = await asyncio.wait_for(queue.get(), timeout=1.0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert received_message.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert received_message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_multiple_subscribers(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test multiple subscribers.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        queue1 = chat_log.subscribe()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        queue2 = chat_log.subscribe()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Both subscribers should receive the message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg1 = await asyncio.wait_for(queue1.get(), timeout=1.0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        msg2 = await asyncio.wait_for(queue2.get(), timeout=1.0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert msg1.content == msg2.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Broadcast message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_unsubscribe(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test unsubscribing from messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        queue = chat_log.subscribe()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert queue in chat_log.subscribers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.unsubscribe(queue)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert queue not in chat_log.subscribers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_messages_no_filter(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting all messages without filters.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Manually add messages to chat log\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(messages) == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_messages_with_limit(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting messages with limit.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages(limit=2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(messages) == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should get the last 2 messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert messages[1].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_messages_by_sender(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test filtering messages by sender.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        alice_messages = chat_log.get_messages(sender=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(alice_messages) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert alice_messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_messages_by_type(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test filtering messages by type.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        moderator_messages = chat_log.get_messages(message_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(moderator_messages) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator_messages[0].message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_messages_since_timestamp(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test filtering messages by timestamp.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add messages with known timestamps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        old_time = time.time() - 100\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        new_time = time.time()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.messages.append(Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Old\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", old_time, 1))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.messages.append(Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", new_time, 2))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        cutoff = time.time() - 50\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        recent_messages = chat_log.get_messages(since_timestamp=cutoff)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(recent_messages) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert recent_messages[0].content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"New\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_recent_messages(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting recent messages.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        recent = chat_log.get_recent_messages(2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(recent) == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert recent[-1].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Most recent\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_conversation_context(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting conversation context for a participant.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add various messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 1),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hi Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 2),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome everyone\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 3, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thanks!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 4),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Good luck\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", time.time(), 5)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        context = chat_log.get_conversation_context(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", context_length=3)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should include Alice's messages and moderator messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(context) <= 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert any(msg.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for msg in context)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert any(msg.message_type == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for msg in context)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_search_messages(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test searching messages by content.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Case insensitive search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(results) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results[0].content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Case sensitive search\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", case_sensitive=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(results) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = chat_log.search_messages(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", case_sensitive=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(results) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_statistics(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting chat log statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            sender = msg.sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][sender] = (\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(sender, 0) + 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        stats = chat_log.get_statistics()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"unique_senders\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 2  # Alice, Bob, moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_per_minute\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"session_duration_minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_save_transcript_json(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript in JSON format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert output_file.exists()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with open(output_file, 'r') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            data = json.load(f)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert data[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][0][\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_save_transcript_txt(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript in TXT format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert output_file.exists()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        content = output_file.read_text()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"DEBATE TRANSCRIPT\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice: Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_save_transcript_html(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript in HTML format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"System message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                                   message_type=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"html\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert output_file.exists()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        content = output_file.read_text()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"<!DOCTYPE html>\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"class=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_save_transcript_invalid_format(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test saving transcript with invalid format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await chat_log.save_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test.xml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"xml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_load_transcript(self, chat_log, tmp_path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test loading transcript from file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Save a transcript first\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.add_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Original message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        output_file = tmp_path / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"transcript.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.save_transcript(str(output_file), \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Clear chat log and reload\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.clear()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await chat_log.load_transcript(str(output_file))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert list(chat_log.messages)[0].content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Original message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_load_transcript_file_not_found(self, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test loading transcript from non-existent file.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(FileNotFoundError):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await chat_log.load_transcript(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"nonexistent.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_clear_chat_log(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test clearing the chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.message_counter = 5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log.clear()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log.messages) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.message_counter == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert chat_log.stats[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_chat_log_len(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test chat log length.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(chat_log) == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_chat_log_iteration(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test iterating over chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        iterated_messages = list(chat_log)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(iterated_messages) == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert iterated_messages[0].sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_chat_log_indexing(self, chat_log, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test indexing chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for msg in sample_messages:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            chat_log.messages.append(msg)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        first_message = chat_log[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert first_message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        last_message = chat_log[-1]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert last_message.sender == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test_human_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tests/test_human_client.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20297,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTests for the HumanClient class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.human_client import HumanClient, CLIInterface, WebInterface, InterfaceConfig\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.chat_log import Message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef interface_config():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test interface configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'mode': 'cli',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'enable_rich_formatting': False,  # Disable for testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'show_typing_indicators': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'enable_reactions': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'input_timeout': 60\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef human_client(interface_config):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", interface_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef sample_messages():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create sample messages for testing.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"What's your opinion?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"I think...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995210.0, 2),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Please respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995220.0, 3, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestInterfaceConfig:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for InterfaceConfig dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_interface_config_defaults(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test interface config with default values.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.enable_rich_formatting == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.show_typing_indicators == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.enable_reactions == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.input_timeout == 120\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_interface_config_custom(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test interface config with custom values.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            enable_rich_formatting=False,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            input_timeout=90\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.mode == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.enable_rich_formatting == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert config.input_timeout == 90\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestCLIInterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for CLIInterface class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_cli_interface_initialization(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test CLI interface initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert interface.config == config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert interface.rich_console is None  # Rich disabled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_display_basic_message(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test displaying message with basic formatting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello world\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await interface.display_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_display_moderator_message(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test displaying moderator message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await interface.display_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Should have moderator prefix\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            args = mock_print.call_args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_input_success(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful input retrieval.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('builtins.input', return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            response = await interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timeout=1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_input_timeout(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test input timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock input to simulate hanging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        async def slow_input():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Too late\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface._get_user_input = slow_input\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", timeout=0.1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Should return empty string on timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_show_notification(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test showing notifications.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(enable_rich_formatting=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = CLIInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch('builtins.print') as mock_print:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await interface.show_notification(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"info\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            mock_print.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            args = mock_print.call_args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ÑπÔ∏è\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestWebInterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for WebInterface class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_web_interface_initialization(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test web interface initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = WebInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert interface.config == config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert interface.websocket is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert interface.pending_responses == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_display_message_no_websocket(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test displaying message without websocket connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = WebInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should not raise an error even without websocket\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await interface.display_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_input_no_websocket(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting input without websocket connection.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = InterfaceConfig(mode=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        interface = WebInterface(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await interface.get_input(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Enter response:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Should return empty string\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestHumanClient:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for HumanClient class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_human_client_initialization(self, interface_config):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", interface_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert client.name == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(client.interface, CLIInterface)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert client.is_active == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert client.conversation_history == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert client.stats['responses_given'] == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_human_client_web_mode(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client with web interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = {'mode': 'web'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WebHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(client.interface, WebInterface)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_human_client_unsupported_mode(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client with unsupported interface mode.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = {'mode': 'unsupported'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported interface mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_response_success(self, human_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful response retrieval.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock the interface get_input method\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['responses_given'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_response_timeout(self, human_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock timeout scenario\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['timeouts'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_get_response_inactive(self, human_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response when client is inactive.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.is_active = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_validate_response(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response validation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Normal response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This is a good response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"This is a good response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Very long response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        long_response = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"x\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 600\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        response = human_client._validate_response(long_response)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(response) <= 503  # 500 + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert response.endswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Very short response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        short_response = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Yes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Note: Very short response]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in short_response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_receive_message(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving a message.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Hello human\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await human_client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should be added to conversation history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(human_client.conversation_history) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.conversation_history[0] == message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should display the message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message.assert_called_once_with(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_receive_own_message(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test receiving own message (should be ignored).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"My own message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0, 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await human_client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should not be added to history or displayed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(human_client.conversation_history) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message.assert_not_called()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_conversation_history_limit(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test conversation history length limit.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add many messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for i in range(60):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await human_client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should be limited to 30 (as per implementation)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(human_client.conversation_history) == 30\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_handle_voting_success(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful voting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Charlie\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock interface methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(side_effect=[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Good arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['voted'] == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['candidate'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # Index 2-1 = 1 -> \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['justification'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Good arguments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_handle_voting_timeout(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['voted'] == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['reason'] == 'timeout'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_handle_voting_invalid_choice(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting with invalid choice.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")  # Out of range\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['voted'] == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['reason'] == 'invalid_choice'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_handle_voting_invalid_format(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting with invalid input format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"not_a_number\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await human_client.handle_voting(candidates, 30)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['voted'] == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result['reason'] == 'invalid_format'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_update_stats_success(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on successful response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client._update_stats(2.5, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['responses_given'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['average_response_time'] == 2.5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['total_response_time'] == 2.5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_update_stats_timeout(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test updating statistics on timeout.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client._update_stats(5.0, success=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['timeouts'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.stats['responses_given'] == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_stats(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting human client statistics.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add some test data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.stats['responses_given'] = 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.stats['timeouts'] = 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.stats['total_response_time'] = 15.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client._update_stats(0, success=True)  # Recalculate average\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        stats = human_client.get_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['name'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['interface_mode'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['responses_given'] == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['timeouts'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'average_response_time' in stats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_set_active(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test setting client active/inactive status.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Set inactive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await human_client.set_active(False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.is_active == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Set active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await human_client.set_active(True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.is_active == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should have called show_notification twice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert human_client.interface.show_notification.call_count == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_show_help(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test showing help information.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await human_client.show_help()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        human_client.interface.show_notification.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        args = human_client.interface.show_notification.call_args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI Jubilee Debate Help\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"COMMANDS:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in args[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_str_representation(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test string representation of human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        string_repr = str(human_client)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in string_repr\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_repr_representation(self, human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test detailed string representation of human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        repr_str = repr(human_client)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"name='TestHuman'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"mode='cli'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"active=True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in repr_str\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_show_context_integration(human_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test showing context to human before response.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should show context notification\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    notification_calls = human_client.interface.show_notification.call_args_list\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert any(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Recent messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in str(call) for call in notification_calls)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should display recent messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert human_client.interface.display_message.call_count >= 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_human_response_validation_edge_cases(human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test edge cases in response validation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Empty response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert result == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Whitespace only\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\t   \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert result == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Response with just newlines\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert result == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Very short meaningful response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    result = human_client._validate_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Note: Very short response]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in result\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_human_client_error_resilience(human_client, sample_messages):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test human client resilience to interface errors.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Mock interface to raise errors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.display_message = AsyncMock(side_effect=Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Interface error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should not crash despite interface errors\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    response = await human_client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", sample_messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_human_client_concurrent_operations(human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test concurrent operations on human client.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Simulate concurrent message receiving\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    tasks = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for i in range(10):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        tasks.append(human_client.receive_message(message))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await asyncio.gather(*tasks)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # All messages should be processed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert len(human_client.conversation_history) == 10\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef test_human_client_stats_calculation(human_client):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test statistics calculation accuracy.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Simulate various response scenarios\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client._update_stats(2.0, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client._update_stats(3.0, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client._update_stats(1.5, success=False)  # Timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_client._update_stats(2.5, success=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stats = human_client.get_stats()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert stats['responses_given'] == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert stats['timeouts'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert stats['participation_rate'] == 0.75  # 3/(3+1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert abs(stats['average_response_time'] - 2.5) < 0.1  # (2.0+3.0+2.5)/3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_voting_with_web_interface():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting behavior with web interface.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config = {'mode': 'web'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"WebUser\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    candidates = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Web interface should handle justification differently\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    result = await client.handle_voting(candidates, 60)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert result['voted'] == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert result['candidate'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert result['justification'] == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # No justification prompt for web\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_human_client_lifecycle():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test complete human client lifecycle.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config = {'mode': 'cli', 'enable_rich_formatting': False}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client = HumanClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"LifecycleTest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Initial state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert client.is_active == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert len(client.conversation_history) == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Mock interface for testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client.interface.display_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client.interface.show_notification = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    client.interface.get_input = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Receive some messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for i in range(3):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        message = Message(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"User{i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Message {i}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 1640995200.0 + i, i)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await client.receive_message(message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert len(client.conversation_history) == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Participate in debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    response = await client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert client.stats['responses_given'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Deactivate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await client.set_active(False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert client.is_active == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should not respond when inactive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    response = await client.get_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Another topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", [])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert response == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test_moderator.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tests/test_moderator.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 9146,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTests for the Moderator class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom unittest.mock import Mock, AsyncMock, patch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.moderator import Moderator, DebatePhase, DebateState\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.chat_log import ChatLog\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.voting import VotingSystem\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.bot_client import BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.human_client import HumanClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef chat_log():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test chat log.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return ChatLog()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef voting_system():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config = {'enabled': True, 'voting_duration': 60}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return VotingSystem(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef mock_participants():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create mock participants.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot = Mock(spec=BotClient)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot.name = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot.get_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    bot.receive_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human = Mock(spec=HumanClient)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human.name = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human.get_response = AsyncMock(return_value=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human.receive_message = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return [bot, human]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef moderator(chat_log, voting_system, mock_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create a test moderator.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    config = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'opening_statement_time': 30,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'discussion_time': 60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'closing_statement_time': 30,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'response_time': 20,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'max_response_time': 60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'warning_time': 45\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return Moderator(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participants=mock_participants,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        chat_log=chat_log,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system=voting_system,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config=config\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestModerator:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for Moderator class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_moderator_initialization(self, moderator):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test moderator initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.topic == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test topic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(moderator.participants) == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in moderator.participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestHuman\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in moderator.participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_introduction_phase(self, moderator, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test introduction phase.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._introduction_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check that introduction message was logged\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert any(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Welcome to AI Jubilee Debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in msg.content for msg in messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_opening_statements_phase(self, moderator, mock_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test opening statements phase.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._opening_statements_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.OPENING_STATEMENTS\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Verify each participant was asked for response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for participant in mock_participants:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            participant.get_response.assert_called()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_give_turn_success(self, moderator, mock_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test successful turn giving.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant = mock_participants[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant.get_response.return_value = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._give_turn(participant.name, 30, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant.get_response.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.current_speaker is None  # Reset after turn\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_give_turn_timeout(self, moderator, mock_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test turn timeout handling.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant = mock_participants[0]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Simulate timeout by making get_response take too long\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        async def slow_response(*args):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await asyncio.sleep(2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Too late\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant.get_response = slow_response\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Use very short timeout for testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._give_turn(participant.name, 0.1, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should have issued a warning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued.get(participant.name, 0) >= 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_voting_phase_enabled(self, moderator):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting phase when voting is enabled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        moderator.voting_system.enabled = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with patch.object(moderator.voting_system, 'start_voting') as mock_start:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with patch.object(moderator.voting_system, 'end_voting') as mock_end:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                mock_end.return_value = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'winner': 'TestBot',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    'vote_counts': {'TestBot': 2, 'TestHuman': 1}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                results = await moderator._voting_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                mock_start.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                mock_end.assert_called_once()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                assert results['winner'] == 'TestBot'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_voting_phase_disabled(self, moderator):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting phase when voting is disabled.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        moderator.voting_system.enabled = False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = await moderator._voting_phase()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_broadcast_message(self, moderator, mock_participants, chat_log):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message broadcasting.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._broadcast_message(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check message was logged\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        messages = chat_log.get_messages()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert any(msg.content == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" for msg in messages)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check all participants received message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for participant in mock_participants:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            participant.receive_message.assert_called()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_handle_timeout_warnings(self, moderator):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test timeout warning system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        participant_name = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # First timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Second timeout\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Third timeout (should trigger mute)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await moderator._handle_timeout(participant_name)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.warnings_issued[participant_name] == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_state(self, moderator):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test state retrieval.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        state = moderator.get_state()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(state, DebateState)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.current_speaker is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_full_debate_flow(self, moderator, mock_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test complete debate flow.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Mock voting system methods\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        moderator.voting_system.start_voting = AsyncMock()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        moderator.voting_system.end_voting = AsyncMock(return_value={\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'winner': 'TestBot',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'vote_counts': {'TestBot': 1, 'TestHuman': 0}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        })\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Run complete debate with short timeouts for testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        moderator.phase_times[DebatePhase.DISCUSSION] = 1  # 1 second\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = await moderator.run_debate()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Verify all phases completed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert moderator.state.phase == DebatePhase.FINISHED\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'winner' in results\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Verify participants were called\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for participant in mock_participants:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            assert participant.get_response.call_count > 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestDebateState:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for DebateState dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_debate_state_initialization(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test DebateState initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        state = DebateState(DebatePhase.DISCUSSION)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.phase == DebatePhase.DISCUSSION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.current_speaker is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.time_remaining == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.turn_order == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.warnings_issued == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_debate_state_with_values(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test DebateState with custom values.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        turn_order = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        warnings = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bot1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        state = DebateState(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            phase=DebatePhase.VOTING,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            current_speaker=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            time_remaining=120,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            turn_order=turn_order,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            warnings_issued=warnings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.phase == DebatePhase.VOTING\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.current_speaker == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.time_remaining == 120\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.turn_order == turn_order\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert state.warnings_issued == warnings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_moderator_error_handling(moderator, mock_participants):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test moderator error handling.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Make participant raise an error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    mock_participants[0].get_response.side_effect = Exception(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should not crash the debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await moderator._give_turn(mock_participants[0].name, 30, \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Moderator should continue functioning\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert moderator.state.phase == DebatePhase.INTRODUCTION\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasync def test_moderator_message_validation(moderator):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test message content validation.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    long_message = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"x\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 1000  # Very long message\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    await moderator._process_response(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TestBot\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", long_message)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Should have been truncated\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    messages = moderator.chat_log.get_messages()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    last_message = messages[-1]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    assert len(last_message.content) <= 503  # 500 + \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        },\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"test_voting.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tests/test_voting.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 16340,\\\\\\\\\\\\\\\\n          \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nTests for the VotingSystem class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport pytest\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport time\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.voting import VotingSystem, Vote, VotingResults\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef voting_config():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test voting configuration.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'enabled': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'voting_duration': 60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'allow_participant_voting': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'require_justification': False,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'anonymous_votes': False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef voting_system(voting_config):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create test voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return VotingSystem(voting_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n@pytest.fixture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef active_voting_system(voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create and start a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    asyncio.create_task(voting_system.start_voting(['Alice', 'Bob', 'Charlie'], 30))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return voting_system\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestVotingSystem:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for VotingSystem class.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_voting_system_initialization(self, voting_config):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting system initialization.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vs = VotingSystem(voting_config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.enabled == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.voting_duration == 60\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.allow_participant_voting == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.require_justification == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.anonymous_votes == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.is_active == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.candidates == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.votes == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_disabled_voting_system(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test disabled voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = {'enabled': False}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vs.enabled == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_start_voting_session(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test starting a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        candidates = ['Alice', 'Bob', 'Charlie']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(candidates, 30)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.is_active == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.candidates == candidates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.eligible_voters == candidates  # allow_participant_voting=True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.start_time is not None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.end_time is not None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_start_voting_disabled_system(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test starting voting on disabled system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = {'enabled': False}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting system is disabled\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await vs.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_start_voting_already_active(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test starting voting when already active.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting session already active\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await voting_system.start_voting(['Charlie', 'Dave'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_cast_valid_vote(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting a valid vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await voting_system.cast_vote('voter1', 'Alice', 'Great arguments')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'voter1' in voting_system.votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.votes['voter1'].candidate == 'Alice'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.votes['voter1'].justification == 'Great arguments'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_cast_vote_no_active_session(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting vote with no active session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_cast_vote_invalid_candidate(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting vote for invalid candidate.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Invalid candidate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await voting_system.cast_vote('voter1', 'Charlie')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_cast_vote_requires_justification(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting system that requires justification.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'enabled': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'require_justification': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'allow_participant_voting': True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Vote without justification should fail\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Vote justification is required\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await vs.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Vote with justification should succeed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await vs.cast_vote('voter1', 'Alice', 'Good points')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_cast_vote_overwrite(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test that new vote overwrites previous vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Bob')  # Change vote\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.votes['voter1'].candidate == 'Bob'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(voting_system.votes) == 1  # Only one vote per voter\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test self-voting when allowed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_self_voting_allowed(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test self-voting when allowed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Should allow participant to vote for themselves\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        result = await voting_system.cast_vote('Alice', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert result == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_self_voting_disallowed(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test self-voting when disallowed.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        config = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'enabled': True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'allow_participant_voting': False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vs = VotingSystem(config)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await vs.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Self-voting is not allowed\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await vs.cast_vote('Alice', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_end_voting_session(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending a voting session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob', 'Charlie'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Cast some votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter2', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter3', 'Bob')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(results, VotingResults)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.winner == 'Alice'  # Most votes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.vote_counts['Alice'] == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.vote_counts['Bob'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.total_votes == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.is_active == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_end_voting_tie(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending voting with a tie.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter2', 'Bob')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"TIE:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results.winner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Alice\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results.winner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Bob\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in results.winner\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_end_voting_no_votes(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending voting with no votes cast.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.winner is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.total_votes == 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.vote_counts == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_end_voting_not_active(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test ending voting when not active.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"No active voting session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_get_vote_summary(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test getting vote summary during active session.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # No active session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        summary = voting_system.get_vote_summary()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert summary == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # With active session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        asyncio.create_task(voting_system.start_voting(['Alice', 'Bob'], 60))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        summary = voting_system.get_vote_summary()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'candidates' in summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'vote_counts' in summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'total_votes' in summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'time_remaining' in summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'is_active' in summary\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_add_remove_eligible_voters(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test adding and removing eligible voters.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.add_eligible_voter('voter1')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'voter1' in voting_system.eligible_voters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.add_eligible_voter('voter2')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(voting_system.eligible_voters) == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.remove_eligible_voter('voter1')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'voter1' not in voting_system.eligible_voters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(voting_system.eligible_voters) == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_is_eligible_voter(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voter eligibility checking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Empty eligible voters list means open voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system._is_eligible_voter('anyone') == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # With specific eligible voters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.add_eligible_voter('voter1')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system._is_eligible_voter('voter1') == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system._is_eligible_voter('voter2') == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_vote_history(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test vote history tracking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # First session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Second session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Charlie', 'Dave'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Charlie')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(voting_system.vote_history) == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Test voter history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voter_history = voting_system.get_voter_history('voter1')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(voter_history) == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voter_history[0].candidate == 'Alice'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voter_history[1].candidate == 'Charlie'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_candidate_performance(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test candidate performance tracking.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Add some mock history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.vote_history = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'candidates': ['Alice', 'Bob'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'results': VotingResults(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    winner='Alice',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    vote_counts={'Alice': 2, 'Bob': 1},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    total_votes=3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    votes_by_voter={},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    voting_duration=60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    participation_rate=1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'candidates': ['Alice', 'Charlie'],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                'results': VotingResults(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    winner='Charlie',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    vote_counts={'Alice': 1, 'Charlie': 2},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    total_votes=3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    votes_by_voter={},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    voting_duration=60,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    participation_rate=1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        performance = voting_system.get_candidate_performance('Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert performance['wins'] == 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert performance['participations'] == 2\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert performance['total_votes'] == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert performance['win_rate'] == 0.5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert performance['avg_votes'] == 1.5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_export_results_json(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting results in JSON format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Create some history\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        json_output = await voting_system.export_results('json')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(json_output, str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'Alice' in json_output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'vote_counts' in json_output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_export_results_csv(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting results in CSV format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        csv_output = await voting_system.export_results('csv')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(csv_output, str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'Session,Timestamp,Candidate,Votes,Winner' in csv_output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'Alice' in csv_output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_export_results_txt(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting results in TXT format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.end_voting()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        txt_output = await voting_system.export_results('txt')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(txt_output, str)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'VOTING HISTORY REPORT' in txt_output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'Alice' in txt_output\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_export_unsupported_format(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test exporting with unsupported format.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Unsupported format\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await voting_system.export_results('xml')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_reset_voting_system(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test resetting the voting system.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Set up some state\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.candidates = ['Alice', 'Bob']\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.votes = {'voter1': Vote('voter1', 'Alice')}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.is_active = True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        voting_system.reset()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.is_active == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.candidates == []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.votes == {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.start_time is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert voting_system.end_time is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_voting_system_status(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test voting system status property.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        status = voting_system.status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'enabled' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'is_active' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'candidates' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'eligible_voters' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'votes_cast' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'time_remaining' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert 'sessions_completed' in status\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    @pytest.mark.asyncio\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    async def test_vote_after_time_expires(self, voting_system):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test casting vote after voting time expires.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Start voting with very short duration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await voting_system.start_voting(['Alice', 'Bob'], 0.1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Wait for voting to expire\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        await asyncio.sleep(0.2)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with pytest.raises(ValueError, match=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Voting period has ended\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            await voting_system.cast_vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestVote:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for Vote dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_vote_creation(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating a vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote = Vote('voter1', 'Alice', 'Great arguments')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vote.voter_id == 'voter1'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vote.candidate == 'Alice'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vote.justification == 'Great arguments'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vote.anonymous == False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert isinstance(vote.timestamp, float)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_vote_anonymous(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating anonymous vote.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote = Vote('voter1', 'Alice', anonymous=True)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vote.anonymous == True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_vote_no_justification(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test vote without justification.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote = Vote('voter1', 'Alice')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert vote.justification is None\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclass TestVotingResults:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test suite for VotingResults dataclass.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    def test_voting_results_creation(self):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Test creating voting results.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        vote_counts = {'Alice': 2, 'Bob': 1}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        votes_by_voter = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'voter1': Vote('voter1', 'Alice'),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'voter2': Vote('voter2', 'Alice'),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            'voter3': Vote('voter3', 'Bob')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        results = VotingResults(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            winner='Alice',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            vote_counts=vote_counts,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            total_votes=3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            votes_by_voter=votes_by_voter,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            voting_duration=60.0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            participation_rate=1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.winner == 'Alice'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.vote_counts == vote_counts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.total_votes == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert len(results.votes_by_voter) == 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.voting_duration == 60.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        assert results.participation_rate == 1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\n      }\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 2896,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# AI Jubilee Debate Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Debate Settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndebate:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  default_topic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The role of artificial intelligence in modern society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_participants: 5\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  time_limit_minutes: 30\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  opening_statement_time: 120  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  response_time: 60  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  closing_statement_time: 90  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  # Debate mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sequential\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" or \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"autonomous\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # AUTONOMOUS MODE: Bots monitor and decide when to speak!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  # Autonomous mode settings\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  min_bot_cooldown: 15          # Minimum seconds between bot responses\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_bot_cooldown: 45          # Maximum cooldown for very active bots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  message_check_interval: 5     # How often bots check for new messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  silence_timeout: 60           # Seconds of silence before moderator intervenes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Available debate topics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntopics:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AI will create more jobs than it destroys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Social media has a net positive impact on democracy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Universal Basic Income is necessary for the future economy\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Climate change requires immediate radical action\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Privacy is more important than security\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work is the future of employment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# AI Bot Configurations\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbots:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosophical, asks probing questions, seeks truth through dialogue. Speaks when curious about underlying assumptions.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"socratic\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Passionate supporter, data-driven, persuasive speaker. Jumps in when position is challenged.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"assertive\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"pro\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  - name: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Mediator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-3.5-turbo\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    provider: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"openai\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Balanced, seeks common ground, diplomatic. Speaks to bridge disagreements and find synthesis.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    debate_style: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"collaborative\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# API Keys (use environment variables in production)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\napi_keys:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  openai: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"${OPENAI_API_KEY}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  anthropic: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"${ANTHROPIC_API_KEY}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Voting System\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nvoting:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  voting_duration: 300  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  allow_participant_voting: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  require_justification: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  anonymous_votes: false\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Chat and Logging\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nchat:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_message_length: 500\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_timestamps: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  log_level: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"INFO\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  save_transcripts: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  transcript_format: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Streaming Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nstreaming:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enabled: false\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  websocket_port: 8080\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_connections: 100\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  broadcast_votes: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Timeouts and Limits\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nlimits:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_response_time: 120  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  warning_time: 90  # seconds\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_retries: 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  rate_limit_per_minute: 10\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Moderation Rules\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nmoderation:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_profanity_filter: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  max_interruptions: 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enforce_turn_order: false  # No turn order in autonomous mode\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  auto_mute_violations: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Human Interface\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ninterface:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  mode: \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"cli\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  # options: cli, web, api\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_rich_formatting: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  show_typing_indicators: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  enable_reactions: true\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_Remote work is the f.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"debate_Remote work is the f.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 13661,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"export_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812154.74717,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"statistics\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"unique_senders\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_by_sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 33,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages_per_minute\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 12.37544767478349,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"session_duration_minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3.5554269353548684,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"current_message_count\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"messages\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠ Welcome to AI  Debate!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüìù Topic: Remote work is the future of employment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüë• Participants: Socrates, Advocate, Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚è±Ô∏è Total time: 30 minutes\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811941.5010219,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Opening Statements Phase\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nEach participant has 120 seconds for their opening statement.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811944.502393,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for opening statement (120s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811944.502721,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 3,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811954.512209,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 4,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Thank you, dear moderator. As we embark on this discourse, let us consider not just the nature of remote work, but also the essence of employment itself. What are the fundamental elements of work? One might posit that they include collaboration, productivity, and satisfaction, among other things.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRemote work, undeniably, has altered the landscape of employment. It transcends geographical boundaries, allows for flexibility, and can, in some cases, increase productivity. Yet, it also brings forth...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811954.5130692,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 5,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for opening statement (120s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811954.5131688,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 6,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811965.525105,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 7,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Thank you, moderator. I firmly believe that remote work represents the future of employment. The digital age has brought about unprecedented technological advancements, enabling us to work from anywhere, at any time. This is not just a passing trend, but a fundamental shift in how we approach work.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nData from a study by Stanford University shows that remote workers are 13% more productive than their in-office counterparts. It also reduces costs for businesses by eliminating the need fo...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811965.5253692,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 8,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for opening statement (120s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811965.5253801,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 9,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 89 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749811995.5549319,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 10,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"hei i don¬¥t belive you\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.5676649,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 11,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üí¨ Discussion Phase Begin\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nOpen discussion for 30 minutes. Maintain respectful dialogue!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.567806,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 12,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.569291,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 13,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Socrates: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812007.569945,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 14,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates: It appears there may be some confusion, my friend. We are here to debate the future of remote work, not to question our trust in one another. I would like to ask you, do you believe that the rise in remote work we have seen in recent years, especially during the pandemic, is a temporary phenomenon, or do you think it hints at a more permanent shift in the way we approach work?\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812011.574508,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 15,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812011.574569,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 16,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812011.5753531,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 17,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.583849,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 18,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Thank you, Socrates, for your question. I firmly believe that the rise in remote work is not just a temporary phenomenon but a reflection of a more significant, more permanent shift in work arrangements. A study from Upwork's \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Future Workforce Report\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" suggests that 22% of the American workforce will be remote by 2025, a staggering 87% increase from pre-pandemic levels. This is not just a response to the pandemic, but a result of businesses realizing the benefits of remote work, includi...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.584952,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 19,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.585004,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 20,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812018.5856278,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 21,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"tell me that you love me\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812027.595841,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 22,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812027.595914,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 23,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Socrates: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812027.597049,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 24,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.60398,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 25,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates: Indeed, the Upwork report is an insightful piece of evidence. However, might we not question whether this shift is wholly beneficial for both employers and employees? For instance, remote work may lead to a blurring of boundaries between work and home life, potentially leading to stress and burnout. Moreover, does this shift not potentially exacerbate inequalities, since not all jobs can be performed remotely ‚Äì a privilege often reserved for certain types of jobs and sectors? Lastly, o...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.605064,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 26,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.6051142,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 27,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812032.605727,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 28,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616073,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 29,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Valid points, Socrates. However, let's tackle them one by one. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nFirstly, the challenge of work-life balance is indeed present in remote work. But it's not unique to it. Many traditionally structured jobs also struggle with it. The key here is proper management and the setting of boundaries, which can be learned and improved. \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nIn terms of exacerbating inequalities, it's true that not all jobs can be performed remotely. Yet, the move towards remote work can potentially reduce inequalit...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616268,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 30,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616277,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 31,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 60 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812041.616369,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 32,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"eliminate me\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812072.650063,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 33,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Socrates's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812072.650076,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 34,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Socrates: 60 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812072.650274,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 35,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Socrates's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.6638489,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 36,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Socrates: I agree, dear advocate, that work-life balance is a challenge that transcends the confines of remote work. However, might it be that the boundary between work and life becomes especially blurred when both occur within the same physical space? \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nAs for the potential of remote work to reduce inequalities, this is indeed a tantalizing prospect. Yet, we must ask ourselves: does the shift to remote work not risk creating a new form of inequality? Those with access to technology, stable inte...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.664929,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 37,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Advocate's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.664972,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 38,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Advocate: 59 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812083.6655931,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 39,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ö†Ô∏è Advocate's response was truncated due to length\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679034,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 40,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Advocate: Socrates, I appreciate your thoughtful concerns about blurring boundaries and potential inequalities. However, I would argue that these are challenges to be managed, not insurmountable barriers.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nIn terms of blurred boundaries, it's crucial to set up remote work policies that respect employees' personal time and create a distinction between work and home life. Companies like Buffer have already demonstrated that this is possible by implementing 'no-work weekends' and mandatory vacation...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679281,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 41,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé§ Human_1's turn for response (60s)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679292,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 42,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1: 60 seconds remaining\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812094.679415,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 43,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"sender\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚è∞ Human_1 exceeded time limit. Warning 1/3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 1749812154.746779,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_id\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 44,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"message_type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"chat\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extract.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extract.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 13781,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nExtract script to read all project files and create a JSON structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nReads all .py, .md, .yml, .yaml files and organizes them in a nested directory structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nRespects .gitignore patterns and skips virtual environments.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport datetime\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nimport fnmatch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom typing import Dict, Any, Set, List\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef parse_gitignore(gitignore_path: Path) -> List[str]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Parse .gitignore file and return list of patterns.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    patterns = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if gitignore_path.exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with open(gitignore_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                for line in f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    line = line.strip()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Skip empty lines and comments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if line and not line.startswith('#'):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        patterns.append(line)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Warning: Could not read .gitignore: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return patterns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef is_ignored_by_gitignore(file_path: Path, root_path: Path, gitignore_patterns: List[str]) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if file is ignored by .gitignore patterns.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get relative path from root\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        relative_path = file_path.relative_to(root_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        path_str = str(relative_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        path_parts = relative_path.parts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for pattern in gitignore_patterns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            # Handle different gitignore pattern types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if pattern.endswith('/'):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Directory pattern\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                pattern = pattern.rstrip('/')\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            elif '/' in pattern:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Path pattern\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if fnmatch.fnmatch(path_str, pattern):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Filename pattern\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if fnmatch.fnmatch(file_path.name, pattern):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Also check if any parent directory matches\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if any(fnmatch.fnmatch(part, pattern) for part in path_parts):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except ValueError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Path is not relative to root\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except Exception:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Any other error, don't ignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        pass\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef should_include_file(file_path: Path) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if file should be included based on extension.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    allowed_extensions = {'.py', '.md', '.yml', '.yaml', '.txt', '.json', '.toml', '.cfg', '.ini'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return file_path.suffix.lower() in allowed_extensions\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef should_skip_directory(dir_name: str) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if directory should be skipped (common build/cache directories).\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    skip_dirs = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '__pycache__',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.git',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.pytest_cache',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'node_modules',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.venv',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'venv',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'env',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.env',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'ENV',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'env.bak',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'venv.bak',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'dist',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'build',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.idea',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.vscode',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'htmlcov',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.coverage',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.mypy_cache',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.tox',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.cache',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'eggs',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '*.egg-info',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.eggs',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'lib',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'lib64',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'parts',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'sdist',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'var',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'wheels',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'share/python-wheels',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '*.egg-info/',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.installed.cfg',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '*.egg',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'MANIFEST',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        '.DS_Store',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'Thumbs.db'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return dir_name in skip_dirs\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef is_virtual_environment(dir_path: Path) -> bool:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if directory is a virtual environment.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    venv_indicators = [\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'pyvenv.cfg',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'Scripts/activate',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'bin/activate',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'Scripts/python.exe',\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        'bin/python'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for indicator in venv_indicators:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if (dir_path / indicator).exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Check for common venv directory names\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    venv_names = {'venv', '.venv', 'env', '.env', 'ENV', 'virtualenv'}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if dir_path.name in venv_names:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return False\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef read_file_content(file_path: Path) -> str:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Read file content safely.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with open(file_path, 'r', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return f.read()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except UnicodeDecodeError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            with open(file_path, 'r', encoding='latin-1') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                return f.read()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Error reading file: {e}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"[Error reading file: {e}]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef extract_directory_structure(root_path: Path, base_path: Path = None, gitignore_patterns: List[str] = None) -> Dict[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Recursively extract directory structure and file contents.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Args:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        root_path: Path to extract from\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_path: Base path for relative calculations (optional)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        gitignore_patterns: List of gitignore patterns to respect\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    Returns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        Dictionary with nested structure representing directories and files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if base_path is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        base_path = root_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if gitignore_patterns is None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        gitignore_patterns = []\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    structure = {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Ensure we have a Path object\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not isinstance(root_path, Path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            root_path = Path(root_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not isinstance(base_path, Path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            base_path = Path(base_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Check if path exists and is directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not root_path.exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Path does not exist: {root_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if not root_path.is_dir():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            return {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Path is not a directory: {root_path}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get all items in directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        items = list(root_path.iterdir())\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        items.sort(key=lambda x: (x.is_file(), x.name.lower()))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        for item in items:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Check if item is ignored by gitignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if is_ignored_by_gitignore(item, base_path, gitignore_patterns):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Skip hidden files except specific ones\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if item.name.startswith('.') and item.name not in {'.env.example', '.gitignore', '.gitattributes'}:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                if item.is_dir():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Skip certain directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if should_skip_directory(item.name):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Skip virtual environments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if is_virtual_environment(item):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Recursively process subdirectories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    substructure = extract_directory_structure(item, base_path, gitignore_patterns)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if substructure:  # Only add if not empty\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        structure[item.name] = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": substructure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                elif item.is_file():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    # Only include certain file types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    if should_include_file(item):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        file_content = read_file_content(item)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            relative_path = str(item.relative_to(base_path))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        except ValueError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            relative_path = str(item)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        structure[item.name] = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": relative_path,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": item.suffix,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": len(file_content),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": file_content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except PermissionError:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                structure[f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error_{item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Permission denied accessing: {item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                structure[f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error_{item.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing {item.name}: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except PermissionError as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        structure[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Permission denied: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        structure[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] = f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing directory: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef count_items_recursive(structure: Dict[str, Any]) -> Dict[str, int]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Count files and directories recursively.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    counts = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for name, item in structure.items():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if name.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if isinstance(item, dict):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                sub_counts = count_items_recursive(item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}))\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"]\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                # Merge file types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                for ext, count in sub_counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].items():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                    counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][ext] = counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(ext, 0) + count\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            elif item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                ext = item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"][ext] = counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"].get(ext, 0) + 1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"] += item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return counts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef create_project_metadata(root_path: Path, structure: Dict[str, Any]) -> Dict[str, Any]:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Create metadata about the project.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    counts = count_items_recursive(structure)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    metadata = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": root_path.name,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extraction_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": datetime.datetime.now().isoformat(),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"root_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": str(root_path.absolute()),\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": counts[\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"],\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"respects_gitignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": True,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"skips_virtual_environments\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": True\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    return metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef preview_structure(structure: Dict[str, Any], indent: int = 0) -> None:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Preview the extracted structure.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    prefix = \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * indent\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    for name, item in structure.items():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if name.startswith(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            continue\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if isinstance(item, dict):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            if item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{prefix}üìÅ {name}/\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                preview_structure(item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"contents\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", {}), indent + 1)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            elif item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\") == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                size = item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", 0)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                ext = item.get(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\", \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{prefix}üìÑ {name} ({size:,} chars, {ext})\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ndef main():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main extraction function.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Get current directory or specified directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    import sys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if len(sys.argv) > 1:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        root_dir = Path(sys.argv[1])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        root_dir = Path.cwd()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Ensure we have a Path object\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not isinstance(root_dir, Path):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        root_dir = Path(root_dir)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not root_dir.exists():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: Directory {root_dir} does not exist\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if not root_dir.is_dir():\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error: {root_dir} is not a directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        return\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîç Extracting project structure from: {root_dir.absolute()}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìÅ Reading all .py, .md, .yml, .yaml, .txt, .json files...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Parse .gitignore if it exists\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    gitignore_path = root_dir / '.gitignore'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    gitignore_patterns = parse_gitignore(gitignore_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if gitignore_patterns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã Found .gitignore with {len(gitignore_patterns)} patterns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã No .gitignore found or empty\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üö´ Skipping virtual environments and build directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Extract the directory structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Create metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        metadata = create_project_metadata(root_dir, structure)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Create project data\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        project_data = {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": metadata,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Output filename\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        output_file = root_dir / \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Write JSON file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        with open(output_file, 'w', encoding='utf-8') as f:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            json.dump(project_data, f, indent=2, ensure_ascii=False)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Extraction complete!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìä Statistics:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Total files: {metadata['total_files']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Total directories: {metadata['total_directories']}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Total size: {metadata['total_size']:,} characters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìÑ Output saved to: {output_file}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Show file type breakdown\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if metadata['file_types']:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüìã File type breakdown:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            for ext, count in sorted(metadata['file_types'].items()):\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                ext_name = ext if ext else \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"(no extension)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n                print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ {ext_name}: {count} files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå Error during extraction: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        import traceback\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        traceback.print_exc()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    # Add preview option\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    import sys\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    if \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--preview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" in sys.argv:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        sys.argv.remove(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"--preview\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Get directory\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if len(sys.argv) > 1:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            root_dir = Path(sys.argv[1])\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            root_dir = Path.cwd()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        # Parse .gitignore\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        gitignore_path = root_dir / '.gitignore'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        gitignore_patterns = parse_gitignore(gitignore_path)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üîç Preview of project structure: {root_dir.name}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        if gitignore_patterns:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n            print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã Respecting .gitignore with {len(gitignore_patterns)} patterns\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 50)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        structure = extract_directory_structure(root_dir, gitignore_patterns=gitignore_patterns)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        preview_structure(structure)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    else:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n        main()\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project.json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".json\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 384,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"metadata\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"project_name\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"AIMafia\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extraction_timestamp\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"2025-06-13T13:34:56.112659\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"root_path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"/Users/voicutomut/Documents/GitHub/AIMafia\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_files\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_directories\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file_types\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {},\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"total_size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  },\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"structure\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"_error\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Error processing directory: 'PosixPath' object has no attribute 'is_directory'\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 2480,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# AI Jubilee Debate System\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nA real-time debate platform where AI bots and humans can engage in structured debates with automated moderation, voting, and live streaming capabilities.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Features\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Multi-participant debates** with AI bots and human participants\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Automated moderation** with configurable rules and timeouts\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Real-time voting system** with vote tallying\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Shared chat log** with timestamps and message ordering\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Live streaming support** via WebSocket\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Configurable debate topics** and bot personalities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Extensible architecture** for adding new AI models and clients\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Quick Start\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. **Install dependencies:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   pip install -r requirements.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. **Configure the system:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   Edit `config.yaml` to set up your debate parameters, API keys, and bot configurations.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. **Run a debate session:**\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   python -m app.main\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Architecture\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe system consists of several key components:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Moderator**: Manages debate flow, enforces rules, and coordinates voting\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Bot Clients**: AI-powered participants using various language models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Human Clients**: Interface for human participants (CLI/web)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Chat Log**: Centralized message queue with timestamps\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Voting System**: Handles vote collection and tallying\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- **Streaming Server**: Optional live broadcast functionality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nThe `config.yaml` file allows you to customize:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Debate topics and formats\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- AI bot personalities and models\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Timeout settings and rules\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Voting parameters\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- Streaming options\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Usage Examples\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Starting a Standard Debate\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.main import start_debate_session\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.moderator import Moderator\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Initialize with 2 AI bots and 1 human participant\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nsession = start_debate_session(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The impact of AI on society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    ai_bots=2,\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    human_participants=1\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n### Custom Bot Configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfrom app.bot_client import BotClient\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Create a bot with specific personality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosopher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"thoughtful and analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Contributing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n1. Fork the repository\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n2. Create a feature branch\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n3. Add tests for new functionality\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n4. Run the test suite: `python -m pytest tests/`\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n5. Submit a pull request\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## Documentation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- [Architecture Details](docs/architecture.md)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- [Usage Guide](docs/usage.md)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n- [API Reference](docs/api_reference.md)\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n## License\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nMIT License - see LICENSE file for details.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"requirements.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"requirements.txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 527,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"# Core dependencies\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nopenai>=1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nanthropic>=0.3.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npyyaml>=6.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nasyncio-mqtt>=0.11.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Environment and configuration\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython-dotenv>=1.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Web framework and streaming\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nfastapi>=0.104.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nwebsockets>=11.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nuvicorn>=0.24.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Data handling\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npydantic>=2.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npython-json-logger>=2.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Testing\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npytest>=7.4.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npytest-asyncio>=0.21.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\npytest-mock>=3.11.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Utilities\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nclick>=8.1.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nrich>=13.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\naiofiles>=23.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Optional AI model providers\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntransformers>=4.30.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ntorch>=2.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n# Development tools\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nblack>=23.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nflake8>=6.0.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nmypy>=1.5.0\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    },\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": {\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"run_debate.py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": 0,\\\\\\\\\\\\\\\\n      \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    }\\\\\\\\\\\\\\\\n  }\\\\\\\\\\\\\\\\n}\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"README.md\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".md\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 2480,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# AI Jubilee Debate System\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nA real-time debate platform where AI bots and humans can engage in structured debates with automated moderation, voting, and live streaming capabilities.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Features\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- **Multi-participant debates** with AI bots and human participants\\\\\\\\\\\\\\\\n- **Automated moderation** with configurable rules and timeouts\\\\\\\\\\\\\\\\n- **Real-time voting system** with vote tallying\\\\\\\\\\\\\\\\n- **Shared chat log** with timestamps and message ordering\\\\\\\\\\\\\\\\n- **Live streaming support** via WebSocket\\\\\\\\\\\\\\\\n- **Configurable debate topics** and bot personalities\\\\\\\\\\\\\\\\n- **Extensible architecture** for adding new AI models and clients\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Quick Start\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. **Install dependencies:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   pip install -r requirements.txt\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n2. **Configure the system:**\\\\\\\\\\\\\\\\n   Edit `config.yaml` to set up your debate parameters, API keys, and bot configurations.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n3. **Run a debate session:**\\\\\\\\\\\\\\\\n   ```bash\\\\\\\\\\\\\\\\n   python -m app.main\\\\\\\\\\\\\\\\n   ```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Architecture\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe system consists of several key components:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- **Moderator**: Manages debate flow, enforces rules, and coordinates voting\\\\\\\\\\\\\\\\n- **Bot Clients**: AI-powered participants using various language models\\\\\\\\\\\\\\\\n- **Human Clients**: Interface for human participants (CLI/web)\\\\\\\\\\\\\\\\n- **Chat Log**: Centralized message queue with timestamps\\\\\\\\\\\\\\\\n- **Voting System**: Handles vote collection and tallying\\\\\\\\\\\\\\\\n- **Streaming Server**: Optional live broadcast functionality\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Configuration\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nThe `config.yaml` file allows you to customize:\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- Debate topics and formats\\\\\\\\\\\\\\\\n- AI bot personalities and models\\\\\\\\\\\\\\\\n- Timeout settings and rules\\\\\\\\\\\\\\\\n- Voting parameters\\\\\\\\\\\\\\\\n- Streaming options\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Usage Examples\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Starting a Standard Debate\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nfrom app.main import start_debate_session\\\\\\\\\\\\\\\\nfrom app.moderator import Moderator\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Initialize with 2 AI bots and 1 human participant\\\\\\\\\\\\\\\\nsession = start_debate_session(\\\\\\\\\\\\\\\\n    topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"The impact of AI on society\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    ai_bots=2,\\\\\\\\\\\\\\\\n    human_participants=1\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n### Custom Bot Configuration\\\\\\\\\\\\\\\\n```python\\\\\\\\\\\\\\\\nfrom app.bot_client import BotClient\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Create a bot with specific personality\\\\\\\\\\\\\\\\nbot = BotClient(\\\\\\\\\\\\\\\\n    name=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Philosopher\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    model=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    personality=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"thoughtful and analytical\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n    stance=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n)\\\\\\\\\\\\\\\\n```\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Contributing\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. Fork the repository\\\\\\\\\\\\\\\\n2. Create a feature branch\\\\\\\\\\\\\\\\n3. Add tests for new functionality\\\\\\\\\\\\\\\\n4. Run the test suite: `python -m pytest tests/`\\\\\\\\\\\\\\\\n5. Submit a pull request\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## Documentation\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n- [Architecture Details](docs/architecture.md)\\\\\\\\\\\\\\\\n- [Usage Guide](docs/usage.md)\\\\\\\\\\\\\\\\n- [API Reference](docs/api_reference.md)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n## License\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nMIT License - see LICENSE file for details.\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"requirements.txt\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"requirements.txt\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".txt\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 527,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"# Core dependencies\\\\\\\\\\\\\\\\nopenai>=1.0.0\\\\\\\\\\\\\\\\nanthropic>=0.3.0\\\\\\\\\\\\\\\\npyyaml>=6.0\\\\\\\\\\\\\\\\nasyncio-mqtt>=0.11.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Environment and configuration\\\\\\\\\\\\\\\\npython-dotenv>=1.0.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Web framework and streaming\\\\\\\\\\\\\\\\nfastapi>=0.104.0\\\\\\\\\\\\\\\\nwebsockets>=11.0\\\\\\\\\\\\\\\\nuvicorn>=0.24.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Data handling\\\\\\\\\\\\\\\\npydantic>=2.0.0\\\\\\\\\\\\\\\\npython-json-logger>=2.0.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Testing\\\\\\\\\\\\\\\\npytest>=7.4.0\\\\\\\\\\\\\\\\npytest-asyncio>=0.21.0\\\\\\\\\\\\\\\\npytest-mock>=3.11.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Utilities\\\\\\\\\\\\\\\\nclick>=8.1.0\\\\\\\\\\\\\\\\nrich>=13.0.0\\\\\\\\\\\\\\\\naiofiles>=23.0.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Optional AI model providers\\\\\\\\\\\\\\\\ntransformers>=4.30.0\\\\\\\\\\\\\\\\ntorch>=2.0.0\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Development tools\\\\\\\\\\\\\\\\nblack>=23.0.0\\\\\\\\\\\\\\\\nflake8>=6.0.0\\\\\\\\\\\\\\\\nmypy>=1.5.0\\\\\\\\\\\\\\\"\\\\\\\\n    },\\\\\\\\n    \\\\\\\\\\\\\\\"run_debate.py\\\\\\\\\\\\\\\": {\\\\\\\\n      \\\\\\\\\\\\\\\"type\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"file\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"path\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"run_debate.py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"extension\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\".py\\\\\\\\\\\\\\\",\\\\\\\\n      \\\\\\\\\\\\\\\"size\\\\\\\\\\\\\\\": 3169,\\\\\\\\n      \\\\\\\\\\\\\\\"content\\\\\\\\\\\\\\\": \\\\\\\\\\\\\\\"#!/usr/bin/env python3\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nSimple script to run AI Jubilee Debate with better error handling.\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nimport asyncio\\\\\\\\\\\\\\\\nimport sys\\\\\\\\\\\\\\\\nimport os\\\\\\\\\\\\\\\\nfrom pathlib import Path\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n# Add the project root to the Python path\\\\\\\\\\\\\\\\nproject_root = Path(__file__).parent\\\\\\\\\\\\\\\\nsys.path.insert(0, str(project_root))\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nfrom dotenv import load_dotenv\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef check_environment():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Check if environment is properly set up.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    # Load .env file\\\\\\\\\\\\\\\\n    load_dotenv()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Check for required API keys\\\\\\\\\\\\\\\\n    openai_key = os.getenv('OPENAI_API_KEY')\\\\\\\\\\\\\\\\n    anthropic_key = os.getenv('ANTHROPIC_API_KEY')\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not openai_key:\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå OPENAI_API_KEY not found in environment variables.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Please add it to your .env file:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   OPENAI_API_KEY=sk-your-key-here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    if not anthropic_key:\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå ANTHROPIC_API_KEY not found in environment variables.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Please add it to your .env file:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ANTHROPIC_API_KEY=sk-ant-your-key-here\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        return False\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚úÖ Environment variables loaded successfully\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    return True\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nasync def run_debate_safely():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Run debate with proper error handling.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        from app.main import start_debate_session\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠ Starting AI Jubilee Debate System...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"ü§ñ AUTONOMOUS MODE: Bots monitor and decide when to speak!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 60)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üìã How it works:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Bots continuously monitor the conversation\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ They decide when they feel compelled to respond\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Humans can speak at any time during discussion\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ More natural, organic debate flow!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   ‚Ä¢ Full conversation history available to all bots\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 60)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        await start_debate_session(\\\\\\\\\\\\\\\\n            topic=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Remote work is the future of employment\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\n            ai_bots=3,  # More bots for better autonomous dynamics\\\\\\\\\\\\\\\\n            human_participants=1\\\\\\\\\\\\\\\\n        )\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    except KeyboardInterrupt:\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüõë Debate interrupted by user. Goodbye!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nDebug information:\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        import traceback\\\\\\\\\\\\\\\\n        traceback.print_exc()\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n        # Try to save any available transcript\\\\\\\\\\\\\\\\n        try:\\\\\\\\\\\\\\\\n            from app.chat_log import ChatLog\\\\\\\\\\\\\\\\n            print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüíæ Attempting to save error transcript...\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n            # This would require access to the chat_log instance\\\\\\\\\\\\\\\\n        except:\\\\\\\\\\\\\\\\n            pass\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\ndef main():\\\\\\\\\\\\\\\\n    \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"Main entry point.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"üé≠ AI Jubilee Debate System\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n    print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\" * 30)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Check environment setup\\\\\\\\\\\\\\\\n    if not check_environment():\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüîß Please fix the environment setup and try again.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        sys.exit(1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Check config file\\\\\\\\\\\\\\\\n    if not Path(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\").exists():\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"‚ùå config.yaml not found!\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        print(\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"   Please make sure you're running from the project root directory.\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        sys.exit(1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n    # Run the debate\\\\\\\\\\\\\\\\n    try:\\\\\\\\\\\\\\\\n        asyncio.run(run_debate_safely())\\\\\\\\\\\\\\\\n    except Exception as e:\\\\\\\\\\\\\\\\n        print(f\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\nüí• Fatal error: {e}\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\\\\\\\\\\\\\\\\n        sys.exit(1)\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\n    main()\\\\\\\\\\\\\\\"\\\\\\\\n    }\\\\\\\\n  }\\\\\\\\n}\\\\\\\"\\\\n    },\\\\n    \\\\\\\"README.md\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"README.md\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".md\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 2672,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"# AI Jubilee Debate System\\\\\\\\n\\\\\\\\nA real-time debate platform where AI bots and humans can engage in structured debates with automated moderation, voting, and live streaming capabilities.\\\\\\\\n\\\\\\\\n## Features\\\\\\\\n\\\\\\\\n- **Multi-participant debates** with AI bots and human participants\\\\\\\\n- **Automated moderation** with configurable rules and timeouts\\\\\\\\n- **Real-time voting system** with vote tallying\\\\\\\\n- **Shared chat log** with timestamps and message ordering\\\\\\\\n- **Live streaming support** via WebSocket\\\\\\\\n- **Configurable debate topics** and bot personalities\\\\\\\\n- **Extensible architecture** for adding new AI models and clients\\\\\\\\n\\\\\\\\n## Quick Start\\\\\\\\n\\\\\\\\n1. **Install dependencies:**\\\\\\\\n   ```bash\\\\\\\\n   pip install -r requirements.txt\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n2. **Configure the system:**\\\\\\\\n   Edit `config.yaml` to set up your debate parameters, API keys, and bot configurations.\\\\\\\\n\\\\\\\\n3. **Run a debate session:**\\\\\\\\n   ```bash\\\\\\\\n   python -m app.main\\\\\\\\n   ```\\\\\\\\n\\\\\\\\n## Architecture\\\\\\\\n\\\\\\\\nThe system consists of several key components:\\\\\\\\n\\\\\\\\n- **Moderator**: Manages debate flow, enforces rules, and coordinates voting\\\\\\\\n- **Bot Clients**: AI-powered participants using various language models\\\\\\\\n- **Human Clients**: Interface for human participants (CLI/web)\\\\\\\\n- **Chat Log**: Centralized message queue with timestamps\\\\\\\\n- **Voting System**: Handles vote collection and tallying\\\\\\\\n- **Streaming Server**: Optional live broadcast functionality\\\\\\\\n\\\\\\\\n## Configuration\\\\\\\\n\\\\\\\\nThe `config.yaml` file allows you to customize:\\\\\\\\n\\\\\\\\n- Debate topics and formats\\\\\\\\n- AI bot personalities and models\\\\\\\\n- Timeout settings and rules\\\\\\\\n- Voting parameters\\\\\\\\n- Streaming options\\\\\\\\n\\\\\\\\n## Usage Examples\\\\\\\\n\\\\\\\\n### Starting a Standard Debate\\\\\\\\n```python\\\\\\\\nfrom app.main import start_debate_session\\\\\\\\nfrom app.moderator import Moderator\\\\\\\\n\\\\\\\\n# Initialize with 2 AI bots and 1 human participant\\\\\\\\nsession = start_debate_session(\\\\\\\\n    topic=\\\\\\\\\\\\\\\"The impact of AI on society\\\\\\\\\\\\\\\",\\\\\\\\n    ai_bots=2,\\\\\\\\n    human_participants=1\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n### Custom Bot Configuration\\\\\\\\n```python\\\\\\\\nfrom app.bot_client import BotClient\\\\\\\\n\\\\\\\\n# Create a bot with specific personality\\\\\\\\nbot = BotClient(\\\\\\\\n    name=\\\\\\\\\\\\\\\"Philosopher\\\\\\\\\\\\\\\",\\\\\\\\n    model=\\\\\\\\\\\\\\\"gpt-4\\\\\\\\\\\\\\\",\\\\\\\\n    personality=\\\\\\\\\\\\\\\"thoughtful and analytical\\\\\\\\\\\\\\\",\\\\\\\\n    stance=\\\\\\\\\\\\\\\"neutral\\\\\\\\\\\\\\\"\\\\\\\\n)\\\\\\\\n```\\\\\\\\n\\\\\\\\n## Contributing\\\\\\\\n\\\\\\\\n1. Fork the repository\\\\\\\\n2. Create a feature branch\\\\\\\\n3. Add tests for new functionality\\\\\\\\n4. Run the test suite: `python -m pytest tests/`\\\\\\\\n5. Submit a pull request\\\\\\\\n\\\\\\\\n## Documentation\\\\\\\\n\\\\\\\\n- [Architecture Details](docs/architecture.md)\\\\\\\\n- [Usage Guide](docs/usage.md)\\\\\\\\n- [API Reference](docs/api_reference.md)\\\\\\\\n\\\\\\\\n## Arhitecture :\\\\\\\\nChat Log ‚Üê All Participants Monitor This\\\\\\\\n    ‚Üì\\\\\\\\n[Bot1] [Bot2] [Bot3] [Moderator Bot] [Human] \\\\\\\\n    ‚Üì\\\\\\\\nAll decide independently when to speak\\\\\\\\n    ‚Üì\\\\\\\\nPost messages back to Chat Log\\\\\\\\n## License\\\\\\\\n\\\\\\\\nMIT License - see LICENSE file for details.\\\\\\\"\\\\n    },\\\\n    \\\\\\\"requirements.txt\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"requirements.txt\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".txt\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 527,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"# Core dependencies\\\\\\\\nopenai>=1.0.0\\\\\\\\nanthropic>=0.3.0\\\\\\\\npyyaml>=6.0\\\\\\\\nasyncio-mqtt>=0.11.0\\\\\\\\n\\\\\\\\n# Environment and configuration\\\\\\\\npython-dotenv>=1.0.0\\\\\\\\n\\\\\\\\n# Web framework and streaming\\\\\\\\nfastapi>=0.104.0\\\\\\\\nwebsockets>=11.0\\\\\\\\nuvicorn>=0.24.0\\\\\\\\n\\\\\\\\n# Data handling\\\\\\\\npydantic>=2.0.0\\\\\\\\npython-json-logger>=2.0.0\\\\\\\\n\\\\\\\\n# Testing\\\\\\\\npytest>=7.4.0\\\\\\\\npytest-asyncio>=0.21.0\\\\\\\\npytest-mock>=3.11.0\\\\\\\\n\\\\\\\\n# Utilities\\\\\\\\nclick>=8.1.0\\\\\\\\nrich>=13.0.0\\\\\\\\naiofiles>=23.0.0\\\\\\\\n\\\\\\\\n# Optional AI model providers\\\\\\\\ntransformers>=4.30.0\\\\\\\\ntorch>=2.0.0\\\\\\\\n\\\\\\\\n# Development tools\\\\\\\\nblack>=23.0.0\\\\\\\\nflake8>=6.0.0\\\\\\\\nmypy>=1.5.0\\\\\\\"\\\\n    },\\\\n    \\\\\\\"run_debate.py\\\\\\\": {\\\\n      \\\\\\\"type\\\\\\\": \\\\\\\"file\\\\\\\",\\\\n      \\\\\\\"path\\\\\\\": \\\\\\\"run_debate.py\\\\\\\",\\\\n      \\\\\\\"extension\\\\\\\": \\\\\\\".py\\\\\\\",\\\\n      \\\\\\\"size\\\\\\\": 7325,\\\\n      \\\\\\\"content\\\\\\\": \\\\\\\"#!/usr/bin/env python3\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\nAutonomous AI Jubilee Debate launcher with full autonomous capabilities.\\\\\\\\n\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\nimport asyncio\\\\\\\\nimport sys\\\\\\\\nimport os\\\\\\\\nfrom pathlib import Path\\\\\\\\n\\\\\\\\n# Add the project root to the Python path\\\\\\\\nproject_root = Path(__file__).parent\\\\\\\\nsys.path.insert(0, str(project_root))\\\\\\\\n\\\\\\\\nfrom dotenv import load_dotenv\\\\\\\\n\\\\\\\\n\\\\\\\\ndef check_environment():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Check if environment is properly set up.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    load_dotenv()\\\\\\\\n\\\\\\\\n    openai_key = os.getenv('OPENAI_API_KEY')\\\\\\\\n    anthropic_key = os.getenv('ANTHROPIC_API_KEY')\\\\\\\\n\\\\\\\\n    if not openai_key:\\\\\\\\n        print(\\\\\\\\\\\\\\\"‚ùå OPENAI_API_KEY not found in environment variables.\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   Please add it to your .env file:\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   OPENAI_API_KEY=sk-your-key-here\\\\\\\\\\\\\\\")\\\\\\\\n        return False\\\\\\\\n\\\\\\\\n    if not anthropic_key:\\\\\\\\n        print(\\\\\\\\\\\\\\\"‚ö†Ô∏è ANTHROPIC_API_KEY not found (optional)\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   Add it to .env file if you want to use Anthropic models:\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ANTHROPIC_API_KEY=sk-ant-your-key-here\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    print(\\\\\\\\\\\\\\\"‚úÖ Environment variables loaded successfully\\\\\\\\\\\\\\\")\\\\\\\\n    return True\\\\\\\\n\\\\\\\\n\\\\\\\\nasync def run_debate_safely(web_mode=False):\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Run truly autonomous debate with AI moderator.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    try:\\\\\\\\n        # Import here to avoid import errors\\\\\\\\n        from app.moderator import Moderator\\\\\\\\n        from app.bot_client import BotClient\\\\\\\\n        from app.human_client import HumanClient\\\\\\\\n        from app.chat_log import ChatLog\\\\\\\\n        from app.voting import VotingSystem\\\\\\\\n        from app.utils import load_config\\\\\\\\n\\\\\\\\n        print(\\\\\\\\\\\\\\\"üé≠ Starting AI Jubilee Debate System...\\\\\\\\\\\\\\\")\\\\\\\\n        if web_mode:\\\\\\\\n            print(\\\\\\\\\\\\\\\"üåê WEB MODE: Starting with web interface\\\\\\\\\\\\\\\")\\\\\\\\n            print(\\\\\\\\\\\\\\\"üîó Access at: http://localhost:8080\\\\\\\\\\\\\\\")\\\\\\\\n        else:\\\\\\\\n            print(\\\\\\\\\\\\\\\"ü§ñ AUTONOMOUS MODE: All participants (including moderator) monitor and decide when to speak!\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\" * 80)\\\\\\\\n\\\\\\\\n        print(\\\\\\\\\\\\\\\"üìã How the new system works:\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ‚Ä¢ ALL participants (bots + moderator) continuously monitor the conversation\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ‚Ä¢ They ALL decide independently when they feel compelled to respond\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ‚Ä¢ Humans can type messages at ANY TIME during discussion\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ‚Ä¢ Completely organic conversation flow - no turn-taking!\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ‚Ä¢ Moderator acts like another intelligent participant\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   ‚Ä¢ Full conversation history available to everyone\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\" * 80)\\\\\\\\n\\\\\\\\n        # Load configuration\\\\\\\\n        config = load_config(\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Override interface mode if web_mode is requested\\\\\\\\n        if web_mode:\\\\\\\\n            config['interface'] = config.get('interface', {})\\\\\\\\n            config['interface']['mode'] = 'web'\\\\\\\\n            config['streaming'] = config.get('streaming', {})\\\\\\\\n            config['streaming']['enabled'] = True\\\\\\\\n\\\\\\\\n        # Initialize components\\\\\\\\n        chat_log = ChatLog()\\\\\\\\n        voting_system = VotingSystem(config.get('voting', {}))\\\\\\\\n\\\\\\\\n        # Create bot clients\\\\\\\\n        bot_clients = []\\\\\\\\n        bot_configs = config.get('bots', [])\\\\\\\\n\\\\\\\\n        for i, bot_config in enumerate(bot_configs):\\\\\\\\n            try:\\\\\\\\n                bot = BotClient(\\\\\\\\n                    name=bot_config['name'],\\\\\\\\n                    model=bot_config['model'],\\\\\\\\n                    provider=bot_config['provider'],\\\\\\\\n                    personality=bot_config['personality'],\\\\\\\\n                    stance=bot_config['stance'],\\\\\\\\n                    api_key=config['api_keys'].get(bot_config['provider'])\\\\\\\\n                )\\\\\\\\n                bot_clients.append(bot)\\\\\\\\n                print(f\\\\\\\\\\\\\\\"‚úÖ Created bot: {bot_config['name']} ({bot_config['stance']})\\\\\\\\\\\\\\\")\\\\\\\\n            except Exception as e:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"‚ùå Failed to create bot {bot_config.get('name', 'Unknown')}: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        # Create human clients\\\\\\\\n        human_clients = []\\\\\\\\n        interface_config = config.get('interface', {})\\\\\\\\n\\\\\\\\n        try:\\\\\\\\n            human = HumanClient(\\\\\\\\n                name=\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\",\\\\\\\\n                config=interface_config\\\\\\\\n            )\\\\\\\\n            human_clients.append(human)\\\\\\\\n            print(f\\\\\\\\\\\\\\\"‚úÖ Created human client: {human.name}\\\\\\\\\\\\\\\")\\\\\\\\n        except Exception as e:\\\\\\\\n            print(f\\\\\\\\\\\\\\\"‚ùå Failed to create human client: {e}\\\\\\\\\\\\\\\")\\\\\\\\n            # Try alternative constructor\\\\\\\\n            try:\\\\\\\\n                human = HumanClient(\\\\\\\\\\\\\\\"Human_1\\\\\\\\\\\\\\\", interface_config)\\\\\\\\n                human_clients.append(human)\\\\\\\\n                print(f\\\\\\\\\\\\\\\"‚úÖ Created human client (alternative): {human.name}\\\\\\\\\\\\\\\")\\\\\\\\n            except Exception as e2:\\\\\\\\n                print(f\\\\\\\\\\\\\\\"‚ùå Alternative constructor also failed: {e2}\\\\\\\\\\\\\\\")\\\\\\\\n                return\\\\\\\\n\\\\\\\\n        # Initialize moderator with AI capabilities\\\\\\\\n        moderator = Moderator(\\\\\\\\n            topic=\\\\\\\\\\\\\\\"Remote work is the future of employment\\\\\\\\\\\\\\\",\\\\\\\\n            participants=bot_clients + human_clients,\\\\\\\\n            chat_log=chat_log,\\\\\\\\n            voting_system=voting_system,\\\\\\\\n            config=config.get('debate', {})\\\\\\\\n        )\\\\\\\\n\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüéØ Topic: Remote work is the future of employment\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"üé≠ AI Moderator: {config.get('moderator', {}).get('name', 'Moderator')} (also autonomous!)\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        if web_mode:\\\\\\\\n            print(\\\\\\\\\\\\\\\"üåê Starting web interface...\\\\\\\\\\\\\\\")\\\\\\\\n            # Start streaming server if in web mode\\\\\\\\n            from app.streaming import StreamingServer\\\\\\\\n            streaming_server = StreamingServer(\\\\\\\\n                chat_log=chat_log,\\\\\\\\n                voting_system=voting_system,\\\\\\\\n                config=config.get('streaming', {})\\\\\\\\n            )\\\\\\\\n            await streaming_server.start()\\\\\\\\n\\\\\\\\n        # Run the debate\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüöÄ Starting truly autonomous debate with AI moderator!\\\\\\\\\\\\\\\")\\\\\\\\n        await moderator.run_debate()\\\\\\\\n\\\\\\\\n    except KeyboardInterrupt:\\\\\\\\n        print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nüõë Debate interrupted by user. Goodbye!\\\\\\\\\\\\\\\")\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nDebug information:\\\\\\\\\\\\\\\")\\\\\\\\n        import traceback\\\\\\\\n        traceback.print_exc()\\\\\\\\n\\\\\\\\n\\\\\\\\ndef main():\\\\\\\\n    \\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"Main entry point.\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\n    print(\\\\\\\\\\\\\\\"üé≠ AI Jubilee Debate System - Autonomous Mode\\\\\\\\\\\\\\\")\\\\\\\\n    print(\\\\\\\\\\\\\\\"=\\\\\\\\\\\\\\\" * 50)\\\\\\\\n\\\\\\\\n    # Check for web mode flag\\\\\\\\n    web_mode = '--web' in sys.argv\\\\\\\\n    if web_mode:\\\\\\\\n        print(\\\\\\\\\\\\\\\"üåê Web mode requested\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Check environment setup\\\\\\\\n    if not check_environment():\\\\\\\\n        print(\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüîß Please fix the environment setup and try again.\\\\\\\\\\\\\\\")\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\n    # Check config file\\\\\\\\n    if not Path(\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\").exists():\\\\\\\\n        print(\\\\\\\\\\\\\\\"‚ùå config.yaml not found!\\\\\\\\\\\\\\\")\\\\\\\\n        print(\\\\\\\\\\\\\\\"   Please make sure you're running from the project root directory.\\\\\\\\\\\\\\\")\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\n    # Show moderator configuration\\\\\\\\n    try:\\\\\\\\n        from app.utils import load_config\\\\\\\\n        config = load_config(\\\\\\\\\\\\\\\"config.yaml\\\\\\\\\\\\\\\")\\\\\\\\n        moderator_config = config.get('moderator', {})\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüé≠ AI Moderator Configuration:\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   Name: {moderator_config.get('name', 'Moderator')}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   Model: {moderator_config.get('model', 'gpt-3.5-turbo')}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   Provider: {moderator_config.get('provider', 'openai')}\\\\\\\\\\\\\\\")\\\\\\\\n        print(f\\\\\\\\\\\\\\\"   Personality: {moderator_config.get('personality', 'Professional facilitator')[:50]}...\\\\\\\\\\\\\\\")\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"‚ö†Ô∏è Could not load moderator config: {e}\\\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    # Run the debate\\\\\\\\n    try:\\\\\\\\n        asyncio.run(run_debate_safely(web_mode))\\\\\\\\n    except Exception as e:\\\\\\\\n        print(f\\\\\\\\\\\\\\\"\\\\\\\\\\\\\\\\nüí• Fatal error: {e}\\\\\\\\\\\\\\\")\\\\\\\\n        sys.exit(1)\\\\\\\\n\\\\\\\\n\\\\\\\\nif __name__ == \\\\\\\\\\\\\\\"__main__\\\\\\\\\\\\\\\":\\\\\\\\n    main()\\\\\\\"\\\\n    }\\\\n  }\\\\n}\\\"\\n    },\\n    \\\"README.md\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"README.md\\\",\\n      \\\"extension\\\": \\\".md\\\",\\n      \\\"size\\\": 2672,\\n      \\\"content\\\": \\\"# AI Jubilee Debate System\\\\n\\\\nA real-time debate platform where AI bots and humans can engage in structured debates with automated moderation, voting, and live streaming capabilities.\\\\n\\\\n## Features\\\\n\\\\n- **Multi-participant debates** with AI bots and human participants\\\\n- **Automated moderation** with configurable rules and timeouts\\\\n- **Real-time voting system** with vote tallying\\\\n- **Shared chat log** with timestamps and message ordering\\\\n- **Live streaming support** via WebSocket\\\\n- **Configurable debate topics** and bot personalities\\\\n- **Extensible architecture** for adding new AI models and clients\\\\n\\\\n## Quick Start\\\\n\\\\n1. **Install dependencies:**\\\\n   ```bash\\\\n   pip install -r requirements.txt\\\\n   ```\\\\n\\\\n2. **Configure the system:**\\\\n   Edit `config.yaml` to set up your debate parameters, API keys, and bot configurations.\\\\n\\\\n3. **Run a debate session:**\\\\n   ```bash\\\\n   python -m app.main\\\\n   ```\\\\n\\\\n## Architecture\\\\n\\\\nThe system consists of several key components:\\\\n\\\\n- **Moderator**: Manages debate flow, enforces rules, and coordinates voting\\\\n- **Bot Clients**: AI-powered participants using various language models\\\\n- **Human Clients**: Interface for human participants (CLI/web)\\\\n- **Chat Log**: Centralized message queue with timestamps\\\\n- **Voting System**: Handles vote collection and tallying\\\\n- **Streaming Server**: Optional live broadcast functionality\\\\n\\\\n## Configuration\\\\n\\\\nThe `config.yaml` file allows you to customize:\\\\n\\\\n- Debate topics and formats\\\\n- AI bot personalities and models\\\\n- Timeout settings and rules\\\\n- Voting parameters\\\\n- Streaming options\\\\n\\\\n## Usage Examples\\\\n\\\\n### Starting a Standard Debate\\\\n```python\\\\nfrom app.main import start_debate_session\\\\nfrom app.moderator import Moderator\\\\n\\\\n# Initialize with 2 AI bots and 1 human participant\\\\nsession = start_debate_session(\\\\n    topic=\\\\\\\"The impact of AI on society\\\\\\\",\\\\n    ai_bots=2,\\\\n    human_participants=1\\\\n)\\\\n```\\\\n\\\\n### Custom Bot Configuration\\\\n```python\\\\nfrom app.bot_client import BotClient\\\\n\\\\n# Create a bot with specific personality\\\\nbot = BotClient(\\\\n    name=\\\\\\\"Philosopher\\\\\\\",\\\\n    model=\\\\\\\"gpt-4\\\\\\\",\\\\n    personality=\\\\\\\"thoughtful and analytical\\\\\\\",\\\\n    stance=\\\\\\\"neutral\\\\\\\"\\\\n)\\\\n```\\\\n\\\\n## Contributing\\\\n\\\\n1. Fork the repository\\\\n2. Create a feature branch\\\\n3. Add tests for new functionality\\\\n4. Run the test suite: `python -m pytest tests/`\\\\n5. Submit a pull request\\\\n\\\\n## Documentation\\\\n\\\\n- [Architecture Details](docs/architecture.md)\\\\n- [Usage Guide](docs/usage.md)\\\\n- [API Reference](docs/api_reference.md)\\\\n\\\\n## Arhitecture :\\\\nChat Log ‚Üê All Participants Monitor This\\\\n    ‚Üì\\\\n[Bot1] [Bot2] [Bot3] [Moderator Bot] [Human] \\\\n    ‚Üì\\\\nAll decide independently when to speak\\\\n    ‚Üì\\\\nPost messages back to Chat Log\\\\n## License\\\\n\\\\nMIT License - see LICENSE file for details.\\\"\\n    },\\n    \\\"requirements.txt\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"requirements.txt\\\",\\n      \\\"extension\\\": \\\".txt\\\",\\n      \\\"size\\\": 527,\\n      \\\"content\\\": \\\"# Core dependencies\\\\nopenai>=1.0.0\\\\nanthropic>=0.3.0\\\\npyyaml>=6.0\\\\nasyncio-mqtt>=0.11.0\\\\n\\\\n# Environment and configuration\\\\npython-dotenv>=1.0.0\\\\n\\\\n# Web framework and streaming\\\\nfastapi>=0.104.0\\\\nwebsockets>=11.0\\\\nuvicorn>=0.24.0\\\\n\\\\n# Data handling\\\\npydantic>=2.0.0\\\\npython-json-logger>=2.0.0\\\\n\\\\n# Testing\\\\npytest>=7.4.0\\\\npytest-asyncio>=0.21.0\\\\npytest-mock>=3.11.0\\\\n\\\\n# Utilities\\\\nclick>=8.1.0\\\\nrich>=13.0.0\\\\naiofiles>=23.0.0\\\\n\\\\n# Optional AI model providers\\\\ntransformers>=4.30.0\\\\ntorch>=2.0.0\\\\n\\\\n# Development tools\\\\nblack>=23.0.0\\\\nflake8>=6.0.0\\\\nmypy>=1.5.0\\\"\\n    },\\n    \\\"run_debate.py\\\": {\\n      \\\"type\\\": \\\"file\\\",\\n      \\\"path\\\": \\\"run_debate.py\\\",\\n      \\\"extension\\\": \\\".py\\\",\\n      \\\"size\\\": 7307,\\n      \\\"content\\\": \\\"#!/usr/bin/env python3\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\nAutonomous AI Jubilee Debate launcher with full autonomous capabilities.\\\\n\\\\\\\"\\\\\\\"\\\\\\\"\\\\n\\\\nimport asyncio\\\\nimport sys\\\\nimport os\\\\nfrom pathlib import Path\\\\n\\\\n# Add the project root to the Python path\\\\nproject_root = Path(__file__).parent\\\\nsys.path.insert(0, str(project_root))\\\\n\\\\nfrom dotenv import load_dotenv\\\\n\\\\n\\\\ndef check_environment():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Check if environment is properly set up.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    load_dotenv()\\\\n\\\\n    openai_key = os.getenv('OPENAI_API_KEY')\\\\n    anthropic_key = os.getenv('ANTHROPIC_API_KEY')\\\\n\\\\n    if not openai_key:\\\\n        print(\\\\\\\"‚ùå OPENAI_API_KEY not found in environment variables.\\\\\\\")\\\\n        print(\\\\\\\"   Please add it to your .env file:\\\\\\\")\\\\n        print(\\\\\\\"   OPENAI_API_KEY=sk-your-key-here\\\\\\\")\\\\n        return False\\\\n\\\\n    if not anthropic_key:\\\\n        print(\\\\\\\"‚ö†Ô∏è ANTHROPIC_API_KEY not found (optional)\\\\\\\")\\\\n        print(\\\\\\\"   Add it to .env file if you want to use Anthropic models:\\\\\\\")\\\\n        print(\\\\\\\"   ANTHROPIC_API_KEY=sk-ant-your-key-here\\\\\\\")\\\\n\\\\n    print(\\\\\\\"‚úÖ Environment variables loaded successfully\\\\\\\")\\\\n    return True\\\\n\\\\n\\\\nasync def run_debate_safely(web_mode=False):\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Run truly autonomous debate with AI moderator.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    try:\\\\n        # Import here to avoid import errors\\\\n        from app.moderator import Moderator\\\\n        from app.bot_client import BotClient\\\\n        from app.human_client import HumanClient\\\\n        from app.chat_log import ChatLog\\\\n        from app.voting import VotingSystem\\\\n        from app.utils import load_config\\\\n\\\\n        print(\\\\\\\"üé≠ Starting AI Jubilee Debate System...\\\\\\\")\\\\n        if web_mode:\\\\n            print(\\\\\\\"üåê WEB MODE: Starting with web interface\\\\\\\")\\\\n            print(\\\\\\\"üîó Access at: http://localhost:8080\\\\\\\")\\\\n        else:\\\\n            print(\\\\\\\"ü§ñ AUTONOMOUS MODE: All participants (including moderator) monitor and decide when to speak!\\\\\\\")\\\\n        print(\\\\\\\"=\\\\\\\" * 80)\\\\n\\\\n        print(\\\\\\\"üìã How the new system works:\\\\\\\")\\\\n        print(\\\\\\\"   ‚Ä¢ ALL participants (bots + moderator) continuously monitor the conversation\\\\\\\")\\\\n        print(\\\\\\\"   ‚Ä¢ They ALL decide independently when they feel compelled to respond\\\\\\\")\\\\n        print(\\\\\\\"   ‚Ä¢ Humans can type messages at ANY TIME during discussion\\\\\\\")\\\\n        print(\\\\\\\"   ‚Ä¢ Completely organic conversation flow - no turn-taking!\\\\\\\")\\\\n        print(\\\\\\\"   ‚Ä¢ Moderator acts like another intelligent participant\\\\\\\")\\\\n        print(\\\\\\\"   ‚Ä¢ Full conversation history available to everyone\\\\\\\")\\\\n        print(\\\\\\\"=\\\\\\\" * 80)\\\\n\\\\n        # Load configuration\\\\n        config = load_config(\\\\\\\"config.yaml\\\\\\\")\\\\n\\\\n        # Override interface mode if web_mode is requested\\\\n        if web_mode:\\\\n            config['interface'] = config.get('interface', {})\\\\n            config['interface']['mode'] = 'web'\\\\n            config['streaming'] = config.get('streaming', {})\\\\n            config['streaming']['enabled'] = True\\\\n\\\\n        # Initialize components\\\\n        chat_log = ChatLog()\\\\n        voting_system = VotingSystem(config.get('voting', {}))\\\\n\\\\n        # Create bot clients\\\\n        bot_clients = []\\\\n        bot_configs = config.get('bots', [])\\\\n\\\\n        for i, bot_config in enumerate(bot_configs):\\\\n            try:\\\\n                bot = BotClient(\\\\n                    name=bot_config['name'],\\\\n                    model=bot_config['model'],\\\\n                    provider=bot_config['provider'],\\\\n                    personality=bot_config['personality'],\\\\n                    stance=bot_config['stance'],\\\\n                    api_key=config['api_keys'].get(bot_config['provider'])\\\\n                )\\\\n                bot_clients.append(bot)\\\\n                print(f\\\\\\\"‚úÖ Created bot: {bot_config['name']} ({bot_config['stance']})\\\\\\\")\\\\n            except Exception as e:\\\\n                print(f\\\\\\\"‚ùå Failed to create bot {bot_config.get('name', 'Unknown')}: {e}\\\\\\\")\\\\n\\\\n        # Create human clients\\\\n        human_clients = []\\\\n        interface_config = config.get('interface', {})\\\\n\\\\n        try:\\\\n            human = HumanClient(\\\\n                name=\\\\\\\"Human_1\\\\\\\",\\\\n                config=interface_config\\\\n            )\\\\n            human_clients.append(human)\\\\n            print(f\\\\\\\"‚úÖ Created human client: {human.name}\\\\\\\")\\\\n        except Exception as e:\\\\n            print(f\\\\\\\"‚ùå Failed to create human client: {e}\\\\\\\")\\\\n            # Try alternative constructor\\\\n            try:\\\\n                human = HumanClient(\\\\\\\"Human_1\\\\\\\", interface_config)\\\\n                human_clients.append(human)\\\\n                print(f\\\\\\\"‚úÖ Created human client (alternative): {human.name}\\\\\\\")\\\\n            except Exception as e2:\\\\n                print(f\\\\\\\"‚ùå Alternative constructor also failed: {e2}\\\\\\\")\\\\n                return\\\\n\\\\n        # Initialize moderator with AI capabilities\\\\n        moderator = Moderator(\\\\n            topic=\\\\\\\"Remote work is the future of employment\\\\\\\",\\\\n            participants=bot_clients + human_clients,\\\\n            chat_log=chat_log,\\\\n            voting_system=voting_system,\\\\n            config=config\\\\n        )\\\\n\\\\n        print(f\\\\\\\"\\\\\\\\nüéØ Topic: Remote work is the future of employment\\\\\\\")\\\\n        print(f\\\\\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\\\\\")\\\\n        print(f\\\\\\\"üé≠ AI Moderator: {config.get('moderator', {}).get('name', 'Moderator')} (also autonomous!)\\\\\\\")\\\\n\\\\n        if web_mode:\\\\n            print(\\\\\\\"üåê Starting web interface...\\\\\\\")\\\\n            # Start streaming server if in web mode\\\\n            from app.streaming import StreamingServer\\\\n            streaming_server = StreamingServer(\\\\n                chat_log=chat_log,\\\\n                voting_system=voting_system,\\\\n                config=config.get('streaming', {})\\\\n            )\\\\n            await streaming_server.start()\\\\n\\\\n        # Run the debate\\\\n        print(f\\\\\\\"\\\\\\\\nüöÄ Starting truly autonomous debate with AI moderator!\\\\\\\")\\\\n        await moderator.run_debate()\\\\n\\\\n    except KeyboardInterrupt:\\\\n        print(\\\\\\\"\\\\\\\\n\\\\\\\\nüõë Debate interrupted by user. Goodbye!\\\\\\\")\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"\\\\\\\\n‚ùå Error during debate: {e}\\\\\\\")\\\\n        print(\\\\\\\"\\\\\\\\nDebug information:\\\\\\\")\\\\n        import traceback\\\\n        traceback.print_exc()\\\\n\\\\n\\\\ndef main():\\\\n    \\\\\\\"\\\\\\\"\\\\\\\"Main entry point.\\\\\\\"\\\\\\\"\\\\\\\"\\\\n    print(\\\\\\\"üé≠ AI Jubilee Debate System - Autonomous Mode\\\\\\\")\\\\n    print(\\\\\\\"=\\\\\\\" * 50)\\\\n\\\\n    # Check for web mode flag\\\\n    web_mode = '--web' in sys.argv\\\\n    if web_mode:\\\\n        print(\\\\\\\"üåê Web mode requested\\\\\\\")\\\\n\\\\n    # Check environment setup\\\\n    if not check_environment():\\\\n        print(\\\\\\\"\\\\\\\\nüîß Please fix the environment setup and try again.\\\\\\\")\\\\n        sys.exit(1)\\\\n\\\\n    # Check config file\\\\n    if not Path(\\\\\\\"config.yaml\\\\\\\").exists():\\\\n        print(\\\\\\\"‚ùå config.yaml not found!\\\\\\\")\\\\n        print(\\\\\\\"   Please make sure you're running from the project root directory.\\\\\\\")\\\\n        sys.exit(1)\\\\n\\\\n    # Show moderator configuration\\\\n    try:\\\\n        from app.utils import load_config\\\\n        config = load_config(\\\\\\\"config.yaml\\\\\\\")\\\\n        moderator_config = config.get('moderator', {})\\\\n        print(f\\\\\\\"\\\\\\\\nüé≠ AI Moderator Configuration:\\\\\\\")\\\\n        print(f\\\\\\\"   Name: {moderator_config.get('name', 'Moderator')}\\\\\\\")\\\\n        print(f\\\\\\\"   Model: {moderator_config.get('model', 'gpt-3.5-turbo')}\\\\\\\")\\\\n        print(f\\\\\\\"   Provider: {moderator_config.get('provider', 'openai')}\\\\\\\")\\\\n        print(f\\\\\\\"   Personality: {moderator_config.get('personality', 'Professional facilitator')[:50]}...\\\\\\\")\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"‚ö†Ô∏è Could not load moderator config: {e}\\\\\\\")\\\\n\\\\n    # Run the debate\\\\n    try:\\\\n        asyncio.run(run_debate_safely(web_mode))\\\\n    except Exception as e:\\\\n        print(f\\\\\\\"\\\\\\\\nüí• Fatal error: {e}\\\\\\\")\\\\n        sys.exit(1)\\\\n\\\\n\\\\nif __name__ == \\\\\\\"__main__\\\\\\\":\\\\n    main()\\\"\\n    }\\n  }\\n}\"\n    },\n    \"README.md\": {\n      \"type\": \"file\",\n      \"path\": \"README.md\",\n      \"extension\": \".md\",\n      \"size\": 2672,\n      \"content\": \"# AI Jubilee Debate System\\n\\nA real-time debate platform where AI bots and humans can engage in structured debates with automated moderation, voting, and live streaming capabilities.\\n\\n## Features\\n\\n- **Multi-participant debates** with AI bots and human participants\\n- **Automated moderation** with configurable rules and timeouts\\n- **Real-time voting system** with vote tallying\\n- **Shared chat log** with timestamps and message ordering\\n- **Live streaming support** via WebSocket\\n- **Configurable debate topics** and bot personalities\\n- **Extensible architecture** for adding new AI models and clients\\n\\n## Quick Start\\n\\n1. **Install dependencies:**\\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n\\n2. **Configure the system:**\\n   Edit `config.yaml` to set up your debate parameters, API keys, and bot configurations.\\n\\n3. **Run a debate session:**\\n   ```bash\\n   python -m app.main\\n   ```\\n\\n## Architecture\\n\\nThe system consists of several key components:\\n\\n- **Moderator**: Manages debate flow, enforces rules, and coordinates voting\\n- **Bot Clients**: AI-powered participants using various language models\\n- **Human Clients**: Interface for human participants (CLI/web)\\n- **Chat Log**: Centralized message queue with timestamps\\n- **Voting System**: Handles vote collection and tallying\\n- **Streaming Server**: Optional live broadcast functionality\\n\\n## Configuration\\n\\nThe `config.yaml` file allows you to customize:\\n\\n- Debate topics and formats\\n- AI bot personalities and models\\n- Timeout settings and rules\\n- Voting parameters\\n- Streaming options\\n\\n## Usage Examples\\n\\n### Starting a Standard Debate\\n```python\\nfrom app.main import start_debate_session\\nfrom app.moderator import Moderator\\n\\n# Initialize with 2 AI bots and 1 human participant\\nsession = start_debate_session(\\n    topic=\\\"The impact of AI on society\\\",\\n    ai_bots=2,\\n    human_participants=1\\n)\\n```\\n\\n### Custom Bot Configuration\\n```python\\nfrom app.bot_client import BotClient\\n\\n# Create a bot with specific personality\\nbot = BotClient(\\n    name=\\\"Philosopher\\\",\\n    model=\\\"gpt-4\\\",\\n    personality=\\\"thoughtful and analytical\\\",\\n    stance=\\\"neutral\\\"\\n)\\n```\\n\\n## Contributing\\n\\n1. Fork the repository\\n2. Create a feature branch\\n3. Add tests for new functionality\\n4. Run the test suite: `python -m pytest tests/`\\n5. Submit a pull request\\n\\n## Documentation\\n\\n- [Architecture Details](docs/architecture.md)\\n- [Usage Guide](docs/usage.md)\\n- [API Reference](docs/api_reference.md)\\n\\n## Arhitecture :\\nChat Log ‚Üê All Participants Monitor This\\n    ‚Üì\\n[Bot1] [Bot2] [Bot3] [Moderator Bot] [Human] \\n    ‚Üì\\nAll decide independently when to speak\\n    ‚Üì\\nPost messages back to Chat Log\\n## License\\n\\nMIT License - see LICENSE file for details.\"\n    },\n    \"requirements.txt\": {\n      \"type\": \"file\",\n      \"path\": \"requirements.txt\",\n      \"extension\": \".txt\",\n      \"size\": 527,\n      \"content\": \"# Core dependencies\\nopenai>=1.0.0\\nanthropic>=0.3.0\\npyyaml>=6.0\\nasyncio-mqtt>=0.11.0\\n\\n# Environment and configuration\\npython-dotenv>=1.0.0\\n\\n# Web framework and streaming\\nfastapi>=0.104.0\\nwebsockets>=11.0\\nuvicorn>=0.24.0\\n\\n# Data handling\\npydantic>=2.0.0\\npython-json-logger>=2.0.0\\n\\n# Testing\\npytest>=7.4.0\\npytest-asyncio>=0.21.0\\npytest-mock>=3.11.0\\n\\n# Utilities\\nclick>=8.1.0\\nrich>=13.0.0\\naiofiles>=23.0.0\\n\\n# Optional AI model providers\\ntransformers>=4.30.0\\ntorch>=2.0.0\\n\\n# Development tools\\nblack>=23.0.0\\nflake8>=6.0.0\\nmypy>=1.5.0\"\n    },\n    \"run_debate.py\": {\n      \"type\": \"file\",\n      \"path\": \"run_debate.py\",\n      \"extension\": \".py\",\n      \"size\": 7364,\n      \"content\": \"#!/usr/bin/env python3\\n\\\"\\\"\\\"\\nAutonomous AI Jubilee Debate launcher with full autonomous capabilities.\\n\\\"\\\"\\\"\\n\\nimport asyncio\\nimport sys\\nimport os\\nfrom pathlib import Path\\n\\n# Add the project root to the Python path\\nproject_root = Path(__file__).parent\\nsys.path.insert(0, str(project_root))\\n\\nfrom dotenv import load_dotenv\\n\\n\\ndef check_environment():\\n    \\\"\\\"\\\"Check if environment is properly set up.\\\"\\\"\\\"\\n    load_dotenv()\\n\\n    openai_key = os.getenv('OPENAI_API_KEY')\\n    anthropic_key = os.getenv('ANTHROPIC_API_KEY')\\n\\n    if not openai_key:\\n        print(\\\"‚ùå OPENAI_API_KEY not found in environment variables.\\\")\\n        print(\\\"   Please add it to your .env file:\\\")\\n        print(\\\"   OPENAI_API_KEY=sk-your-key-here\\\")\\n        return False\\n\\n    if not anthropic_key:\\n        print(\\\"‚ö†Ô∏è ANTHROPIC_API_KEY not found (optional)\\\")\\n        print(\\\"   Add it to .env file if you want to use Anthropic models:\\\")\\n        print(\\\"   ANTHROPIC_API_KEY=sk-ant-your-key-here\\\")\\n\\n    print(\\\"‚úÖ Environment variables loaded successfully\\\")\\n    return True\\n\\n\\nasync def run_debate_safely(web_mode=False):\\n    \\\"\\\"\\\"Run truly autonomous debate with AI moderator.\\\"\\\"\\\"\\n    try:\\n        # Import here to avoid import errors\\n        from app.moderator import Moderator\\n        from app.bot_client import BotClient\\n        from app.human_client import HumanClient\\n        from app.chat_log import ChatLog\\n        from app.voting import VotingSystem\\n        from app.utils import load_config\\n\\n        print(\\\"üé≠ Starting AI Jubilee Debate System...\\\")\\n        if web_mode:\\n            print(\\\"üåê WEB MODE: Starting with web interface\\\")\\n            print(\\\"üîó Access at: http://localhost:8080\\\")\\n        else:\\n            print(\\\"ü§ñ AUTONOMOUS MODE: All participants (including moderator) monitor and decide when to speak!\\\")\\n        print(\\\"=\\\" * 80)\\n\\n        print(\\\"üìã How the new system works:\\\")\\n        print(\\\"   ‚Ä¢ ALL participants (bots + moderator) continuously monitor the conversation\\\")\\n        print(\\\"   ‚Ä¢ They ALL decide independently when they feel compelled to respond\\\")\\n        print(\\\"   ‚Ä¢ Humans can type messages at ANY TIME during discussion\\\")\\n        print(\\\"   ‚Ä¢ Completely organic conversation flow - no turn-taking!\\\")\\n        print(\\\"   ‚Ä¢ Moderator acts like another intelligent participant\\\")\\n        print(\\\"   ‚Ä¢ Full conversation history available to everyone\\\")\\n        print(\\\"=\\\" * 80)\\n\\n        # Load configuration\\n        config = load_config(\\\"config.yaml\\\")\\n\\n        # Override interface mode if web_mode is requested\\n        if web_mode:\\n            config['interface'] = config.get('interface', {})\\n            config['interface']['mode'] = 'web'\\n            config['streaming'] = config.get('streaming', {})\\n            config['streaming']['enabled'] = True\\n\\n        # Initialize components\\n        chat_log = ChatLog()\\n        voting_system = VotingSystem(config.get('voting', {}))\\n\\n        # Create bot clients\\n        bot_clients = []\\n        bot_configs = config.get('bots', [])\\n\\n        for i, bot_config in enumerate(bot_configs):\\n            try:\\n                bot = BotClient(\\n                    name=bot_config['name'],\\n                    model=bot_config['model'],\\n                    provider=bot_config['provider'],\\n                    personality=bot_config['personality'],\\n                    stance=bot_config['stance'],\\n                    api_key=config['api_keys'].get(bot_config['provider']),\\n                    max_tokens=bot_config['max_tokens']\\n                )\\n                bot_clients.append(bot)\\n                print(f\\\"‚úÖ Created bot: {bot_config['name']} ({bot_config['stance']})\\\")\\n            except Exception as e:\\n                print(f\\\"‚ùå Failed to create bot {bot_config.get('name', 'Unknown')}: {e}\\\")\\n\\n        # Create human clients\\n        human_clients = []\\n        interface_config = config.get('interface', {})\\n\\n        try:\\n            human = HumanClient(\\n                name=\\\"Human_1\\\",\\n                config=interface_config\\n            )\\n            human_clients.append(human)\\n            print(f\\\"‚úÖ Created human client: {human.name}\\\")\\n        except Exception as e:\\n            print(f\\\"‚ùå Failed to create human client: {e}\\\")\\n            # Try alternative constructor\\n            try:\\n                human = HumanClient(\\\"Human_1\\\", interface_config)\\n                human_clients.append(human)\\n                print(f\\\"‚úÖ Created human client (alternative): {human.name}\\\")\\n            except Exception as e2:\\n                print(f\\\"‚ùå Alternative constructor also failed: {e2}\\\")\\n                return\\n\\n        # Initialize moderator with AI capabilities\\n        moderator = Moderator(\\n            topic=\\\"Remote work is the future of employment\\\",\\n            participants=bot_clients + human_clients,\\n            chat_log=chat_log,\\n            voting_system=voting_system,\\n            config=config\\n        )\\n\\n        print(f\\\"\\\\nüéØ Topic: Remote work is the future of employment\\\")\\n        print(f\\\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\\\")\\n        print(f\\\"üé≠ AI Moderator: {config.get('moderator', {}).get('name', 'Moderator')} (also autonomous!)\\\")\\n\\n        if web_mode:\\n            print(\\\"üåê Starting web interface...\\\")\\n            # Start streaming server if in web mode\\n            from app.streaming import StreamingServer\\n            streaming_server = StreamingServer(\\n                chat_log=chat_log,\\n                voting_system=voting_system,\\n                config=config.get('streaming', {})\\n            )\\n            await streaming_server.start()\\n\\n        # Run the debate\\n        print(f\\\"\\\\nüöÄ Starting truly autonomous debate with AI moderator!\\\")\\n        await moderator.run_debate()\\n\\n    except KeyboardInterrupt:\\n        print(\\\"\\\\n\\\\nüõë Debate interrupted by user. Goodbye!\\\")\\n    except Exception as e:\\n        print(f\\\"\\\\n‚ùå Error during debate: {e}\\\")\\n        print(\\\"\\\\nDebug information:\\\")\\n        import traceback\\n        traceback.print_exc()\\n\\n\\ndef main():\\n    \\\"\\\"\\\"Main entry point.\\\"\\\"\\\"\\n    print(\\\"üé≠ AI Jubilee Debate System - Autonomous Mode\\\")\\n    print(\\\"=\\\" * 50)\\n\\n    # Check for web mode flag\\n    web_mode = '--web' in sys.argv\\n    if web_mode:\\n        print(\\\"üåê Web mode requested\\\")\\n\\n    # Check environment setup\\n    if not check_environment():\\n        print(\\\"\\\\nüîß Please fix the environment setup and try again.\\\")\\n        sys.exit(1)\\n\\n    # Check config file\\n    if not Path(\\\"config.yaml\\\").exists():\\n        print(\\\"‚ùå config.yaml not found!\\\")\\n        print(\\\"   Please make sure you're running from the project root directory.\\\")\\n        sys.exit(1)\\n\\n    # Show moderator configuration\\n    try:\\n        from app.utils import load_config\\n        config = load_config(\\\"config.yaml\\\")\\n        moderator_config = config.get('moderator', {})\\n        print(f\\\"\\\\nüé≠ AI Moderator Configuration:\\\")\\n        print(f\\\"   Name: {moderator_config.get('name', 'Moderator')}\\\")\\n        print(f\\\"   Model: {moderator_config.get('model', 'gpt-3.5-turbo')}\\\")\\n        print(f\\\"   Provider: {moderator_config.get('provider', 'openai')}\\\")\\n        print(f\\\"   Personality: {moderator_config.get('personality', 'Professional facilitator')[:50]}...\\\")\\n    except Exception as e:\\n        print(f\\\"‚ö†Ô∏è Could not load moderator config: {e}\\\")\\n\\n    # Run the debate\\n    try:\\n        asyncio.run(run_debate_safely(web_mode))\\n    except Exception as e:\\n        print(f\\\"\\\\nüí• Fatal error: {e}\\\")\\n        sys.exit(1)\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\"\n    }\n  }\n}"
    },
    "README.md": {
      "type": "file",
      "path": "README.md",
      "extension": ".md",
      "size": 2672,
      "content": "# AI Jubilee Debate System\n\nA real-time debate platform where AI bots and humans can engage in structured debates with automated moderation, voting, and live streaming capabilities.\n\n## Features\n\n- **Multi-participant debates** with AI bots and human participants\n- **Automated moderation** with configurable rules and timeouts\n- **Real-time voting system** with vote tallying\n- **Shared chat log** with timestamps and message ordering\n- **Live streaming support** via WebSocket\n- **Configurable debate topics** and bot personalities\n- **Extensible architecture** for adding new AI models and clients\n\n## Quick Start\n\n1. **Install dependencies:**\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n2. **Configure the system:**\n   Edit `config.yaml` to set up your debate parameters, API keys, and bot configurations.\n\n3. **Run a debate session:**\n   ```bash\n   python -m app.main\n   ```\n\n## Architecture\n\nThe system consists of several key components:\n\n- **Moderator**: Manages debate flow, enforces rules, and coordinates voting\n- **Bot Clients**: AI-powered participants using various language models\n- **Human Clients**: Interface for human participants (CLI/web)\n- **Chat Log**: Centralized message queue with timestamps\n- **Voting System**: Handles vote collection and tallying\n- **Streaming Server**: Optional live broadcast functionality\n\n## Configuration\n\nThe `config.yaml` file allows you to customize:\n\n- Debate topics and formats\n- AI bot personalities and models\n- Timeout settings and rules\n- Voting parameters\n- Streaming options\n\n## Usage Examples\n\n### Starting a Standard Debate\n```python\nfrom app.main import start_debate_session\nfrom app.moderator import Moderator\n\n# Initialize with 2 AI bots and 1 human participant\nsession = start_debate_session(\n    topic=\"The impact of AI on society\",\n    ai_bots=2,\n    human_participants=1\n)\n```\n\n### Custom Bot Configuration\n```python\nfrom app.bot_client import BotClient\n\n# Create a bot with specific personality\nbot = BotClient(\n    name=\"Philosopher\",\n    model=\"gpt-4\",\n    personality=\"thoughtful and analytical\",\n    stance=\"neutral\"\n)\n```\n\n## Contributing\n\n1. Fork the repository\n2. Create a feature branch\n3. Add tests for new functionality\n4. Run the test suite: `python -m pytest tests/`\n5. Submit a pull request\n\n## Documentation\n\n- [Architecture Details](docs/architecture.md)\n- [Usage Guide](docs/usage.md)\n- [API Reference](docs/api_reference.md)\n\n## Arhitecture :\nChat Log ‚Üê All Participants Monitor This\n    ‚Üì\n[Bot1] [Bot2] [Bot3] [Moderator Bot] [Human] \n    ‚Üì\nAll decide independently when to speak\n    ‚Üì\nPost messages back to Chat Log\n## License\n\nMIT License - see LICENSE file for details."
    },
    "requirements.txt": {
      "type": "file",
      "path": "requirements.txt",
      "extension": ".txt",
      "size": 544,
      "content": "# Core dependencies\nopenai>=1.0.0\nanthropic>=0.3.0\npyyaml>=6.0\nasyncio-mqtt>=0.11.0\n\n# Environment and configuration\npython-dotenv>=1.0.0\n\n# Web framework and streaming\nfastapi>=0.104.0\nwebsockets>=11.0\nuvicorn>=0.24.0\n\n# Data handling\npydantic>=2.0.0\npython-json-logger>=2.0.0\n\n# Testing\npytest>=7.4.0\npytest-asyncio>=0.21.0\npytest-mock>=3.11.0\n\n# Utilities\nclick>=8.1.0\nrich>=13.0.0\naiofiles>=23.0.0\n\n# Optional AI model providers\ntransformers>=4.30.0\ntorch>=2.0.0\n\n# Development tools\nblack>=23.0.0\nflake8>=6.0.0\nmypy>=1.5.0\n\n#Web\nwebsockets"
    },
    "run_debate.py": {
      "type": "file",
      "path": "run_debate.py",
      "extension": ".py",
      "size": 7364,
      "content": "#!/usr/bin/env python3\n\"\"\"\nAutonomous AI Jubilee Debate launcher with full autonomous capabilities.\n\"\"\"\n\nimport asyncio\nimport sys\nimport os\nfrom pathlib import Path\n\n# Add the project root to the Python path\nproject_root = Path(__file__).parent\nsys.path.insert(0, str(project_root))\n\nfrom dotenv import load_dotenv\n\n\ndef check_environment():\n    \"\"\"Check if environment is properly set up.\"\"\"\n    load_dotenv()\n\n    openai_key = os.getenv('OPENAI_API_KEY')\n    anthropic_key = os.getenv('ANTHROPIC_API_KEY')\n\n    if not openai_key:\n        print(\"‚ùå OPENAI_API_KEY not found in environment variables.\")\n        print(\"   Please add it to your .env file:\")\n        print(\"   OPENAI_API_KEY=sk-your-key-here\")\n        return False\n\n    if not anthropic_key:\n        print(\"‚ö†Ô∏è ANTHROPIC_API_KEY not found (optional)\")\n        print(\"   Add it to .env file if you want to use Anthropic models:\")\n        print(\"   ANTHROPIC_API_KEY=sk-ant-your-key-here\")\n\n    print(\"‚úÖ Environment variables loaded successfully\")\n    return True\n\n\nasync def run_debate_safely(web_mode=False):\n    \"\"\"Run truly autonomous debate with AI moderator.\"\"\"\n    try:\n        # Import here to avoid import errors\n        from app.moderator import Moderator\n        from app.bot_client import BotClient\n        from app.human_client import HumanClient\n        from app.chat_log import ChatLog\n        from app.voting import VotingSystem\n        from app.utils import load_config\n\n        print(\"üé≠ Starting AI Jubilee Debate System...\")\n        if web_mode:\n            print(\"üåê WEB MODE: Starting with web interface\")\n            print(\"üîó Access at: http://localhost:8080\")\n        else:\n            print(\"ü§ñ AUTONOMOUS MODE: All participants (including moderator) monitor and decide when to speak!\")\n        print(\"=\" * 80)\n\n        print(\"üìã How the new system works:\")\n        print(\"   ‚Ä¢ ALL participants (bots + moderator) continuously monitor the conversation\")\n        print(\"   ‚Ä¢ They ALL decide independently when they feel compelled to respond\")\n        print(\"   ‚Ä¢ Humans can type messages at ANY TIME during discussion\")\n        print(\"   ‚Ä¢ Completely organic conversation flow - no turn-taking!\")\n        print(\"   ‚Ä¢ Moderator acts like another intelligent participant\")\n        print(\"   ‚Ä¢ Full conversation history available to everyone\")\n        print(\"=\" * 80)\n\n        # Load configuration\n        config = load_config(\"config.yaml\")\n\n        # Override interface mode if web_mode is requested\n        if web_mode:\n            config['interface'] = config.get('interface', {})\n            config['interface']['mode'] = 'web'\n            config['streaming'] = config.get('streaming', {})\n            config['streaming']['enabled'] = True\n\n        # Initialize components\n        chat_log = ChatLog()\n        voting_system = VotingSystem(config.get('voting', {}))\n\n        # Create bot clients\n        bot_clients = []\n        bot_configs = config.get('bots', [])\n\n        for i, bot_config in enumerate(bot_configs):\n            try:\n                bot = BotClient(\n                    name=bot_config['name'],\n                    model=bot_config['model'],\n                    provider=bot_config['provider'],\n                    personality=bot_config['personality'],\n                    stance=bot_config['stance'],\n                    api_key=config['api_keys'].get(bot_config['provider']),\n                    max_tokens=bot_config['max_tokens']\n                )\n                bot_clients.append(bot)\n                print(f\"‚úÖ Created bot: {bot_config['name']} ({bot_config['stance']})\")\n            except Exception as e:\n                print(f\"‚ùå Failed to create bot {bot_config.get('name', 'Unknown')}: {e}\")\n\n        # Create human clients\n        human_clients = []\n        interface_config = config.get('interface', {})\n\n        try:\n            human = HumanClient(\n                name=\"Human_1\",\n                config=interface_config\n            )\n            human_clients.append(human)\n            print(f\"‚úÖ Created human client: {human.name}\")\n        except Exception as e:\n            print(f\"‚ùå Failed to create human client: {e}\")\n            # Try alternative constructor\n            try:\n                human = HumanClient(\"Human_1\", interface_config)\n                human_clients.append(human)\n                print(f\"‚úÖ Created human client (alternative): {human.name}\")\n            except Exception as e2:\n                print(f\"‚ùå Alternative constructor also failed: {e2}\")\n                return\n\n        # Initialize moderator with AI capabilities\n        moderator = Moderator(\n            topic=\"Remote work is the future of employment\",\n            participants=bot_clients + human_clients,\n            chat_log=chat_log,\n            voting_system=voting_system,\n            config=config\n        )\n\n        print(f\"\\nüéØ Topic: Remote work is the future of employment\")\n        print(f\"üë• Participants: {len(bot_clients)} AI bots, {len(human_clients)} humans\")\n        print(f\"üé≠ AI Moderator: {config.get('moderator', {}).get('name', 'Moderator')} (also autonomous!)\")\n\n        if web_mode:\n            print(\"üåê Starting web interface...\")\n            # Start streaming server if in web mode\n            from app.streaming import StreamingServer\n            streaming_server = StreamingServer(\n                chat_log=chat_log,\n                voting_system=voting_system,\n                config=config.get('streaming', {})\n            )\n            await streaming_server.start()\n\n        # Run the debate\n        print(f\"\\nüöÄ Starting truly autonomous debate with AI moderator!\")\n        await moderator.run_debate()\n\n    except KeyboardInterrupt:\n        print(\"\\n\\nüõë Debate interrupted by user. Goodbye!\")\n    except Exception as e:\n        print(f\"\\n‚ùå Error during debate: {e}\")\n        print(\"\\nDebug information:\")\n        import traceback\n        traceback.print_exc()\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    print(\"üé≠ AI Jubilee Debate System - Autonomous Mode\")\n    print(\"=\" * 50)\n\n    # Check for web mode flag\n    web_mode = '--web' in sys.argv\n    if web_mode:\n        print(\"üåê Web mode requested\")\n\n    # Check environment setup\n    if not check_environment():\n        print(\"\\nüîß Please fix the environment setup and try again.\")\n        sys.exit(1)\n\n    # Check config file\n    if not Path(\"config.yaml\").exists():\n        print(\"‚ùå config.yaml not found!\")\n        print(\"   Please make sure you're running from the project root directory.\")\n        sys.exit(1)\n\n    # Show moderator configuration\n    try:\n        from app.utils import load_config\n        config = load_config(\"config.yaml\")\n        moderator_config = config.get('moderator', {})\n        print(f\"\\nüé≠ AI Moderator Configuration:\")\n        print(f\"   Name: {moderator_config.get('name', 'Moderator')}\")\n        print(f\"   Model: {moderator_config.get('model', 'gpt-3.5-turbo')}\")\n        print(f\"   Provider: {moderator_config.get('provider', 'openai')}\")\n        print(f\"   Personality: {moderator_config.get('personality', 'Professional facilitator')[:50]}...\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Could not load moderator config: {e}\")\n\n    # Run the debate\n    try:\n        asyncio.run(run_debate_safely(web_mode))\n    except Exception as e:\n        print(f\"\\nüí• Fatal error: {e}\")\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    main()"
    },
    "run_web_debate.py": {
      "type": "file",
      "path": "run_web_debate.py",
      "extension": ".py",
      "size": 4770,
      "content": "#!/usr/bin/env python3\n\"\"\"\nSimple web runner that integrates your existing system with the web interface.\nFixed version with proper participant information handling.\n\"\"\"\n\nimport asyncio\nimport threading\nimport http.server\nimport socketserver\nfrom pathlib import Path\nimport sys\nimport os\n\n# Add current directory to path\nsys.path.append(os.path.dirname(os.path.abspath(__file__)))\n\n# Import your existing components\nfrom app.web_server import DebateWebServer  # Your existing web server\nfrom app.utils import load_config\nfrom app.moderator import Moderator\nfrom app.chat_log import ChatLog\nfrom app.voting import VotingSystem\nfrom app.bot_client import BotClient\nfrom app.human_client import HumanClient\n\n\ndef serve_html():\n    \"\"\"Serve the HTML interface on port 8080.\"\"\"\n    PORT = 8080\n    web_dir = Path(\"web\")\n\n    if not web_dir.exists():\n        print(f\"‚ùå Web directory not found: {web_dir}\")\n        return\n\n    class WebHandler(http.server.SimpleHTTPRequestHandler):\n        def __init__(self, *args, **kwargs):\n            super().__init__(*args, directory=str(web_dir), **kwargs)\n\n        def log_message(self, format, *args):\n            # Suppress HTTP server logs\n            pass\n\n    try:\n        with socketserver.TCPServer((\"\", PORT), WebHandler) as httpd:\n            print(f\"üåê Web interface running at: http://localhost:{PORT}\")\n            httpd.serve_forever()\n    except OSError as e:\n        print(f\"‚ö†Ô∏è Port {PORT} in use. Web interface may already be running.\")\n\n\nasync def run_web_debate():\n    \"\"\"Run debate with web interface using your existing system.\"\"\"\n\n    print(\"üé≠ AI Jubilee Debate - Web Edition\")\n    print(\"=\" * 50)\n\n    # Start HTML server in background\n    html_thread = threading.Thread(target=serve_html, daemon=True)\n    html_thread.start()\n\n    # Load your existing config\n    print(\"üìã Loading configuration...\")\n    try:\n        config = load_config()\n    except Exception as e:\n        print(f\"‚ùå Failed to load config: {e}\")\n        return\n\n    # Create WebSocket server (your existing one)\n    print(\"üîó Starting WebSocket server...\")\n    web_server = DebateWebServer()\n    try:\n        await web_server.start_server()\n    except Exception as e:\n        print(f\"‚ùå Failed to start WebSocket: {e}\")\n        return\n\n    # Create your existing components\n    print(\"üöÄ Setting up debate components...\")\n\n    # Chat log with web integration\n    chat_log = ChatLog()\n    chat_log.set_web_server(web_server)  # Connect to web server\n\n    # Voting system\n    voting_config = config.get('voting', {})\n    voting_system = VotingSystem(voting_config)\n\n    # Create bots using your existing system\n    participants = []\n\n    # Get API keys - handle missing api_keys section gracefully\n    api_keys = config.get('api_keys', {})\n    if not api_keys:\n        # Fallback to environment variables\n        api_keys = {\n            'openai': os.getenv('OPENAI_API_KEY'),\n            'anthropic': os.getenv('ANTHROPIC_API_KEY')\n        }\n\n    # Load bots from config\n    for bot_config in config.get('bots', []):\n        try:\n            provider = bot_config['provider']\n            api_key = api_keys.get(provider)\n            if not api_key:\n                print(f\"‚ö†Ô∏è No API key for {provider}, skipping {bot_config['name']}\")\n                continue\n\n            bot = BotClient(\n                name=bot_config['name'],\n                model=bot_config['model'],\n                provider=provider,\n                personality=bot_config['personality'],\n                stance=bot_config['stance'],\n                api_key=api_key,\n                temperature=bot_config.get('temperature', 0.8),\n                max_tokens=bot_config.get('max_tokens', 120)\n            )\n            participants.append(bot)\n            print(f\"‚úÖ Created bot: {bot.name} ({bot.config.stance}, {bot.config.personality[:30]}...)\")\n\n        except Exception as e:\n            print(f\"‚ùå Failed to create bot {bot_config['name']}: {e}\")\n\n    # Add human participant\n    human_config = config.get('interface', {})\n    human = HumanClient(\"Human_1\", human_config)\n    participants.append(human)\n    print(f\"‚úÖ Created human participant: {human.name}\")\n\n    # Pass participant information to web server BEFORE creating moderator\n    web_server.set_participants(participants)\n\n    # Broadcast initial participant info\n    await web_server.broadcast_participants_update()\n\n    # Create moderator\n    topic = config['debate'].get('default_topic', 'Remote work is the future of employment')\n\n    # Handle moderator configuration properly\n    moderator_config = config.get('debate', {})\n    moderator = Moderator(\n        topic=topic,\n        participants=participants,\n        chat_log=chat_log,\n        voting_system=voting_system,\n        config=moderator_config\n    )"
    }
  }
}